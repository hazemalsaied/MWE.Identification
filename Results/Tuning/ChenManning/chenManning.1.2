Using Theano backend.
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,32             ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
True           ,relu           ,0.5            ,200            ,False          ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
45             ,1e-07          ,0.014          ,0.01           ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,50             ,True           ,True           ,50             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,
__________________________________________________________________________________________________
300            ,True           ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, False, True, False, 1, 1, 32, True, relu, 0.5, 200, False, 45, 1e-07, 0.014, 0.01, val_loss, 4, 50, True, True, 50, 300, True
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (16h:52)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of valid (projective) examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 18)           0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 18)           0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 18, 300)      12666000    input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 18, 50)       1000        input_2[0][0]                    
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 12, 50)       2550        input_3[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 5400)         0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 900)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 600)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 6900)         0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
                                                                 flatten_3[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 200)          1380200     concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 200)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 200)          0           activation_2[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 3)            603         dropout_1[0][0]                  
==================================================================================================
Total params: 14,050,353
Trainable params: 14,050,353
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 449500 samples, validate on 299668 samples
Epoch 1/100
 - 159s - loss: 8.0587 - acc: 0.5000 - val_loss: 8.0591 - val_acc: 0.5000
Epoch 2/100
 - 159s - loss: 8.0591 - acc: 0.5000 - val_loss: 8.0591 - val_acc: 0.5000
Epoch 3/100
 - 159s - loss: 8.0592 - acc: 0.5000 - val_loss: 8.0591 - val_acc: 0.5000
Epoch 4/100
 - 155s - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0591 - val_acc: 0.5000
Epoch 5/100
 - 155s - loss: 8.0591 - acc: 0.5000 - val_loss: 8.0591 - val_acc: 0.5000
Epoch 6/100
 - 155s - loss: 8.0591 - acc: 0.5000 - val_loss: 8.0591 - val_acc: 0.5000
Epoch 00006: early stopping
 Number of training examples : 17225
 Number of valid (projective) examples : 2089
Dep Parsing accuracy = 50.0
Loss = 8.059, 
	XP Ends: 1/7 (17 h:16)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
