*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: NON.COMPO
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, lemma, compactVocab, favorisationCoeff, focused, importantSentences, importantTransitions, overSampling, sampleWeight, bPadding, batchSize, chickPoint, compactVocab, dense1, dense1Activation, dense1Dropout, dense1UnitNumber, dense2, dense2Activation, dense2Dropout, dense2UnitNumber, earlyStop, epochs, features, inputItems, lemma, loss, lr, minDelta, optimizer, posEmb, predictVerbose, s0Padding, s1Padding, tokenEmb, trainable, validationSplit, verbose
==================================================================================================
# Configs: NonCompo, sharedtask2, fixedSize, True, False, 6, True, True, False, True, True, 2, 64, False, False, True, relu, 0.43, 60, False, relu, 0, 0, True, 40, False, 4, True, categorical_crossentropy, 0.059, 0.2, adagrad, 42, False, 5, 5, 480, True, 0.1, 0
==================================================================================================
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================
	Train deformed lemmas: 41

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57%
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 520785
==================================================================================================
Train data = 181825, Train data = 623847,
==================================================================================================
	Training time : 0:07:24.964305
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545
# Parameters = 3753568
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_7 (InputLayer)            (None, 4)            0
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 480)       3621600     input_7[0][0]
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 42)        6384        input_8[0][0]
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 1920)         0           embedding_7[0][0]
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 168)          0           embedding_8[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 2088)         0           flatten_7[0][0]
                                                                 flatten_8[0][0]
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 60)           125340      concatenate_4[0][0]
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 60)           0           dense_7[0][0]
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4)            244         dropout_4[0][0]
==================================================================================================
Total params: 3,753,568
Trainable params: 3,753,568
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 338417
	data size after focused sampling = 338417
	data size before sampling = 338417
	data size after sampling = 580172
	4 Labels in train : Counter({0: 145043, 1: 145043, 2: 145043, 3: 145043})
	4 Labels in valid : Counter({0: 14651, 2: 14578, 1: 14436, 3: 14353})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 522154 samples, validate on 58018 samples
Epoch 1/40
 - 14s - loss: 0.1089 - acc: 0.9794 - val_loss: 0.0702 - val_acc: 0.9863
Epoch 2/40
 - 14s - loss: 0.0696 - acc: 0.9865 - val_loss: 0.0694 - val_acc: 0.9872
Epoch 3/40
 - 14s - loss: 0.0646 - acc: 0.9872 - val_loss: 0.0685 - val_acc: 0.9873

==================================================================================================
	Training time : 0:01:00.360608
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:55.416355
==================================================================================================
	Identification : 0.614
	P, R  : 0.763, 0.513

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================
	Train deformed lemmas: 23

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62%
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 424242
==================================================================================================
Train data = 123224, Train data = 362052,
==================================================================================================
	Training time : 0:02:19.426873
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7218
# Parameters = 3597322
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_9 (InputLayer)            (None, 4)            0
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 480)       3464640     input_9[0][0]
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 42)        7098        input_10[0][0]
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 1920)         0           embedding_9[0][0]
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 168)          0           embedding_10[0][0]
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 2088)         0           flatten_9[0][0]
                                                                 flatten_10[0][0]
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 60)           125340      concatenate_5[0][0]
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 60)           0           dense_9[0][0]
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 4)            244         dropout_5[0][0]
==================================================================================================
Total params: 3,597,322
Trainable params: 3,597,322
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 287218
	data size after focused sampling = 287218
	data size before sampling = 287218
	data size after sampling = 475396
	4 Labels in train : Counter({0: 118849, 1: 118849, 2: 118849, 3: 118849})
	4 Labels in valid : Counter({3: 12069, 0: 11879, 1: 11804, 2: 11788})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 427856 samples, validate on 47540 samples
Epoch 1/40
 - 12s - loss: 0.1249 - acc: 0.9769 - val_loss: 0.0820 - val_acc: 0.9850
Epoch 2/40
 - 12s - loss: 0.0818 - acc: 0.9852 - val_loss: 0.0772 - val_acc: 0.9859
Epoch 3/40
 - 11s - loss: 0.0761 - acc: 0.9862 - val_loss: 0.0772 - val_acc: 0.9860

==================================================================================================
	Training time : 0:00:48.041498
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:01:21.251636
==================================================================================================
	Identification : 0.662
	P, R  : 0.779, 0.575

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================
	Train deformed lemmas: 31277
	Train important deformed Lemmas: 3223

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 48.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 31%
	Recognizable MWEs: 100.0 %

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 763810
==================================================================================================
Train data = 245118, Train data = 600620,
==================================================================================================
	Training time : 0:04:32.692187
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 10506
	After : 8665
# Parameters = 4289362
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_11 (InputLayer)           (None, 4)            0
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 480)       4159200     input_11[0][0]
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 42)        4578        input_12[0][0]
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 1920)         0           embedding_11[0][0]
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 168)          0           embedding_12[0][0]
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 2088)         0           flatten_11[0][0]
                                                                 flatten_12[0][0]
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 60)           125340      concatenate_6[0][0]
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 60)           0           dense_11[0][0]
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 4)            244         dropout_6[0][0]
==================================================================================================
Total params: 4,289,362
Trainable params: 4,289,362
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 434708
	data size after focused sampling = 434708
	data size before sampling = 434708
	data size after sampling = 743072
	4 Labels in train : Counter({0: 185768, 1: 185768, 2: 185768, 3: 185768})
	4 Labels in valid : Counter({0: 18630, 2: 18613, 1: 18539, 3: 18526})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 668764 samples, validate on 74308 samples
Epoch 1/40
 - 18s - loss: 0.1102 - acc: 0.9762 - val_loss: 0.0753 - val_acc: 0.9835
Epoch 2/40
 - 18s - loss: 0.0762 - acc: 0.9835 - val_loss: 0.0749 - val_acc: 0.9842
Epoch 3/40
 - 18s - loss: 0.0716 - acc: 0.9844 - val_loss: 0.0738 - val_acc: 0.9849

==================================================================================================
	Training time : 0:01:15.954534
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:36.276332
==================================================================================================
	Identification : 0.544
	P, R  : 0.594, 0.502

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
