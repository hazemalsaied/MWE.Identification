Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_godHzI.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 3841/4043 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX 980 (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,126            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.083          ,50             ,12             ,25             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
5              ,50             ,False          ,False          ,159            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 126, True, 0.083, 50, 12, 25, 5, 50, False, False, 159
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (13h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       285950      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1824        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 50)        571900      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 5)         760         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 37)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 150)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 15)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 159)          93969       concatenate_1[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 165)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 324)          0           phraseRnn[0][0]                  
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 126)          40950       concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            508         dense_1[0][0]                    
==================================================================================================
Total params: 995,861
Trainable params: 995,861
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 134s - loss: 0.3763 - acc: 0.9614 - val_loss: 0.0640 - val_acc: 0.9837
Epoch 2/40
 - 135s - loss: 0.0566 - acc: 0.9855 - val_loss: 0.0593 - val_acc: 0.9849
Epoch 3/40
 - 134s - loss: 0.0519 - acc: 0.9870 - val_loss: 0.0608 - val_acc: 0.9846
Epoch 4/40
 - 141s - loss: 0.0500 - acc: 0.9876 - val_loss: 0.0607 - val_acc: 0.9849
Epoch 5/40
 - 134s - loss: 0.0486 - acc: 0.9879 - val_loss: 0.0648 - val_acc: 0.9848
Epoch 00005: early stopping
	TRAINING TIME: 12.22 minutes 
==================================================================================================
	PARSING TIME: 4.1 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.778, 0.361

==================================================================================================
	XP Ends: 1/7 (13 h:59)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (13h:59)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       235025      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       2028        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 50)        470050      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 5)         845         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 50, 37)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 150)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 15)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 159)          93969       concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 165)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 324)          0           phraseRnn[0][0]                  
                                                                 concatenate_5[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 126)          40950       concatenate_6[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            508         dense_3[0][0]                    
==================================================================================================
Total params: 843,375
Trainable params: 843,375
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 96s - loss: 12.0928 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 2/40
 - 97s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 3/40
 - 92s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 4/40
 - 92s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 5/40
 - 92s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 00005: early stopping
	TRAINING TIME: 8.27 minutes 
==================================================================================================
	PARSING TIME: 16.77 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.047

==================================================================================================
	XP Ends: 1/7 (14 h:24)
==================================================================================================
/home/halsaied/miniconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.py:399: UserWarning: The graph doesn't contain a node that depends on the root element.
  "The graph doesn't contain a node " "that depends on the root element."
# Seed: 0
==================================================================================================
XP Starts: 1/7 (14h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       551775      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1308        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 50)        1103550     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 5)         545         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 50, 37)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 150)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 15)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 159)          93969       concatenate_7[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 165)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 324)          0           phraseRnn[0][0]                  
                                                                 concatenate_8[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 126)          40950       concatenate_9[0][0]              
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            508         dense_5[0][0]                    
==================================================================================================
Total params: 1,792,605
Trainable params: 1,792,605
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 189s - loss: 0.0849 - acc: 0.9798 - val_loss: 0.0611 - val_acc: 0.9834
Epoch 2/40
 - 194s - loss: 0.0528 - acc: 0.9862 - val_loss: 0.0649 - val_acc: 0.9821
Epoch 3/40
 - 198s - loss: 0.0509 - acc: 0.9868 - val_loss: 0.0618 - val_acc: 0.9835
Epoch 4/40
 - 198s - loss: 0.0499 - acc: 0.9870 - val_loss: 0.0667 - val_acc: 0.9831
Epoch 5/40
 - 198s - loss: 0.0488 - acc: 0.9872 - val_loss: 0.0786 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 17.75 minutes 
==================================================================================================
	PARSING TIME: 2.78 minutes 
==================================================================================================
	Identification : 0.503
	P, R  : 0.503, 0.504

==================================================================================================
	XP Ends: 1/7 (14 h:45)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,58             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.012          ,50             ,8              ,33             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
5              ,41             ,True           ,True           ,327            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 58, False, 0.012, 50, 8, 33, 5, 41, True, True, 327
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (14h:45)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 33)       248985      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 41)        309345      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 5)         760         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 50, 41)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 205)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 25)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 327)          482652      concatenate_10[0][0]             
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 230)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 557)          0           phraseRnn[0][0]                  
                                                                 concatenate_11[0][0]             
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 58)           32364       concatenate_12[0][0]             
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4)            236         dense_7[0][0]                    
==================================================================================================
Total params: 1,075,558
Trainable params: 1,075,558
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 229s - loss: 0.1032 - acc: 0.9734 - val_loss: 0.0734 - val_acc: 0.9817
Epoch 2/40
 - 230s - loss: 0.0640 - acc: 0.9832 - val_loss: 0.0708 - val_acc: 0.9830
Epoch 3/40
 - 230s - loss: 0.0587 - acc: 0.9850 - val_loss: 0.0961 - val_acc: 0.9771
Epoch 4/40
 - 229s - loss: 0.0560 - acc: 0.9858 - val_loss: 0.0704 - val_acc: 0.9842
Epoch 5/40
 - 229s - loss: 0.0542 - acc: 0.9863 - val_loss: 0.0708 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 19.88 minutes 
==================================================================================================
	PARSING TIME: 5.58 minutes 
==================================================================================================
	Identification : 0.592
	P, R  : 0.767, 0.482

==================================================================================================
	XP Ends: 1/7 (15 h:11)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (15h:11)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 33)       238953      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 41)        296881      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 5)         845         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 50, 41)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 205)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 25)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 327)          482652      concatenate_13[0][0]             
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 230)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 557)          0           phraseRnn[0][0]                  
                                                                 concatenate_14[0][0]             
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 58)           32364       concatenate_15[0][0]             
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 4)            236         dense_9[0][0]                    
==================================================================================================
Total params: 1,053,283
Trainable params: 1,053,283
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 157s - loss: 0.1026 - acc: 0.9730 - val_loss: 0.0752 - val_acc: 0.9805
Epoch 2/40
 - 157s - loss: 0.0634 - acc: 0.9836 - val_loss: 0.0731 - val_acc: 0.9818
Epoch 3/40
 - 157s - loss: 0.0571 - acc: 0.9854 - val_loss: 0.0735 - val_acc: 0.9822
Epoch 4/40
 - 157s - loss: 0.0539 - acc: 0.9866 - val_loss: 0.0739 - val_acc: 0.9826
Epoch 5/40
 - 157s - loss: 0.0518 - acc: 0.9872 - val_loss: 0.0755 - val_acc: 0.9827
Epoch 00005: early stopping
	TRAINING TIME: 13.62 minutes 
==================================================================================================
	PARSING TIME: 8.47 minutes 
==================================================================================================
	Identification : 0.549
	P, R  : 0.537, 0.561

==================================================================================================
	XP Ends: 1/7 (15 h:33)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (15h:33)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 33)       455169      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 41)        565513      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 5)         545         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 50, 41)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 205)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 25)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 327)          482652      concatenate_16[0][0]             
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 230)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 557)          0           phraseRnn[0][0]                  
                                                                 concatenate_17[0][0]             
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 58)           32364       concatenate_18[0][0]             
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 4)            236         dense_11[0][0]                   
==================================================================================================
Total params: 1,537,351
Trainable params: 1,537,351
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 311s - loss: 0.0848 - acc: 0.9779 - val_loss: 0.0663 - val_acc: 0.9828
Epoch 2/40
 - 311s - loss: 0.0582 - acc: 0.9851 - val_loss: 0.0658 - val_acc: 0.9834
Epoch 3/40
 - 311s - loss: 0.0534 - acc: 0.9865 - val_loss: 0.0670 - val_acc: 0.9835
Epoch 4/40
 - 310s - loss: 0.0510 - acc: 0.9872 - val_loss: 0.0693 - val_acc: 0.9834
Epoch 5/40
 - 310s - loss: 0.0494 - acc: 0.9877 - val_loss: 0.0708 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 27.33 minutes 
==================================================================================================
	PARSING TIME: 3.68 minutes 
==================================================================================================
	Identification : 0.485
	P, R  : 0.498, 0.473

==================================================================================================
	XP Ends: 1/7 (16 h:5)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,412            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.108          ,50             ,6              ,77             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
6              ,63             ,True           ,True           ,65             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 412, True, 0.108, 50, 6, 77, 6, 63, True, True, 65
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (16h:5)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 77)       580965      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 63)        475335      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         912         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 50, 83)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 315)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 65)           29055       concatenate_19[0][0]             
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 345)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 410)          0           phraseRnn[0][0]                  
                                                                 concatenate_20[0][0]             
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 412)          169332      concatenate_21[0][0]             
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 4)            1652        dense_13[0][0]                   
==================================================================================================
Total params: 1,258,163
Trainable params: 1,258,163
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 135s - loss: 0.1788 - acc: 0.9750 - val_loss: 0.0575 - val_acc: 0.9852
Epoch 2/40
 - 135s - loss: 0.0522 - acc: 0.9871 - val_loss: 0.0574 - val_acc: 0.9855
Epoch 3/40
 - 134s - loss: 0.0479 - acc: 0.9884 - val_loss: 0.0585 - val_acc: 0.9857
Epoch 4/40
 - 134s - loss: 0.0460 - acc: 0.9889 - val_loss: 0.0626 - val_acc: 0.9855
Epoch 5/40
 - 143s - loss: 0.0449 - acc: 0.9892 - val_loss: 0.0651 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 12.13 minutes 
==================================================================================================
	PARSING TIME: 4.12 minutes 
==================================================================================================
	Identification : 0.595
	P, R  : 0.756, 0.491

==================================================================================================
	XP Ends: 1/7 (16 h:21)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (16h:21)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 77)       557557      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 63)        456183      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         1014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 50, 83)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 315)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 65)           29055       concatenate_22[0][0]             
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 345)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 410)          0           phraseRnn[0][0]                  
                                                                 concatenate_23[0][0]             
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 412)          169332      concatenate_24[0][0]             
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 4)            1652        dense_15[0][0]                   
==================================================================================================
Total params: 1,215,807
Trainable params: 1,215,807
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 92s - loss: 12.0891 - acc: 0.2496 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 2/40
 - 92s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 3/40
 - 92s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 4/40
 - 91s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 5/40
 - 91s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 00005: early stopping
	TRAINING TIME: 8.1 minutes 
==================================================================================================
	PARSING TIME: 6.1 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (16 h:36)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (16h:36)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 77)       1062061     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 63)        868959      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         654         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 50, 83)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 315)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 65)           29055       concatenate_25[0][0]             
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 345)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 410)          0           phraseRnn[0][0]                  
                                                                 concatenate_26[0][0]             
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 412)          169332      concatenate_27[0][0]             
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 4)            1652        dense_17[0][0]                   
==================================================================================================
Total params: 2,132,367
Trainable params: 2,132,367
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 180s - loss: 12.0860 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 2/40
 - 180s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 3/40
 - 180s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 4/40
 - 179s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 5/40
 - 179s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 00005: early stopping
	TRAINING TIME: 16.35 minutes 
==================================================================================================
	PARSING TIME: 2.58 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (16 h:55)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,132            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.068          ,50             ,14             ,128            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
5              ,29             ,False          ,True           ,45             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 132, True, 0.068, 50, 14, 128, 5, 29, False, True, 45
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (16h:55)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 128)      1464064     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2128        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 29)        331702      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         760         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 50, 142)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 116)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           25380       concatenate_28[0][0]             
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 136)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 181)          0           phraseRnn[0][0]                  
                                                                 concatenate_29[0][0]             
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 132)          24024       concatenate_30[0][0]             
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 4)            532         dense_19[0][0]                   
==================================================================================================
Total params: 1,848,590
Trainable params: 1,848,590
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 137s - loss: 0.0684 - acc: 0.9821 - val_loss: 0.0540 - val_acc: 0.9862
Epoch 2/40
 - 136s - loss: 0.0491 - acc: 0.9880 - val_loss: 0.0539 - val_acc: 0.9866
Epoch 3/40
 - 136s - loss: 0.0463 - acc: 0.9889 - val_loss: 0.0557 - val_acc: 0.9866
Epoch 4/40
 - 136s - loss: 0.0452 - acc: 0.9892 - val_loss: 0.0614 - val_acc: 0.9856
Epoch 5/40
 - 136s - loss: 0.0444 - acc: 0.9893 - val_loss: 0.0636 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 12.17 minutes 
==================================================================================================
	PARSING TIME: 4.22 minutes 
==================================================================================================
	Identification : 0.52
	P, R  : 0.45, 0.615

==================================================================================================
	XP Ends: 1/7 (17 h:12)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (17h:12)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 128)      1203328     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2366        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 29)        272629      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         845         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 50, 142)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 116)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           25380       concatenate_31[0][0]             
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 136)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 181)          0           phraseRnn[0][0]                  
                                                                 concatenate_32[0][0]             
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 132)          24024       concatenate_33[0][0]             
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 4)            532         dense_21[0][0]                   
==================================================================================================
Total params: 1,529,104
Trainable params: 1,529,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0759 - acc: 0.9792 - val_loss: 0.0564 - val_acc: 0.9852
Epoch 2/40
 - 93s - loss: 0.0522 - acc: 0.9869 - val_loss: 0.0572 - val_acc: 0.9852
Epoch 3/40
 - 92s - loss: 0.0486 - acc: 0.9881 - val_loss: 0.0630 - val_acc: 0.9852
Epoch 4/40
 - 92s - loss: 0.0472 - acc: 0.9885 - val_loss: 0.0646 - val_acc: 0.9849
Epoch 5/40
 - 92s - loss: 0.0465 - acc: 0.9885 - val_loss: 0.0706 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 8.13 minutes 
==================================================================================================
	PARSING TIME: 6.17 minutes 
==================================================================================================
	Identification : 0.491
	P, R  : 0.413, 0.604

==================================================================================================
	XP Ends: 1/7 (17 h:27)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (17h:27)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 128)      2825088     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       1526        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 29)        640059      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         545         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 50, 142)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 116)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           25380       concatenate_34[0][0]             
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 136)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 181)          0           phraseRnn[0][0]                  
                                                                 concatenate_35[0][0]             
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 132)          24024       concatenate_36[0][0]             
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 4)            532         dense_23[0][0]                   
==================================================================================================
Total params: 3,517,154
Trainable params: 3,517,154
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 185s - loss: 0.0643 - acc: 0.9829 - val_loss: 0.0591 - val_acc: 0.9845
Epoch 2/40
 - 184s - loss: 0.0494 - acc: 0.9876 - val_loss: 0.0589 - val_acc: 0.9846
Epoch 3/40
 - 184s - loss: 0.0468 - acc: 0.9884 - val_loss: 0.0659 - val_acc: 0.9841
Epoch 4/40
 - 184s - loss: 0.0448 - acc: 0.9890 - val_loss: 0.0792 - val_acc: 0.9840
Epoch 5/40
 - 184s - loss: 0.0436 - acc: 0.9892 - val_loss: 0.0901 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 16.73 minutes 
==================================================================================================
	PARSING TIME: 2.7 minutes 
==================================================================================================
	Identification : 0.463
	P, R  : 0.422, 0.512

==================================================================================================
	XP Ends: 1/7 (17 h:47)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,39             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.012          ,50             ,14             ,192            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,85             ,False          ,True           ,364            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 39, False, 0.012, 50, 14, 192, 10, 85, False, True, 364
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (17h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 192)      1448640     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2128        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 85)        641325      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 50, 206)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 340)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 364)          831376      concatenate_37[0][0]             
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 380)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 744)          0           phraseRnn[0][0]                  
                                                                 concatenate_38[0][0]             
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 39)           29055       concatenate_39[0][0]             
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 4)            160         dense_25[0][0]                   
==================================================================================================
Total params: 2,954,204
Trainable params: 2,954,204
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 310s - loss: 0.0815 - acc: 0.9786 - val_loss: 0.0642 - val_acc: 0.9841
Epoch 2/40
 - 310s - loss: 0.0560 - acc: 0.9859 - val_loss: 0.0621 - val_acc: 0.9847
Epoch 3/40
 - 310s - loss: 0.0512 - acc: 0.9873 - val_loss: 0.0622 - val_acc: 0.9851
Epoch 4/40
 - 310s - loss: 0.0487 - acc: 0.9881 - val_loss: 0.0641 - val_acc: 0.9850
Epoch 5/40
 - 310s - loss: 0.0472 - acc: 0.9886 - val_loss: 0.0662 - val_acc: 0.9848
Epoch 00005: early stopping
	TRAINING TIME: 26.68 minutes 
==================================================================================================
	PARSING TIME: 7.23 minutes 
==================================================================================================
	Identification : 0.587
	P, R  : 0.773, 0.473

==================================================================================================
	XP Ends: 1/7 (18 h:21)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (18h:21)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 192)      1390272     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2366        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 85)        615485      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 50, 206)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 340)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 364)          831376      concatenate_40[0][0]             
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 380)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 744)          0           phraseRnn[0][0]                  
                                                                 concatenate_41[0][0]             
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 39)           29055       concatenate_42[0][0]             
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 4)            160         dense_27[0][0]                   
==================================================================================================
Total params: 2,870,404
Trainable params: 2,870,404
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 210s - loss: 0.1014 - acc: 0.9734 - val_loss: 0.0727 - val_acc: 0.9816
Epoch 2/40
 - 210s - loss: 0.0620 - acc: 0.9839 - val_loss: 0.0706 - val_acc: 0.9829
Epoch 3/40
 - 210s - loss: 0.0558 - acc: 0.9859 - val_loss: 0.0716 - val_acc: 0.9830
Epoch 4/40
 - 210s - loss: 0.0528 - acc: 0.9868 - val_loss: 0.0722 - val_acc: 0.9832
Epoch 5/40
 - 210s - loss: 0.0509 - acc: 0.9874 - val_loss: 0.0742 - val_acc: 0.9829
Epoch 00005: early stopping
	TRAINING TIME: 18.02 minutes 
==================================================================================================
	PARSING TIME: 11.17 minutes 
==================================================================================================
	Identification : 0.523
	P, R  : 0.48, 0.575

==================================================================================================
	XP Ends: 1/7 (18 h:50)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (18h:50)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 192)      2648256     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       1526        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 85)        1172405     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 50, 206)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 340)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 364)          831376      concatenate_43[0][0]             
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 380)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 744)          0           phraseRnn[0][0]                  
                                                                 concatenate_44[0][0]             
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 39)           29055       concatenate_45[0][0]             
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 4)            160         dense_29[0][0]                   
==================================================================================================
Total params: 4,683,868
Trainable params: 4,683,868
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 420s - loss: 0.0816 - acc: 0.9786 - val_loss: 0.0648 - val_acc: 0.9827
Epoch 2/40
 - 420s - loss: 0.0569 - acc: 0.9852 - val_loss: 0.0632 - val_acc: 0.9835
Epoch 3/40
 - 420s - loss: 0.0529 - acc: 0.9865 - val_loss: 0.0649 - val_acc: 0.9835
Epoch 4/40
 - 420s - loss: 0.0508 - acc: 0.9871 - val_loss: 0.0682 - val_acc: 0.9833
Epoch 5/40
 - 420s - loss: 0.0495 - acc: 0.9875 - val_loss: 0.0696 - val_acc: 0.9832
Epoch 00005: early stopping
	TRAINING TIME: 36.35 minutes 
==================================================================================================
	PARSING TIME: 4.92 minutes 
==================================================================================================
	Identification : 0.455
	P, R  : 0.567, 0.38

==================================================================================================
	XP Ends: 1/7 (19 h:32)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,192            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.013          ,50             ,5              ,41             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,98             ,True           ,True           ,62             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 192, True, 0.013, 50, 5, 41, 10, 98, True, True, 62
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (19h:32)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 41)       468958      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 98)        1120924     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 50, 46)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 490)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 62)           20274       concatenate_46[0][0]             
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 540)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 602)          0           phraseRnn[0][0]                  
                                                                 concatenate_47[0][0]             
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 192)          115776      concatenate_48[0][0]             
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 4)            772         dense_31[0][0]                   
==================================================================================================
Total params: 1,728,984
Trainable params: 1,728,984
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 0.0687 - acc: 0.9820 - val_loss: 0.0546 - val_acc: 0.9861
Epoch 2/40
 - 136s - loss: 0.0500 - acc: 0.9878 - val_loss: 0.0595 - val_acc: 0.9847
Epoch 3/40
 - 135s - loss: 0.0471 - acc: 0.9886 - val_loss: 0.0561 - val_acc: 0.9862
Epoch 4/40
 - 135s - loss: 0.0456 - acc: 0.9891 - val_loss: 0.0587 - val_acc: 0.9862
Epoch 5/40
 - 136s - loss: 0.0449 - acc: 0.9893 - val_loss: 0.0610 - val_acc: 0.9861
Epoch 00005: early stopping
	TRAINING TIME: 12.05 minutes 
==================================================================================================
	PARSING TIME: 4.22 minutes 
==================================================================================================
	Identification : 0.543
	P, R  : 0.563, 0.525

==================================================================================================
	XP Ends: 1/7 (19 h:49)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (19h:49)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 41)       385441      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 98)        921298      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 50, 46)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 490)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 62)           20274       concatenate_49[0][0]             
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 540)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 602)          0           phraseRnn[0][0]                  
                                                                 concatenate_50[0][0]             
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 192)          115776      concatenate_51[0][0]             
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 4)            772         dense_33[0][0]                   
==================================================================================================
Total params: 1,446,096
Trainable params: 1,446,096
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 92s - loss: 0.0801 - acc: 0.9783 - val_loss: 0.0600 - val_acc: 0.9841
Epoch 2/40
 - 92s - loss: 0.0545 - acc: 0.9863 - val_loss: 0.0600 - val_acc: 0.9844
Epoch 3/40
 - 93s - loss: 0.0503 - acc: 0.9877 - val_loss: 0.0622 - val_acc: 0.9844
Epoch 4/40
 - 92s - loss: 0.0484 - acc: 0.9881 - val_loss: 0.0658 - val_acc: 0.9845
Epoch 5/40
 - 92s - loss: 0.0473 - acc: 0.9884 - val_loss: 0.0693 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 8.15 minutes 
==================================================================================================
	PARSING TIME: 6.37 minutes 
==================================================================================================
	Identification : 0.441
	P, R  : 0.357, 0.577

==================================================================================================
	XP Ends: 1/7 (20 h:4)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (20h:4)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 41)       904911      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 98)        2162958     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 50, 46)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 490)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 62)           20274       concatenate_52[0][0]             
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 540)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 602)          0           phraseRnn[0][0]                  
                                                                 concatenate_53[0][0]             
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 192)          115776      concatenate_54[0][0]             
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 4)            772         dense_35[0][0]                   
==================================================================================================
Total params: 3,206,326
Trainable params: 3,206,326
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 182s - loss: 0.0670 - acc: 0.9821 - val_loss: 0.0606 - val_acc: 0.9843
Epoch 2/40
 - 190s - loss: 0.0497 - acc: 0.9876 - val_loss: 0.0599 - val_acc: 0.9845
Epoch 3/40
 - 188s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0638 - val_acc: 0.9841
Epoch 4/40
 - 181s - loss: 0.0451 - acc: 0.9891 - val_loss: 0.0692 - val_acc: 0.9840
Epoch 5/40
 - 180s - loss: 0.0442 - acc: 0.9893 - val_loss: 0.0749 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 16.7 minutes 
==================================================================================================
	PARSING TIME: 2.78 minutes 
==================================================================================================
	Identification : 0.456
	P, R  : 0.432, 0.482

==================================================================================================
	XP Ends: 1/7 (20 h:23)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,51             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.044          ,50             ,48             ,51             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,186            ,True           ,True           ,349            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 51, True, 0.044, 50, 48, 51, 10, 186, True, True, 349
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (20h:23)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 51)       583338      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 48)       7296        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 186)       2127468     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 50, 99)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 930)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 349)          470103      concatenate_55[0][0]             
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 980)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 1329)         0           phraseRnn[0][0]                  
                                                                 concatenate_56[0][0]             
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 51)           67830       concatenate_57[0][0]             
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 4)            208         dense_37[0][0]                   
==================================================================================================
Total params: 3,257,763
Trainable params: 3,257,763
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 212s - loss: 8.0561 - acc: 0.4998 - val_loss: 8.0632 - val_acc: 0.4997
Epoch 2/40
 - 213s - loss: 2.0439 - acc: 0.8625 - val_loss: 0.0555 - val_acc: 0.9858
Epoch 3/40
 - 213s - loss: 0.0521 - acc: 0.9871 - val_loss: 0.0548 - val_acc: 0.9862
Epoch 4/40
 - 213s - loss: 0.0486 - acc: 0.9882 - val_loss: 0.0565 - val_acc: 0.9859
Epoch 5/40
 - 213s - loss: 0.0471 - acc: 0.9886 - val_loss: 0.0581 - val_acc: 0.9860
Epoch 6/40
 - 213s - loss: 0.0463 - acc: 0.9887 - val_loss: 0.0609 - val_acc: 0.9860
Epoch 00006: early stopping
	TRAINING TIME: 22.05 minutes 
==================================================================================================
	PARSING TIME: 4.97 minutes 
==================================================================================================
	Identification : 0.513
	P, R  : 0.774, 0.384

==================================================================================================
	XP Ends: 1/7 (20 h:51)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (20h:51)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 51)       479451      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 48)       8112        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 186)       1748586     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 50, 99)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 930)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 349)          470103      concatenate_58[0][0]             
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 980)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 1329)         0           phraseRnn[0][0]                  
                                                                 concatenate_59[0][0]             
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 51)           67830       concatenate_60[0][0]             
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 4)            208         dense_39[0][0]                   
==================================================================================================
Total params: 2,775,980
Trainable params: 2,775,980
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 144s - loss: 0.1030 - acc: 0.9741 - val_loss: 0.0595 - val_acc: 0.9841
Epoch 2/40
 - 144s - loss: 0.0547 - acc: 0.9863 - val_loss: 0.0611 - val_acc: 0.9839
Epoch 3/40
 - 144s - loss: 0.0508 - acc: 0.9873 - val_loss: 0.0626 - val_acc: 0.9843
Epoch 4/40
 - 144s - loss: 0.0490 - acc: 0.9879 - val_loss: 0.0649 - val_acc: 0.9843
Epoch 5/40
 - 144s - loss: 0.0479 - acc: 0.9882 - val_loss: 0.0671 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 12.52 minutes 
==================================================================================================
	PARSING TIME: 7.78 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.392, 0.597

==================================================================================================
	XP Ends: 1/7 (21 h:11)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (21h:12)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 51)       1125621     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 48)       5232        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 186)       4105206     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_61 (Concatenate)    (None, 50, 99)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 930)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 349)          470103      concatenate_61[0][0]             
__________________________________________________________________________________________________
concatenate_62 (Concatenate)    (None, 980)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_63 (Concatenate)    (None, 1329)         0           phraseRnn[0][0]                  
                                                                 concatenate_62[0][0]             
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 51)           67830       concatenate_63[0][0]             
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 4)            208         dense_41[0][0]                   
==================================================================================================
Total params: 5,775,290
Trainable params: 5,775,290
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 290s - loss: 0.0837 - acc: 0.9807 - val_loss: 0.0599 - val_acc: 0.9841
Epoch 2/40
 - 290s - loss: 0.0500 - acc: 0.9875 - val_loss: 0.0613 - val_acc: 0.9841
Epoch 3/40
 - 290s - loss: 0.0471 - acc: 0.9885 - val_loss: 0.0635 - val_acc: 0.9839
Epoch 4/40
 - 290s - loss: 0.0459 - acc: 0.9888 - val_loss: 0.0692 - val_acc: 0.9837
Epoch 5/40
 - 290s - loss: 0.0448 - acc: 0.9891 - val_loss: 0.0751 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 25.55 minutes 
==================================================================================================
	PARSING TIME: 3.32 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.493, 0.455

==================================================================================================
	XP Ends: 1/7 (21 h:41)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,233            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.021          ,50             ,14             ,35             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
20             ,174            ,True           ,True           ,171            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 233, True, 0.021, 50, 14, 35, 20, 174, True, True, 171
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (21h:41)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 35)       264075      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2128        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 174)       1312830     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 20)        3040        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_64 (Concatenate)    (None, 50, 49)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 870)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 100)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 171)          113373      concatenate_64[0][0]             
__________________________________________________________________________________________________
concatenate_65 (Concatenate)    (None, 970)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 1141)         0           phraseRnn[0][0]                  
                                                                 concatenate_65[0][0]             
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 233)          266086      concatenate_66[0][0]             
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 4)            936         dense_43[0][0]                   
==================================================================================================
Total params: 1,962,468
Trainable params: 1,962,468
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 135s - loss: 0.0642 - acc: 0.9831 - val_loss: 0.0553 - val_acc: 0.9857
Epoch 2/40
 - 135s - loss: 0.0499 - acc: 0.9877 - val_loss: 0.0549 - val_acc: 0.9862
Epoch 3/40
 - 135s - loss: 0.0469 - acc: 0.9886 - val_loss: 0.0667 - val_acc: 0.9861
Epoch 4/40
 - 135s - loss: 0.0454 - acc: 0.9891 - val_loss: 0.0609 - val_acc: 0.9858
Epoch 5/40
 - 135s - loss: 0.0445 - acc: 0.9893 - val_loss: 0.0662 - val_acc: 0.9857
Epoch 00005: early stopping
	TRAINING TIME: 12.07 minutes 
==================================================================================================
	PARSING TIME: 4.12 minutes 
==================================================================================================
	Identification : 0.585
	P, R  : 0.697, 0.504

==================================================================================================
	XP Ends: 1/7 (21 h:57)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (21h:57)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 35)       253435      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2366        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 174)       1259934     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 20)        3380        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_67 (Concatenate)    (None, 50, 49)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 870)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 100)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 171)          113373      concatenate_67[0][0]             
__________________________________________________________________________________________________
concatenate_68 (Concatenate)    (None, 970)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_69 (Concatenate)    (None, 1141)         0           phraseRnn[0][0]                  
                                                                 concatenate_68[0][0]             
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 233)          266086      concatenate_69[0][0]             
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 4)            936         dense_45[0][0]                   
==================================================================================================
Total params: 1,899,510
Trainable params: 1,899,510
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0755 - acc: 0.9798 - val_loss: 0.0610 - val_acc: 0.9842
Epoch 2/40
 - 93s - loss: 0.0526 - acc: 0.9867 - val_loss: 0.0709 - val_acc: 0.9804
Epoch 3/40
 - 93s - loss: 0.0487 - acc: 0.9881 - val_loss: 0.0631 - val_acc: 0.9841
Epoch 4/40
 - 92s - loss: 0.0471 - acc: 0.9885 - val_loss: 0.0681 - val_acc: 0.9842
Epoch 5/40
 - 92s - loss: 0.0462 - acc: 0.9887 - val_loss: 0.0706 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 8.18 minutes 
==================================================================================================
	PARSING TIME: 6.37 minutes 
==================================================================================================
	Identification : 0.516
	P, R  : 0.434, 0.635

==================================================================================================
	XP Ends: 1/7 (22 h:12)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (22h:12)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 35)       482755      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       1526        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 174)       2399982     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 20)        2180        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_70 (Concatenate)    (None, 50, 49)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 870)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 100)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 171)          113373      concatenate_70[0][0]             
__________________________________________________________________________________________________
concatenate_71 (Concatenate)    (None, 970)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_72 (Concatenate)    (None, 1141)         0           phraseRnn[0][0]                  
                                                                 concatenate_71[0][0]             
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 233)          266086      concatenate_72[0][0]             
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 4)            936         dense_47[0][0]                   
==================================================================================================
Total params: 3,266,838
Trainable params: 3,266,838
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 186s - loss: 0.0653 - acc: 0.9824 - val_loss: 0.0564 - val_acc: 0.9847
Epoch 2/40
 - 187s - loss: 0.0515 - acc: 0.9869 - val_loss: 0.0571 - val_acc: 0.9846
Epoch 3/40
 - 186s - loss: 0.0484 - acc: 0.9880 - val_loss: 0.0608 - val_acc: 0.9844
Epoch 4/40
 - 185s - loss: 0.0465 - acc: 0.9886 - val_loss: 0.0666 - val_acc: 0.9842
Epoch 5/40
 - 185s - loss: 0.0452 - acc: 0.9889 - val_loss: 0.0735 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 16.92 minutes 
==================================================================================================
	PARSING TIME: 2.72 minutes 
==================================================================================================
	Identification : 0.515
	P, R  : 0.476, 0.561

==================================================================================================
	XP Ends: 1/7 (22 h:32)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,41             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.129          ,50             ,22             ,91             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
44             ,148            ,True           ,True           ,190            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 41, False, 0.129, 50, 22, 91, 44, 148, True, True, 190
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (22h:32)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 91)       1040858     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       3344        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 148)       1692824     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 44)        6688        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_73 (Concatenate)    (None, 50, 113)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 740)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 220)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 190)          231040      concatenate_73[0][0]             
__________________________________________________________________________________________________
concatenate_74 (Concatenate)    (None, 960)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_75 (Concatenate)    (None, 1150)         0           phraseRnn[0][0]                  
                                                                 concatenate_74[0][0]             
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 41)           47191       concatenate_75[0][0]             
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 4)            168         dense_49[0][0]                   
==================================================================================================
Total params: 3,022,113
Trainable params: 3,022,113
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 169s - loss: 12.0805 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 2/40
 - 169s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 3/40
 - 169s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 4/40
 - 169s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 5/40
 - 169s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 00005: early stopping
	TRAINING TIME: 14.88 minutes 
==================================================================================================
	PARSING TIME: 5.02 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (22 h:53)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (22h:53)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 91)       855491      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       3718        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 148)       1391348     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 44)        7436        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_76 (Concatenate)    (None, 50, 113)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 740)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 220)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 190)          231040      concatenate_76[0][0]             
__________________________________________________________________________________________________
concatenate_77 (Concatenate)    (None, 960)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_78 (Concatenate)    (None, 1150)         0           phraseRnn[0][0]                  
                                                                 concatenate_77[0][0]             
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 41)           47191       concatenate_78[0][0]             
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 4)            168         dense_51[0][0]                   
==================================================================================================
Total params: 2,536,392
Trainable params: 2,536,392
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 113s - loss: 0.1372 - acc: 0.9749 - val_loss: 0.0603 - val_acc: 0.9841
Epoch 2/40
 - 113s - loss: 0.0545 - acc: 0.9863 - val_loss: 0.0601 - val_acc: 0.9846
Epoch 3/40
 - 113s - loss: 0.0504 - acc: 0.9875 - val_loss: 0.0633 - val_acc: 0.9846
Epoch 4/40
 - 113s - loss: 0.0489 - acc: 0.9879 - val_loss: 0.0667 - val_acc: 0.9846
Epoch 5/40
 - 113s - loss: 0.0480 - acc: 0.9882 - val_loss: 0.0687 - val_acc: 0.9846
Epoch 00005: early stopping
	TRAINING TIME: 9.95 minutes 
==================================================================================================
	PARSING TIME: 8.0 minutes 
==================================================================================================
	Identification : 0.47
	P, R  : 0.393, 0.584

==================================================================================================
	XP Ends: 1/7 (23 h:11)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (23h:11)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 91)       2008461     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       2398        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 148)       3266508     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 44)        4796        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_79 (Concatenate)    (None, 50, 113)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 740)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 220)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 190)          231040      concatenate_79[0][0]             
__________________________________________________________________________________________________
concatenate_80 (Concatenate)    (None, 960)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_81 (Concatenate)    (None, 1150)         0           phraseRnn[0][0]                  
                                                                 concatenate_80[0][0]             
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 41)           47191       concatenate_81[0][0]             
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 4)            168         dense_53[0][0]                   
==================================================================================================
Total params: 5,560,562
Trainable params: 5,560,562
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 229s - loss: 12.0879 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 2/40
 - 228s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 3/40
 - 228s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 4/40
 - 228s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 5/40
 - 229s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 20.43 minutes 
==================================================================================================
	PARSING TIME: 5.85 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (23 h:38)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,186            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.027          ,50             ,25             ,58             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
36             ,37             ,True           ,False          ,190            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 186, True, 0.027, 50, 25, 58, 36, 37, True, False, 190
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (23h:38)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 58)       663404      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       3800        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 37)        423206      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 36)        5472        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_82 (Concatenate)    (None, 50, 83)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 148)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 144)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 190)          156180      concatenate_82[0][0]             
__________________________________________________________________________________________________
concatenate_83 (Concatenate)    (None, 292)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_84 (Concatenate)    (None, 482)          0           phraseRnn[0][0]                  
                                                                 concatenate_83[0][0]             
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 186)          89838       concatenate_84[0][0]             
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 4)            748         dense_55[0][0]                   
==================================================================================================
Total params: 1,342,648
Trainable params: 1,342,648
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 138s - loss: 0.0980 - acc: 0.9786 - val_loss: 0.1106 - val_acc: 0.9838
Epoch 2/40
 - 137s - loss: 0.0536 - acc: 0.9865 - val_loss: 0.0576 - val_acc: 0.9853
Epoch 3/40
 - 137s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0581 - val_acc: 0.9856
Epoch 4/40
 - 137s - loss: 0.0474 - acc: 0.9885 - val_loss: 0.0612 - val_acc: 0.9854
Epoch 5/40
 - 137s - loss: 0.0460 - acc: 0.9888 - val_loss: 0.0662 - val_acc: 0.9852
Epoch 00005: early stopping
	TRAINING TIME: 12.2 minutes 
==================================================================================================
	PARSING TIME: 4.3 minutes 
==================================================================================================
	Identification : 0.478
	P, R  : 0.397, 0.6

==================================================================================================
	XP Ends: 1/7 (23 h:54)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (23h:54)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 58)       545258      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       4225        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 37)        347837      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 36)        6084        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 50, 83)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 148)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 144)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 190)          156180      concatenate_85[0][0]             
__________________________________________________________________________________________________
concatenate_86 (Concatenate)    (None, 292)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_87 (Concatenate)    (None, 482)          0           phraseRnn[0][0]                  
                                                                 concatenate_86[0][0]             
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 186)          89838       concatenate_87[0][0]             
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 4)            748         dense_57[0][0]                   
==================================================================================================
Total params: 1,150,170
Trainable params: 1,150,170
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0754 - acc: 0.9793 - val_loss: 0.0601 - val_acc: 0.9841
Epoch 2/40
 - 93s - loss: 0.0551 - acc: 0.9858 - val_loss: 0.0605 - val_acc: 0.9839
Epoch 3/40
 - 93s - loss: 0.0505 - acc: 0.9874 - val_loss: 0.0637 - val_acc: 0.9839
Epoch 4/40
 - 93s - loss: 0.0483 - acc: 0.9881 - val_loss: 0.0692 - val_acc: 0.9835
Epoch 5/40
 - 92s - loss: 0.0469 - acc: 0.9884 - val_loss: 0.0763 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 8.25 minutes 
==================================================================================================
	PARSING TIME: 6.4 minutes 
==================================================================================================
	Identification : 0.402
	P, R  : 0.3, 0.611

==================================================================================================
	XP Ends: 2/7 (0 h:10)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (0h:10)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 58)       1280118     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       2725        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 37)        816627      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 36)        3924        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_88 (Concatenate)    (None, 50, 83)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 148)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 144)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 190)          156180      concatenate_88[0][0]             
__________________________________________________________________________________________________
concatenate_89 (Concatenate)    (None, 292)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_90 (Concatenate)    (None, 482)          0           phraseRnn[0][0]                  
                                                                 concatenate_89[0][0]             
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 186)          89838       concatenate_90[0][0]             
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 4)            748         dense_59[0][0]                   
==================================================================================================
Total params: 2,350,160
Trainable params: 2,350,160
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 182s - loss: 0.0774 - acc: 0.9796 - val_loss: 0.0639 - val_acc: 0.9823
Epoch 2/40
 - 182s - loss: 0.0529 - acc: 0.9863 - val_loss: 0.0620 - val_acc: 0.9832
Epoch 3/40
 - 181s - loss: 0.0495 - acc: 0.9876 - val_loss: 0.0648 - val_acc: 0.9831
Epoch 4/40
 - 181s - loss: 0.0476 - acc: 0.9881 - val_loss: 0.0704 - val_acc: 0.9832
Epoch 5/40
 - 181s - loss: 0.0463 - acc: 0.9885 - val_loss: 0.0747 - val_acc: 0.9831
Epoch 00005: early stopping
	TRAINING TIME: 16.47 minutes 
==================================================================================================
	PARSING TIME: 2.85 minutes 
==================================================================================================
	Identification : 0.488
	P, R  : 0.445, 0.539

==================================================================================================
	XP Ends: 2/7 (0 h:29)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,86             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.031          ,50             ,34             ,48             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
16             ,96             ,True           ,True           ,89             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 86, False, 0.031, 50, 34, 48, 16, 96, True, True, 89
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (0h:29)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 48)       362160      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 34)       5168        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 96)        724320      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 16)        2432        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_91 (Concatenate)    (None, 50, 82)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 480)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 80)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 89)           61232       concatenate_91[0][0]             
__________________________________________________________________________________________________
concatenate_92 (Concatenate)    (None, 560)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_93 (Concatenate)    (None, 649)          0           phraseRnn[0][0]                  
                                                                 concatenate_92[0][0]             
__________________________________________________________________________________________________
dense_61 (Dense)                (None, 86)           55900       concatenate_93[0][0]             
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 4)            348         dense_61[0][0]                   
==================================================================================================
Total params: 1,211,560
Trainable params: 1,211,560
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 164s - loss: 0.0647 - acc: 0.9830 - val_loss: 0.0564 - val_acc: 0.9855
Epoch 2/40
 - 164s - loss: 0.0498 - acc: 0.9877 - val_loss: 0.0545 - val_acc: 0.9864
Epoch 3/40
 - 164s - loss: 0.0468 - acc: 0.9887 - val_loss: 0.0567 - val_acc: 0.9861
Epoch 4/40
 - 163s - loss: 0.0453 - acc: 0.9891 - val_loss: 0.0597 - val_acc: 0.9861
Epoch 5/40
 - 163s - loss: 0.0444 - acc: 0.9894 - val_loss: 0.0631 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 14.43 minutes 
==================================================================================================
	PARSING TIME: 5.13 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.68, 0.501

==================================================================================================
	XP Ends: 2/7 (0 h:49)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (0h:49)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 48)       347568      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 34)       5746        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 96)        695136      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 16)        2704        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_94 (Concatenate)    (None, 50, 82)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 480)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 80)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 89)           61232       concatenate_94[0][0]             
__________________________________________________________________________________________________
concatenate_95 (Concatenate)    (None, 560)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_96 (Concatenate)    (None, 649)          0           phraseRnn[0][0]                  
                                                                 concatenate_95[0][0]             
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 86)           55900       concatenate_96[0][0]             
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 4)            348         dense_63[0][0]                   
==================================================================================================
Total params: 1,168,634
Trainable params: 1,168,634
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 0.0747 - acc: 0.9798 - val_loss: 0.0601 - val_acc: 0.9842
Epoch 2/40
 - 108s - loss: 0.0527 - acc: 0.9867 - val_loss: 0.0612 - val_acc: 0.9842
Epoch 3/40
 - 108s - loss: 0.0491 - acc: 0.9879 - val_loss: 0.0622 - val_acc: 0.9848
Epoch 4/40
 - 108s - loss: 0.0474 - acc: 0.9884 - val_loss: 0.0667 - val_acc: 0.9846
Epoch 5/40
 - 108s - loss: 0.0464 - acc: 0.9886 - val_loss: 0.0717 - val_acc: 0.9848
Epoch 00005: early stopping
	TRAINING TIME: 9.52 minutes 
==================================================================================================
	PARSING TIME: 8.22 minutes 
==================================================================================================
	Identification : 0.5
	P, R  : 0.416, 0.627

==================================================================================================
	XP Ends: 2/7 (1 h:7)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (1h:7)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 48)       662064      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 34)       3706        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 96)        1324128     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 16)        1744        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_97 (Concatenate)    (None, 50, 82)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 480)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 80)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 89)           61232       concatenate_97[0][0]             
__________________________________________________________________________________________________
concatenate_98 (Concatenate)    (None, 560)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_99 (Concatenate)    (None, 649)          0           phraseRnn[0][0]                  
                                                                 concatenate_98[0][0]             
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 86)           55900       concatenate_99[0][0]             
__________________________________________________________________________________________________
dense_66 (Dense)                (None, 4)            348         dense_65[0][0]                   
==================================================================================================
Total params: 2,109,122
Trainable params: 2,109,122
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 221s - loss: 0.0653 - acc: 0.9824 - val_loss: 0.0566 - val_acc: 0.9846
Epoch 2/40
 - 220s - loss: 0.0514 - acc: 0.9869 - val_loss: 0.0573 - val_acc: 0.9846
Epoch 3/40
 - 220s - loss: 0.0485 - acc: 0.9880 - val_loss: 0.0598 - val_acc: 0.9845
Epoch 4/40
 - 219s - loss: 0.0468 - acc: 0.9886 - val_loss: 0.0638 - val_acc: 0.9844
Epoch 5/40
 - 219s - loss: 0.0456 - acc: 0.9888 - val_loss: 0.0719 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 19.78 minutes 
==================================================================================================
	PARSING TIME: 3.47 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.456, 0.547

==================================================================================================
	XP Ends: 2/7 (1 h:31)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,30             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.038          ,50             ,31             ,60             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
9              ,38             ,True           ,False          ,42             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 30, True, 0.038, 50, 31, 60, 9, 38, True, False, 42
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (1h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 60)       452700      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 31)       4712        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 38)        286710      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 9)         1368        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_100 (Concatenate)   (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 152)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 36)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 42)           16884       concatenate_100[0][0]            
__________________________________________________________________________________________________
concatenate_101 (Concatenate)   (None, 188)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_102 (Concatenate)   (None, 230)          0           phraseRnn[0][0]                  
                                                                 concatenate_101[0][0]            
__________________________________________________________________________________________________
dense_67 (Dense)                (None, 30)           6930        concatenate_102[0][0]            
__________________________________________________________________________________________________
dense_68 (Dense)                (None, 4)            124         dense_67[0][0]                   
==================================================================================================
Total params: 769,428
Trainable params: 769,428
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 0.0665 - acc: 0.9825 - val_loss: 0.0577 - val_acc: 0.9850
Epoch 2/40
 - 134s - loss: 0.0518 - acc: 0.9869 - val_loss: 0.0574 - val_acc: 0.9853
Epoch 3/40
 - 134s - loss: 0.0487 - acc: 0.9880 - val_loss: 0.0587 - val_acc: 0.9854
Epoch 4/40
 - 134s - loss: 0.0471 - acc: 0.9886 - val_loss: 0.0611 - val_acc: 0.9854
Epoch 5/40
 - 134s - loss: 0.0459 - acc: 0.9889 - val_loss: 0.0637 - val_acc: 0.9852
Epoch 00005: early stopping
	TRAINING TIME: 11.93 minutes 
==================================================================================================
	PARSING TIME: 4.05 minutes 
==================================================================================================
	Identification : 0.582
	P, R  : 0.734, 0.482

==================================================================================================
	XP Ends: 2/7 (1 h:47)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (1h:47)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 60)       434460      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 31)       5239        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 38)        275158      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 9)         1521        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_103 (Concatenate)   (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 152)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 36)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 42)           16884       concatenate_103[0][0]            
__________________________________________________________________________________________________
concatenate_104 (Concatenate)   (None, 188)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_105 (Concatenate)   (None, 230)          0           phraseRnn[0][0]                  
                                                                 concatenate_104[0][0]            
__________________________________________________________________________________________________
dense_69 (Dense)                (None, 30)           6930        concatenate_105[0][0]            
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 4)            124         dense_69[0][0]                   
==================================================================================================
Total params: 740,316
Trainable params: 740,316
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 92s - loss: 0.0763 - acc: 0.9793 - val_loss: 0.0643 - val_acc: 0.9830
Epoch 2/40
 - 92s - loss: 0.0562 - acc: 0.9854 - val_loss: 0.0621 - val_acc: 0.9834
Epoch 3/40
 - 91s - loss: 0.0521 - acc: 0.9868 - val_loss: 0.0644 - val_acc: 0.9835
Epoch 4/40
 - 91s - loss: 0.0499 - acc: 0.9875 - val_loss: 0.0697 - val_acc: 0.9829
Epoch 5/40
 - 91s - loss: 0.0484 - acc: 0.9880 - val_loss: 0.0751 - val_acc: 0.9825
Epoch 00005: early stopping
	TRAINING TIME: 8.07 minutes 
==================================================================================================
	PARSING TIME: 6.43 minutes 
==================================================================================================
	Identification : 0.417
	P, R  : 0.316, 0.611

==================================================================================================
	XP Ends: 2/7 (2 h:2)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (2h:2)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 60)       827580      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 31)       3379        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 38)        524134      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 9)         981         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_106 (Concatenate)   (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 152)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 36)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 42)           16884       concatenate_106[0][0]            
__________________________________________________________________________________________________
concatenate_107 (Concatenate)   (None, 188)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_108 (Concatenate)   (None, 230)          0           phraseRnn[0][0]                  
                                                                 concatenate_107[0][0]            
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 30)           6930        concatenate_108[0][0]            
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 4)            124         dense_71[0][0]                   
==================================================================================================
Total params: 1,380,012
Trainable params: 1,380,012
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 178s - loss: 0.0674 - acc: 0.9816 - val_loss: 0.0579 - val_acc: 0.9840
Epoch 2/40
 - 177s - loss: 0.0535 - acc: 0.9860 - val_loss: 0.0580 - val_acc: 0.9839
Epoch 3/40
 - 177s - loss: 0.0503 - acc: 0.9873 - val_loss: 0.0606 - val_acc: 0.9836
Epoch 4/40
 - 177s - loss: 0.0485 - acc: 0.9879 - val_loss: 0.0644 - val_acc: 0.9835
Epoch 5/40
 - 177s - loss: 0.0473 - acc: 0.9883 - val_loss: 0.0689 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 16.12 minutes 
==================================================================================================
	PARSING TIME: 2.72 minutes 
==================================================================================================
	Identification : 0.478
	P, R  : 0.497, 0.461

==================================================================================================
	XP Ends: 2/7 (2 h:21)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,181            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.073          ,50             ,48             ,114            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
5              ,59             ,True           ,False          ,38             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 181, True, 0.073, 50, 48, 114, 5, 59, True, False, 38
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (2h:21)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 114)      1303932     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 48)       7296        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 59)        674842      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         760         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_109 (Concatenate)   (None, 50, 162)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 236)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 38)           22914       concatenate_109[0][0]            
__________________________________________________________________________________________________
concatenate_110 (Concatenate)   (None, 256)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_111 (Concatenate)   (None, 294)          0           phraseRnn[0][0]                  
                                                                 concatenate_110[0][0]            
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 181)          53395       concatenate_111[0][0]            
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 4)            728         dense_73[0][0]                   
==================================================================================================
Total params: 2,063,867
Trainable params: 2,063,867
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 0.0699 - acc: 0.9821 - val_loss: 0.0537 - val_acc: 0.9864
Epoch 2/40
 - 137s - loss: 0.0496 - acc: 0.9878 - val_loss: 0.0645 - val_acc: 0.9863
Epoch 3/40
 - 136s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0568 - val_acc: 0.9862
Epoch 4/40
 - 136s - loss: 0.0452 - acc: 0.9892 - val_loss: 0.0606 - val_acc: 0.9859
Epoch 5/40
 - 136s - loss: 0.0443 - acc: 0.9893 - val_loss: 0.0655 - val_acc: 0.9861
Epoch 00005: early stopping
	TRAINING TIME: 12.1 minutes 
==================================================================================================
	PARSING TIME: 4.23 minutes 
==================================================================================================
	Identification : 0.507
	P, R  : 0.484, 0.533

==================================================================================================
	XP Ends: 2/7 (2 h:38)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (2h:38)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 114)      1071714     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 48)       8112        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 59)        554659      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         845         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_112 (Concatenate)   (None, 50, 162)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 236)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 38)           22914       concatenate_112[0][0]            
__________________________________________________________________________________________________
concatenate_113 (Concatenate)   (None, 256)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_114 (Concatenate)   (None, 294)          0           phraseRnn[0][0]                  
                                                                 concatenate_113[0][0]            
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 181)          53395       concatenate_114[0][0]            
__________________________________________________________________________________________________
dense_76 (Dense)                (None, 4)            728         dense_75[0][0]                   
==================================================================================================
Total params: 1,712,367
Trainable params: 1,712,367
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0808 - acc: 0.9782 - val_loss: 0.0605 - val_acc: 0.9837
Epoch 2/40
 - 93s - loss: 0.0537 - acc: 0.9864 - val_loss: 0.0604 - val_acc: 0.9844
Epoch 3/40
 - 93s - loss: 0.0497 - acc: 0.9877 - val_loss: 0.0657 - val_acc: 0.9840
Epoch 4/40
 - 92s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0702 - val_acc: 0.9843
Epoch 5/40
 - 92s - loss: 0.0466 - acc: 0.9885 - val_loss: 0.0787 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 8.2 minutes 
==================================================================================================
	PARSING TIME: 6.6 minutes 
==================================================================================================
	Identification : 0.406
	P, R  : 0.328, 0.533

==================================================================================================
	XP Ends: 2/7 (2 h:53)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (2h:53)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 114)      2516094     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 48)       5232        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 59)        1302189     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         545         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_115 (Concatenate)   (None, 50, 162)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 236)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 38)           22914       concatenate_115[0][0]            
__________________________________________________________________________________________________
concatenate_116 (Concatenate)   (None, 256)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_117 (Concatenate)   (None, 294)          0           phraseRnn[0][0]                  
                                                                 concatenate_116[0][0]            
__________________________________________________________________________________________________
dense_77 (Dense)                (None, 181)          53395       concatenate_117[0][0]            
__________________________________________________________________________________________________
dense_78 (Dense)                (None, 4)            728         dense_77[0][0]                   
==================================================================================================
Total params: 3,901,097
Trainable params: 3,901,097
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 184s - loss: 0.0658 - acc: 0.9828 - val_loss: 0.0621 - val_acc: 0.9844
Epoch 2/40
 - 183s - loss: 0.0494 - acc: 0.9875 - val_loss: 0.0608 - val_acc: 0.9838
Epoch 3/40
 - 183s - loss: 0.0464 - acc: 0.9886 - val_loss: 0.0752 - val_acc: 0.9833
Epoch 4/40
 - 184s - loss: 0.0444 - acc: 0.9891 - val_loss: 0.0785 - val_acc: 0.9833
Epoch 5/40
 - 184s - loss: 0.0434 - acc: 0.9893 - val_loss: 0.0898 - val_acc: 0.9831
Epoch 00005: early stopping
	TRAINING TIME: 16.72 minutes 
==================================================================================================
	PARSING TIME: 2.77 minutes 
==================================================================================================
	Identification : 0.479
	P, R  : 0.414, 0.569

==================================================================================================
	XP Ends: 2/7 (3 h:13)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,196            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.053          ,50             ,8              ,164            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
11             ,118            ,True           ,True           ,451            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 196, False, 0.053, 50, 8, 164, 11, 118, True, True, 451
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (3h:13)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 164)      1237380     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 118)       890310      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1672        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_118 (Concatenate)   (None, 50, 172)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 590)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 451)          1125696     concatenate_118[0][0]            
__________________________________________________________________________________________________
concatenate_119 (Concatenate)   (None, 645)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_120 (Concatenate)   (None, 1096)         0           phraseRnn[0][0]                  
                                                                 concatenate_119[0][0]            
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 196)          215012      concatenate_120[0][0]            
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 4)            788         dense_79[0][0]                   
==================================================================================================
Total params: 3,472,074
Trainable params: 3,472,074
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 374s - loss: 12.0738 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 2/40
 - 374s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 3/40
 - 374s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 4/40
 - 374s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 5/40
 - 374s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 00005: early stopping
	TRAINING TIME: 32.05 minutes 
==================================================================================================
	PARSING TIME: 17.52 minutes 
==================================================================================================
	Identification : 0.0
	P, R  : 0.0, 0.001

==================================================================================================
	XP Ends: 2/7 (4 h:3)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (4h:3)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 164)      1187524     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 118)       854438      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1859        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_121 (Concatenate)   (None, 50, 172)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 590)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 451)          1125696     concatenate_121[0][0]            
__________________________________________________________________________________________________
concatenate_122 (Concatenate)   (None, 645)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_123 (Concatenate)   (None, 1096)         0           phraseRnn[0][0]                  
                                                                 concatenate_122[0][0]            
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 196)          215012      concatenate_123[0][0]            
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 4)            788         dense_81[0][0]                   
==================================================================================================
Total params: 3,386,669
Trainable params: 3,386,669
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 254s - loss: 12.0741 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 2/40
 - 254s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 3/40
 - 254s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 4/40
 - 254s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 5/40
 - 254s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 00005: early stopping
	TRAINING TIME: 21.65 minutes 
==================================================================================================
	PARSING TIME: 31.53 minutes 
==================================================================================================
	Identification : 0.0
	P, R  : 0.0, 0.025

==================================================================================================
	XP Ends: 2/7 (4 h:57)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (4h:57)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 164)      2262052     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 118)       1627574     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1199        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_124 (Concatenate)   (None, 50, 172)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 590)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 451)          1125696     concatenate_124[0][0]            
__________________________________________________________________________________________________
concatenate_125 (Concatenate)   (None, 645)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_126 (Concatenate)   (None, 1096)         0           phraseRnn[0][0]                  
                                                                 concatenate_125[0][0]            
__________________________________________________________________________________________________
dense_83 (Dense)                (None, 196)          215012      concatenate_126[0][0]            
__________________________________________________________________________________________________
dense_84 (Dense)                (None, 4)            788         dense_83[0][0]                   
==================================================================================================
Total params: 5,233,193
Trainable params: 5,233,193
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 507s - loss: 12.0843 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 2/40
 - 507s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 3/40
 - 507s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 4/40
 - 507s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 5/40
 - 507s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 00005: early stopping
	TRAINING TIME: 43.75 minutes 
==================================================================================================
	PARSING TIME: 5.85 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (5 h:47)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,50             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.149          ,50             ,6              ,41             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
14             ,155            ,False          ,True           ,38             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 50, False, 0.149, 50, 6, 41, 14, 155, False, True, 38
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (5h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 41)       309345      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 155)       1169475     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 14)        2128        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_127 (Concatenate)   (None, 50, 47)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 620)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 56)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 38)           13072       concatenate_127[0][0]            
__________________________________________________________________________________________________
concatenate_128 (Concatenate)   (None, 676)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_129 (Concatenate)   (None, 714)          0           phraseRnn[0][0]                  
                                                                 concatenate_128[0][0]            
__________________________________________________________________________________________________
dense_85 (Dense)                (None, 50)           35750       concatenate_129[0][0]            
__________________________________________________________________________________________________
dense_86 (Dense)                (None, 4)            204         dense_85[0][0]                   
==================================================================================================
Total params: 1,530,886
Trainable params: 1,530,886
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 160s - loss: 0.0924 - acc: 0.9802 - val_loss: 0.0572 - val_acc: 0.9851
Epoch 2/40
 - 160s - loss: 0.0524 - acc: 0.9869 - val_loss: 0.0586 - val_acc: 0.9854
Epoch 3/40
 - 160s - loss: 0.0497 - acc: 0.9877 - val_loss: 0.0591 - val_acc: 0.9851
Epoch 4/40
 - 160s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0609 - val_acc: 0.9853
Epoch 5/40
 - 160s - loss: 0.0469 - acc: 0.9886 - val_loss: 0.0630 - val_acc: 0.9854
Epoch 00005: early stopping
	TRAINING TIME: 14.1 minutes 
==================================================================================================
	PARSING TIME: 5.2 minutes 
==================================================================================================
	Identification : 0.599
	P, R  : 0.745, 0.501

==================================================================================================
	XP Ends: 2/7 (6 h:6)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (6h:6)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 41)       296881      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 155)       1122355     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 14)        2366        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_130 (Concatenate)   (None, 50, 47)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 620)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 56)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 38)           13072       concatenate_130[0][0]            
__________________________________________________________________________________________________
concatenate_131 (Concatenate)   (None, 676)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_132 (Concatenate)   (None, 714)          0           phraseRnn[0][0]                  
                                                                 concatenate_131[0][0]            
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 50)           35750       concatenate_132[0][0]            
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 4)            204         dense_87[0][0]                   
==================================================================================================
Total params: 1,471,642
Trainable params: 1,471,642
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0933 - acc: 0.9782 - val_loss: 0.0660 - val_acc: 0.9826
Epoch 2/40
 - 110s - loss: 0.0550 - acc: 0.9859 - val_loss: 0.0672 - val_acc: 0.9825
Epoch 3/40
 - 110s - loss: 0.0511 - acc: 0.9871 - val_loss: 0.0660 - val_acc: 0.9839
Epoch 4/40
 - 110s - loss: 0.0492 - acc: 0.9877 - val_loss: 0.0701 - val_acc: 0.9840
Epoch 5/40
 - 110s - loss: 0.0480 - acc: 0.9882 - val_loss: 0.0739 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 9.73 minutes 
==================================================================================================
	PARSING TIME: 7.93 minutes 
==================================================================================================
	Identification : 0.566
	P, R  : 0.523, 0.617

==================================================================================================
	XP Ends: 2/7 (6 h:24)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (6h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 41)       565513      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 155)       2137915     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 14)        1526        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_133 (Concatenate)   (None, 50, 47)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 620)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 56)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 38)           13072       concatenate_133[0][0]            
__________________________________________________________________________________________________
concatenate_134 (Concatenate)   (None, 676)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_135 (Concatenate)   (None, 714)          0           phraseRnn[0][0]                  
                                                                 concatenate_134[0][0]            
__________________________________________________________________________________________________
dense_89 (Dense)                (None, 50)           35750       concatenate_135[0][0]            
__________________________________________________________________________________________________
dense_90 (Dense)                (None, 4)            204         dense_89[0][0]                   
==================================================================================================
Total params: 2,754,634
Trainable params: 2,754,634
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 217s - loss: 0.1242 - acc: 0.9772 - val_loss: 0.0614 - val_acc: 0.9835
Epoch 2/40
 - 217s - loss: 0.0542 - acc: 0.9857 - val_loss: 0.0600 - val_acc: 0.9841
Epoch 3/40
 - 217s - loss: 0.0514 - acc: 0.9866 - val_loss: 0.0626 - val_acc: 0.9840
Epoch 4/40
 - 217s - loss: 0.0499 - acc: 0.9871 - val_loss: 0.0697 - val_acc: 0.9839
Epoch 5/40
 - 215s - loss: 0.0489 - acc: 0.9874 - val_loss: 0.0729 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 19.52 minutes 
==================================================================================================
	PARSING TIME: 3.52 minutes 
==================================================================================================
	Identification : 0.499
	P, R  : 0.463, 0.541

==================================================================================================
	XP Ends: 2/7 (6 h:48)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,28             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.034          ,50             ,20             ,105            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
25             ,171            ,False          ,False          ,44             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 28, True, 0.034, 50, 20, 105, 25, 171, False, False, 44
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (6h:48)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 105)      1200990     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3040        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 171)       1955898     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 25)        3800        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_136 (Concatenate)   (None, 50, 125)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 513)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 75)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 44)           22440       concatenate_136[0][0]            
__________________________________________________________________________________________________
concatenate_137 (Concatenate)   (None, 588)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_138 (Concatenate)   (None, 632)          0           phraseRnn[0][0]                  
                                                                 concatenate_137[0][0]            
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 28)           17724       concatenate_138[0][0]            
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 4)            116         dense_91[0][0]                   
==================================================================================================
Total params: 3,204,008
Trainable params: 3,204,008
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 137s - loss: 0.0651 - acc: 0.9828 - val_loss: 0.0805 - val_acc: 0.9845
Epoch 2/40
 - 137s - loss: 0.0507 - acc: 0.9873 - val_loss: 0.0552 - val_acc: 0.9861
Epoch 3/40
 - 137s - loss: 0.0477 - acc: 0.9883 - val_loss: 0.0572 - val_acc: 0.9860
Epoch 4/40
 - 137s - loss: 0.0462 - acc: 0.9888 - val_loss: 0.0603 - val_acc: 0.9858
Epoch 5/40
 - 137s - loss: 0.0453 - acc: 0.9891 - val_loss: 0.0643 - val_acc: 0.9855
Epoch 00005: early stopping
	TRAINING TIME: 12.1 minutes 
==================================================================================================
	PARSING TIME: 4.22 minutes 
==================================================================================================
	Identification : 0.512
	P, R  : 0.459, 0.578

==================================================================================================
	XP Ends: 2/7 (7 h:5)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (7h:5)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 105)      987105      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3380        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 171)       1607571     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 25)        4225        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_139 (Concatenate)   (None, 50, 125)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 513)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 75)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 44)           22440       concatenate_139[0][0]            
__________________________________________________________________________________________________
concatenate_140 (Concatenate)   (None, 588)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_141 (Concatenate)   (None, 632)          0           phraseRnn[0][0]                  
                                                                 concatenate_140[0][0]            
__________________________________________________________________________________________________
dense_93 (Dense)                (None, 28)           17724       concatenate_141[0][0]            
__________________________________________________________________________________________________
dense_94 (Dense)                (None, 4)            116         dense_93[0][0]                   
==================================================================================================
Total params: 2,642,561
Trainable params: 2,642,561
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0745 - acc: 0.9796 - val_loss: 0.0605 - val_acc: 0.9837
Epoch 2/40
 - 94s - loss: 0.0546 - acc: 0.9860 - val_loss: 0.0607 - val_acc: 0.9843
Epoch 3/40
 - 94s - loss: 0.0508 - acc: 0.9873 - val_loss: 0.0648 - val_acc: 0.9835
Epoch 4/40
 - 93s - loss: 0.0491 - acc: 0.9879 - val_loss: 0.0689 - val_acc: 0.9836
Epoch 5/40
 - 93s - loss: 0.0479 - acc: 0.9882 - val_loss: 0.0723 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 8.25 minutes 
==================================================================================================
	PARSING TIME: 6.47 minutes 
==================================================================================================
	Identification : 0.382
	P, R  : 0.282, 0.59

==================================================================================================
	XP Ends: 2/7 (7 h:20)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (7h:20)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 105)      2317455     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       2180        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 171)       3774141     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 25)        2725        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_142 (Concatenate)   (None, 50, 125)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 513)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 75)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 44)           22440       concatenate_142[0][0]            
__________________________________________________________________________________________________
concatenate_143 (Concatenate)   (None, 588)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_144 (Concatenate)   (None, 632)          0           phraseRnn[0][0]                  
                                                                 concatenate_143[0][0]            
__________________________________________________________________________________________________
dense_95 (Dense)                (None, 28)           17724       concatenate_144[0][0]            
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 4)            116         dense_95[0][0]                   
==================================================================================================
Total params: 6,136,781
Trainable params: 6,136,781
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 186s - loss: 0.0642 - acc: 0.9829 - val_loss: 0.0606 - val_acc: 0.9837
Epoch 2/40
 - 186s - loss: 0.0511 - acc: 0.9868 - val_loss: 0.0604 - val_acc: 0.9837
Epoch 3/40
 - 185s - loss: 0.0489 - acc: 0.9877 - val_loss: 0.0634 - val_acc: 0.9836
Epoch 4/40
 - 184s - loss: 0.0472 - acc: 0.9881 - val_loss: 0.0690 - val_acc: 0.9832
Epoch 5/40
 - 184s - loss: 0.0460 - acc: 0.9885 - val_loss: 0.0727 - val_acc: 0.9832
Epoch 00005: early stopping
	TRAINING TIME: 16.8 minutes 
==================================================================================================
	PARSING TIME: 2.73 minutes 
==================================================================================================
	Identification : 0.502
	P, R  : 0.446, 0.573

==================================================================================================
	XP Ends: 2/7 (7 h:40)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,28             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.087          ,50             ,12             ,78             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
42             ,150            ,False          ,True           ,300            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 28, False, 0.087, 50, 12, 78, 42, 150, False, True, 300
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (7h:40)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 78)       588510      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1824        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 150)       1131750     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 42)        6384        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_145 (Concatenate)   (None, 50, 90)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 600)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 168)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 300)          469200      concatenate_145[0][0]            
__________________________________________________________________________________________________
concatenate_146 (Concatenate)   (None, 768)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_147 (Concatenate)   (None, 1068)         0           phraseRnn[0][0]                  
                                                                 concatenate_146[0][0]            
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 28)           29932       concatenate_147[0][0]            
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 4)            116         dense_97[0][0]                   
==================================================================================================
Total params: 2,227,716
Trainable params: 2,227,716
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 223s - loss: 12.0816 - acc: 0.2502 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 2/40
 - 223s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 3/40
 - 223s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 4/40
 - 223s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 5/40
 - 223s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 00005: early stopping
	TRAINING TIME: 19.38 minutes 
==================================================================================================
	PARSING TIME: 5.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (8 h:5)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (8h:5)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 78)       564798      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       2028        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 150)       1086150     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 42)        7098        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_148 (Concatenate)   (None, 50, 90)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 600)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 168)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 300)          469200      concatenate_148[0][0]            
__________________________________________________________________________________________________
concatenate_149 (Concatenate)   (None, 768)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_150 (Concatenate)   (None, 1068)         0           phraseRnn[0][0]                  
                                                                 concatenate_149[0][0]            
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 28)           29932       concatenate_150[0][0]            
__________________________________________________________________________________________________
dense_100 (Dense)               (None, 4)            116         dense_99[0][0]                   
==================================================================================================
Total params: 2,159,322
Trainable params: 2,159,322
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 151s - loss: 12.0881 - acc: 0.2496 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 2/40
 - 151s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 3/40
 - 151s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 4/40
 - 151s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 5/40
 - 151s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 00005: early stopping
	TRAINING TIME: 13.12 minutes 
==================================================================================================
	PARSING TIME: 8.12 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (8 h:26)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (8h:26)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 78)       1075854     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1308        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 150)       2068950     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 42)        4578        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_151 (Concatenate)   (None, 50, 90)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 600)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 168)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 300)          469200      concatenate_151[0][0]            
__________________________________________________________________________________________________
concatenate_152 (Concatenate)   (None, 768)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_153 (Concatenate)   (None, 1068)         0           phraseRnn[0][0]                  
                                                                 concatenate_152[0][0]            
__________________________________________________________________________________________________
dense_101 (Dense)               (None, 28)           29932       concatenate_153[0][0]            
__________________________________________________________________________________________________
dense_102 (Dense)               (None, 4)            116         dense_101[0][0]                  
==================================================================================================
Total params: 3,649,938
Trainable params: 3,649,938
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 302s - loss: 0.0761 - acc: 0.9807 - val_loss: 0.0587 - val_acc: 0.9841
Epoch 2/40
 - 302s - loss: 0.0542 - acc: 0.9858 - val_loss: 0.0591 - val_acc: 0.9841
Epoch 3/40
 - 302s - loss: 0.0509 - acc: 0.9871 - val_loss: 0.0619 - val_acc: 0.9837
Epoch 4/40
 - 302s - loss: 0.0489 - acc: 0.9877 - val_loss: 0.0656 - val_acc: 0.9839
Epoch 5/40
 - 302s - loss: 0.0476 - acc: 0.9881 - val_loss: 0.0686 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 26.6 minutes 
==================================================================================================
	PARSING TIME: 3.68 minutes 
==================================================================================================
	Identification : 0.46
	P, R  : 0.546, 0.398

==================================================================================================
	XP Ends: 2/7 (8 h:57)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,241            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.144          ,50             ,33             ,76             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
46             ,134            ,True           ,False          ,244            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 241, False, 0.144, 50, 33, 76, 46, 134, True, False, 244
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (8h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 76)       573420      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 33)       5016        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 134)       1011030     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 46)        6992        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_154 (Concatenate)   (None, 50, 109)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 536)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 184)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 244)          345504      concatenate_154[0][0]            
__________________________________________________________________________________________________
concatenate_155 (Concatenate)   (None, 720)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_156 (Concatenate)   (None, 964)          0           phraseRnn[0][0]                  
                                                                 concatenate_155[0][0]            
__________________________________________________________________________________________________
dense_103 (Dense)               (None, 241)          232565      concatenate_156[0][0]            
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 4)            968         dense_103[0][0]                  
==================================================================================================
Total params: 2,175,495
Trainable params: 2,175,495
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 189s - loss: 12.0859 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 2/40
 - 189s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 3/40
 - 189s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 4/40
 - 189s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 5/40
 - 189s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 00005: early stopping
	TRAINING TIME: 16.58 minutes 
==================================================================================================
	PARSING TIME: 9.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (9 h:23)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (9h:23)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 76)       550316      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 33)       5577        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 134)       970294      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 46)        7774        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_157 (Concatenate)   (None, 50, 109)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 536)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 184)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 244)          345504      concatenate_157[0][0]            
__________________________________________________________________________________________________
concatenate_158 (Concatenate)   (None, 720)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_159 (Concatenate)   (None, 964)          0           phraseRnn[0][0]                  
                                                                 concatenate_158[0][0]            
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 241)          232565      concatenate_159[0][0]            
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 4)            968         dense_105[0][0]                  
==================================================================================================
Total params: 2,112,998
Trainable params: 2,112,998
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 128s - loss: 12.0762 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 2/40
 - 128s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 3/40
 - 128s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 4/40
 - 128s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 5/40
 - 128s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 00005: early stopping
	TRAINING TIME: 11.15 minutes 
==================================================================================================
	PARSING TIME: 14.08 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (9 h:49)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (9h:49)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 76)       1048268     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 33)       3597        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 134)       1848262     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 46)        5014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_160 (Concatenate)   (None, 50, 109)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 536)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 184)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 244)          345504      concatenate_160[0][0]            
__________________________________________________________________________________________________
concatenate_161 (Concatenate)   (None, 720)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_162 (Concatenate)   (None, 964)          0           phraseRnn[0][0]                  
                                                                 concatenate_161[0][0]            
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 241)          232565      concatenate_162[0][0]            
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 4)            968         dense_107[0][0]                  
==================================================================================================
Total params: 3,484,178
Trainable params: 3,484,178
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 255s - loss: 12.0878 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 2/40
 - 255s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 3/40
 - 255s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 4/40
 - 255s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 5/40
 - 255s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 00005: early stopping
	TRAINING TIME: 22.7 minutes 
==================================================================================================
	PARSING TIME: 6.12 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (10 h:18)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,167            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.054          ,50             ,45             ,104            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
5              ,34             ,True           ,False          ,29             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 167, False, 0.054, 50, 45, 104, 5, 34, True, False, 29
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (10h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 104)      1189552     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 45)       6840        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 34)        388892      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         760         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_163 (Concatenate)   (None, 50, 149)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 136)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 29)           20764       concatenate_163[0][0]            
__________________________________________________________________________________________________
concatenate_164 (Concatenate)   (None, 156)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_165 (Concatenate)   (None, 185)          0           phraseRnn[0][0]                  
                                                                 concatenate_164[0][0]            
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 167)          31062       concatenate_165[0][0]            
__________________________________________________________________________________________________
dense_110 (Dense)               (None, 4)            672         dense_109[0][0]                  
==================================================================================================
Total params: 1,638,542
Trainable params: 1,638,542
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 161s - loss: 0.0653 - acc: 0.9830 - val_loss: 0.0544 - val_acc: 0.9862
Epoch 2/40
 - 161s - loss: 0.0497 - acc: 0.9877 - val_loss: 0.0566 - val_acc: 0.9857
Epoch 3/40
 - 161s - loss: 0.0468 - acc: 0.9887 - val_loss: 0.0582 - val_acc: 0.9860
Epoch 4/40
 - 161s - loss: 0.0452 - acc: 0.9891 - val_loss: 0.0633 - val_acc: 0.9861
Epoch 5/40
 - 161s - loss: 0.0444 - acc: 0.9893 - val_loss: 0.0688 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 14.23 minutes 
==================================================================================================
	PARSING TIME: 5.33 minutes 
==================================================================================================
	Identification : 0.531
	P, R  : 0.538, 0.524

==================================================================================================
	XP Ends: 2/7 (10 h:38)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (10h:38)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 104)      977704      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 45)       7605        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 34)        319634      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         845         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_166 (Concatenate)   (None, 50, 149)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 136)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 29)           20764       concatenate_166[0][0]            
__________________________________________________________________________________________________
concatenate_167 (Concatenate)   (None, 156)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_168 (Concatenate)   (None, 185)          0           phraseRnn[0][0]                  
                                                                 concatenate_167[0][0]            
__________________________________________________________________________________________________
dense_111 (Dense)               (None, 167)          31062       concatenate_168[0][0]            
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 4)            672         dense_111[0][0]                  
==================================================================================================
Total params: 1,358,286
Trainable params: 1,358,286
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 112s - loss: 0.0768 - acc: 0.9787 - val_loss: 0.0623 - val_acc: 0.9828
Epoch 2/40
 - 111s - loss: 0.0542 - acc: 0.9862 - val_loss: 0.0600 - val_acc: 0.9843
Epoch 3/40
 - 111s - loss: 0.0501 - acc: 0.9876 - val_loss: 0.0638 - val_acc: 0.9842
Epoch 4/40
 - 111s - loss: 0.0480 - acc: 0.9882 - val_loss: 0.0715 - val_acc: 0.9838
Epoch 5/40
 - 111s - loss: 0.0465 - acc: 0.9885 - val_loss: 0.0800 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 9.85 minutes 
==================================================================================================
	PARSING TIME: 8.07 minutes 
==================================================================================================
	Identification : 0.409
	P, R  : 0.317, 0.575

==================================================================================================
	XP Ends: 2/7 (10 h:56)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (10h:56)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 104)      2295384     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 45)       4905        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 34)        750414      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         545         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_169 (Concatenate)   (None, 50, 149)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 136)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 29)           20764       concatenate_169[0][0]            
__________________________________________________________________________________________________
concatenate_170 (Concatenate)   (None, 156)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_171 (Concatenate)   (None, 185)          0           phraseRnn[0][0]                  
                                                                 concatenate_170[0][0]            
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 167)          31062       concatenate_171[0][0]            
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 4)            672         dense_113[0][0]                  
==================================================================================================
Total params: 3,103,746
Trainable params: 3,103,746
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 219s - loss: 0.0637 - acc: 0.9829 - val_loss: 0.0585 - val_acc: 0.9842
Epoch 2/40
 - 220s - loss: 0.0496 - acc: 0.9875 - val_loss: 0.0604 - val_acc: 0.9842
Epoch 3/40
 - 219s - loss: 0.0465 - acc: 0.9886 - val_loss: 0.0691 - val_acc: 0.9838
Epoch 4/40
 - 219s - loss: 0.0445 - acc: 0.9891 - val_loss: 0.0826 - val_acc: 0.9833
Epoch 5/40
 - 219s - loss: 0.0434 - acc: 0.9893 - val_loss: 0.0941 - val_acc: 0.9833
Epoch 00005: early stopping
	TRAINING TIME: 19.75 minutes 
==================================================================================================
	PARSING TIME: 3.5 minutes 
==================================================================================================
	Identification : 0.499
	P, R  : 0.429, 0.596

==================================================================================================
	XP Ends: 2/7 (11 h:20)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,444            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.075          ,50             ,40             ,169            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
7              ,43             ,True           ,True           ,356            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 444, True, 0.075, 50, 40, 169, 7, 43, True, True, 356
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (11h:20)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 169)      1275105     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 40)       6080        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 43)        324435      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1064        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_172 (Concatenate)   (None, 50, 209)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 215)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 356)          604488      concatenate_172[0][0]            
__________________________________________________________________________________________________
concatenate_173 (Concatenate)   (None, 250)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_174 (Concatenate)   (None, 606)          0           phraseRnn[0][0]                  
                                                                 concatenate_173[0][0]            
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 444)          269508      concatenate_174[0][0]            
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 4)            1780        dense_115[0][0]                  
==================================================================================================
Total params: 2,482,460
Trainable params: 2,482,460
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 238s - loss: 12.0963 - acc: 0.2492 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 2/40
 - 238s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 3/40
 - 238s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 4/40
 - 238s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 5/40
 - 238s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 00005: early stopping
	TRAINING TIME: 20.68 minutes 
==================================================================================================
	PARSING TIME: 10.83 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.007

==================================================================================================
	XP Ends: 2/7 (11 h:52)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (11h:52)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 169)      1223729     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 40)       6760        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 43)        311363      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1183        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_175 (Concatenate)   (None, 50, 209)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 215)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 356)          604488      concatenate_175[0][0]            
__________________________________________________________________________________________________
concatenate_176 (Concatenate)   (None, 250)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_177 (Concatenate)   (None, 606)          0           phraseRnn[0][0]                  
                                                                 concatenate_176[0][0]            
__________________________________________________________________________________________________
dense_117 (Dense)               (None, 444)          269508      concatenate_177[0][0]            
__________________________________________________________________________________________________
dense_118 (Dense)               (None, 4)            1780        dense_117[0][0]                  
==================================================================================================
Total params: 2,418,811
Trainable params: 2,418,811
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 161s - loss: 12.0731 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 2/40
 - 161s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 3/40
 - 161s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 4/40
 - 161s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 5/40
 - 161s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 00005: early stopping
	TRAINING TIME: 13.93 minutes 
==================================================================================================
	PARSING TIME: 15.67 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (12 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (12h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 169)      2331017     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 40)       4360        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 43)        593099      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         763         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_178 (Concatenate)   (None, 50, 209)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 215)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 356)          604488      concatenate_178[0][0]            
__________________________________________________________________________________________________
concatenate_179 (Concatenate)   (None, 250)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_180 (Concatenate)   (None, 606)          0           phraseRnn[0][0]                  
                                                                 concatenate_179[0][0]            
__________________________________________________________________________________________________
dense_119 (Dense)               (None, 444)          269508      concatenate_180[0][0]            
__________________________________________________________________________________________________
dense_120 (Dense)               (None, 4)            1780        dense_119[0][0]                  
==================================================================================================
Total params: 3,805,015
Trainable params: 3,805,015
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 322s - loss: 12.0886 - acc: 0.2498 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 2/40
 - 322s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 3/40
 - 322s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 4/40
 - 322s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 5/40
 - 322s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 00005: early stopping
	TRAINING TIME: 28.25 minutes 
==================================================================================================
	PARSING TIME: 6.82 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (12 h:57)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,44             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.031          ,50             ,7              ,70             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
11             ,132            ,True           ,True           ,25             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 44, False, 0.031, 50, 7, 70, 11, 132, True, True, 25
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (12h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 70)       528150      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 132)       995940      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1672        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_181 (Concatenate)   (None, 50, 77)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 660)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 25)           10300       concatenate_181[0][0]            
__________________________________________________________________________________________________
concatenate_182 (Concatenate)   (None, 715)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_183 (Concatenate)   (None, 740)          0           phraseRnn[0][0]                  
                                                                 concatenate_182[0][0]            
__________________________________________________________________________________________________
dense_121 (Dense)               (None, 44)           32604       concatenate_183[0][0]            
__________________________________________________________________________________________________
dense_122 (Dense)               (None, 4)            180         dense_121[0][0]                  
==================================================================================================
Total params: 1,569,910
Trainable params: 1,569,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 160s - loss: 0.0641 - acc: 0.9832 - val_loss: 0.0549 - val_acc: 0.9858
Epoch 2/40
 - 161s - loss: 0.0498 - acc: 0.9877 - val_loss: 0.0556 - val_acc: 0.9861
Epoch 3/40
 - 160s - loss: 0.0469 - acc: 0.9886 - val_loss: 0.0571 - val_acc: 0.9860
Epoch 4/40
 - 161s - loss: 0.0456 - acc: 0.9891 - val_loss: 0.0588 - val_acc: 0.9860
Epoch 5/40
 - 160s - loss: 0.0447 - acc: 0.9892 - val_loss: 0.0633 - val_acc: 0.9857
Epoch 00005: early stopping
	TRAINING TIME: 14.22 minutes 
==================================================================================================
	PARSING TIME: 5.2 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.771, 0.482

==================================================================================================
	XP Ends: 2/7 (13 h:17)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (13h:17)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 70)       506870      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 132)       955812      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1859        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_184 (Concatenate)   (None, 50, 77)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 660)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 25)           10300       concatenate_184[0][0]            
__________________________________________________________________________________________________
concatenate_185 (Concatenate)   (None, 715)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_186 (Concatenate)   (None, 740)          0           phraseRnn[0][0]                  
                                                                 concatenate_185[0][0]            
__________________________________________________________________________________________________
dense_123 (Dense)               (None, 44)           32604       concatenate_186[0][0]            
__________________________________________________________________________________________________
dense_124 (Dense)               (None, 4)            180         dense_123[0][0]                  
==================================================================================================
Total params: 1,508,808
Trainable params: 1,508,808
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0724 - acc: 0.9805 - val_loss: 0.0595 - val_acc: 0.9843
Epoch 2/40
 - 110s - loss: 0.0522 - acc: 0.9869 - val_loss: 0.0596 - val_acc: 0.9848
Epoch 3/40
 - 110s - loss: 0.0490 - acc: 0.9880 - val_loss: 0.1310 - val_acc: 0.9628
Epoch 4/40
 - 109s - loss: 0.0477 - acc: 0.9883 - val_loss: 0.0640 - val_acc: 0.9847
Epoch 5/40
 - 109s - loss: 0.0465 - acc: 0.9886 - val_loss: 0.0688 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 9.73 minutes 
==================================================================================================
	PARSING TIME: 7.98 minutes 
==================================================================================================
	Identification : 0.491
	P, R  : 0.41, 0.611

==================================================================================================
	XP Ends: 2/7 (13 h:35)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (13h:35)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 70)       965510      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 132)       1820676     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1199        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_187 (Concatenate)   (None, 50, 77)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 660)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 25)           10300       concatenate_187[0][0]            
__________________________________________________________________________________________________
concatenate_188 (Concatenate)   (None, 715)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_189 (Concatenate)   (None, 740)          0           phraseRnn[0][0]                  
                                                                 concatenate_188[0][0]            
__________________________________________________________________________________________________
dense_125 (Dense)               (None, 44)           32604       concatenate_189[0][0]            
__________________________________________________________________________________________________
dense_126 (Dense)               (None, 4)            180         dense_125[0][0]                  
==================================================================================================
Total params: 2,831,232
Trainable params: 2,831,232
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 218s - loss: 0.0651 - acc: 0.9823 - val_loss: 0.0566 - val_acc: 0.9846
Epoch 2/40
 - 218s - loss: 0.0513 - acc: 0.9870 - val_loss: 0.0602 - val_acc: 0.9836
Epoch 3/40
 - 218s - loss: 0.0485 - acc: 0.9879 - val_loss: 0.0613 - val_acc: 0.9844
Epoch 4/40
 - 218s - loss: 0.0470 - acc: 0.9885 - val_loss: 0.0640 - val_acc: 0.9841
Epoch 5/40
 - 218s - loss: 0.0458 - acc: 0.9888 - val_loss: 0.0692 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 19.68 minutes 
==================================================================================================
	PARSING TIME: 3.45 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.512, 0.482

==================================================================================================
	XP Ends: 2/7 (13 h:59)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,171            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.014          ,50             ,7              ,32             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
11             ,116            ,False          ,True           ,414            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 171, True, 0.014, 50, 7, 32, 11, 116, False, True, 414
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (13h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 32)       366016      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 116)       1326808     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 11)        1672        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_190 (Concatenate)   (None, 50, 39)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 464)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 44)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 414)          563868      concatenate_190[0][0]            
__________________________________________________________________________________________________
concatenate_191 (Concatenate)   (None, 508)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_192 (Concatenate)   (None, 922)          0           phraseRnn[0][0]                  
                                                                 concatenate_191[0][0]            
__________________________________________________________________________________________________
dense_127 (Dense)               (None, 171)          157833      concatenate_192[0][0]            
__________________________________________________________________________________________________
dense_128 (Dense)               (None, 4)            688         dense_127[0][0]                  
==================================================================================================
Total params: 2,417,949
Trainable params: 2,417,949
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 234s - loss: 0.1093 - acc: 0.9734 - val_loss: 0.0651 - val_acc: 0.9834
Epoch 2/40
 - 235s - loss: 0.0579 - acc: 0.9853 - val_loss: 0.0631 - val_acc: 0.9846
Epoch 3/40
 - 235s - loss: 0.0530 - acc: 0.9869 - val_loss: 0.0633 - val_acc: 0.9845
Epoch 4/40
 - 234s - loss: 0.0505 - acc: 0.9875 - val_loss: 0.0641 - val_acc: 0.9846
Epoch 5/40
 - 234s - loss: 0.0490 - acc: 0.9880 - val_loss: 0.0660 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 20.33 minutes 
==================================================================================================
	PARSING TIME: 5.6 minutes 
==================================================================================================
	Identification : 0.517
	P, R  : 0.729, 0.401

==================================================================================================
	XP Ends: 2/7 (14 h:25)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (14h:25)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 32)       300832      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 116)       1090516     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 11)        1859        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_193 (Concatenate)   (None, 50, 39)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 464)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 44)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 414)          563868      concatenate_193[0][0]            
__________________________________________________________________________________________________
concatenate_194 (Concatenate)   (None, 508)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_195 (Concatenate)   (None, 922)          0           phraseRnn[0][0]                  
                                                                 concatenate_194[0][0]            
__________________________________________________________________________________________________
dense_129 (Dense)               (None, 171)          157833      concatenate_195[0][0]            
__________________________________________________________________________________________________
dense_130 (Dense)               (None, 4)            688         dense_129[0][0]                  
==================================================================================================
Total params: 2,116,779
Trainable params: 2,116,779
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 160s - loss: 0.1193 - acc: 0.9678 - val_loss: 0.0710 - val_acc: 0.9806
Epoch 2/40
 - 160s - loss: 0.0623 - acc: 0.9838 - val_loss: 0.0665 - val_acc: 0.9830
Epoch 3/40
 - 160s - loss: 0.0563 - acc: 0.9856 - val_loss: 0.0698 - val_acc: 0.9824
Epoch 4/40
 - 160s - loss: 0.0534 - acc: 0.9865 - val_loss: 0.1070 - val_acc: 0.9790
Epoch 5/40
 - 160s - loss: 0.0518 - acc: 0.9868 - val_loss: 0.0740 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 13.8 minutes 
==================================================================================================
	PARSING TIME: 8.47 minutes 
==================================================================================================
	Identification : 0.52
	P, R  : 0.545, 0.497

==================================================================================================
	XP Ends: 2/7 (14 h:48)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (14h:48)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 32)       706272      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 116)       2560236     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 11)        1199        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_196 (Concatenate)   (None, 50, 39)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 464)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 44)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 414)          563868      concatenate_196[0][0]            
__________________________________________________________________________________________________
concatenate_197 (Concatenate)   (None, 508)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_198 (Concatenate)   (None, 922)          0           phraseRnn[0][0]                  
                                                                 concatenate_197[0][0]            
__________________________________________________________________________________________________
dense_131 (Dense)               (None, 171)          157833      concatenate_198[0][0]            
__________________________________________________________________________________________________
dense_132 (Dense)               (None, 4)            688         dense_131[0][0]                  
==================================================================================================
Total params: 3,990,859
Trainable params: 3,990,859
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 321s - loss: 0.0879 - acc: 0.9771 - val_loss: 0.0685 - val_acc: 0.9810
Epoch 2/40
 - 321s - loss: 0.0549 - acc: 0.9859 - val_loss: 0.0670 - val_acc: 0.9828
Epoch 3/40
 - 321s - loss: 0.0506 - acc: 0.9872 - val_loss: 0.0676 - val_acc: 0.9833
Epoch 4/40
 - 321s - loss: 0.0484 - acc: 0.9879 - val_loss: 0.0718 - val_acc: 0.9828
Epoch 5/40
 - 321s - loss: 0.0471 - acc: 0.9883 - val_loss: 0.0741 - val_acc: 0.9828
Epoch 00005: early stopping
	TRAINING TIME: 28.15 minutes 
==================================================================================================
	PARSING TIME: 3.8 minutes 
==================================================================================================
	Identification : 0.507
	P, R  : 0.459, 0.567

==================================================================================================
	XP Ends: 2/7 (15 h:20)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,60             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.033          ,50             ,7              ,99             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
19             ,131            ,True           ,True           ,83             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 60, True, 0.033, 50, 7, 99, 19, 131, True, True, 83
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (15h:20)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 99)       1132362     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 131)       1498378     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 19)        2888        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_199 (Concatenate)   (None, 50, 106)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 655)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 95)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 83)           47310       concatenate_199[0][0]            
__________________________________________________________________________________________________
concatenate_200 (Concatenate)   (None, 750)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_201 (Concatenate)   (None, 833)          0           phraseRnn[0][0]                  
                                                                 concatenate_200[0][0]            
__________________________________________________________________________________________________
dense_133 (Dense)               (None, 60)           50040       concatenate_201[0][0]            
__________________________________________________________________________________________________
dense_134 (Dense)               (None, 4)            244         dense_133[0][0]                  
==================================================================================================
Total params: 2,732,286
Trainable params: 2,732,286
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 140s - loss: 0.0634 - acc: 0.9833 - val_loss: 0.0527 - val_acc: 0.9863
Epoch 2/40
 - 138s - loss: 0.0484 - acc: 0.9882 - val_loss: 0.0538 - val_acc: 0.9864
Epoch 3/40
 - 138s - loss: 0.0459 - acc: 0.9890 - val_loss: 0.0560 - val_acc: 0.9864
Epoch 4/40
 - 138s - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0597 - val_acc: 0.9865
Epoch 5/40
 - 139s - loss: 0.0442 - acc: 0.9894 - val_loss: 0.0628 - val_acc: 0.9865
Epoch 00005: early stopping
	TRAINING TIME: 12.35 minutes 
==================================================================================================
	PARSING TIME: 4.15 minutes 
==================================================================================================
	Identification : 0.538
	P, R  : 0.493, 0.593

==================================================================================================
	XP Ends: 2/7 (15 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (15h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 99)       930699      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 131)       1231531     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 19)        3211        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_202 (Concatenate)   (None, 50, 106)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 655)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 95)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 83)           47310       concatenate_202[0][0]            
__________________________________________________________________________________________________
concatenate_203 (Concatenate)   (None, 750)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_204 (Concatenate)   (None, 833)          0           phraseRnn[0][0]                  
                                                                 concatenate_203[0][0]            
__________________________________________________________________________________________________
dense_135 (Dense)               (None, 60)           50040       concatenate_204[0][0]            
__________________________________________________________________________________________________
dense_136 (Dense)               (None, 4)            244         dense_135[0][0]                  
==================================================================================================
Total params: 2,264,218
Trainable params: 2,264,218
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0742 - acc: 0.9798 - val_loss: 0.0573 - val_acc: 0.9851
Epoch 2/40
 - 93s - loss: 0.0520 - acc: 0.9870 - val_loss: 0.0587 - val_acc: 0.9849
Epoch 3/40
 - 93s - loss: 0.0485 - acc: 0.9882 - val_loss: 0.0622 - val_acc: 0.9850
Epoch 4/40
 - 92s - loss: 0.0471 - acc: 0.9885 - val_loss: 0.0661 - val_acc: 0.9848
Epoch 5/40
 - 92s - loss: 0.0464 - acc: 0.9885 - val_loss: 0.0727 - val_acc: 0.9846
Epoch 00005: early stopping
	TRAINING TIME: 8.2 minutes 
==================================================================================================
	PARSING TIME: 6.4 minutes 
==================================================================================================
	Identification : 0.447
	P, R  : 0.344, 0.638

==================================================================================================
	XP Ends: 2/7 (15 h:52)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (15h:52)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 99)       2185029     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 131)       2891301     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 19)        2071        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_205 (Concatenate)   (None, 50, 106)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 655)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 95)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 83)           47310       concatenate_205[0][0]            
__________________________________________________________________________________________________
concatenate_206 (Concatenate)   (None, 750)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_207 (Concatenate)   (None, 833)          0           phraseRnn[0][0]                  
                                                                 concatenate_206[0][0]            
__________________________________________________________________________________________________
dense_137 (Dense)               (None, 60)           50040       concatenate_207[0][0]            
__________________________________________________________________________________________________
dense_138 (Dense)               (None, 4)            244         dense_137[0][0]                  
==================================================================================================
Total params: 5,176,758
Trainable params: 5,176,758
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 184s - loss: 0.0623 - acc: 0.9833 - val_loss: 0.0574 - val_acc: 0.9846
Epoch 2/40
 - 183s - loss: 0.0483 - acc: 0.9881 - val_loss: 0.0584 - val_acc: 0.9846
Epoch 3/40
 - 184s - loss: 0.0458 - acc: 0.9890 - val_loss: 0.0620 - val_acc: 0.9845
Epoch 4/40
 - 184s - loss: 0.0444 - acc: 0.9892 - val_loss: 0.0737 - val_acc: 0.9842
Epoch 5/40
 - 182s - loss: 0.0432 - acc: 0.9894 - val_loss: 0.0815 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 16.75 minutes 
==================================================================================================
	PARSING TIME: 2.72 minutes 
==================================================================================================
	Identification : 0.494
	P, R  : 0.451, 0.545

==================================================================================================
	XP Ends: 2/7 (16 h:12)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,70             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.029          ,50             ,16             ,89             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
9              ,104            ,True           ,True           ,27             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 70, False, 0.029, 50, 16, 89, 9, 104, True, True, 27
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (16h:12)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 89)       671505      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 16)       2432        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 104)       784680      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         1368        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_208 (Concatenate)   (None, 50, 105)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 520)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 27)           14364       concatenate_208[0][0]            
__________________________________________________________________________________________________
concatenate_209 (Concatenate)   (None, 565)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_210 (Concatenate)   (None, 592)          0           phraseRnn[0][0]                  
                                                                 concatenate_209[0][0]            
__________________________________________________________________________________________________
dense_139 (Dense)               (None, 70)           41510       concatenate_210[0][0]            
__________________________________________________________________________________________________
dense_140 (Dense)               (None, 4)            284         dense_139[0][0]                  
==================================================================================================
Total params: 1,516,143
Trainable params: 1,516,143
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 161s - loss: 0.0642 - acc: 0.9832 - val_loss: 0.0549 - val_acc: 0.9861
Epoch 2/40
 - 161s - loss: 0.0498 - acc: 0.9878 - val_loss: 0.0551 - val_acc: 0.9861
Epoch 3/40
 - 161s - loss: 0.0469 - acc: 0.9886 - val_loss: 0.0581 - val_acc: 0.9860
Epoch 4/40
 - 161s - loss: 0.0454 - acc: 0.9891 - val_loss: 0.0611 - val_acc: 0.9857
Epoch 5/40
 - 161s - loss: 0.0445 - acc: 0.9893 - val_loss: 0.0658 - val_acc: 0.9856
Epoch 00005: early stopping
	TRAINING TIME: 14.12 minutes 
==================================================================================================
	PARSING TIME: 5.17 minutes 
==================================================================================================
	Identification : 0.559
	P, R  : 0.689, 0.47

==================================================================================================
	XP Ends: 2/7 (16 h:31)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (16h:31)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 89)       644449      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 16)       2704        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 104)       753064      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         1521        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_211 (Concatenate)   (None, 50, 105)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 520)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 27)           14364       concatenate_211[0][0]            
__________________________________________________________________________________________________
concatenate_212 (Concatenate)   (None, 565)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_213 (Concatenate)   (None, 592)          0           phraseRnn[0][0]                  
                                                                 concatenate_212[0][0]            
__________________________________________________________________________________________________
dense_141 (Dense)               (None, 70)           41510       concatenate_213[0][0]            
__________________________________________________________________________________________________
dense_142 (Dense)               (None, 4)            284         dense_141[0][0]                  
==================================================================================================
Total params: 1,457,896
Trainable params: 1,457,896
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 0.0739 - acc: 0.9800 - val_loss: 0.0689 - val_acc: 0.9842
Epoch 2/40
 - 109s - loss: 0.0525 - acc: 0.9867 - val_loss: 0.0591 - val_acc: 0.9848
Epoch 3/40
 - 109s - loss: 0.0490 - acc: 0.9879 - val_loss: 0.0608 - val_acc: 0.9851
Epoch 4/40
 - 109s - loss: 0.0474 - acc: 0.9884 - val_loss: 0.0635 - val_acc: 0.9847
Epoch 5/40
 - 109s - loss: 0.0465 - acc: 0.9887 - val_loss: 0.0675 - val_acc: 0.9848
Epoch 00005: early stopping
	TRAINING TIME: 9.62 minutes 
==================================================================================================
	PARSING TIME: 7.93 minutes 
==================================================================================================
	Identification : 0.52
	P, R  : 0.449, 0.617

==================================================================================================
	XP Ends: 2/7 (16 h:49)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (16h:49)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 89)       1227577     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 16)       1744        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 104)       1434472     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         981         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_214 (Concatenate)   (None, 50, 105)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 520)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 27)           14364       concatenate_214[0][0]            
__________________________________________________________________________________________________
concatenate_215 (Concatenate)   (None, 565)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_216 (Concatenate)   (None, 592)          0           phraseRnn[0][0]                  
                                                                 concatenate_215[0][0]            
__________________________________________________________________________________________________
dense_143 (Dense)               (None, 70)           41510       concatenate_216[0][0]            
__________________________________________________________________________________________________
dense_144 (Dense)               (None, 4)            284         dense_143[0][0]                  
==================================================================================================
Total params: 2,720,932
Trainable params: 2,720,932
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 218s - loss: 0.0658 - acc: 0.9822 - val_loss: 0.0571 - val_acc: 0.9846
Epoch 2/40
 - 218s - loss: 0.0514 - acc: 0.9869 - val_loss: 0.0574 - val_acc: 0.9847
Epoch 3/40
 - 218s - loss: 0.0484 - acc: 0.9880 - val_loss: 0.0601 - val_acc: 0.9846
Epoch 4/40
 - 218s - loss: 0.0468 - acc: 0.9886 - val_loss: 0.0654 - val_acc: 0.9842
Epoch 5/40
 - 217s - loss: 0.0457 - acc: 0.9889 - val_loss: 0.0696 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 19.62 minutes 
==================================================================================================
	PARSING TIME: 3.58 minutes 
==================================================================================================
	Identification : 0.462
	P, R  : 0.501, 0.429

==================================================================================================
	XP Ends: 2/7 (17 h:13)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,468            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.195          ,50             ,5              ,49             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
16             ,52             ,True           ,False          ,62             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 468, True, 0.195, 50, 5, 49, 16, 52, True, False, 62
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (17h:13)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 49)       560462      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 52)        594776      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 16)        2432        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_217 (Concatenate)   (None, 50, 54)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 208)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 64)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 62)           21762       concatenate_217[0][0]            
__________________________________________________________________________________________________
concatenate_218 (Concatenate)   (None, 272)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_219 (Concatenate)   (None, 334)          0           phraseRnn[0][0]                  
                                                                 concatenate_218[0][0]            
__________________________________________________________________________________________________
dense_145 (Dense)               (None, 468)          156780      concatenate_219[0][0]            
__________________________________________________________________________________________________
dense_146 (Dense)               (None, 4)            1876        dense_145[0][0]                  
==================================================================================================
Total params: 1,338,848
Trainable params: 1,338,848
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 12.0873 - acc: 0.2499 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 2/40
 - 136s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 3/40
 - 135s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 4/40
 - 135s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 5/40
 - 135s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 12.05 minutes 
==================================================================================================
	PARSING TIME: 7.63 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (17 h:33)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (17h:33)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 49)       460649      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 52)        488852      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 16)        2704        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_220 (Concatenate)   (None, 50, 54)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 208)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 64)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 62)           21762       concatenate_220[0][0]            
__________________________________________________________________________________________________
concatenate_221 (Concatenate)   (None, 272)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_222 (Concatenate)   (None, 334)          0           phraseRnn[0][0]                  
                                                                 concatenate_221[0][0]            
__________________________________________________________________________________________________
dense_147 (Dense)               (None, 468)          156780      concatenate_222[0][0]            
__________________________________________________________________________________________________
dense_148 (Dense)               (None, 4)            1876        dense_147[0][0]                  
==================================================================================================
Total params: 1,133,468
Trainable params: 1,133,468
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 92s - loss: 12.0965 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 2/40
 - 92s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 3/40
 - 92s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 4/40
 - 92s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 5/40
 - 92s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 00005: early stopping
	TRAINING TIME: 8.15 minutes 
==================================================================================================
	PARSING TIME: 11.6 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (17 h:53)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (17h:53)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 49)       1081479     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 52)        1147692     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 16)        1744        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_223 (Concatenate)   (None, 50, 54)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 208)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 64)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 62)           21762       concatenate_223[0][0]            
__________________________________________________________________________________________________
concatenate_224 (Concatenate)   (None, 272)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_225 (Concatenate)   (None, 334)          0           phraseRnn[0][0]                  
                                                                 concatenate_224[0][0]            
__________________________________________________________________________________________________
dense_149 (Dense)               (None, 468)          156780      concatenate_225[0][0]            
__________________________________________________________________________________________________
dense_150 (Dense)               (None, 4)            1876        dense_149[0][0]                  
==================================================================================================
Total params: 2,411,878
Trainable params: 2,411,878
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 180s - loss: 12.0848 - acc: 0.2501 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 2/40
 - 180s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 3/40
 - 180s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 4/40
 - 180s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 5/40
 - 180s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 00005: early stopping
	TRAINING TIME: 16.45 minutes 
==================================================================================================
	PARSING TIME: 2.58 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (18 h:13)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,105            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.051          ,50             ,20             ,50             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,64             ,True           ,True           ,141            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 105, False, 0.051, 50, 20, 50, 8, 64, True, True, 141
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (18h:13)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 50)       571900      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3040        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 64)        732032      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_226 (Concatenate)   (None, 50, 70)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 320)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 141)          119568      concatenate_226[0][0]            
__________________________________________________________________________________________________
concatenate_227 (Concatenate)   (None, 360)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_228 (Concatenate)   (None, 501)          0           phraseRnn[0][0]                  
                                                                 concatenate_227[0][0]            
__________________________________________________________________________________________________
dense_151 (Dense)               (None, 105)          52710       concatenate_228[0][0]            
__________________________________________________________________________________________________
dense_152 (Dense)               (None, 4)            424         dense_151[0][0]                  
==================================================================================================
Total params: 1,480,890
Trainable params: 1,480,890
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 161s - loss: 0.0812 - acc: 0.9813 - val_loss: 0.0543 - val_acc: 0.9858
Epoch 2/40
 - 161s - loss: 0.0496 - acc: 0.9878 - val_loss: 0.0548 - val_acc: 0.9863
Epoch 3/40
 - 161s - loss: 0.0467 - acc: 0.9887 - val_loss: 0.0570 - val_acc: 0.9862
Epoch 4/40
 - 161s - loss: 0.0453 - acc: 0.9892 - val_loss: 0.0600 - val_acc: 0.9862
Epoch 5/40
 - 161s - loss: 0.0445 - acc: 0.9893 - val_loss: 0.0642 - val_acc: 0.9861
Epoch 00005: early stopping
	TRAINING TIME: 14.2 minutes 
==================================================================================================
	PARSING TIME: 5.32 minutes 
==================================================================================================
	Identification : 0.55
	P, R  : 0.543, 0.557

==================================================================================================
	XP Ends: 2/7 (18 h:32)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (18h:32)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 50)       470050      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3380        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 64)        601664      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_229 (Concatenate)   (None, 50, 70)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 320)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 141)          119568      concatenate_229[0][0]            
__________________________________________________________________________________________________
concatenate_230 (Concatenate)   (None, 360)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_231 (Concatenate)   (None, 501)          0           phraseRnn[0][0]                  
                                                                 concatenate_230[0][0]            
__________________________________________________________________________________________________
dense_153 (Dense)               (None, 105)          52710       concatenate_231[0][0]            
__________________________________________________________________________________________________
dense_154 (Dense)               (None, 4)            424         dense_153[0][0]                  
==================================================================================================
Total params: 1,249,148
Trainable params: 1,249,148
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 0.0925 - acc: 0.9768 - val_loss: 0.0588 - val_acc: 0.9844
Epoch 2/40
 - 109s - loss: 0.0539 - acc: 0.9863 - val_loss: 0.0597 - val_acc: 0.9845
Epoch 3/40
 - 108s - loss: 0.0502 - acc: 0.9875 - val_loss: 0.0619 - val_acc: 0.9845
Epoch 4/40
 - 108s - loss: 0.0482 - acc: 0.9882 - val_loss: 0.0654 - val_acc: 0.9845
Epoch 5/40
 - 108s - loss: 0.0472 - acc: 0.9884 - val_loss: 0.0705 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 9.57 minutes 
==================================================================================================
	PARSING TIME: 8.03 minutes 
==================================================================================================
	Identification : 0.442
	P, R  : 0.342, 0.624

==================================================================================================
	XP Ends: 2/7 (18 h:50)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (18h:50)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 50)       1103550     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       2180        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 64)        1412544     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_232 (Concatenate)   (None, 50, 70)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 320)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 141)          119568      concatenate_232[0][0]            
__________________________________________________________________________________________________
concatenate_233 (Concatenate)   (None, 360)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_234 (Concatenate)   (None, 501)          0           phraseRnn[0][0]                  
                                                                 concatenate_233[0][0]            
__________________________________________________________________________________________________
dense_155 (Dense)               (None, 105)          52710       concatenate_234[0][0]            
__________________________________________________________________________________________________
dense_156 (Dense)               (None, 4)            424         dense_155[0][0]                  
==================================================================================================
Total params: 2,691,848
Trainable params: 2,691,848
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 219s - loss: 0.0686 - acc: 0.9827 - val_loss: 0.0577 - val_acc: 0.9846
Epoch 2/40
 - 219s - loss: 0.0486 - acc: 0.9879 - val_loss: 0.0594 - val_acc: 0.9844
Epoch 3/40
 - 219s - loss: 0.0459 - acc: 0.9889 - val_loss: 0.0634 - val_acc: 0.9844
Epoch 4/40
 - 219s - loss: 0.0444 - acc: 0.9892 - val_loss: 0.0730 - val_acc: 0.9841
Epoch 5/40
 - 218s - loss: 0.0433 - acc: 0.9894 - val_loss: 0.0844 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 19.75 minutes 
==================================================================================================
	PARSING TIME: 3.45 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.458, 0.543

==================================================================================================
	XP Ends: 2/7 (19 h:14)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,34             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.124          ,50             ,22             ,129            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
24             ,106            ,True           ,False          ,128            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 34, False, 0.124, 50, 22, 129, 24, 106, True, False, 128
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (19h:14)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 129)      973305      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       3344        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 106)       799770      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        3648        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_235 (Concatenate)   (None, 50, 151)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 424)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 128)          143360      concatenate_235[0][0]            
__________________________________________________________________________________________________
concatenate_236 (Concatenate)   (None, 520)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_237 (Concatenate)   (None, 648)          0           phraseRnn[0][0]                  
                                                                 concatenate_236[0][0]            
__________________________________________________________________________________________________
dense_157 (Dense)               (None, 34)           22066       concatenate_237[0][0]            
__________________________________________________________________________________________________
dense_158 (Dense)               (None, 4)            140         dense_157[0][0]                  
==================================================================================================
Total params: 1,945,633
Trainable params: 1,945,633
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 167s - loss: 0.0765 - acc: 0.9816 - val_loss: 0.0580 - val_acc: 0.9851
Epoch 2/40
 - 166s - loss: 0.0524 - acc: 0.9868 - val_loss: 0.0576 - val_acc: 0.9852
Epoch 3/40
 - 165s - loss: 0.0496 - acc: 0.9878 - val_loss: 0.0589 - val_acc: 0.9851
Epoch 4/40
 - 165s - loss: 0.0477 - acc: 0.9883 - val_loss: 0.0615 - val_acc: 0.9852
Epoch 5/40
 - 166s - loss: 0.0464 - acc: 0.9888 - val_loss: 0.0649 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 14.72 minutes 
==================================================================================================
	PARSING TIME: 5.22 minutes 
==================================================================================================
	Identification : 0.58
	P, R  : 0.604, 0.558

==================================================================================================
	XP Ends: 2/7 (19 h:34)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (19h:34)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 129)      934089      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       3718        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 106)       767546      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        4056        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_238 (Concatenate)   (None, 50, 151)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 424)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 128)          143360      concatenate_238[0][0]            
__________________________________________________________________________________________________
concatenate_239 (Concatenate)   (None, 520)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_240 (Concatenate)   (None, 648)          0           phraseRnn[0][0]                  
                                                                 concatenate_239[0][0]            
__________________________________________________________________________________________________
dense_159 (Dense)               (None, 34)           22066       concatenate_240[0][0]            
__________________________________________________________________________________________________
dense_160 (Dense)               (None, 4)            140         dense_159[0][0]                  
==================================================================================================
Total params: 1,874,975
Trainable params: 1,874,975
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 0.1173 - acc: 0.9760 - val_loss: 0.0650 - val_acc: 0.9831
Epoch 2/40
 - 110s - loss: 0.0562 - acc: 0.9853 - val_loss: 0.0650 - val_acc: 0.9833
Epoch 3/40
 - 110s - loss: 0.0523 - acc: 0.9868 - val_loss: 0.0666 - val_acc: 0.9834
Epoch 4/40
 - 110s - loss: 0.0501 - acc: 0.9874 - val_loss: 0.0698 - val_acc: 0.9831
Epoch 5/40
 - 110s - loss: 0.0485 - acc: 0.9879 - val_loss: 0.0725 - val_acc: 0.9831
Epoch 00005: early stopping
	TRAINING TIME: 9.65 minutes 
==================================================================================================
	PARSING TIME: 8.12 minutes 
==================================================================================================
	Identification : 0.467
	P, R  : 0.374, 0.62

==================================================================================================
	XP Ends: 2/7 (19 h:53)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (19h:53)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 129)      1779297     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       2398        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 106)       1462058     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        2616        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_241 (Concatenate)   (None, 50, 151)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 424)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 128)          143360      concatenate_241[0][0]            
__________________________________________________________________________________________________
concatenate_242 (Concatenate)   (None, 520)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_243 (Concatenate)   (None, 648)          0           phraseRnn[0][0]                  
                                                                 concatenate_242[0][0]            
__________________________________________________________________________________________________
dense_161 (Dense)               (None, 34)           22066       concatenate_243[0][0]            
__________________________________________________________________________________________________
dense_162 (Dense)               (None, 4)            140         dense_161[0][0]                  
==================================================================================================
Total params: 3,411,935
Trainable params: 3,411,935
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 220s - loss: 0.0735 - acc: 0.9809 - val_loss: 0.0585 - val_acc: 0.9838
Epoch 2/40
 - 220s - loss: 0.0541 - acc: 0.9858 - val_loss: 0.0602 - val_acc: 0.9836
Epoch 3/40
 - 220s - loss: 0.0509 - acc: 0.9870 - val_loss: 0.0618 - val_acc: 0.9838
Epoch 4/40
 - 219s - loss: 0.0487 - acc: 0.9878 - val_loss: 0.0687 - val_acc: 0.9834
Epoch 5/40
 - 218s - loss: 0.0472 - acc: 0.9882 - val_loss: 0.0758 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 19.73 minutes 
==================================================================================================
	PARSING TIME: 3.53 minutes 
==================================================================================================
	Identification : 0.483
	P, R  : 0.447, 0.525

==================================================================================================
	XP Ends: 2/7 (20 h:16)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,480            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.194          ,50             ,8              ,54             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
25             ,169            ,True           ,True           ,303            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 480, True, 0.194, 50, 8, 54, 25, 169, True, True, 303
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (20h:16)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 54)       617652      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 169)       1933022     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        3800        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_244 (Concatenate)   (None, 50, 62)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 845)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 303)          332694      concatenate_244[0][0]            
__________________________________________________________________________________________________
concatenate_245 (Concatenate)   (None, 970)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_246 (Concatenate)   (None, 1273)         0           phraseRnn[0][0]                  
                                                                 concatenate_245[0][0]            
__________________________________________________________________________________________________
dense_163 (Dense)               (None, 480)          611520      concatenate_246[0][0]            
__________________________________________________________________________________________________
dense_164 (Dense)               (None, 4)            1924        dense_163[0][0]                  
==================================================================================================
Total params: 3,501,828
Trainable params: 3,501,828
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 177s - loss: 8.7263 - acc: 0.4585 - val_loss: 8.0628 - val_acc: 0.4998
Epoch 2/40
 - 177s - loss: 8.0636 - acc: 0.4997 - val_loss: 8.0628 - val_acc: 0.4998
Epoch 3/40
 - 177s - loss: 8.0636 - acc: 0.4997 - val_loss: 8.0628 - val_acc: 0.4998
Epoch 4/40
 - 177s - loss: 8.0636 - acc: 0.4997 - val_loss: 8.0628 - val_acc: 0.4998
Epoch 5/40
 - 177s - loss: 8.0636 - acc: 0.4997 - val_loss: 8.0628 - val_acc: 0.4998
Epoch 00005: early stopping
	TRAINING TIME: 15.62 minutes 
==================================================================================================
	PARSING TIME: 7.33 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (20 h:40)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (20h:40)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 54)       507654      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 169)       1588769     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        4225        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_247 (Concatenate)   (None, 50, 62)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 845)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 303)          332694      concatenate_247[0][0]            
__________________________________________________________________________________________________
concatenate_248 (Concatenate)   (None, 970)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_249 (Concatenate)   (None, 1273)         0           phraseRnn[0][0]                  
                                                                 concatenate_248[0][0]            
__________________________________________________________________________________________________
dense_165 (Dense)               (None, 480)          611520      concatenate_249[0][0]            
__________________________________________________________________________________________________
dense_166 (Dense)               (None, 4)            1924        dense_165[0][0]                  
==================================================================================================
Total params: 3,048,138
Trainable params: 3,048,138
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 119s - loss: 12.0644 - acc: 0.2512 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 2/40
 - 119s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 3/40
 - 119s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 4/40
 - 119s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 5/40
 - 119s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 00005: early stopping
	TRAINING TIME: 10.45 minutes 
==================================================================================================
	PARSING TIME: 6.08 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (20 h:57)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (20h:57)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 54)       1191834     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 169)       3729999     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        2725        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_250 (Concatenate)   (None, 50, 62)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 845)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 303)          332694      concatenate_250[0][0]            
__________________________________________________________________________________________________
concatenate_251 (Concatenate)   (None, 970)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_252 (Concatenate)   (None, 1273)         0           phraseRnn[0][0]                  
                                                                 concatenate_251[0][0]            
__________________________________________________________________________________________________
dense_167 (Dense)               (None, 480)          611520      concatenate_252[0][0]            
__________________________________________________________________________________________________
dense_168 (Dense)               (None, 4)            1924        dense_167[0][0]                  
==================================================================================================
Total params: 5,871,568
Trainable params: 5,871,568
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 239s - loss: 8.0907 - acc: 0.4979 - val_loss: 8.0376 - val_acc: 0.5013
Epoch 2/40
 - 245s - loss: 8.0704 - acc: 0.4993 - val_loss: 8.0376 - val_acc: 0.5013
Epoch 3/40
 - 239s - loss: 8.0704 - acc: 0.4993 - val_loss: 8.0376 - val_acc: 0.5013
Epoch 4/40
 - 239s - loss: 8.0704 - acc: 0.4993 - val_loss: 8.0376 - val_acc: 0.5013
Epoch 5/40
 - 239s - loss: 8.0704 - acc: 0.4993 - val_loss: 8.0376 - val_acc: 0.5013
Epoch 00005: early stopping
	TRAINING TIME: 21.53 minutes 
==================================================================================================
	PARSING TIME: 5.12 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (21 h:24)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,241            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.088          ,50             ,9              ,73             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
28             ,165            ,False          ,True           ,120            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 241, True, 0.088, 50, 9, 73, 28, 165, False, True, 120
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (21h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 73)       834974      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1368        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 165)       1887270     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 28)        4256        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_253 (Concatenate)   (None, 50, 82)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 660)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 112)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 120)          73080       concatenate_253[0][0]            
__________________________________________________________________________________________________
concatenate_254 (Concatenate)   (None, 772)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_255 (Concatenate)   (None, 892)          0           phraseRnn[0][0]                  
                                                                 concatenate_254[0][0]            
__________________________________________________________________________________________________
dense_169 (Dense)               (None, 241)          215213      concatenate_255[0][0]            
__________________________________________________________________________________________________
dense_170 (Dense)               (None, 4)            968         dense_169[0][0]                  
==================================================================================================
Total params: 3,017,129
Trainable params: 3,017,129
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 137s - loss: 0.2762 - acc: 0.9697 - val_loss: 0.0555 - val_acc: 0.9859
Epoch 2/40
 - 137s - loss: 0.0513 - acc: 0.9873 - val_loss: 0.0560 - val_acc: 0.9858
Epoch 3/40
 - 137s - loss: 0.0478 - acc: 0.9884 - val_loss: 0.0566 - val_acc: 0.9861
Epoch 4/40
 - 137s - loss: 0.0460 - acc: 0.9888 - val_loss: 0.0632 - val_acc: 0.9861
Epoch 5/40
 - 137s - loss: 0.0449 - acc: 0.9891 - val_loss: 0.0711 - val_acc: 0.9861
Epoch 00005: early stopping
	TRAINING TIME: 12.2 minutes 
==================================================================================================
	PARSING TIME: 4.2 minutes 
==================================================================================================
	Identification : 0.546
	P, R  : 0.485, 0.625

==================================================================================================
	XP Ends: 2/7 (21 h:40)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (21h:40)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 73)       686273      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1521        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 165)       1551165     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 28)        4732        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_256 (Concatenate)   (None, 50, 82)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 660)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 112)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 120)          73080       concatenate_256[0][0]            
__________________________________________________________________________________________________
concatenate_257 (Concatenate)   (None, 772)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_258 (Concatenate)   (None, 892)          0           phraseRnn[0][0]                  
                                                                 concatenate_257[0][0]            
__________________________________________________________________________________________________
dense_171 (Dense)               (None, 241)          215213      concatenate_258[0][0]            
__________________________________________________________________________________________________
dense_172 (Dense)               (None, 4)            968         dense_171[0][0]                  
==================================================================================================
Total params: 2,532,952
Trainable params: 2,532,952
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.2271 - acc: 0.9698 - val_loss: 0.0616 - val_acc: 0.9843
Epoch 2/40
 - 94s - loss: 0.0558 - acc: 0.9860 - val_loss: 0.0627 - val_acc: 0.9846
Epoch 3/40
 - 94s - loss: 0.0517 - acc: 0.9875 - val_loss: 0.0654 - val_acc: 0.9848
Epoch 4/40
 - 94s - loss: 0.0500 - acc: 0.9880 - val_loss: 0.0709 - val_acc: 0.9847
Epoch 5/40
 - 93s - loss: 0.0486 - acc: 0.9883 - val_loss: 0.0854 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 8.3 minutes 
==================================================================================================
	PARSING TIME: 6.32 minutes 
==================================================================================================
	Identification : 0.488
	P, R  : 0.427, 0.57

==================================================================================================
	XP Ends: 2/7 (21 h:55)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (21h:55)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 73)       1611183     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        981         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 165)       3641715     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 28)        3052        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_259 (Concatenate)   (None, 50, 82)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 660)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 112)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 120)          73080       concatenate_259[0][0]            
__________________________________________________________________________________________________
concatenate_260 (Concatenate)   (None, 772)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_261 (Concatenate)   (None, 892)          0           phraseRnn[0][0]                  
                                                                 concatenate_260[0][0]            
__________________________________________________________________________________________________
dense_173 (Dense)               (None, 241)          215213      concatenate_261[0][0]            
__________________________________________________________________________________________________
dense_174 (Dense)               (None, 4)            968         dense_173[0][0]                  
==================================================================================================
Total params: 5,546,192
Trainable params: 5,546,192
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 191s - loss: 12.0798 - acc: 0.2503 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 2/40
 - 191s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 3/40
 - 191s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 4/40
 - 191s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 5/40
 - 191s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 00005: early stopping
	TRAINING TIME: 17.43 minutes 
==================================================================================================
	PARSING TIME: 2.6 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (22 h:16)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,78             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.142          ,50             ,17             ,79             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
9              ,58             ,False          ,True           ,358            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 78, True, 0.142, 50, 17, 79, 9, 58, False, True, 358
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (22h:16)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 79)       903602      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2584        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 58)        663404      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 9)         1368        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_262 (Concatenate)   (None, 50, 96)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 232)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 36)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 358)          488670      concatenate_262[0][0]            
__________________________________________________________________________________________________
concatenate_263 (Concatenate)   (None, 268)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_264 (Concatenate)   (None, 626)          0           phraseRnn[0][0]                  
                                                                 concatenate_263[0][0]            
__________________________________________________________________________________________________
dense_175 (Dense)               (None, 78)           48906       concatenate_264[0][0]            
__________________________________________________________________________________________________
dense_176 (Dense)               (None, 4)            316         dense_175[0][0]                  
==================================================================================================
Total params: 2,108,850
Trainable params: 2,108,850
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 210s - loss: 12.0868 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 2/40
 - 210s - loss: 12.0925 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 3/40
 - 210s - loss: 12.0925 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 4/40
 - 210s - loss: 12.0925 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 5/40
 - 210s - loss: 12.0925 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 00005: early stopping
	TRAINING TIME: 18.23 minutes 
==================================================================================================
	PARSING TIME: 9.23 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (22 h:44)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (22h:44)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 79)       742679      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2873        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 58)        545258      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 9)         1521        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_265 (Concatenate)   (None, 50, 96)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 232)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 36)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 358)          488670      concatenate_265[0][0]            
__________________________________________________________________________________________________
concatenate_266 (Concatenate)   (None, 268)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_267 (Concatenate)   (None, 626)          0           phraseRnn[0][0]                  
                                                                 concatenate_266[0][0]            
__________________________________________________________________________________________________
dense_177 (Dense)               (None, 78)           48906       concatenate_267[0][0]            
__________________________________________________________________________________________________
dense_178 (Dense)               (None, 4)            316         dense_177[0][0]                  
==================================================================================================
Total params: 1,830,223
Trainable params: 1,830,223
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 142s - loss: 12.0733 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 2/40
 - 142s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 3/40
 - 142s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 4/40
 - 142s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 5/40
 - 142s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 00005: early stopping
	TRAINING TIME: 12.37 minutes 
==================================================================================================
	PARSING TIME: 7.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (23 h:4)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (23h:4)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 79)       1743609     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       1853        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 58)        1280118     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 9)         981         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_268 (Concatenate)   (None, 50, 96)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 232)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 36)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 358)          488670      concatenate_268[0][0]            
__________________________________________________________________________________________________
concatenate_269 (Concatenate)   (None, 268)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_270 (Concatenate)   (None, 626)          0           phraseRnn[0][0]                  
                                                                 concatenate_269[0][0]            
__________________________________________________________________________________________________
dense_179 (Dense)               (None, 78)           48906       concatenate_270[0][0]            
__________________________________________________________________________________________________
dense_180 (Dense)               (None, 4)            316         dense_179[0][0]                  
==================================================================================================
Total params: 3,564,453
Trainable params: 3,564,453
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 284s - loss: 12.0888 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 2/40
 - 284s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 3/40
 - 284s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 4/40
 - 284s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 5/40
 - 284s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 25.07 minutes 
==================================================================================================
	PARSING TIME: 5.83 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (23 h:35)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,252            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.018          ,50             ,11             ,43             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
11             ,61             ,True           ,True           ,430            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 252, True, 0.018, 50, 11, 43, 11, 61, True, True, 430
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (23h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 43)       491834      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1672        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 61)        697718      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1672        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_271 (Concatenate)   (None, 50, 54)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 305)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 430)          625650      concatenate_271[0][0]            
__________________________________________________________________________________________________
concatenate_272 (Concatenate)   (None, 360)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_273 (Concatenate)   (None, 790)          0           phraseRnn[0][0]                  
                                                                 concatenate_272[0][0]            
__________________________________________________________________________________________________
dense_181 (Dense)               (None, 252)          199332      concatenate_273[0][0]            
__________________________________________________________________________________________________
dense_182 (Dense)               (None, 4)            1012        dense_181[0][0]                  
==================================================================================================
Total params: 2,018,890
Trainable params: 2,018,890
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 241s - loss: 0.0708 - acc: 0.9813 - val_loss: 0.0548 - val_acc: 0.9858
Epoch 2/40
 - 241s - loss: 0.0504 - acc: 0.9876 - val_loss: 0.0548 - val_acc: 0.9860
Epoch 3/40
 - 241s - loss: 0.0470 - acc: 0.9887 - val_loss: 0.0567 - val_acc: 0.9861
Epoch 4/40
 - 241s - loss: 0.0455 - acc: 0.9891 - val_loss: 0.0601 - val_acc: 0.9858
Epoch 5/40
 - 241s - loss: 0.0447 - acc: 0.9893 - val_loss: 0.0631 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 20.98 minutes 
==================================================================================================
	PARSING TIME: 5.77 minutes 
==================================================================================================
	Identification : 0.544
	P, R  : 0.566, 0.524

==================================================================================================
	XP Ends: 3/7 (0 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (0h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 43)       404243      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1859        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 61)        573461      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1859        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_274 (Concatenate)   (None, 50, 54)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 305)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 430)          625650      concatenate_274[0][0]            
__________________________________________________________________________________________________
concatenate_275 (Concatenate)   (None, 360)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_276 (Concatenate)   (None, 790)          0           phraseRnn[0][0]                  
                                                                 concatenate_275[0][0]            
__________________________________________________________________________________________________
dense_183 (Dense)               (None, 252)          199332      concatenate_276[0][0]            
__________________________________________________________________________________________________
dense_184 (Dense)               (None, 4)            1012        dense_183[0][0]                  
==================================================================================================
Total params: 1,807,416
Trainable params: 1,807,416
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 164s - loss: 11.2045 - acc: 0.3014 - val_loss: 11.2699 - val_acc: 0.2995
Epoch 2/40
 - 164s - loss: 11.2433 - acc: 0.3017 - val_loss: 11.2898 - val_acc: 0.2987
Epoch 3/40
 - 164s - loss: 11.2570 - acc: 0.3011 - val_loss: 11.3029 - val_acc: 0.2978
Epoch 4/40
 - 164s - loss: 11.2667 - acc: 0.3006 - val_loss: 11.3121 - val_acc: 0.2973
Epoch 5/40
 - 164s - loss: 11.2727 - acc: 0.3003 - val_loss: 11.3126 - val_acc: 0.2972
Epoch 00005: early stopping
	TRAINING TIME: 14.15 minutes 
==================================================================================================
	PARSING TIME: 16.02 minutes 
==================================================================================================
	Identification : 0.0
	P, R  : 0.0, 0.018

==================================================================================================
	XP Ends: 3/7 (0 h:33)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (0h:33)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 43)       949053      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1199        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 61)        1346331     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1199        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_277 (Concatenate)   (None, 50, 54)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 305)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 430)          625650      concatenate_277[0][0]            
__________________________________________________________________________________________________
concatenate_278 (Concatenate)   (None, 360)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_279 (Concatenate)   (None, 790)          0           phraseRnn[0][0]                  
                                                                 concatenate_278[0][0]            
__________________________________________________________________________________________________
dense_185 (Dense)               (None, 252)          199332      concatenate_279[0][0]            
__________________________________________________________________________________________________
dense_186 (Dense)               (None, 4)            1012        dense_185[0][0]                  
==================================================================================================
Total params: 3,123,776
Trainable params: 3,123,776
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 329s - loss: 12.0848 - acc: 0.2499 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 2/40
 - 329s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 3/40
 - 329s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 4/40
 - 329s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 5/40
 - 329s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 28.85 minutes 
==================================================================================================
	PARSING TIME: 6.95 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (1 h:9)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,56             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.046          ,50             ,12             ,58             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
12             ,49             ,True           ,False          ,65             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 56, False, 0.046, 50, 12, 58, 12, 49, True, False, 65
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (1h:9)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 58)       437610      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1824        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 49)        369705      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 12)        1824        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_280 (Concatenate)   (None, 50, 70)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 196)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 48)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 65)           35360       concatenate_280[0][0]            
__________________________________________________________________________________________________
concatenate_281 (Concatenate)   (None, 244)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_282 (Concatenate)   (None, 309)          0           phraseRnn[0][0]                  
                                                                 concatenate_281[0][0]            
__________________________________________________________________________________________________
dense_187 (Dense)               (None, 56)           17360       concatenate_282[0][0]            
__________________________________________________________________________________________________
dense_188 (Dense)               (None, 4)            228         dense_187[0][0]                  
==================================================================================================
Total params: 863,911
Trainable params: 863,911
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 159s - loss: 0.0652 - acc: 0.9830 - val_loss: 0.0576 - val_acc: 0.9852
Epoch 2/40
 - 159s - loss: 0.0510 - acc: 0.9873 - val_loss: 0.0572 - val_acc: 0.9855
Epoch 3/40
 - 163s - loss: 0.0478 - acc: 0.9883 - val_loss: 0.0587 - val_acc: 0.9855
Epoch 4/40
 - 170s - loss: 0.0462 - acc: 0.9889 - val_loss: 0.0612 - val_acc: 0.9853
Epoch 5/40
 - 160s - loss: 0.0451 - acc: 0.9891 - val_loss: 0.0666 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 14.35 minutes 
==================================================================================================
	PARSING TIME: 5.67 minutes 
==================================================================================================
	Identification : 0.57
	P, R  : 0.651, 0.507

==================================================================================================
	XP Ends: 3/7 (1 h:29)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (1h:29)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 58)       419978      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       2028        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 49)        354809      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 12)        2028        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_283 (Concatenate)   (None, 50, 70)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 196)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 48)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 65)           35360       concatenate_283[0][0]            
__________________________________________________________________________________________________
concatenate_284 (Concatenate)   (None, 244)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_285 (Concatenate)   (None, 309)          0           phraseRnn[0][0]                  
                                                                 concatenate_284[0][0]            
__________________________________________________________________________________________________
dense_189 (Dense)               (None, 56)           17360       concatenate_285[0][0]            
__________________________________________________________________________________________________
dense_190 (Dense)               (None, 4)            228         dense_189[0][0]                  
==================================================================================================
Total params: 831,791
Trainable params: 831,791
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 115s - loss: 0.0780 - acc: 0.9786 - val_loss: 0.0631 - val_acc: 0.9830
Epoch 2/40
 - 109s - loss: 0.0573 - acc: 0.9851 - val_loss: 0.0669 - val_acc: 0.9827
Epoch 3/40
 - 109s - loss: 0.0530 - acc: 0.9864 - val_loss: 0.0651 - val_acc: 0.9831
Epoch 4/40
 - 109s - loss: 0.0505 - acc: 0.9873 - val_loss: 0.0680 - val_acc: 0.9831
Epoch 5/40
 - 114s - loss: 0.0487 - acc: 0.9878 - val_loss: 0.0708 - val_acc: 0.9828
Epoch 00005: early stopping
	TRAINING TIME: 9.78 minutes 
==================================================================================================
	PARSING TIME: 8.43 minutes 
==================================================================================================
	Identification : 0.484
	P, R  : 0.416, 0.58

==================================================================================================
	XP Ends: 3/7 (1 h:48)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (1h:48)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 58)       799994      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1308        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 49)        675857      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 12)        1308        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_286 (Concatenate)   (None, 50, 70)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 196)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 48)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 65)           35360       concatenate_286[0][0]            
__________________________________________________________________________________________________
concatenate_287 (Concatenate)   (None, 244)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_288 (Concatenate)   (None, 309)          0           phraseRnn[0][0]                  
                                                                 concatenate_287[0][0]            
__________________________________________________________________________________________________
dense_191 (Dense)               (None, 56)           17360       concatenate_288[0][0]            
__________________________________________________________________________________________________
dense_192 (Dense)               (None, 4)            228         dense_191[0][0]                  
==================================================================================================
Total params: 1,531,415
Trainable params: 1,531,415
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 228s - loss: 0.0653 - acc: 0.9822 - val_loss: 0.0577 - val_acc: 0.9843
Epoch 2/40
 - 223s - loss: 0.0526 - acc: 0.9863 - val_loss: 0.0585 - val_acc: 0.9840
Epoch 3/40
 - 216s - loss: 0.0497 - acc: 0.9874 - val_loss: 0.0615 - val_acc: 0.9838
Epoch 4/40
 - 230s - loss: 0.0479 - acc: 0.9881 - val_loss: 0.0670 - val_acc: 0.9835
Epoch 5/40
 - 226s - loss: 0.0465 - acc: 0.9885 - val_loss: 0.0717 - val_acc: 0.9833
Epoch 00005: early stopping
	TRAINING TIME: 20.15 minutes 
==================================================================================================
	PARSING TIME: 3.53 minutes 
==================================================================================================
	Identification : 0.481
	P, R  : 0.446, 0.522

==================================================================================================
	XP Ends: 3/7 (2 h:12)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,168            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.112          ,50             ,10             ,67             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
31             ,55             ,True           ,True           ,52             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 168, False, 0.112, 50, 10, 67, 31, 55, True, True, 52
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (2h:12)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 67)       505515      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 10)       1520        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 55)        414975      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 31)        4712        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_289 (Concatenate)   (None, 50, 77)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 275)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 155)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 52)           27040       concatenate_289[0][0]            
__________________________________________________________________________________________________
concatenate_290 (Concatenate)   (None, 430)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_291 (Concatenate)   (None, 482)          0           phraseRnn[0][0]                  
                                                                 concatenate_290[0][0]            
__________________________________________________________________________________________________
dense_193 (Dense)               (None, 168)          81144       concatenate_291[0][0]            
__________________________________________________________________________________________________
dense_194 (Dense)               (None, 4)            676         dense_193[0][0]                  
==================================================================================================
Total params: 1,035,582
Trainable params: 1,035,582
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 162s - loss: 12.0735 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 2/40
 - 166s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 3/40
 - 168s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 4/40
 - 172s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 5/40
 - 177s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 00005: early stopping
	TRAINING TIME: 14.95 minutes 
==================================================================================================
	PARSING TIME: 15.87 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.067

==================================================================================================
	XP Ends: 3/7 (2 h:43)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (2h:43)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 67)       485147      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 10)       1690        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 55)        398255      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 31)        5239        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_292 (Concatenate)   (None, 50, 77)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 275)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 155)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 52)           27040       concatenate_292[0][0]            
__________________________________________________________________________________________________
concatenate_293 (Concatenate)   (None, 430)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_294 (Concatenate)   (None, 482)          0           phraseRnn[0][0]                  
                                                                 concatenate_293[0][0]            
__________________________________________________________________________________________________
dense_195 (Dense)               (None, 168)          81144       concatenate_294[0][0]            
__________________________________________________________________________________________________
dense_196 (Dense)               (None, 4)            676         dense_195[0][0]                  
==================================================================================================
Total params: 999,191
Trainable params: 999,191
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 115s - loss: 0.1343 - acc: 0.9762 - val_loss: 0.0634 - val_acc: 0.9830
Epoch 2/40
 - 112s - loss: 0.0541 - acc: 0.9862 - val_loss: 0.0619 - val_acc: 0.9839
Epoch 3/40
 - 112s - loss: 0.0499 - acc: 0.9877 - val_loss: 0.0647 - val_acc: 0.9843
Epoch 4/40
 - 109s - loss: 0.0481 - acc: 0.9882 - val_loss: 0.0671 - val_acc: 0.9843
Epoch 5/40
 - 113s - loss: 0.0469 - acc: 0.9885 - val_loss: 0.0727 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 9.87 minutes 
==================================================================================================
	PARSING TIME: 8.3 minutes 
==================================================================================================
	Identification : 0.543
	P, R  : 0.475, 0.633

==================================================================================================
	XP Ends: 3/7 (3 h:2)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (3h:2)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 67)       924131      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 10)       1090        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 55)        758615      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 31)        3379        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_295 (Concatenate)   (None, 50, 77)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 275)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 155)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 52)           27040       concatenate_295[0][0]            
__________________________________________________________________________________________________
concatenate_296 (Concatenate)   (None, 430)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_297 (Concatenate)   (None, 482)          0           phraseRnn[0][0]                  
                                                                 concatenate_296[0][0]            
__________________________________________________________________________________________________
dense_197 (Dense)               (None, 168)          81144       concatenate_297[0][0]            
__________________________________________________________________________________________________
dense_198 (Dense)               (None, 4)            676         dense_197[0][0]                  
==================================================================================================
Total params: 1,796,075
Trainable params: 1,796,075
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 218s - loss: 3.2307 - acc: 0.7890 - val_loss: 0.0605 - val_acc: 0.9833
Epoch 2/40
 - 231s - loss: 0.0551 - acc: 0.9857 - val_loss: 0.0572 - val_acc: 0.9846
Epoch 3/40
 - 231s - loss: 0.0499 - acc: 0.9875 - val_loss: 0.0593 - val_acc: 0.9845
Epoch 4/40
 - 226s - loss: 0.0476 - acc: 0.9883 - val_loss: 0.0648 - val_acc: 0.9844
Epoch 5/40
 - 230s - loss: 0.0458 - acc: 0.9887 - val_loss: 0.0771 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 20.43 minutes 
==================================================================================================
	PARSING TIME: 3.57 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.439, 0.573

==================================================================================================
	XP Ends: 3/7 (3 h:26)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,25             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.019          ,50             ,27             ,101            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
6              ,85             ,True           ,True           ,133            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 25, False, 0.019, 50, 27, 101, 6, 85, True, True, 133
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (3h:26)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 101)      762045      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 27)       4104        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 85)        641325      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         912         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_298 (Concatenate)   (None, 50, 128)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 425)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 133)          139384      concatenate_298[0][0]            
__________________________________________________________________________________________________
concatenate_299 (Concatenate)   (None, 455)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_300 (Concatenate)   (None, 588)          0           phraseRnn[0][0]                  
                                                                 concatenate_299[0][0]            
__________________________________________________________________________________________________
dense_199 (Dense)               (None, 25)           14725       concatenate_300[0][0]            
__________________________________________________________________________________________________
dense_200 (Dense)               (None, 4)            104         dense_199[0][0]                  
==================================================================================================
Total params: 1,562,599
Trainable params: 1,562,599
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 175s - loss: 0.0777 - acc: 0.9801 - val_loss: 0.0631 - val_acc: 0.9842
Epoch 2/40
 - 170s - loss: 0.0542 - acc: 0.9864 - val_loss: 0.0613 - val_acc: 0.9850
Epoch 3/40
 - 165s - loss: 0.0498 - acc: 0.9878 - val_loss: 0.0636 - val_acc: 0.9848
Epoch 4/40
 - 168s - loss: 0.0477 - acc: 0.9885 - val_loss: 0.0646 - val_acc: 0.9849
Epoch 5/40
 - 170s - loss: 0.0464 - acc: 0.9888 - val_loss: 0.0682 - val_acc: 0.9849
Epoch 00005: early stopping
	TRAINING TIME: 14.93 minutes 
==================================================================================================
	PARSING TIME: 5.25 minutes 
==================================================================================================
	Identification : 0.575
	P, R  : 0.768, 0.46

==================================================================================================
	XP Ends: 3/7 (3 h:47)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (3h:47)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 101)      731341      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 27)       4563        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 85)        615485      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         1014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_301 (Concatenate)   (None, 50, 128)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 425)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 133)          139384      concatenate_301[0][0]            
__________________________________________________________________________________________________
concatenate_302 (Concatenate)   (None, 455)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_303 (Concatenate)   (None, 588)          0           phraseRnn[0][0]                  
                                                                 concatenate_302[0][0]            
__________________________________________________________________________________________________
dense_201 (Dense)               (None, 25)           14725       concatenate_303[0][0]            
__________________________________________________________________________________________________
dense_202 (Dense)               (None, 4)            104         dense_201[0][0]                  
==================================================================================================
Total params: 1,506,616
Trainable params: 1,506,616
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 117s - loss: 0.0832 - acc: 0.9778 - val_loss: 0.0657 - val_acc: 0.9829
Epoch 2/40
 - 112s - loss: 0.0570 - acc: 0.9855 - val_loss: 0.0637 - val_acc: 0.9837
Epoch 3/40
 - 112s - loss: 0.0521 - acc: 0.9871 - val_loss: 0.0653 - val_acc: 0.9836
Epoch 4/40
 - 117s - loss: 0.0499 - acc: 0.9877 - val_loss: 0.0687 - val_acc: 0.9834
Epoch 5/40
 - 112s - loss: 0.0485 - acc: 0.9882 - val_loss: 0.0735 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 10.08 minutes 
==================================================================================================
	PARSING TIME: 8.77 minutes 
==================================================================================================
	Identification : 0.538
	P, R  : 0.544, 0.533

==================================================================================================
	XP Ends: 3/7 (4 h:6)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (4h:6)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 101)      1393093     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 27)       2943        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 85)        1172405     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         654         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_304 (Concatenate)   (None, 50, 128)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 425)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 133)          139384      concatenate_304[0][0]            
__________________________________________________________________________________________________
concatenate_305 (Concatenate)   (None, 455)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_306 (Concatenate)   (None, 588)          0           phraseRnn[0][0]                  
                                                                 concatenate_305[0][0]            
__________________________________________________________________________________________________
dense_203 (Dense)               (None, 25)           14725       concatenate_306[0][0]            
__________________________________________________________________________________________________
dense_204 (Dense)               (None, 4)            104         dense_203[0][0]                  
==================================================================================================
Total params: 2,723,308
Trainable params: 2,723,308
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 229s - loss: 0.0744 - acc: 0.9804 - val_loss: 0.0608 - val_acc: 0.9840
Epoch 2/40
 - 233s - loss: 0.0540 - acc: 0.9861 - val_loss: 0.0603 - val_acc: 0.9840
Epoch 3/40
 - 232s - loss: 0.0504 - acc: 0.9874 - val_loss: 0.0628 - val_acc: 0.9838
Epoch 4/40
 - 223s - loss: 0.0485 - acc: 0.9881 - val_loss: 0.0655 - val_acc: 0.9837
Epoch 5/40
 - 230s - loss: 0.0472 - acc: 0.9885 - val_loss: 0.0690 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 20.6 minutes 
==================================================================================================
	PARSING TIME: 3.53 minutes 
==================================================================================================
	Identification : 0.489
	P, R  : 0.486, 0.492

==================================================================================================
	XP Ends: 3/7 (4 h:31)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,63             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.063          ,50             ,9              ,27             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,105            ,False          ,False          ,282            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 63, False, 0.063, 50, 9, 27, 10, 105, False, False, 282
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (4h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 27)       308826      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1368        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 105)       1200990     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_307 (Concatenate)   (None, 50, 36)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 315)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 282)          359832      concatenate_307[0][0]            
__________________________________________________________________________________________________
concatenate_308 (Concatenate)   (None, 345)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_309 (Concatenate)   (None, 627)          0           phraseRnn[0][0]                  
                                                                 concatenate_308[0][0]            
__________________________________________________________________________________________________
dense_205 (Dense)               (None, 63)           39564       concatenate_309[0][0]            
__________________________________________________________________________________________________
dense_206 (Dense)               (None, 4)            256         dense_205[0][0]                  
==================================================================================================
Total params: 1,912,356
Trainable params: 1,912,356
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 200s - loss: 12.0811 - acc: 0.2501 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 2/40
 - 201s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 3/40
 - 201s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 4/40
 - 201s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 5/40
 - 201s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 00005: early stopping
	TRAINING TIME: 17.55 minutes 
==================================================================================================
	PARSING TIME: 5.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (4 h:54)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (4h:54)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 27)       253827      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1521        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 105)       987105      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_310 (Concatenate)   (None, 50, 36)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 315)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 282)          359832      concatenate_310[0][0]            
__________________________________________________________________________________________________
concatenate_311 (Concatenate)   (None, 345)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_312 (Concatenate)   (None, 627)          0           phraseRnn[0][0]                  
                                                                 concatenate_311[0][0]            
__________________________________________________________________________________________________
dense_207 (Dense)               (None, 63)           39564       concatenate_312[0][0]            
__________________________________________________________________________________________________
dense_208 (Dense)               (None, 4)            256         dense_207[0][0]                  
==================================================================================================
Total params: 1,643,795
Trainable params: 1,643,795
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 136s - loss: 12.0710 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 2/40
 - 136s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 3/40
 - 136s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 4/40
 - 134s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 5/40
 - 134s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 00005: early stopping
	TRAINING TIME: 11.83 minutes 
==================================================================================================
	PARSING TIME: 7.68 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (5 h:14)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (5h:14)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 27)       595917      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        981         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 105)       2317455     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_313 (Concatenate)   (None, 50, 36)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 315)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 282)          359832      concatenate_313[0][0]            
__________________________________________________________________________________________________
concatenate_314 (Concatenate)   (None, 345)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_315 (Concatenate)   (None, 627)          0           phraseRnn[0][0]                  
                                                                 concatenate_314[0][0]            
__________________________________________________________________________________________________
dense_209 (Dense)               (None, 63)           39564       concatenate_315[0][0]            
__________________________________________________________________________________________________
dense_210 (Dense)               (None, 4)            256         dense_209[0][0]                  
==================================================================================================
Total params: 3,315,095
Trainable params: 3,315,095
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 269s - loss: 0.0730 - acc: 0.9813 - val_loss: 0.0601 - val_acc: 0.9834
Epoch 2/40
 - 272s - loss: 0.0529 - acc: 0.9861 - val_loss: 0.0616 - val_acc: 0.9834
Epoch 3/40
 - 271s - loss: 0.0508 - acc: 0.9868 - val_loss: 0.0647 - val_acc: 0.9831
Epoch 4/40
 - 271s - loss: 0.0493 - acc: 0.9873 - val_loss: 0.0754 - val_acc: 0.9837
Epoch 5/40
 - 271s - loss: 0.0476 - acc: 0.9876 - val_loss: 0.0887 - val_acc: 0.9833
Epoch 00005: early stopping
	TRAINING TIME: 24.03 minutes 
==================================================================================================
	PARSING TIME: 3.55 minutes 
==================================================================================================
	Identification : 0.433
	P, R  : 0.487, 0.39

==================================================================================================
	XP Ends: 3/7 (5 h:42)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,38             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.07           ,50             ,20             ,117            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
24             ,123            ,False          ,True           ,154            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 38, False, 0.07, 50, 20, 117, 24, 123, False, True, 154
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (5h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 117)      1338246     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3040        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 123)       1406874     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        3648        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_316 (Concatenate)   (None, 50, 137)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 492)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 154)          179872      concatenate_316[0][0]            
__________________________________________________________________________________________________
concatenate_317 (Concatenate)   (None, 588)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_318 (Concatenate)   (None, 742)          0           phraseRnn[0][0]                  
                                                                 concatenate_317[0][0]            
__________________________________________________________________________________________________
dense_211 (Dense)               (None, 38)           28234       concatenate_318[0][0]            
__________________________________________________________________________________________________
dense_212 (Dense)               (None, 4)            156         dense_211[0][0]                  
==================================================================================================
Total params: 2,960,070
Trainable params: 2,960,070
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 163s - loss: 12.0810 - acc: 0.2501 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 2/40
 - 169s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 3/40
 - 163s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 4/40
 - 163s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 5/40
 - 168s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 00005: early stopping
	TRAINING TIME: 14.65 minutes 
==================================================================================================
	PARSING TIME: 5.03 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (6 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (6h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 117)      1099917     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3380        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 123)       1156323     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        4056        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_319 (Concatenate)   (None, 50, 137)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 492)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 154)          179872      concatenate_319[0][0]            
__________________________________________________________________________________________________
concatenate_320 (Concatenate)   (None, 588)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_321 (Concatenate)   (None, 742)          0           phraseRnn[0][0]                  
                                                                 concatenate_320[0][0]            
__________________________________________________________________________________________________
dense_213 (Dense)               (None, 38)           28234       concatenate_321[0][0]            
__________________________________________________________________________________________________
dense_214 (Dense)               (None, 4)            156         dense_213[0][0]                  
==================================================================================================
Total params: 2,471,938
Trainable params: 2,471,938
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 111s - loss: 0.0805 - acc: 0.9788 - val_loss: 0.0600 - val_acc: 0.9843
Epoch 2/40
 - 117s - loss: 0.0541 - acc: 0.9863 - val_loss: 0.0598 - val_acc: 0.9843
Epoch 3/40
 - 111s - loss: 0.0506 - acc: 0.9874 - val_loss: 0.0612 - val_acc: 0.9841
Epoch 4/40
 - 117s - loss: 0.0490 - acc: 0.9878 - val_loss: 0.0647 - val_acc: 0.9843
Epoch 5/40
 - 116s - loss: 0.0477 - acc: 0.9882 - val_loss: 0.0661 - val_acc: 0.9849
Epoch 00005: early stopping
	TRAINING TIME: 10.07 minutes 
==================================================================================================
	PARSING TIME: 8.47 minutes 
==================================================================================================
	Identification : 0.459
	P, R  : 0.365, 0.618

==================================================================================================
	XP Ends: 3/7 (6 h:21)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (6h:21)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 117)      2582307     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       2180        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 123)       2714733     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        2616        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_322 (Concatenate)   (None, 50, 137)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 492)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 154)          179872      concatenate_322[0][0]            
__________________________________________________________________________________________________
concatenate_323 (Concatenate)   (None, 588)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_324 (Concatenate)   (None, 742)          0           phraseRnn[0][0]                  
                                                                 concatenate_323[0][0]            
__________________________________________________________________________________________________
dense_215 (Dense)               (None, 38)           28234       concatenate_324[0][0]            
__________________________________________________________________________________________________
dense_216 (Dense)               (None, 4)            156         dense_215[0][0]                  
==================================================================================================
Total params: 5,510,098
Trainable params: 5,510,098
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 236s - loss: 0.0708 - acc: 0.9815 - val_loss: 0.0607 - val_acc: 0.9836
Epoch 2/40
 - 225s - loss: 0.0514 - acc: 0.9869 - val_loss: 0.0619 - val_acc: 0.9833
Epoch 3/40
 - 230s - loss: 0.0495 - acc: 0.9874 - val_loss: 0.0640 - val_acc: 0.9833
Epoch 4/40
 - 238s - loss: 0.0484 - acc: 0.9877 - val_loss: 0.0669 - val_acc: 0.9834
Epoch 5/40
 - 237s - loss: 0.0472 - acc: 0.9878 - val_loss: 0.0939 - val_acc: 0.9832
Epoch 00005: early stopping
	TRAINING TIME: 20.95 minutes 
==================================================================================================
	PARSING TIME: 3.53 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.507, 0.48

==================================================================================================
	XP Ends: 3/7 (6 h:45)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,318            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.011          ,50             ,9              ,49             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
7              ,59             ,True           ,True           ,138            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 318, False, 0.011, 50, 9, 49, 7, 59, True, True, 138
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (6h:45)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 49)       369705      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1368        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 59)        445155      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1064        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_325 (Concatenate)   (None, 50, 58)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 295)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 138)          108744      concatenate_325[0][0]            
__________________________________________________________________________________________________
concatenate_326 (Concatenate)   (None, 330)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_327 (Concatenate)   (None, 468)          0           phraseRnn[0][0]                  
                                                                 concatenate_326[0][0]            
__________________________________________________________________________________________________
dense_217 (Dense)               (None, 318)          149142      concatenate_327[0][0]            
__________________________________________________________________________________________________
dense_218 (Dense)               (None, 4)            1276        dense_217[0][0]                  
==================================================================================================
Total params: 1,076,454
Trainable params: 1,076,454
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 168s - loss: 0.0707 - acc: 0.9813 - val_loss: 0.0592 - val_acc: 0.9849
Epoch 2/40
 - 171s - loss: 0.0519 - acc: 0.9870 - val_loss: 0.0569 - val_acc: 0.9853
Epoch 3/40
 - 166s - loss: 0.0484 - acc: 0.9882 - val_loss: 0.0575 - val_acc: 0.9858
Epoch 4/40
 - 170s - loss: 0.0467 - acc: 0.9888 - val_loss: 0.0603 - val_acc: 0.9854
Epoch 5/40
 - 167s - loss: 0.0456 - acc: 0.9891 - val_loss: 0.0622 - val_acc: 0.9856
Epoch 00005: early stopping
	TRAINING TIME: 15.0 minutes 
==================================================================================================
	PARSING TIME: 5.37 minutes 
==================================================================================================
	Identification : 0.582
	P, R  : 0.744, 0.478

==================================================================================================
	XP Ends: 3/7 (7 h:6)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (7h:6)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 49)       354809      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1521        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 59)        427219      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1183        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_328 (Concatenate)   (None, 50, 58)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 295)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 138)          108744      concatenate_328[0][0]            
__________________________________________________________________________________________________
concatenate_329 (Concatenate)   (None, 330)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_330 (Concatenate)   (None, 468)          0           phraseRnn[0][0]                  
                                                                 concatenate_329[0][0]            
__________________________________________________________________________________________________
dense_219 (Dense)               (None, 318)          149142      concatenate_330[0][0]            
__________________________________________________________________________________________________
dense_220 (Dense)               (None, 4)            1276        dense_219[0][0]                  
==================================================================================================
Total params: 1,043,894
Trainable params: 1,043,894
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 121s - loss: 0.0805 - acc: 0.9782 - val_loss: 0.0732 - val_acc: 0.9797
Epoch 2/40
 - 109s - loss: 0.0559 - acc: 0.9858 - val_loss: 0.0620 - val_acc: 0.9838
Epoch 3/40
 - 110s - loss: 0.0514 - acc: 0.9872 - val_loss: 0.0626 - val_acc: 0.9843
Epoch 4/40
 - 109s - loss: 0.0492 - acc: 0.9879 - val_loss: 0.0653 - val_acc: 0.9835
Epoch 5/40
 - 116s - loss: 0.0480 - acc: 0.9882 - val_loss: 0.0675 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 10.0 minutes 
==================================================================================================
	PARSING TIME: 8.53 minutes 
==================================================================================================
	Identification : 0.533
	P, R  : 0.482, 0.595

==================================================================================================
	XP Ends: 3/7 (7 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (7h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 49)       675857      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        981         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 59)        813787      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         763         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_331 (Concatenate)   (None, 50, 58)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 295)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 138)          108744      concatenate_331[0][0]            
__________________________________________________________________________________________________
concatenate_332 (Concatenate)   (None, 330)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_333 (Concatenate)   (None, 468)          0           phraseRnn[0][0]                  
                                                                 concatenate_332[0][0]            
__________________________________________________________________________________________________
dense_221 (Dense)               (None, 318)          149142      concatenate_333[0][0]            
__________________________________________________________________________________________________
dense_222 (Dense)               (None, 4)            1276        dense_221[0][0]                  
==================================================================================================
Total params: 1,750,550
Trainable params: 1,750,550
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 258s - loss: 0.0705 - acc: 0.9811 - val_loss: 0.0595 - val_acc: 0.9836
Epoch 2/40
 - 231s - loss: 0.0535 - acc: 0.9861 - val_loss: 0.0584 - val_acc: 0.9842
Epoch 3/40
 - 221s - loss: 0.0500 - acc: 0.9875 - val_loss: 0.0611 - val_acc: 0.9839
Epoch 4/40
 - 231s - loss: 0.0481 - acc: 0.9882 - val_loss: 0.0647 - val_acc: 0.9840
Epoch 5/40
 - 217s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0687 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 20.88 minutes 
==================================================================================================
	PARSING TIME: 3.63 minutes 
==================================================================================================
	Identification : 0.494
	P, R  : 0.478, 0.512

==================================================================================================
	XP Ends: 3/7 (7 h:50)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,115            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.04           ,50             ,33             ,178            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
35             ,119            ,True           ,True           ,61             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 115, False, 0.04, 50, 33, 178, 35, 119, True, True, 61
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (7h:50)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 178)      1343010     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 33)       5016        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 119)       897855      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 35)        5320        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_334 (Concatenate)   (None, 50, 211)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 595)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 175)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 61)           66612       concatenate_334[0][0]            
__________________________________________________________________________________________________
concatenate_335 (Concatenate)   (None, 770)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_336 (Concatenate)   (None, 831)          0           phraseRnn[0][0]                  
                                                                 concatenate_335[0][0]            
__________________________________________________________________________________________________
dense_223 (Dense)               (None, 115)          95680       concatenate_336[0][0]            
__________________________________________________________________________________________________
dense_224 (Dense)               (None, 4)            464         dense_223[0][0]                  
==================================================================================================
Total params: 2,413,957
Trainable params: 2,413,957
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 173s - loss: 0.0647 - acc: 0.9831 - val_loss: 0.0546 - val_acc: 0.9861
Epoch 2/40
 - 165s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0543 - val_acc: 0.9860
Epoch 3/40
 - 172s - loss: 0.0466 - acc: 0.9888 - val_loss: 0.0590 - val_acc: 0.9857
Epoch 4/40
 - 163s - loss: 0.0450 - acc: 0.9892 - val_loss: 0.0620 - val_acc: 0.9858
Epoch 5/40
 - 164s - loss: 0.0440 - acc: 0.9894 - val_loss: 0.0662 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 14.75 minutes 
==================================================================================================
	PARSING TIME: 5.65 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.612, 0.546

==================================================================================================
	XP Ends: 3/7 (8 h:11)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (8h:11)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 178)      1288898     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 33)       5577        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 119)       861679      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 35)        5915        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_337 (Concatenate)   (None, 50, 211)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 595)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 175)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 61)           66612       concatenate_337[0][0]            
__________________________________________________________________________________________________
concatenate_338 (Concatenate)   (None, 770)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_339 (Concatenate)   (None, 831)          0           phraseRnn[0][0]                  
                                                                 concatenate_338[0][0]            
__________________________________________________________________________________________________
dense_225 (Dense)               (None, 115)          95680       concatenate_339[0][0]            
__________________________________________________________________________________________________
dense_226 (Dense)               (None, 4)            464         dense_225[0][0]                  
==================================================================================================
Total params: 2,324,825
Trainable params: 2,324,825
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 111s - loss: 0.0719 - acc: 0.9807 - val_loss: 0.0587 - val_acc: 0.9848
Epoch 2/40
 - 111s - loss: 0.0518 - acc: 0.9871 - val_loss: 0.0610 - val_acc: 0.9847
Epoch 3/40
 - 113s - loss: 0.0482 - acc: 0.9882 - val_loss: 0.0617 - val_acc: 0.9849
Epoch 4/40
 - 111s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0659 - val_acc: 0.9848
Epoch 5/40
 - 110s - loss: 0.0460 - acc: 0.9887 - val_loss: 0.0731 - val_acc: 0.9844
Epoch 00005: early stopping
	TRAINING TIME: 9.78 minutes 
==================================================================================================
	PARSING TIME: 8.52 minutes 
==================================================================================================
	Identification : 0.452
	P, R  : 0.349, 0.642

==================================================================================================
	XP Ends: 3/7 (8 h:30)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (8h:30)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 178)      2455154     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 33)       3597        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 119)       1641367     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 35)        3815        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_340 (Concatenate)   (None, 50, 211)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 595)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 175)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 61)           66612       concatenate_340[0][0]            
__________________________________________________________________________________________________
concatenate_341 (Concatenate)   (None, 770)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_342 (Concatenate)   (None, 831)          0           phraseRnn[0][0]                  
                                                                 concatenate_341[0][0]            
__________________________________________________________________________________________________
dense_227 (Dense)               (None, 115)          95680       concatenate_342[0][0]            
__________________________________________________________________________________________________
dense_228 (Dense)               (None, 4)            464         dense_227[0][0]                  
==================================================================================================
Total params: 4,266,689
Trainable params: 4,266,689
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 235s - loss: 0.0647 - acc: 0.9825 - val_loss: 0.0575 - val_acc: 0.9846
Epoch 2/40
 - 233s - loss: 0.0510 - acc: 0.9870 - val_loss: 0.0572 - val_acc: 0.9849
Epoch 3/40
 - 223s - loss: 0.0480 - acc: 0.9882 - val_loss: 0.0608 - val_acc: 0.9846
Epoch 4/40
 - 222s - loss: 0.0463 - acc: 0.9886 - val_loss: 0.0677 - val_acc: 0.9843
Epoch 5/40
 - 228s - loss: 0.0451 - acc: 0.9889 - val_loss: 0.0781 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 20.48 minutes 
==================================================================================================
	PARSING TIME: 3.58 minutes 
==================================================================================================
	Identification : 0.496
	P, R  : 0.472, 0.522

==================================================================================================
	XP Ends: 3/7 (8 h:54)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,31             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.049          ,50             ,27             ,64             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,127            ,True           ,True           ,58             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 31, True, 0.049, 50, 27, 64, 10, 127, True, True, 58
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (8h:54)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 64)       482880      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 27)       4104        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 127)       958215      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_343 (Concatenate)   (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 635)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 58)           26100       concatenate_343[0][0]            
__________________________________________________________________________________________________
concatenate_344 (Concatenate)   (None, 685)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_345 (Concatenate)   (None, 743)          0           phraseRnn[0][0]                  
                                                                 concatenate_344[0][0]            
__________________________________________________________________________________________________
dense_229 (Dense)               (None, 31)           23064       concatenate_345[0][0]            
__________________________________________________________________________________________________
dense_230 (Dense)               (None, 4)            128         dense_229[0][0]                  
==================================================================================================
Total params: 1,496,011
Trainable params: 1,496,011
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 0.0651 - acc: 0.9830 - val_loss: 0.0550 - val_acc: 0.9857
Epoch 2/40
 - 136s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0551 - val_acc: 0.9862
Epoch 3/40
 - 136s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0573 - val_acc: 0.9861
Epoch 4/40
 - 137s - loss: 0.0452 - acc: 0.9892 - val_loss: 0.0606 - val_acc: 0.9859
Epoch 5/40
 - 139s - loss: 0.0444 - acc: 0.9894 - val_loss: 0.0643 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 12.18 minutes 
==================================================================================================
	PARSING TIME: 5.0 minutes 
==================================================================================================
	Identification : 0.591
	P, R  : 0.7, 0.512

==================================================================================================
	XP Ends: 3/7 (9 h:12)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (9h:12)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 64)       463424      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 27)       4563        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 127)       919607      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_346 (Concatenate)   (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 635)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 58)           26100       concatenate_346[0][0]            
__________________________________________________________________________________________________
concatenate_347 (Concatenate)   (None, 685)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_348 (Concatenate)   (None, 743)          0           phraseRnn[0][0]                  
                                                                 concatenate_347[0][0]            
__________________________________________________________________________________________________
dense_231 (Dense)               (None, 31)           23064       concatenate_348[0][0]            
__________________________________________________________________________________________________
dense_232 (Dense)               (None, 4)            128         dense_231[0][0]                  
==================================================================================================
Total params: 1,438,576
Trainable params: 1,438,576
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0731 - acc: 0.9802 - val_loss: 0.0596 - val_acc: 0.9843
Epoch 2/40
 - 93s - loss: 0.0521 - acc: 0.9869 - val_loss: 0.0622 - val_acc: 0.9850
Epoch 3/40
 - 92s - loss: 0.0484 - acc: 0.9881 - val_loss: 0.0621 - val_acc: 0.9845
Epoch 4/40
 - 92s - loss: 0.0472 - acc: 0.9885 - val_loss: 0.0651 - val_acc: 0.9847
Epoch 5/40
 - 94s - loss: 0.0462 - acc: 0.9887 - val_loss: 0.0677 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 8.25 minutes 
==================================================================================================
	PARSING TIME: 6.58 minutes 
==================================================================================================
	Identification : 0.549
	P, R  : 0.495, 0.615

==================================================================================================
	XP Ends: 3/7 (9 h:27)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (9h:27)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 64)       882752      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 27)       2943        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 127)       1751711     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_349 (Concatenate)   (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 635)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 58)           26100       concatenate_349[0][0]            
__________________________________________________________________________________________________
concatenate_350 (Concatenate)   (None, 685)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_351 (Concatenate)   (None, 743)          0           phraseRnn[0][0]                  
                                                                 concatenate_350[0][0]            
__________________________________________________________________________________________________
dense_233 (Dense)               (None, 31)           23064       concatenate_351[0][0]            
__________________________________________________________________________________________________
dense_234 (Dense)               (None, 4)            128         dense_233[0][0]                  
==================================================================================================
Total params: 2,687,788
Trainable params: 2,687,788
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 183s - loss: 0.0666 - acc: 0.9819 - val_loss: 0.0577 - val_acc: 0.9841
Epoch 2/40
 - 184s - loss: 0.0514 - acc: 0.9869 - val_loss: 0.0574 - val_acc: 0.9845
Epoch 3/40
 - 184s - loss: 0.0483 - acc: 0.9880 - val_loss: 0.0607 - val_acc: 0.9843
Epoch 4/40
 - 184s - loss: 0.0465 - acc: 0.9886 - val_loss: 0.0645 - val_acc: 0.9842
Epoch 5/40
 - 184s - loss: 0.0455 - acc: 0.9889 - val_loss: 0.0678 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 16.8 minutes 
==================================================================================================
	PARSING TIME: 2.72 minutes 
==================================================================================================
	Identification : 0.486
	P, R  : 0.557, 0.431

==================================================================================================
	XP Ends: 3/7 (9 h:47)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,172            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.13           ,50             ,33             ,99             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
6              ,138            ,False          ,True           ,259            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 172, True, 0.13, 50, 33, 99, 6, 138, False, True, 259
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (9h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 99)       746955      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 33)       5016        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 138)       1041210     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 6)         912         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_352 (Concatenate)   (None, 50, 132)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 552)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 24)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 259)          304584      concatenate_352[0][0]            
__________________________________________________________________________________________________
concatenate_353 (Concatenate)   (None, 576)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_354 (Concatenate)   (None, 835)          0           phraseRnn[0][0]                  
                                                                 concatenate_353[0][0]            
__________________________________________________________________________________________________
dense_235 (Dense)               (None, 172)          143792      concatenate_354[0][0]            
__________________________________________________________________________________________________
dense_236 (Dense)               (None, 4)            692         dense_235[0][0]                  
==================================================================================================
Total params: 2,243,161
Trainable params: 2,243,161
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 170s - loss: 11.8120 - acc: 0.2668 - val_loss: 11.7568 - val_acc: 0.2706
Epoch 2/40
 - 170s - loss: 11.8140 - acc: 0.2670 - val_loss: 11.7568 - val_acc: 0.2706
Epoch 3/40
 - 170s - loss: 11.8140 - acc: 0.2670 - val_loss: 11.7568 - val_acc: 0.2706
Epoch 4/40
 - 170s - loss: 11.8140 - acc: 0.2670 - val_loss: 11.7568 - val_acc: 0.2706
Epoch 5/40
 - 170s - loss: 11.8140 - acc: 0.2670 - val_loss: 11.7568 - val_acc: 0.2706
Epoch 00005: early stopping
	TRAINING TIME: 15.05 minutes 
==================================================================================================
	PARSING TIME: 7.58 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (10 h:10)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (10h:10)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 99)       716859      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 33)       5577        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 138)       999258      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 6)         1014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_355 (Concatenate)   (None, 50, 132)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 552)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 24)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 259)          304584      concatenate_355[0][0]            
__________________________________________________________________________________________________
concatenate_356 (Concatenate)   (None, 576)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_357 (Concatenate)   (None, 835)          0           phraseRnn[0][0]                  
                                                                 concatenate_356[0][0]            
__________________________________________________________________________________________________
dense_237 (Dense)               (None, 172)          143792      concatenate_357[0][0]            
__________________________________________________________________________________________________
dense_238 (Dense)               (None, 4)            692         dense_237[0][0]                  
==================================================================================================
Total params: 2,171,776
Trainable params: 2,171,776
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 115s - loss: 12.0908 - acc: 0.2495 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 2/40
 - 115s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 3/40
 - 115s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 4/40
 - 115s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 5/40
 - 115s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 00005: early stopping
	TRAINING TIME: 10.12 minutes 
==================================================================================================
	PARSING TIME: 11.65 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (10 h:32)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (10h:32)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 99)       1365507     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 33)       3597        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 138)       1903434     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 6)         654         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_358 (Concatenate)   (None, 50, 132)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 552)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 24)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 259)          304584      concatenate_358[0][0]            
__________________________________________________________________________________________________
concatenate_359 (Concatenate)   (None, 576)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_360 (Concatenate)   (None, 835)          0           phraseRnn[0][0]                  
                                                                 concatenate_359[0][0]            
__________________________________________________________________________________________________
dense_239 (Dense)               (None, 172)          143792      concatenate_360[0][0]            
__________________________________________________________________________________________________
dense_240 (Dense)               (None, 4)            692         dense_239[0][0]                  
==================================================================================================
Total params: 3,722,260
Trainable params: 3,722,260
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 230s - loss: 12.0791 - acc: 0.2504 - val_loss: 12.1001 - val_acc: 0.2493
Epoch 2/40
 - 230s - loss: 12.0845 - acc: 0.2503 - val_loss: 12.1001 - val_acc: 0.2493
Epoch 3/40
 - 230s - loss: 12.0845 - acc: 0.2503 - val_loss: 12.1001 - val_acc: 0.2493
Epoch 4/40
 - 230s - loss: 12.0845 - acc: 0.2503 - val_loss: 12.1001 - val_acc: 0.2493
Epoch 5/40
 - 230s - loss: 12.0845 - acc: 0.2503 - val_loss: 12.1001 - val_acc: 0.2493
Epoch 00005: early stopping
	TRAINING TIME: 20.57 minutes 
==================================================================================================
	PARSING TIME: 5.07 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (10 h:58)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,193            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.013          ,50             ,28             ,116            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,117            ,True           ,True           ,296            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 193, True, 0.013, 50, 28, 116, 10, 117, True, True, 296
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (10h:58)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 116)      875220      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 28)       4256        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 117)       882765      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_361 (Concatenate)   (None, 50, 144)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 585)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 296)          391608      concatenate_361[0][0]            
__________________________________________________________________________________________________
concatenate_362 (Concatenate)   (None, 635)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_363 (Concatenate)   (None, 931)          0           phraseRnn[0][0]                  
                                                                 concatenate_362[0][0]            
__________________________________________________________________________________________________
dense_241 (Dense)               (None, 193)          179876      concatenate_363[0][0]            
__________________________________________________________________________________________________
dense_242 (Dense)               (None, 4)            776         dense_241[0][0]                  
==================================================================================================
Total params: 2,336,021
Trainable params: 2,336,021
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 186s - loss: 0.0676 - acc: 0.9822 - val_loss: 0.0561 - val_acc: 0.9856
Epoch 2/40
 - 186s - loss: 0.0509 - acc: 0.9874 - val_loss: 0.0558 - val_acc: 0.9859
Epoch 3/40
 - 186s - loss: 0.0476 - acc: 0.9885 - val_loss: 0.0577 - val_acc: 0.9860
Epoch 4/40
 - 186s - loss: 0.0459 - acc: 0.9890 - val_loss: 0.0598 - val_acc: 0.9858
Epoch 5/40
 - 186s - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0640 - val_acc: 0.9855
Epoch 00005: early stopping
	TRAINING TIME: 16.47 minutes 
==================================================================================================
	PARSING TIME: 4.4 minutes 
==================================================================================================
	Identification : 0.568
	P, R  : 0.775, 0.448

==================================================================================================
	XP Ends: 3/7 (11 h:19)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (11h:19)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 116)      839956      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 28)       4732        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 117)       847197      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_364 (Concatenate)   (None, 50, 144)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 585)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 296)          391608      concatenate_364[0][0]            
__________________________________________________________________________________________________
concatenate_365 (Concatenate)   (None, 635)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_366 (Concatenate)   (None, 931)          0           phraseRnn[0][0]                  
                                                                 concatenate_365[0][0]            
__________________________________________________________________________________________________
dense_243 (Dense)               (None, 193)          179876      concatenate_366[0][0]            
__________________________________________________________________________________________________
dense_244 (Dense)               (None, 4)            776         dense_243[0][0]                  
==================================================================================================
Total params: 2,265,835
Trainable params: 2,265,835
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 127s - loss: 1.2928 - acc: 0.9009 - val_loss: 0.0738 - val_acc: 0.9809
Epoch 2/40
 - 127s - loss: 0.0645 - acc: 0.9836 - val_loss: 0.0713 - val_acc: 0.9822
Epoch 3/40
 - 127s - loss: 0.0577 - acc: 0.9855 - val_loss: 0.0744 - val_acc: 0.9827
Epoch 4/40
 - 127s - loss: 0.0548 - acc: 0.9863 - val_loss: 0.1088 - val_acc: 0.9722
Epoch 5/40
 - 127s - loss: 0.0533 - acc: 0.9867 - val_loss: 0.0742 - val_acc: 0.9828
Epoch 00005: early stopping
	TRAINING TIME: 11.12 minutes 
==================================================================================================
	PARSING TIME: 7.1 minutes 
==================================================================================================
	Identification : 0.467
	P, R  : 0.37, 0.633

==================================================================================================
	XP Ends: 3/7 (11 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (11h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 116)      1599988     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 28)       3052        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 117)       1613781     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_367 (Concatenate)   (None, 50, 144)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 585)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 296)          391608      concatenate_367[0][0]            
__________________________________________________________________________________________________
concatenate_368 (Concatenate)   (None, 635)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_369 (Concatenate)   (None, 931)          0           phraseRnn[0][0]                  
                                                                 concatenate_368[0][0]            
__________________________________________________________________________________________________
dense_245 (Dense)               (None, 193)          179876      concatenate_369[0][0]            
__________________________________________________________________________________________________
dense_246 (Dense)               (None, 4)            776         dense_245[0][0]                  
==================================================================================================
Total params: 3,790,171
Trainable params: 3,790,171
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 254s - loss: 0.0686 - acc: 0.9815 - val_loss: 0.0581 - val_acc: 0.9842
Epoch 2/40
 - 254s - loss: 0.0524 - acc: 0.9865 - val_loss: 0.0585 - val_acc: 0.9846
Epoch 3/40
 - 254s - loss: 0.0493 - acc: 0.9878 - val_loss: 0.0612 - val_acc: 0.9841
Epoch 4/40
 - 254s - loss: 0.0474 - acc: 0.9883 - val_loss: 0.0650 - val_acc: 0.9839
Epoch 5/40
 - 254s - loss: 0.0462 - acc: 0.9887 - val_loss: 0.0708 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 22.62 minutes 
==================================================================================================
	PARSING TIME: 3.0 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.513, 0.439

==================================================================================================
	XP Ends: 3/7 (12 h:4)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,146            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.014          ,50             ,13             ,30             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
25             ,43             ,True           ,True           ,356            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 146, True, 0.014, 50, 13, 30, 25, 43, True, True, 356
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (12h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 30)       343140      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1976        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 43)        491834      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        3800        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_370 (Concatenate)   (None, 50, 43)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 215)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 356)          427200      concatenate_370[0][0]            
__________________________________________________________________________________________________
concatenate_371 (Concatenate)   (None, 340)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_372 (Concatenate)   (None, 696)          0           phraseRnn[0][0]                  
                                                                 concatenate_371[0][0]            
__________________________________________________________________________________________________
dense_247 (Dense)               (None, 146)          101762      concatenate_372[0][0]            
__________________________________________________________________________________________________
dense_248 (Dense)               (None, 4)            588         dense_247[0][0]                  
==================================================================================================
Total params: 1,370,300
Trainable params: 1,370,300
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 195s - loss: 0.0953 - acc: 0.9766 - val_loss: 0.0626 - val_acc: 0.9841
Epoch 2/40
 - 195s - loss: 0.0569 - acc: 0.9856 - val_loss: 0.0811 - val_acc: 0.9849
Epoch 3/40
 - 195s - loss: 0.0514 - acc: 0.9872 - val_loss: 0.0610 - val_acc: 0.9851
Epoch 4/40
 - 195s - loss: 0.0483 - acc: 0.9882 - val_loss: 0.0654 - val_acc: 0.9850
Epoch 5/40
 - 195s - loss: 0.0465 - acc: 0.9888 - val_loss: 0.0662 - val_acc: 0.9853
Epoch 00005: early stopping
	TRAINING TIME: 17.1 minutes 
==================================================================================================
	PARSING TIME: 4.73 minutes 
==================================================================================================
	Identification : 0.521
	P, R  : 0.452, 0.615

==================================================================================================
	XP Ends: 3/7 (12 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (12h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 30)       282030      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       2197        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 43)        404243      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        4225        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_373 (Concatenate)   (None, 50, 43)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 215)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 356)          427200      concatenate_373[0][0]            
__________________________________________________________________________________________________
concatenate_374 (Concatenate)   (None, 340)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_375 (Concatenate)   (None, 696)          0           phraseRnn[0][0]                  
                                                                 concatenate_374[0][0]            
__________________________________________________________________________________________________
dense_249 (Dense)               (None, 146)          101762      concatenate_375[0][0]            
__________________________________________________________________________________________________
dense_250 (Dense)               (None, 4)            588         dense_249[0][0]                  
==================================================================================================
Total params: 1,222,245
Trainable params: 1,222,245
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 132s - loss: 0.0801 - acc: 0.9779 - val_loss: 0.0627 - val_acc: 0.9830
Epoch 2/40
 - 132s - loss: 0.0560 - acc: 0.9859 - val_loss: 0.0613 - val_acc: 0.9839
Epoch 3/40
 - 132s - loss: 0.0513 - acc: 0.9874 - val_loss: 0.0617 - val_acc: 0.9840
Epoch 4/40
 - 132s - loss: 0.0491 - acc: 0.9880 - val_loss: 0.0657 - val_acc: 0.9838
Epoch 5/40
 - 132s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0692 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 11.5 minutes 
==================================================================================================
	PARSING TIME: 7.23 minutes 
==================================================================================================
	Identification : 0.387
	P, R  : 0.278, 0.638

==================================================================================================
	XP Ends: 3/7 (12 h:45)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (12h:45)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 30)       662130      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1417        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 43)        949053      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        2725        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_376 (Concatenate)   (None, 50, 43)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 215)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 356)          427200      concatenate_376[0][0]            
__________________________________________________________________________________________________
concatenate_377 (Concatenate)   (None, 340)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_378 (Concatenate)   (None, 696)          0           phraseRnn[0][0]                  
                                                                 concatenate_377[0][0]            
__________________________________________________________________________________________________
dense_251 (Dense)               (None, 146)          101762      concatenate_378[0][0]            
__________________________________________________________________________________________________
dense_252 (Dense)               (None, 4)            588         dense_251[0][0]                  
==================================================================================================
Total params: 2,144,875
Trainable params: 2,144,875
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 264s - loss: 0.0697 - acc: 0.9807 - val_loss: 0.0613 - val_acc: 0.9834
Epoch 2/40
 - 264s - loss: 0.0509 - acc: 0.9872 - val_loss: 0.0608 - val_acc: 0.9838
Epoch 3/40
 - 264s - loss: 0.0473 - acc: 0.9885 - val_loss: 0.0635 - val_acc: 0.9838
Epoch 4/40
 - 264s - loss: 0.0456 - acc: 0.9890 - val_loss: 0.0687 - val_acc: 0.9833
Epoch 5/40
 - 264s - loss: 0.0444 - acc: 0.9892 - val_loss: 0.0732 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 23.45 minutes 
==================================================================================================
	PARSING TIME: 3.1 minutes 
==================================================================================================
	Identification : 0.509
	P, R  : 0.444, 0.596

==================================================================================================
	XP Ends: 3/7 (13 h:12)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,202            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.026          ,50             ,47             ,28             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,31             ,True           ,True           ,98             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 202, True, 0.026, 50, 47, 28, 10, 31, True, True, 98
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (13h:12)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 28)       211260      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 47)       7144        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 31)        233895      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_379 (Concatenate)   (None, 50, 75)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 155)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 98)           51156       concatenate_379[0][0]            
__________________________________________________________________________________________________
concatenate_380 (Concatenate)   (None, 205)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_381 (Concatenate)   (None, 303)          0           phraseRnn[0][0]                  
                                                                 concatenate_380[0][0]            
__________________________________________________________________________________________________
dense_253 (Dense)               (None, 202)          61408       concatenate_381[0][0]            
__________________________________________________________________________________________________
dense_254 (Dense)               (None, 4)            812         dense_253[0][0]                  
==================================================================================================
Total params: 567,195
Trainable params: 567,195
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 133s - loss: 0.0661 - acc: 0.9825 - val_loss: 0.0557 - val_acc: 0.9854
Epoch 2/40
 - 133s - loss: 0.0506 - acc: 0.9874 - val_loss: 0.0561 - val_acc: 0.9860
Epoch 3/40
 - 133s - loss: 0.0473 - acc: 0.9885 - val_loss: 0.0568 - val_acc: 0.9860
Epoch 4/40
 - 133s - loss: 0.0458 - acc: 0.9890 - val_loss: 0.0609 - val_acc: 0.9860
Epoch 5/40
 - 133s - loss: 0.0446 - acc: 0.9893 - val_loss: 0.0648 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 11.93 minutes 
==================================================================================================
	PARSING TIME: 4.12 minutes 
==================================================================================================
	Identification : 0.591
	P, R  : 0.77, 0.479

==================================================================================================
	XP Ends: 3/7 (13 h:29)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (13h:29)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 28)       202748      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 47)       7943        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 31)        224471      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_382 (Concatenate)   (None, 50, 75)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 155)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 98)           51156       concatenate_382[0][0]            
__________________________________________________________________________________________________
concatenate_383 (Concatenate)   (None, 205)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_384 (Concatenate)   (None, 303)          0           phraseRnn[0][0]                  
                                                                 concatenate_383[0][0]            
__________________________________________________________________________________________________
dense_255 (Dense)               (None, 202)          61408       concatenate_384[0][0]            
__________________________________________________________________________________________________
dense_256 (Dense)               (None, 4)            812         dense_255[0][0]                  
==================================================================================================
Total params: 550,228
Trainable params: 550,228
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 92s - loss: 0.0745 - acc: 0.9798 - val_loss: 0.0609 - val_acc: 0.9840
Epoch 2/40
 - 92s - loss: 0.0536 - acc: 0.9864 - val_loss: 0.0609 - val_acc: 0.9844
Epoch 3/40
 - 91s - loss: 0.0494 - acc: 0.9879 - val_loss: 0.0622 - val_acc: 0.9842
Epoch 4/40
 - 91s - loss: 0.0477 - acc: 0.9884 - val_loss: 0.0655 - val_acc: 0.9844
Epoch 5/40
 - 91s - loss: 0.0467 - acc: 0.9885 - val_loss: 0.0705 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 8.08 minutes 
==================================================================================================
	PARSING TIME: 6.3 minutes 
==================================================================================================
	Identification : 0.492
	P, R  : 0.408, 0.62

==================================================================================================
	XP Ends: 3/7 (13 h:44)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (13h:44)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 28)       386204      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 47)       5123        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 31)        427583      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_385 (Concatenate)   (None, 50, 75)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 155)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 98)           51156       concatenate_385[0][0]            
__________________________________________________________________________________________________
concatenate_386 (Concatenate)   (None, 205)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_387 (Concatenate)   (None, 303)          0           phraseRnn[0][0]                  
                                                                 concatenate_386[0][0]            
__________________________________________________________________________________________________
dense_257 (Dense)               (None, 202)          61408       concatenate_387[0][0]            
__________________________________________________________________________________________________
dense_258 (Dense)               (None, 4)            812         dense_257[0][0]                  
==================================================================================================
Total params: 933,376
Trainable params: 933,376
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 180s - loss: 0.0668 - acc: 0.9818 - val_loss: 0.0575 - val_acc: 0.9845
Epoch 2/40
 - 180s - loss: 0.0522 - acc: 0.9867 - val_loss: 0.0576 - val_acc: 0.9843
Epoch 3/40
 - 180s - loss: 0.0490 - acc: 0.9878 - val_loss: 0.0612 - val_acc: 0.9841
Epoch 4/40
 - 180s - loss: 0.0472 - acc: 0.9884 - val_loss: 0.0652 - val_acc: 0.9839
Epoch 5/40
 - 180s - loss: 0.0459 - acc: 0.9888 - val_loss: 0.0714 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 16.45 minutes 
==================================================================================================
	PARSING TIME: 2.8 minutes 
==================================================================================================
	Identification : 0.513
	P, R  : 0.494, 0.533

==================================================================================================
	XP Ends: 3/7 (14 h:3)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,412            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.016          ,50             ,5              ,55             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
14             ,161            ,True           ,False          ,428            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 412, False, 0.016, 50, 5, 55, 14, 161, True, False, 428
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (14h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 55)       414975      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 161)       1214745     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 14)        2128        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_388 (Concatenate)   (None, 50, 60)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 644)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 56)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 428)          837168      concatenate_388[0][0]            
__________________________________________________________________________________________________
concatenate_389 (Concatenate)   (None, 700)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_390 (Concatenate)   (None, 1128)         0           phraseRnn[0][0]                  
                                                                 concatenate_389[0][0]            
__________________________________________________________________________________________________
dense_259 (Dense)               (None, 412)          465148      concatenate_390[0][0]            
__________________________________________________________________________________________________
dense_260 (Dense)               (None, 4)            1652        dense_259[0][0]                  
==================================================================================================
Total params: 2,936,576
Trainable params: 2,936,576
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 297s - loss: 12.0783 - acc: 0.2503 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 2/40
 - 297s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 3/40
 - 297s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 4/40
 - 297s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 5/40
 - 297s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 00005: early stopping
	TRAINING TIME: 25.63 minutes 
==================================================================================================
	PARSING TIME: 7.32 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (14 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (14h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 55)       398255      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 161)       1165801     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 14)        2366        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_391 (Concatenate)   (None, 50, 60)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 644)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 56)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 428)          837168      concatenate_391[0][0]            
__________________________________________________________________________________________________
concatenate_392 (Concatenate)   (None, 700)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_393 (Concatenate)   (None, 1128)         0           phraseRnn[0][0]                  
                                                                 concatenate_392[0][0]            
__________________________________________________________________________________________________
dense_261 (Dense)               (None, 412)          465148      concatenate_393[0][0]            
__________________________________________________________________________________________________
dense_262 (Dense)               (None, 4)            1652        dense_261[0][0]                  
==================================================================================================
Total params: 2,871,235
Trainable params: 2,871,235
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 202s - loss: 0.0935 - acc: 0.9756 - val_loss: 0.0655 - val_acc: 0.9823
Epoch 2/40
 - 202s - loss: 0.0589 - acc: 0.9845 - val_loss: 0.0664 - val_acc: 0.9822
Epoch 3/40
 - 202s - loss: 0.0548 - acc: 0.9859 - val_loss: 0.0652 - val_acc: 0.9829
Epoch 4/40
 - 202s - loss: 0.0516 - acc: 0.9869 - val_loss: 0.0689 - val_acc: 0.9828
Epoch 5/40
 - 202s - loss: 0.0497 - acc: 0.9875 - val_loss: 0.0700 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 17.4 minutes 
==================================================================================================
	PARSING TIME: 11.55 minutes 
==================================================================================================
	Identification : 0.512
	P, R  : 0.447, 0.6

==================================================================================================
	XP Ends: 3/7 (15 h:6)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (15h:6)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 55)       758615      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 161)       2220673     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 14)        1526        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_394 (Concatenate)   (None, 50, 60)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 644)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 56)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 428)          837168      concatenate_394[0][0]            
__________________________________________________________________________________________________
concatenate_395 (Concatenate)   (None, 700)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_396 (Concatenate)   (None, 1128)         0           phraseRnn[0][0]                  
                                                                 concatenate_395[0][0]            
__________________________________________________________________________________________________
dense_263 (Dense)               (None, 412)          465148      concatenate_396[0][0]            
__________________________________________________________________________________________________
dense_264 (Dense)               (None, 4)            1652        dense_263[0][0]                  
==================================================================================================
Total params: 4,285,327
Trainable params: 4,285,327
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 402s - loss: 0.0791 - acc: 0.9794 - val_loss: 0.0613 - val_acc: 0.9835
Epoch 2/40
 - 402s - loss: 0.0559 - acc: 0.9851 - val_loss: 0.0595 - val_acc: 0.9838
Epoch 3/40
 - 402s - loss: 0.0528 - acc: 0.9862 - val_loss: 0.0622 - val_acc: 0.9833
Epoch 4/40
 - 402s - loss: 0.0507 - acc: 0.9870 - val_loss: 0.0654 - val_acc: 0.9836
Epoch 5/40
 - 402s - loss: 0.0496 - acc: 0.9873 - val_loss: 0.0692 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 35.03 minutes 
==================================================================================================
## OAR [2019-07-03 15:42:28] Job 1988945 KILLED ##
