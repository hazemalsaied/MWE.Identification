Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_vIUCMK.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 10869/11441 Mb (0.950000) on cuda
Mapped name None to device cuda: Tesla K40m (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,36             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.063          ,50             ,44             ,47             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
7              ,42             ,True           ,False          ,35             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 36, False, 0.063, 50, 44, 47, 7, 42, True, False, 35
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (14h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 47)       537586      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 44)       6688        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 42)        480396      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 7)         1064        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 168)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 28)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 35)           17780       concatenate_1[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 196)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 231)          0           phraseRnn[0][0]                  
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 36)           8352        concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            148         dense_1[0][0]                    
==================================================================================================
Total params: 1,052,014
Trainable params: 1,052,014
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 308s - loss: 0.0658 - acc: 0.9827 - val_loss: 0.0542 - val_acc: 0.9862
Epoch 2/40
 - 307s - loss: 0.0500 - acc: 0.9876 - val_loss: 0.0543 - val_acc: 0.9863
Epoch 3/40
 - 308s - loss: 0.0475 - acc: 0.9884 - val_loss: 0.0575 - val_acc: 0.9857
Epoch 4/40
 - 309s - loss: 0.0461 - acc: 0.9889 - val_loss: 0.0604 - val_acc: 0.9857
Epoch 5/40
 - 308s - loss: 0.0451 - acc: 0.9891 - val_loss: 0.0635 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 29.93 minutes 
==================================================================================================
	PARSING TIME: 9.98 minutes 
==================================================================================================
	Identification : 0.515
	P, R  : 0.465, 0.578

==================================================================================================
	XP Ends: 28/6 (14 h:44)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (14h:44)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 47)       441847      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 44)       7436        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 42)        394842      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 7)         1183        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 168)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 28)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 35)           17780       concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 196)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 231)          0           phraseRnn[0][0]                  
                                                                 concatenate_5[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 36)           8352        concatenate_6[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            148         dense_3[0][0]                    
==================================================================================================
Total params: 871,588
Trainable params: 871,588
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 217s - loss: 0.0771 - acc: 0.9786 - val_loss: 0.0610 - val_acc: 0.9838
Epoch 2/40
 - 217s - loss: 0.0547 - acc: 0.9861 - val_loss: 0.0619 - val_acc: 0.9843
Epoch 3/40
 - 214s - loss: 0.0504 - acc: 0.9874 - val_loss: 0.0642 - val_acc: 0.9837
Epoch 4/40
 - 217s - loss: 0.0482 - acc: 0.9881 - val_loss: 0.0687 - val_acc: 0.9838
Epoch 5/40
 - 215s - loss: 0.0472 - acc: 0.9884 - val_loss: 0.0746 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 19.03 minutes 
==================================================================================================
	PARSING TIME: 15.28 minutes 
==================================================================================================
	Identification : 0.392
	P, R  : 0.307, 0.544

==================================================================================================
	XP Ends: 28/6 (15 h:19)
==================================================================================================
/home/halsaied/miniconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.py:399: UserWarning: The graph doesn't contain a node that depends on the root element.
  "The graph doesn't contain a node " "that depends on the root element."
# Seed: 0
==================================================================================================
XP Starts: 28/6 (15h:19)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 47)       1037337     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 44)       4796        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 42)        926982      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 7)         763         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 168)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 28)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 35)           17780       concatenate_7[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 196)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 231)          0           phraseRnn[0][0]                  
                                                                 concatenate_8[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 36)           8352        concatenate_9[0][0]              
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            148         dense_5[0][0]                    
==================================================================================================
Total params: 1,996,158
Trainable params: 1,996,158
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 423s - loss: 0.0636 - acc: 0.9829 - val_loss: 0.0584 - val_acc: 0.9841
Epoch 2/40
 - 417s - loss: 0.0495 - acc: 0.9876 - val_loss: 0.0624 - val_acc: 0.9834
Epoch 3/40
 - 420s - loss: 0.0466 - acc: 0.9886 - val_loss: 0.0628 - val_acc: 0.9839
Epoch 4/40
 - 413s - loss: 0.0449 - acc: 0.9891 - val_loss: 0.0713 - val_acc: 0.9836
Epoch 5/40
 - 416s - loss: 0.0438 - acc: 0.9893 - val_loss: 0.0811 - val_acc: 0.9833
Epoch 00005: early stopping
	TRAINING TIME: 37.5 minutes 
==================================================================================================
	PARSING TIME: 6.75 minutes 
==================================================================================================
	Identification : 0.483
	P, R  : 0.41, 0.588

==================================================================================================
	XP Ends: 28/6 (16 h:4)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,60             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.018          ,50             ,18             ,49             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
20             ,160            ,True           ,True           ,96             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 60, False, 0.018, 50, 18, 49, 20, 160, True, True, 96
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (16h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 49)       560462      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       2736        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 160)       1830080     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 20)        3040        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 50, 67)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 800)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 100)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 96)           62976       concatenate_10[0][0]             
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 900)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 996)          0           phraseRnn[0][0]                  
                                                                 concatenate_11[0][0]             
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 60)           59820       concatenate_12[0][0]             
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4)            244         dense_7[0][0]                    
==================================================================================================
Total params: 2,519,358
Trainable params: 2,519,358
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 337s - loss: 0.0654 - acc: 0.9828 - val_loss: 0.0538 - val_acc: 0.9862
Epoch 2/40
 - 338s - loss: 0.0491 - acc: 0.9881 - val_loss: 0.0536 - val_acc: 0.9865
Epoch 3/40
 - 337s - loss: 0.0464 - acc: 0.9888 - val_loss: 0.0556 - val_acc: 0.9864
Epoch 4/40
 - 338s - loss: 0.0453 - acc: 0.9892 - val_loss: 0.0585 - val_acc: 0.9861
Epoch 5/40
 - 337s - loss: 0.0446 - acc: 0.9893 - val_loss: 0.0604 - val_acc: 0.9865
Epoch 00005: early stopping
	TRAINING TIME: 29.7 minutes 
==================================================================================================
	PARSING TIME: 10.1 minutes 
==================================================================================================
	Identification : 0.55
	P, R  : 0.526, 0.576

==================================================================================================
	XP Ends: 28/6 (16 h:44)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (16h:45)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 49)       460649      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       3042        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 160)       1504160     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 20)        3380        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 50, 67)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 800)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 100)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 96)           62976       concatenate_13[0][0]             
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 900)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 996)          0           phraseRnn[0][0]                  
                                                                 concatenate_14[0][0]             
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 60)           59820       concatenate_15[0][0]             
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 4)            244         dense_9[0][0]                    
==================================================================================================
Total params: 2,094,271
Trainable params: 2,094,271
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 227s - loss: 0.0773 - acc: 0.9790 - val_loss: 0.0584 - val_acc: 0.9847
Epoch 2/40
 - 227s - loss: 0.0532 - acc: 0.9867 - val_loss: 0.0593 - val_acc: 0.9847
Epoch 3/40
 - 227s - loss: 0.0494 - acc: 0.9879 - val_loss: 0.0986 - val_acc: 0.9735
Epoch 4/40
 - 227s - loss: 0.0479 - acc: 0.9882 - val_loss: 0.0660 - val_acc: 0.9845
Epoch 5/40
 - 227s - loss: 0.0469 - acc: 0.9885 - val_loss: 0.0699 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 19.9 minutes 
==================================================================================================
	PARSING TIME: 15.35 minutes 
==================================================================================================
	Identification : 0.435
	P, R  : 0.342, 0.597

==================================================================================================
	XP Ends: 28/6 (17 h:20)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (17h:20)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 49)       1081479     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       1962        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 160)       3531360     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 20)        2180        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 50, 67)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 800)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 100)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 96)           62976       concatenate_16[0][0]             
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 900)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 996)          0           phraseRnn[0][0]                  
                                                                 concatenate_17[0][0]             
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 60)           59820       concatenate_18[0][0]             
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 4)            244         dense_11[0][0]                   
==================================================================================================
Total params: 4,740,021
Trainable params: 4,740,021
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 462s - loss: 0.0647 - acc: 0.9827 - val_loss: 0.0580 - val_acc: 0.9842
Epoch 2/40
 - 462s - loss: 0.0488 - acc: 0.9879 - val_loss: 0.0586 - val_acc: 0.9847
Epoch 3/40
 - 484s - loss: 0.0461 - acc: 0.9889 - val_loss: 0.0638 - val_acc: 0.9842
Epoch 4/40
 - 485s - loss: 0.0447 - acc: 0.9892 - val_loss: 0.0704 - val_acc: 0.9845
Epoch 5/40
 - 486s - loss: 0.0436 - acc: 0.9893 - val_loss: 0.0796 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 42.47 minutes 
==================================================================================================
	PARSING TIME: 6.82 minutes 
==================================================================================================
	Identification : 0.485
	P, R  : 0.434, 0.549

==================================================================================================
	XP Ends: 28/6 (18 h:10)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,259            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.071          ,50             ,6              ,53             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
11             ,42             ,True           ,False          ,72             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 259, False, 0.071, 50, 6, 53, 11, 42, True, False, 72
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (18h:10)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       399885      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 42)        316890      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 11)        1672        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 50, 59)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 168)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 44)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 72)           38016       concatenate_19[0][0]             
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 212)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 284)          0           phraseRnn[0][0]                  
                                                                 concatenate_20[0][0]             
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 259)          73815       concatenate_21[0][0]             
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 4)            1040        dense_13[0][0]                   
==================================================================================================
Total params: 832,230
Trainable params: 832,230
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 325s - loss: 12.0897 - acc: 0.2494 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 2/40
 - 321s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 3/40
 - 321s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 4/40
 - 321s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 5/40
 - 321s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 00005: early stopping
	TRAINING TIME: 28.22 minutes 
==================================================================================================
	PARSING TIME: 18.07 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (18 h:57)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (18h:57)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       383773      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 42)        304122      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 11)        1859        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 50, 59)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 168)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 44)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 72)           38016       concatenate_22[0][0]             
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 212)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 284)          0           phraseRnn[0][0]                  
                                                                 concatenate_23[0][0]             
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 259)          73815       concatenate_24[0][0]             
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 4)            1040        dense_15[0][0]                   
==================================================================================================
Total params: 803,639
Trainable params: 803,639
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 213s - loss: 0.1466 - acc: 0.9749 - val_loss: 0.0628 - val_acc: 0.9833
Epoch 2/40
 - 213s - loss: 0.0560 - acc: 0.9854 - val_loss: 0.0626 - val_acc: 0.9837
Epoch 3/40
 - 213s - loss: 0.0518 - acc: 0.9870 - val_loss: 0.0647 - val_acc: 0.9835
Epoch 4/40
 - 213s - loss: 0.0495 - acc: 0.9876 - val_loss: 0.0690 - val_acc: 0.9837
Epoch 5/40
 - 213s - loss: 0.0480 - acc: 0.9881 - val_loss: 0.0758 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 18.7 minutes 
==================================================================================================
	PARSING TIME: 15.4 minutes 
==================================================================================================
	Identification : 0.461
	P, R  : 0.371, 0.608

==================================================================================================
	XP Ends: 28/6 (19 h:32)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (19h:32)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       731029      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 42)        579306      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 11)        1199        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 50, 59)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 168)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 44)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 72)           38016       concatenate_25[0][0]             
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 212)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 284)          0           phraseRnn[0][0]                  
                                                                 concatenate_26[0][0]             
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 259)          73815       concatenate_27[0][0]             
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 4)            1040        dense_17[0][0]                   
==================================================================================================
Total params: 1,425,059
Trainable params: 1,425,059
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 424s - loss: 0.0675 - acc: 0.9817 - val_loss: 0.0585 - val_acc: 0.9840
Epoch 2/40
 - 494s - loss: 0.0527 - acc: 0.9863 - val_loss: 0.0587 - val_acc: 0.9841
Epoch 3/40
 - 455s - loss: 0.0494 - acc: 0.9875 - val_loss: 0.0637 - val_acc: 0.9841
Epoch 4/40
 - 453s - loss: 0.0471 - acc: 0.9882 - val_loss: 0.0771 - val_acc: 0.9835
Epoch 5/40
 - 452s - loss: 0.0459 - acc: 0.9887 - val_loss: 0.0779 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 40.67 minutes 
==================================================================================================
	PARSING TIME: 6.62 minutes 
==================================================================================================
	Identification : 0.468
	P, R  : 0.461, 0.475

==================================================================================================
	XP Ends: 28/6 (20 h:20)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,31             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.196          ,50             ,20             ,120            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
19             ,36             ,False          ,True           ,30             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 31, True, 0.196, 50, 20, 120, 19, 36, False, True, 30
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (20h:20)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 120)      905400      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3040        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 36)        271620      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 19)        2888        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 50, 140)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 144)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 76)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 30)           15390       concatenate_28[0][0]             
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 220)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 250)          0           phraseRnn[0][0]                  
                                                                 concatenate_29[0][0]             
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 31)           7781        concatenate_30[0][0]             
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 4)            128         dense_19[0][0]                   
==================================================================================================
Total params: 1,206,247
Trainable params: 1,206,247
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 261s - loss: 0.0734 - acc: 0.9820 - val_loss: 0.0577 - val_acc: 0.9851
Epoch 2/40
 - 262s - loss: 0.0520 - acc: 0.9870 - val_loss: 0.0561 - val_acc: 0.9857
Epoch 3/40
 - 262s - loss: 0.0490 - acc: 0.9880 - val_loss: 0.0583 - val_acc: 0.9859
Epoch 4/40
 - 262s - loss: 0.0473 - acc: 0.9885 - val_loss: 0.0596 - val_acc: 0.9859
Epoch 5/40
 - 261s - loss: 0.0463 - acc: 0.9888 - val_loss: 0.0637 - val_acc: 0.9857
Epoch 00005: early stopping
	TRAINING TIME: 23.27 minutes 
==================================================================================================
	PARSING TIME: 7.87 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.595, 0.551

==================================================================================================
	XP Ends: 28/6 (20 h:52)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (20h:52)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 120)      868920      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3380        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 36)        260676      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 19)        3211        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 50, 140)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 144)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 76)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 30)           15390       concatenate_31[0][0]             
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 220)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 250)          0           phraseRnn[0][0]                  
                                                                 concatenate_32[0][0]             
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 31)           7781        concatenate_33[0][0]             
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 4)            128         dense_21[0][0]                   
==================================================================================================
Total params: 1,159,486
Trainable params: 1,159,486
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 178s - loss: 0.1029 - acc: 0.9771 - val_loss: 0.0651 - val_acc: 0.9830
Epoch 2/40
 - 179s - loss: 0.0566 - acc: 0.9856 - val_loss: 0.0658 - val_acc: 0.9836
Epoch 3/40
 - 178s - loss: 0.0514 - acc: 0.9871 - val_loss: 0.0726 - val_acc: 0.9840
Epoch 4/40
 - 176s - loss: 0.0489 - acc: 0.9879 - val_loss: 0.0737 - val_acc: 0.9843
Epoch 5/40
 - 176s - loss: 0.0476 - acc: 0.9882 - val_loss: 0.0823 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 15.67 minutes 
==================================================================================================
	PARSING TIME: 11.82 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.539, 0.609

==================================================================================================
	XP Ends: 28/6 (21 h:20)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (21h:20)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 120)      1655160     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       2180        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 36)        496548      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 19)        2071        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 50, 140)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 144)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 76)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 30)           15390       concatenate_34[0][0]             
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 220)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 250)          0           phraseRnn[0][0]                  
                                                                 concatenate_35[0][0]             
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 31)           7781        concatenate_36[0][0]             
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 4)            128         dense_23[0][0]                   
==================================================================================================
Total params: 2,179,258
Trainable params: 2,179,258
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 344s - loss: 0.0730 - acc: 0.9809 - val_loss: 0.0619 - val_acc: 0.9838
Epoch 2/40
 - 346s - loss: 0.0540 - acc: 0.9858 - val_loss: 0.0592 - val_acc: 0.9842
Epoch 3/40
 - 342s - loss: 0.0514 - acc: 0.9868 - val_loss: 0.0604 - val_acc: 0.9837
Epoch 4/40
 - 341s - loss: 0.0498 - acc: 0.9873 - val_loss: 0.0655 - val_acc: 0.9838
Epoch 5/40
 - 343s - loss: 0.0487 - acc: 0.9876 - val_loss: 0.0686 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 31.2 minutes 
==================================================================================================
	PARSING TIME: 5.28 minutes 
==================================================================================================
	Identification : 0.494
	P, R  : 0.462, 0.531

==================================================================================================
	XP Ends: 28/6 (21 h:57)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,41             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.139          ,50             ,15             ,90             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
13             ,36             ,True           ,True           ,28             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 41, False, 0.139, 50, 15, 90, 13, 36, True, True, 28
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (21h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 90)       679050      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       2280        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 36)        271620      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 13)        1976        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 50, 105)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 180)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 65)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 28)           15008       concatenate_37[0][0]             
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 245)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 273)          0           phraseRnn[0][0]                  
                                                                 concatenate_38[0][0]             
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 41)           11234       concatenate_39[0][0]             
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 4)            168         dense_25[0][0]                   
==================================================================================================
Total params: 981,336
Trainable params: 981,336
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 306s - loss: 0.0686 - acc: 0.9825 - val_loss: 0.0553 - val_acc: 0.9858
Epoch 2/40
 - 306s - loss: 0.0504 - acc: 0.9875 - val_loss: 0.0558 - val_acc: 0.9857
Epoch 3/40
 - 334s - loss: 0.0473 - acc: 0.9886 - val_loss: 0.0580 - val_acc: 0.9859
Epoch 4/40
 - 333s - loss: 0.0459 - acc: 0.9889 - val_loss: 0.0593 - val_acc: 0.9859
Epoch 5/40
 - 368s - loss: 0.0448 - acc: 0.9893 - val_loss: 0.0644 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 29.02 minutes 
==================================================================================================
	PARSING TIME: 10.28 minutes 
==================================================================================================
	Identification : 0.576
	P, R  : 0.657, 0.512

==================================================================================================
	XP Ends: 28/6 (22 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (22h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 90)       651690      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       2535        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 36)        260676      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 13)        2197        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 50, 105)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 180)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 65)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 28)           15008       concatenate_40[0][0]             
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 245)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 273)          0           phraseRnn[0][0]                  
                                                                 concatenate_41[0][0]             
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 41)           11234       concatenate_42[0][0]             
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 4)            168         dense_27[0][0]                   
==================================================================================================
Total params: 943,508
Trainable params: 943,508
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 232s - loss: 0.0815 - acc: 0.9792 - val_loss: 0.0633 - val_acc: 0.9827
Epoch 2/40
 - 255s - loss: 0.0534 - acc: 0.9866 - val_loss: 0.0617 - val_acc: 0.9840
Epoch 3/40
 - 255s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0637 - val_acc: 0.9840
Epoch 4/40
 - 256s - loss: 0.0478 - acc: 0.9884 - val_loss: 0.0682 - val_acc: 0.9842
Epoch 5/40
 - 252s - loss: 0.0467 - acc: 0.9886 - val_loss: 0.0759 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 21.78 minutes 
==================================================================================================
	PARSING TIME: 15.82 minutes 
==================================================================================================
	Identification : 0.521
	P, R  : 0.445, 0.627

==================================================================================================
	XP Ends: 28/6 (23 h:16)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (23h:16)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 90)       1241370     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       1635        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 36)        496548      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 13)        1417        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 50, 105)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 180)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 65)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 28)           15008       concatenate_43[0][0]             
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 245)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 273)          0           phraseRnn[0][0]                  
                                                                 concatenate_44[0][0]             
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 41)           11234       concatenate_45[0][0]             
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 4)            168         dense_29[0][0]                   
==================================================================================================
Total params: 1,767,380
Trainable params: 1,767,380
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 448s - loss: 0.0684 - acc: 0.9816 - val_loss: 0.0573 - val_acc: 0.9844
Epoch 2/40
 - 449s - loss: 0.0518 - acc: 0.9868 - val_loss: 0.0586 - val_acc: 0.9844
Epoch 3/40
 - 444s - loss: 0.0485 - acc: 0.9880 - val_loss: 0.0628 - val_acc: 0.9843
Epoch 4/40
 - 495s - loss: 0.0469 - acc: 0.9885 - val_loss: 0.0664 - val_acc: 0.9844
Epoch 5/40
 - 451s - loss: 0.0456 - acc: 0.9889 - val_loss: 0.0722 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 40.87 minutes 
==================================================================================================
	PARSING TIME: 6.83 minutes 
==================================================================================================
	Identification : 0.485
	P, R  : 0.463, 0.51

==================================================================================================
	XP Ends: 29/6 (0 h:4)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,127            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.012          ,50             ,49             ,44             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
15             ,79             ,True           ,False          ,101            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 127, False, 0.012, 50, 49, 44, 15, 79, True, False, 101
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (0h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 44)       503272      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       7448        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 79)        903602      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 15)        2280        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 50, 93)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 316)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 60)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 101)          78780       concatenate_46[0][0]             
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 376)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 477)          0           phraseRnn[0][0]                  
                                                                 concatenate_47[0][0]             
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 127)          60706       concatenate_48[0][0]             
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 4)            512         dense_31[0][0]                   
==================================================================================================
Total params: 1,556,600
Trainable params: 1,556,600
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 377s - loss: 0.0736 - acc: 0.9809 - val_loss: 0.0592 - val_acc: 0.9847
Epoch 2/40
 - 377s - loss: 0.0532 - acc: 0.9868 - val_loss: 0.0582 - val_acc: 0.9855
Epoch 3/40
 - 378s - loss: 0.0497 - acc: 0.9879 - val_loss: 0.0587 - val_acc: 0.9855
Epoch 4/40
 - 378s - loss: 0.0478 - acc: 0.9884 - val_loss: 0.0603 - val_acc: 0.9855
Epoch 5/40
 - 384s - loss: 0.0466 - acc: 0.9888 - val_loss: 0.0630 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 33.17 minutes 
==================================================================================================
	PARSING TIME: 10.37 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.65, 0.397

==================================================================================================
	XP Ends: 29/6 (0 h:48)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (0h:48)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 44)       413644      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       8281        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 79)        742679      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 15)        2535        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 50, 93)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 316)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 60)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 101)          78780       concatenate_49[0][0]             
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 376)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 477)          0           phraseRnn[0][0]                  
                                                                 concatenate_50[0][0]             
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 127)          60706       concatenate_51[0][0]             
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 4)            512         dense_33[0][0]                   
==================================================================================================
Total params: 1,307,137
Trainable params: 1,307,137
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 255s - loss: 0.0840 - acc: 0.9771 - val_loss: 0.0641 - val_acc: 0.9830
Epoch 2/40
 - 257s - loss: 0.0580 - acc: 0.9853 - val_loss: 0.0630 - val_acc: 0.9832
Epoch 3/40
 - 259s - loss: 0.0532 - acc: 0.9868 - val_loss: 0.0653 - val_acc: 0.9834
Epoch 4/40
 - 257s - loss: 0.0508 - acc: 0.9874 - val_loss: 0.0688 - val_acc: 0.9832
Epoch 5/40
 - 258s - loss: 0.0493 - acc: 0.9878 - val_loss: 0.0718 - val_acc: 0.9832
Epoch 00005: early stopping
	TRAINING TIME: 22.4 minutes 
==================================================================================================
	PARSING TIME: 16.28 minutes 
==================================================================================================
	Identification : 0.403
	P, R  : 0.313, 0.566

==================================================================================================
	XP Ends: 29/6 (1 h:27)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (1h:27)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 44)       971124      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       5341        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 79)        1743609     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 15)        1635        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 50, 93)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 316)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 60)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 101)          78780       concatenate_52[0][0]             
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 376)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 477)          0           phraseRnn[0][0]                  
                                                                 concatenate_53[0][0]             
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 127)          60706       concatenate_54[0][0]             
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 4)            512         dense_35[0][0]                   
==================================================================================================
Total params: 2,861,707
Trainable params: 2,861,707
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 484s - loss: 0.0709 - acc: 0.9807 - val_loss: 0.0639 - val_acc: 0.9830
Epoch 2/40
 - 486s - loss: 0.0518 - acc: 0.9868 - val_loss: 0.0621 - val_acc: 0.9833
Epoch 3/40
 - 484s - loss: 0.0483 - acc: 0.9881 - val_loss: 0.0650 - val_acc: 0.9834
Epoch 4/40
 - 486s - loss: 0.0464 - acc: 0.9887 - val_loss: 0.0700 - val_acc: 0.9831
Epoch 5/40
 - 484s - loss: 0.0452 - acc: 0.9890 - val_loss: 0.0752 - val_acc: 0.9827
Epoch 00005: early stopping
	TRAINING TIME: 43.17 minutes 
==================================================================================================
	PARSING TIME: 6.97 minutes 
==================================================================================================
	Identification : 0.507
	P, R  : 0.457, 0.569

==================================================================================================
	XP Ends: 29/6 (2 h:18)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,132            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.011          ,50             ,17             ,34             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
7              ,67             ,True           ,False          ,450            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 132, True, 0.011, 50, 17, 34, 7, 67, True, False, 450
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (2h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 34)       256530      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2584        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 67)        505515      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 7)         1064        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 50, 51)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 268)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 28)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 450)          677700      concatenate_55[0][0]             
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 296)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 746)          0           phraseRnn[0][0]                  
                                                                 concatenate_56[0][0]             
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 132)          98604       concatenate_57[0][0]             
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 4)            532         dense_37[0][0]                   
==================================================================================================
Total params: 1,542,529
Trainable params: 1,542,529
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 612s - loss: 0.0819 - acc: 0.9791 - val_loss: 0.0653 - val_acc: 0.9838
Epoch 2/40
 - 611s - loss: 0.0564 - acc: 0.9859 - val_loss: 0.0640 - val_acc: 0.9848
Epoch 3/40
 - 584s - loss: 0.0519 - acc: 0.9871 - val_loss: 0.0653 - val_acc: 0.9845
Epoch 4/40
 - 583s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0665 - val_acc: 0.9849
Epoch 5/40
 - 584s - loss: 0.0481 - acc: 0.9882 - val_loss: 0.0678 - val_acc: 0.9848
Epoch 00005: early stopping
	TRAINING TIME: 51.22 minutes 
==================================================================================================
	PARSING TIME: 9.68 minutes 
==================================================================================================
	Identification : 0.591
	P, R  : 0.748, 0.488

==================================================================================================
	XP Ends: 29/6 (3 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (3h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 34)       246194      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2873        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 67)        485147      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 7)         1183        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 50, 51)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 268)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 28)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 450)          677700      concatenate_58[0][0]             
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 296)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 746)          0           phraseRnn[0][0]                  
                                                                 concatenate_59[0][0]             
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 132)          98604       concatenate_60[0][0]             
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 4)            532         dense_39[0][0]                   
==================================================================================================
Total params: 1,512,233
Trainable params: 1,512,233
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 413s - loss: 0.0894 - acc: 0.9758 - val_loss: 0.0812 - val_acc: 0.9772
Epoch 2/40
 - 414s - loss: 0.0606 - acc: 0.9842 - val_loss: 0.0673 - val_acc: 0.9825
Epoch 3/40
 - 414s - loss: 0.0555 - acc: 0.9858 - val_loss: 0.0694 - val_acc: 0.9820
Epoch 4/40
 - 414s - loss: 0.0526 - acc: 0.9866 - val_loss: 0.0699 - val_acc: 0.9826
Epoch 5/40
 - 414s - loss: 0.0511 - acc: 0.9872 - val_loss: 0.0722 - val_acc: 0.9824
Epoch 00005: early stopping
	TRAINING TIME: 35.38 minutes 
==================================================================================================
	PARSING TIME: 14.57 minutes 
==================================================================================================
	Identification : 0.511
	P, R  : 0.466, 0.566

==================================================================================================
	XP Ends: 29/6 (4 h:10)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (4h:11)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 34)       468962      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       1853        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 67)        924131      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 7)         763         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_61 (Concatenate)    (None, 50, 51)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 268)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 28)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 450)          677700      concatenate_61[0][0]             
__________________________________________________________________________________________________
concatenate_62 (Concatenate)    (None, 296)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_63 (Concatenate)    (None, 746)          0           phraseRnn[0][0]                  
                                                                 concatenate_62[0][0]             
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 132)          98604       concatenate_63[0][0]             
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 4)            532         dense_41[0][0]                   
==================================================================================================
Total params: 2,172,545
Trainable params: 2,172,545
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 786s - loss: 0.0754 - acc: 0.9795 - val_loss: 0.0615 - val_acc: 0.9833
Epoch 2/40
 - 787s - loss: 0.0561 - acc: 0.9854 - val_loss: 0.0611 - val_acc: 0.9836
Epoch 3/40
 - 823s - loss: 0.0523 - acc: 0.9867 - val_loss: 0.0624 - val_acc: 0.9834
Epoch 4/40
 - 824s - loss: 0.0501 - acc: 0.9874 - val_loss: 0.0660 - val_acc: 0.9830
Epoch 5/40
 - 824s - loss: 0.0488 - acc: 0.9878 - val_loss: 0.0692 - val_acc: 0.9830
Epoch 00005: early stopping
	TRAINING TIME: 70.1 minutes 
==================================================================================================
	PARSING TIME: 6.32 minutes 
==================================================================================================
	Identification : 0.484
	P, R  : 0.471, 0.498

==================================================================================================
	XP Ends: 29/6 (5 h:28)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,43             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.034          ,50             ,39             ,35             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
13             ,52             ,False          ,False          ,185            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 43, False, 0.034, 50, 39, 35, 13, 52, False, False, 185
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (5h:28)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 35)       400330      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 39)       5928        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 52)        594776      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 13)        1976        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_64 (Concatenate)    (None, 50, 74)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 39)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 185)          192400      concatenate_64[0][0]             
__________________________________________________________________________________________________
concatenate_65 (Concatenate)    (None, 195)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 380)          0           phraseRnn[0][0]                  
                                                                 concatenate_65[0][0]             
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 43)           16383       concatenate_66[0][0]             
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 4)            176         dense_43[0][0]                   
==================================================================================================
Total params: 1,211,969
Trainable params: 1,211,969
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 418s - loss: 0.0682 - acc: 0.9822 - val_loss: 0.0563 - val_acc: 0.9851
Epoch 2/40
 - 419s - loss: 0.0514 - acc: 0.9872 - val_loss: 0.0554 - val_acc: 0.9858
Epoch 3/40
 - 419s - loss: 0.0483 - acc: 0.9882 - val_loss: 0.0582 - val_acc: 0.9855
Epoch 4/40
 - 418s - loss: 0.0467 - acc: 0.9887 - val_loss: 0.0619 - val_acc: 0.9851
Epoch 5/40
 - 419s - loss: 0.0458 - acc: 0.9889 - val_loss: 0.0650 - val_acc: 0.9851
Epoch 00005: early stopping
	TRAINING TIME: 36.38 minutes 
==================================================================================================
	PARSING TIME: 9.88 minutes 
==================================================================================================
	Identification : 0.524
	P, R  : 0.709, 0.415

==================================================================================================
	XP Ends: 29/6 (6 h:15)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (6h:15)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 35)       329035      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 39)       6591        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 52)        488852      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 13)        2197        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_67 (Concatenate)    (None, 50, 74)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 39)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 185)          192400      concatenate_67[0][0]             
__________________________________________________________________________________________________
concatenate_68 (Concatenate)    (None, 195)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_69 (Concatenate)    (None, 380)          0           phraseRnn[0][0]                  
                                                                 concatenate_68[0][0]             
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 43)           16383       concatenate_69[0][0]             
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 4)            176         dense_45[0][0]                   
==================================================================================================
Total params: 1,035,634
Trainable params: 1,035,634
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 283s - loss: 0.0898 - acc: 0.9749 - val_loss: 0.0660 - val_acc: 0.9822
Epoch 2/40
 - 283s - loss: 0.0609 - acc: 0.9842 - val_loss: 0.0657 - val_acc: 0.9820
Epoch 3/40
 - 283s - loss: 0.0570 - acc: 0.9851 - val_loss: 0.0664 - val_acc: 0.9824
Epoch 4/40
 - 283s - loss: 0.0549 - acc: 0.9857 - val_loss: 0.0670 - val_acc: 0.9828
Epoch 5/40
 - 283s - loss: 0.0528 - acc: 0.9864 - val_loss: 0.0728 - val_acc: 0.9825
Epoch 00005: early stopping
	TRAINING TIME: 24.62 minutes 
==================================================================================================
	PARSING TIME: 15.17 minutes 
==================================================================================================
	Identification : 0.448
	P, R  : 0.361, 0.591

==================================================================================================
	XP Ends: 29/6 (6 h:55)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (6h:55)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 35)       772485      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 39)       4251        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 52)        1147692     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 13)        1417        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_70 (Concatenate)    (None, 50, 74)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 39)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 185)          192400      concatenate_70[0][0]             
__________________________________________________________________________________________________
concatenate_71 (Concatenate)    (None, 195)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_72 (Concatenate)    (None, 380)          0           phraseRnn[0][0]                  
                                                                 concatenate_71[0][0]             
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 43)           16383       concatenate_72[0][0]             
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 4)            176         dense_47[0][0]                   
==================================================================================================
Total params: 2,134,804
Trainable params: 2,134,804
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 594s - loss: 0.0667 - acc: 0.9819 - val_loss: 0.0604 - val_acc: 0.9838
Epoch 2/40
 - 593s - loss: 0.0516 - acc: 0.9867 - val_loss: 0.0608 - val_acc: 0.9835
Epoch 3/40
 - 593s - loss: 0.0490 - acc: 0.9877 - val_loss: 0.0662 - val_acc: 0.9827
Epoch 4/40
 - 593s - loss: 0.0473 - acc: 0.9883 - val_loss: 0.0694 - val_acc: 0.9829
Epoch 5/40
 - 594s - loss: 0.0460 - acc: 0.9885 - val_loss: 0.0790 - val_acc: 0.9829
Epoch 00005: early stopping
	TRAINING TIME: 52.18 minutes 
==================================================================================================
	PARSING TIME: 7.08 minutes 
==================================================================================================
	Identification : 0.492
	P, R  : 0.447, 0.547

==================================================================================================
	XP Ends: 29/6 (7 h:55)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,89             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.011          ,50             ,15             ,87             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
48             ,76             ,True           ,False          ,61             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 89, True, 0.011, 50, 15, 87, 48, 76, True, False, 61
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (7h:55)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 87)       656415      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       2280        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 76)        573420      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 48)        7296        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_73 (Concatenate)    (None, 50, 102)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 304)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 192)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 61)           30012       concatenate_73[0][0]             
__________________________________________________________________________________________________
concatenate_74 (Concatenate)    (None, 496)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_75 (Concatenate)    (None, 557)          0           phraseRnn[0][0]                  
                                                                 concatenate_74[0][0]             
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 89)           49662       concatenate_75[0][0]             
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 4)            360         dense_49[0][0]                   
==================================================================================================
Total params: 1,319,445
Trainable params: 1,319,445
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 286s - loss: 0.0711 - acc: 0.9816 - val_loss: 0.0598 - val_acc: 0.9845
Epoch 2/40
 - 286s - loss: 0.0547 - acc: 0.9863 - val_loss: 0.0597 - val_acc: 0.9849
Epoch 3/40
 - 283s - loss: 0.0511 - acc: 0.9874 - val_loss: 0.0601 - val_acc: 0.9848
Epoch 4/40
 - 285s - loss: 0.0491 - acc: 0.9879 - val_loss: 0.0615 - val_acc: 0.9849
Epoch 5/40
 - 285s - loss: 0.0478 - acc: 0.9883 - val_loss: 0.0630 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 25.22 minutes 
==================================================================================================
	PARSING TIME: 8.78 minutes 
==================================================================================================
	Identification : 0.582
	P, R  : 0.722, 0.488

==================================================================================================
	XP Ends: 29/6 (8 h:30)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (8h:30)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 87)       629967      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       2535        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 76)        550316      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 48)        8112        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_76 (Concatenate)    (None, 50, 102)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 304)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 192)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 61)           30012       concatenate_76[0][0]             
__________________________________________________________________________________________________
concatenate_77 (Concatenate)    (None, 496)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_78 (Concatenate)    (None, 557)          0           phraseRnn[0][0]                  
                                                                 concatenate_77[0][0]             
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 89)           49662       concatenate_78[0][0]             
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 4)            360         dense_51[0][0]                   
==================================================================================================
Total params: 1,270,964
Trainable params: 1,270,964
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 193s - loss: 0.0808 - acc: 0.9784 - val_loss: 0.0676 - val_acc: 0.9820
Epoch 2/40
 - 193s - loss: 0.0604 - acc: 0.9843 - val_loss: 0.0650 - val_acc: 0.9827
Epoch 3/40
 - 190s - loss: 0.0556 - acc: 0.9858 - val_loss: 0.0657 - val_acc: 0.9831
Epoch 4/40
 - 190s - loss: 0.0529 - acc: 0.9866 - val_loss: 0.0678 - val_acc: 0.9831
Epoch 5/40
 - 188s - loss: 0.0510 - acc: 0.9872 - val_loss: 0.0713 - val_acc: 0.9827
Epoch 00005: early stopping
	TRAINING TIME: 16.77 minutes 
==================================================================================================
	PARSING TIME: 12.5 minutes 
==================================================================================================
	Identification : 0.45
	P, R  : 0.363, 0.593

==================================================================================================
	XP Ends: 29/6 (9 h:0)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (9h:0)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 87)       1199991     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       1635        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 76)        1048268     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 48)        5232        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_79 (Concatenate)    (None, 50, 102)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 304)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 192)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 61)           30012       concatenate_79[0][0]             
__________________________________________________________________________________________________
concatenate_80 (Concatenate)    (None, 496)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_81 (Concatenate)    (None, 557)          0           phraseRnn[0][0]                  
                                                                 concatenate_80[0][0]             
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 89)           49662       concatenate_81[0][0]             
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 4)            360         dense_53[0][0]                   
==================================================================================================
Total params: 2,335,160
Trainable params: 2,335,160
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 414s - loss: 0.0719 - acc: 0.9807 - val_loss: 0.0630 - val_acc: 0.9828
Epoch 2/40
 - 344s - loss: 0.0557 - acc: 0.9855 - val_loss: 0.0609 - val_acc: 0.9835
Epoch 3/40
 - 343s - loss: 0.0522 - acc: 0.9867 - val_loss: 0.0622 - val_acc: 0.9834
Epoch 4/40
 - 374s - loss: 0.0501 - acc: 0.9874 - val_loss: 0.0669 - val_acc: 0.9830
Epoch 5/40
 - 372s - loss: 0.0488 - acc: 0.9878 - val_loss: 0.0699 - val_acc: 0.9832
Epoch 00005: early stopping
	TRAINING TIME: 33.38 minutes 
==================================================================================================
	PARSING TIME: 5.55 minutes 
==================================================================================================
	Identification : 0.475
	P, R  : 0.446, 0.508

==================================================================================================
	XP Ends: 29/6 (9 h:39)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,26             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.05           ,50             ,8              ,171            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
12             ,192            ,True           ,True           ,470            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 26, False, 0.05, 50, 8, 171, 12, 192, True, True, 470
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (9h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 171)      1290195     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 192)       1448640     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 12)        1824        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_82 (Concatenate)    (None, 50, 179)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 960)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 60)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 470)          1222000     concatenate_82[0][0]             
__________________________________________________________________________________________________
concatenate_83 (Concatenate)    (None, 1020)         0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_84 (Concatenate)    (None, 1490)         0           phraseRnn[0][0]                  
                                                                 concatenate_83[0][0]             
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 26)           38766       concatenate_84[0][0]             
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 4)            108         dense_55[0][0]                   
==================================================================================================
Total params: 4,002,749
Trainable params: 4,002,749
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 869s - loss: 0.0933 - acc: 0.9776 - val_loss: 0.0668 - val_acc: 0.9838
Epoch 2/40
 - 870s - loss: 0.0580 - acc: 0.9860 - val_loss: 0.0682 - val_acc: 0.9845
Epoch 3/40
 - 832s - loss: 0.0535 - acc: 0.9870 - val_loss: 0.0688 - val_acc: 0.9848
Epoch 4/40
 - 832s - loss: 0.0512 - acc: 0.9876 - val_loss: 0.0699 - val_acc: 0.9846
Epoch 5/40
 - 832s - loss: 0.0499 - acc: 0.9880 - val_loss: 0.0714 - val_acc: 0.9848
Epoch 00005: early stopping
	TRAINING TIME: 72.15 minutes 
==================================================================================================
	PARSING TIME: 13.1 minutes 
==================================================================================================
	Identification : 0.576
	P, R  : 0.691, 0.494

==================================================================================================
	XP Ends: 29/6 (11 h:5)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (11h:5)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 171)      1238211     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 192)       1390272     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 12)        2028        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 50, 179)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 960)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 60)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 470)          1222000     concatenate_85[0][0]             
__________________________________________________________________________________________________
concatenate_86 (Concatenate)    (None, 1020)         0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_87 (Concatenate)    (None, 1490)         0           phraseRnn[0][0]                  
                                                                 concatenate_86[0][0]             
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 26)           38766       concatenate_87[0][0]             
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 4)            108         dense_57[0][0]                   
==================================================================================================
Total params: 3,892,737
Trainable params: 3,892,737
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 566s - loss: 12.0893 - acc: 0.2495 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 2/40
 - 566s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 3/40
 - 566s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 4/40
 - 566s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 5/40
 - 566s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 00005: early stopping
	TRAINING TIME: 48.18 minutes 
==================================================================================================
	PARSING TIME: 19.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (12 h:13)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (12h:13)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 171)      2358603     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 192)       2648256     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 12)        1308        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_88 (Concatenate)    (None, 50, 179)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 960)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 60)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 470)          1222000     concatenate_88[0][0]             
__________________________________________________________________________________________________
concatenate_89 (Concatenate)    (None, 1020)         0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_90 (Concatenate)    (None, 1490)         0           phraseRnn[0][0]                  
                                                                 concatenate_89[0][0]             
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 26)           38766       concatenate_90[0][0]             
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 4)            108         dense_59[0][0]                   
==================================================================================================
Total params: 6,269,913
Trainable params: 6,269,913
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 1131s - loss: 0.0757 - acc: 0.9802 - val_loss: 0.0583 - val_acc: 0.9841
Epoch 2/40
 - 1132s - loss: 0.0528 - acc: 0.9865 - val_loss: 0.0593 - val_acc: 0.9843
Epoch 3/40
 - 1131s - loss: 0.0495 - acc: 0.9877 - val_loss: 0.0614 - val_acc: 0.9839
Epoch 4/40
 - 1131s - loss: 0.0476 - acc: 0.9884 - val_loss: 0.0745 - val_acc: 0.9838
Epoch 5/40
 - 1131s - loss: 0.0465 - acc: 0.9886 - val_loss: 0.0689 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 97.15 minutes 
==================================================================================================
	PARSING TIME: 8.68 minutes 
==================================================================================================
	Identification : 0.486
	P, R  : 0.572, 0.422

==================================================================================================
	XP Ends: 29/6 (14 h:0)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,37             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.024          ,50             ,49             ,34             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
6              ,110            ,True           ,True           ,142            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 37, False, 0.024, 50, 49, 34, 6, 110, True, True, 142
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (14h:0)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 34)       256530      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       7448        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 110)       829950      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         912         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_91 (Concatenate)    (None, 50, 83)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 550)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 142)          128368      concatenate_91[0][0]             
__________________________________________________________________________________________________
concatenate_92 (Concatenate)    (None, 580)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_93 (Concatenate)    (None, 722)          0           phraseRnn[0][0]                  
                                                                 concatenate_92[0][0]             
__________________________________________________________________________________________________
dense_61 (Dense)                (None, 37)           26751       concatenate_93[0][0]             
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 4)            152         dense_61[0][0]                   
==================================================================================================
Total params: 1,250,111
Trainable params: 1,250,111
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 406s - loss: 0.0766 - acc: 0.9802 - val_loss: 0.0603 - val_acc: 0.9844
Epoch 2/40
 - 405s - loss: 0.0540 - acc: 0.9864 - val_loss: 0.0604 - val_acc: 0.9853
Epoch 3/40
 - 406s - loss: 0.0508 - acc: 0.9873 - val_loss: 0.0601 - val_acc: 0.9854
Epoch 4/40
 - 405s - loss: 0.0492 - acc: 0.9878 - val_loss: 0.0616 - val_acc: 0.9853
Epoch 5/40
 - 405s - loss: 0.0481 - acc: 0.9881 - val_loss: 0.0633 - val_acc: 0.9854
Epoch 00005: early stopping
	TRAINING TIME: 35.42 minutes 
==================================================================================================
	PARSING TIME: 10.18 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.777, 0.479

==================================================================================================
	XP Ends: 29/6 (14 h:46)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (14h:46)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 34)       246194      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       8281        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 110)       796510      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         1014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_94 (Concatenate)    (None, 50, 83)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 550)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 142)          128368      concatenate_94[0][0]             
__________________________________________________________________________________________________
concatenate_95 (Concatenate)    (None, 580)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_96 (Concatenate)    (None, 722)          0           phraseRnn[0][0]                  
                                                                 concatenate_95[0][0]             
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 37)           26751       concatenate_96[0][0]             
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 4)            152         dense_63[0][0]                   
==================================================================================================
Total params: 1,207,270
Trainable params: 1,207,270
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 275s - loss: 0.0788 - acc: 0.9785 - val_loss: 0.0614 - val_acc: 0.9838
Epoch 2/40
 - 275s - loss: 0.0542 - acc: 0.9863 - val_loss: 0.0650 - val_acc: 0.9843
Epoch 3/40
 - 274s - loss: 0.0503 - acc: 0.9876 - val_loss: 0.0615 - val_acc: 0.9845
Epoch 4/40
 - 275s - loss: 0.0484 - acc: 0.9882 - val_loss: 0.0643 - val_acc: 0.9843
Epoch 5/40
 - 275s - loss: 0.0473 - acc: 0.9885 - val_loss: 0.0658 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 23.97 minutes 
==================================================================================================
	PARSING TIME: 15.12 minutes 
==================================================================================================
	Identification : 0.513
	P, R  : 0.443, 0.609

==================================================================================================
	XP Ends: 29/6 (15 h:26)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (15h:26)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 34)       468962      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       5341        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 110)       1517230     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         654         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_97 (Concatenate)    (None, 50, 83)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 550)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 142)          128368      concatenate_97[0][0]             
__________________________________________________________________________________________________
concatenate_98 (Concatenate)    (None, 580)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_99 (Concatenate)    (None, 722)          0           phraseRnn[0][0]                  
                                                                 concatenate_98[0][0]             
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 37)           26751       concatenate_99[0][0]             
__________________________________________________________________________________________________
dense_66 (Dense)                (None, 4)            152         dense_65[0][0]                   
==================================================================================================
Total params: 2,147,458
Trainable params: 2,147,458
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 521s - loss: 0.0741 - acc: 0.9802 - val_loss: 0.0597 - val_acc: 0.9838
Epoch 2/40
 - 520s - loss: 0.0544 - acc: 0.9858 - val_loss: 0.0592 - val_acc: 0.9841
Epoch 3/40
 - 521s - loss: 0.0508 - acc: 0.9871 - val_loss: 0.0617 - val_acc: 0.9842
Epoch 4/40
 - 520s - loss: 0.0487 - acc: 0.9879 - val_loss: 0.0642 - val_acc: 0.9842
Epoch 5/40
 - 521s - loss: 0.0473 - acc: 0.9883 - val_loss: 0.0679 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 46.28 minutes 
==================================================================================================
	PARSING TIME: 6.88 minutes 
==================================================================================================
	Identification : 0.51
	P, R  : 0.53, 0.492

==================================================================================================
	XP Ends: 29/6 (16 h:20)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,45             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.024          ,50             ,42             ,156            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,192            ,True           ,False          ,133            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 45, False, 0.024, 50, 42, 156, 8, 192, True, False, 133
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (16h:20)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 156)      1177020     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 42)       6384        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 192)       1448640     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_100 (Concatenate)   (None, 50, 198)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 768)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 133)          176624      concatenate_100[0][0]            
__________________________________________________________________________________________________
concatenate_101 (Concatenate)   (None, 800)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_102 (Concatenate)   (None, 933)          0           phraseRnn[0][0]                  
                                                                 concatenate_101[0][0]            
__________________________________________________________________________________________________
dense_67 (Dense)                (None, 45)           42030       concatenate_102[0][0]            
__________________________________________________________________________________________________
dense_68 (Dense)                (None, 4)            184         dense_67[0][0]                   
==================================================================================================
Total params: 2,852,098
Trainable params: 2,852,098
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 429s - loss: 0.0664 - acc: 0.9826 - val_loss: 0.0579 - val_acc: 0.9852
Epoch 2/40
 - 429s - loss: 0.0511 - acc: 0.9873 - val_loss: 0.0568 - val_acc: 0.9857
Epoch 3/40
 - 429s - loss: 0.0481 - acc: 0.9882 - val_loss: 0.0595 - val_acc: 0.9853
Epoch 4/40
 - 429s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0613 - val_acc: 0.9853
Epoch 5/40
 - 429s - loss: 0.0455 - acc: 0.9890 - val_loss: 0.0635 - val_acc: 0.9851
Epoch 00005: early stopping
	TRAINING TIME: 37.38 minutes 
==================================================================================================
	PARSING TIME: 9.9 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.746, 0.47

==================================================================================================
	XP Ends: 29/6 (17 h:8)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (17h:8)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 156)      1129596     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 42)       7098        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 192)       1390272     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_103 (Concatenate)   (None, 50, 198)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 768)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 133)          176624      concatenate_103[0][0]            
__________________________________________________________________________________________________
concatenate_104 (Concatenate)   (None, 800)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_105 (Concatenate)   (None, 933)          0           phraseRnn[0][0]                  
                                                                 concatenate_104[0][0]            
__________________________________________________________________________________________________
dense_69 (Dense)                (None, 45)           42030       concatenate_105[0][0]            
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 4)            184         dense_69[0][0]                   
==================================================================================================
Total params: 2,747,156
Trainable params: 2,747,156
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 291s - loss: 0.0758 - acc: 0.9791 - val_loss: 0.0624 - val_acc: 0.9838
Epoch 2/40
 - 291s - loss: 0.0550 - acc: 0.9859 - val_loss: 0.0617 - val_acc: 0.9839
Epoch 3/40
 - 291s - loss: 0.0509 - acc: 0.9873 - val_loss: 0.0634 - val_acc: 0.9838
Epoch 4/40
 - 291s - loss: 0.0488 - acc: 0.9880 - val_loss: 0.0671 - val_acc: 0.9839
Epoch 5/40
 - 291s - loss: 0.0476 - acc: 0.9883 - val_loss: 0.0711 - val_acc: 0.9833
Epoch 00005: early stopping
	TRAINING TIME: 25.28 minutes 
==================================================================================================
	PARSING TIME: 15.65 minutes 
==================================================================================================
	Identification : 0.478
	P, R  : 0.405, 0.582

==================================================================================================
	XP Ends: 29/6 (17 h:49)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (17h:49)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 156)      2151708     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 42)       4578        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 192)       2648256     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_106 (Concatenate)   (None, 50, 198)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 768)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 133)          176624      concatenate_106[0][0]            
__________________________________________________________________________________________________
concatenate_107 (Concatenate)   (None, 800)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_108 (Concatenate)   (None, 933)          0           phraseRnn[0][0]                  
                                                                 concatenate_107[0][0]            
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 45)           42030       concatenate_108[0][0]            
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 4)            184         dense_71[0][0]                   
==================================================================================================
Total params: 5,024,252
Trainable params: 5,024,252
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 583s - loss: 0.0685 - acc: 0.9816 - val_loss: 0.0590 - val_acc: 0.9842
Epoch 2/40
 - 582s - loss: 0.0533 - acc: 0.9862 - val_loss: 0.0591 - val_acc: 0.9840
Epoch 3/40
 - 611s - loss: 0.0504 - acc: 0.9872 - val_loss: 0.0617 - val_acc: 0.9837
Epoch 4/40
 - 612s - loss: 0.0486 - acc: 0.9879 - val_loss: 0.0649 - val_acc: 0.9835
Epoch 5/40
 - 611s - loss: 0.0472 - acc: 0.9883 - val_loss: 0.0697 - val_acc: 0.9829
Epoch 00005: early stopping
	TRAINING TIME: 52.93 minutes 
==================================================================================================
	PARSING TIME: 7.1 minutes 
==================================================================================================
	Identification : 0.471
	P, R  : 0.519, 0.431

==================================================================================================
	XP Ends: 29/6 (18 h:50)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,419            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.019          ,50             ,6              ,73             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
41             ,123            ,False          ,True           ,89             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 419, False, 0.019, 50, 6, 73, 41, 123, False, True, 89
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (18h:50)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 73)       550785      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 123)       928035      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 41)        6232        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_109 (Concatenate)   (None, 50, 79)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 492)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 164)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 89)           60164       concatenate_109[0][0]            
__________________________________________________________________________________________________
concatenate_110 (Concatenate)   (None, 656)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_111 (Concatenate)   (None, 745)          0           phraseRnn[0][0]                  
                                                                 concatenate_110[0][0]            
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 419)          312574      concatenate_111[0][0]            
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 4)            1680        dense_73[0][0]                   
==================================================================================================
Total params: 1,860,382
Trainable params: 1,860,382
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 339s - loss: 0.0636 - acc: 0.9832 - val_loss: 0.0567 - val_acc: 0.9852
Epoch 2/40
 - 339s - loss: 0.0499 - acc: 0.9877 - val_loss: 0.0545 - val_acc: 0.9863
Epoch 3/40
 - 338s - loss: 0.0469 - acc: 0.9886 - val_loss: 0.0570 - val_acc: 0.9864
Epoch 4/40
 - 338s - loss: 0.0454 - acc: 0.9891 - val_loss: 0.0616 - val_acc: 0.9860
Epoch 5/40
 - 338s - loss: 0.0444 - acc: 0.9893 - val_loss: 0.0659 - val_acc: 0.9860
Epoch 00005: early stopping
	TRAINING TIME: 29.88 minutes 
==================================================================================================
	PARSING TIME: 9.98 minutes 
==================================================================================================
	Identification : 0.575
	P, R  : 0.633, 0.527

==================================================================================================
	XP Ends: 29/6 (19 h:31)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (19h:31)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 73)       528593      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 123)       890643      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 41)        6929        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_112 (Concatenate)   (None, 50, 79)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 492)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 164)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 89)           60164       concatenate_112[0][0]            
__________________________________________________________________________________________________
concatenate_113 (Concatenate)   (None, 656)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_114 (Concatenate)   (None, 745)          0           phraseRnn[0][0]                  
                                                                 concatenate_113[0][0]            
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 419)          312574      concatenate_114[0][0]            
__________________________________________________________________________________________________
dense_76 (Dense)                (None, 4)            1680        dense_75[0][0]                   
==================================================================================================
Total params: 1,801,597
Trainable params: 1,801,597
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 230s - loss: 0.0722 - acc: 0.9804 - val_loss: 0.0605 - val_acc: 0.9842
Epoch 2/40
 - 230s - loss: 0.0526 - acc: 0.9867 - val_loss: 0.0620 - val_acc: 0.9842
Epoch 3/40
 - 229s - loss: 0.0491 - acc: 0.9880 - val_loss: 0.0631 - val_acc: 0.9847
Epoch 4/40
 - 230s - loss: 0.0474 - acc: 0.9883 - val_loss: 0.0681 - val_acc: 0.9847
Epoch 5/40
 - 229s - loss: 0.0464 - acc: 0.9886 - val_loss: 0.0751 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 20.18 minutes 
==================================================================================================
	PARSING TIME: 15.32 minutes 
==================================================================================================
	Identification : 0.494
	P, R  : 0.402, 0.642

==================================================================================================
	XP Ends: 29/6 (20 h:7)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (20h:7)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 73)       1006889     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 123)       1696539     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 41)        4469        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_115 (Concatenate)   (None, 50, 79)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 492)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 164)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 89)           60164       concatenate_115[0][0]            
__________________________________________________________________________________________________
concatenate_116 (Concatenate)   (None, 656)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_117 (Concatenate)   (None, 745)          0           phraseRnn[0][0]                  
                                                                 concatenate_116[0][0]            
__________________________________________________________________________________________________
dense_77 (Dense)                (None, 419)          312574      concatenate_117[0][0]            
__________________________________________________________________________________________________
dense_78 (Dense)                (None, 4)            1680        dense_77[0][0]                   
==================================================================================================
Total params: 3,082,969
Trainable params: 3,082,969
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 483s - loss: 0.0658 - acc: 0.9821 - val_loss: 0.0566 - val_acc: 0.9847
Epoch 2/40
 - 484s - loss: 0.0524 - acc: 0.9863 - val_loss: 0.0571 - val_acc: 0.9846
Epoch 3/40
 - 483s - loss: 0.0496 - acc: 0.9875 - val_loss: 0.0603 - val_acc: 0.9844
Epoch 4/40
 - 484s - loss: 0.0477 - acc: 0.9880 - val_loss: 0.0670 - val_acc: 0.9843
Epoch 5/40
 - 482s - loss: 0.0462 - acc: 0.9884 - val_loss: 0.0748 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 43.28 minutes 
==================================================================================================
	PARSING TIME: 8.02 minutes 
==================================================================================================
	Identification : 0.477
	P, R  : 0.438, 0.524

==================================================================================================
	XP Ends: 29/6 (20 h:59)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,53             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.104          ,50             ,11             ,83             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
39             ,50             ,True           ,True           ,32             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 53, False, 0.104, 50, 11, 83, 39, 50, True, True, 32
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (20h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 83)       626235      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1672        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 50)        377250      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 39)        5928        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_118 (Concatenate)   (None, 50, 94)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 250)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 195)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 32)           16256       concatenate_118[0][0]            
__________________________________________________________________________________________________
concatenate_119 (Concatenate)   (None, 445)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_120 (Concatenate)   (None, 477)          0           phraseRnn[0][0]                  
                                                                 concatenate_119[0][0]            
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 53)           25334       concatenate_120[0][0]            
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 4)            216         dense_79[0][0]                   
==================================================================================================
Total params: 1,052,891
Trainable params: 1,052,891
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 334s - loss: 0.0695 - acc: 0.9826 - val_loss: 0.0552 - val_acc: 0.9856
Epoch 2/40
 - 335s - loss: 0.0502 - acc: 0.9875 - val_loss: 0.0563 - val_acc: 0.9859
Epoch 3/40
 - 308s - loss: 0.0471 - acc: 0.9886 - val_loss: 0.0589 - val_acc: 0.9857
Epoch 4/40
 - 307s - loss: 0.0455 - acc: 0.9891 - val_loss: 0.0628 - val_acc: 0.9859
Epoch 5/40
 - 309s - loss: 0.0445 - acc: 0.9893 - val_loss: 0.0683 - val_acc: 0.9855
Epoch 00005: early stopping
	TRAINING TIME: 28.18 minutes 
==================================================================================================
	PARSING TIME: 10.35 minutes 
==================================================================================================
	Identification : 0.566
	P, R  : 0.615, 0.525

==================================================================================================
	XP Ends: 29/6 (21 h:38)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (21h:38)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 83)       601003      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1859        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 50)        362050      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 39)        6591        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_121 (Concatenate)   (None, 50, 94)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 250)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 195)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 32)           16256       concatenate_121[0][0]            
__________________________________________________________________________________________________
concatenate_122 (Concatenate)   (None, 445)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_123 (Concatenate)   (None, 477)          0           phraseRnn[0][0]                  
                                                                 concatenate_122[0][0]            
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 53)           25334       concatenate_123[0][0]            
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 4)            216         dense_81[0][0]                   
==================================================================================================
Total params: 1,013,309
Trainable params: 1,013,309
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 226s - loss: 0.0769 - acc: 0.9801 - val_loss: 0.0613 - val_acc: 0.9840
Epoch 2/40
 - 226s - loss: 0.0524 - acc: 0.9869 - val_loss: 0.0614 - val_acc: 0.9842
Epoch 3/40
 - 226s - loss: 0.0487 - acc: 0.9881 - val_loss: 0.0632 - val_acc: 0.9847
Epoch 4/40
 - 226s - loss: 0.0473 - acc: 0.9885 - val_loss: 0.0663 - val_acc: 0.9844
Epoch 5/40
 - 236s - loss: 0.0462 - acc: 0.9887 - val_loss: 0.0763 - val_acc: 0.9845
Epoch 00005: early stopping
	TRAINING TIME: 20.05 minutes 
==================================================================================================
	PARSING TIME: 15.95 minutes 
==================================================================================================
	Identification : 0.499
	P, R  : 0.412, 0.631

==================================================================================================
	XP Ends: 29/6 (22 h:15)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (22h:15)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 83)       1144819     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1199        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 50)        689650      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 39)        4251        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_124 (Concatenate)   (None, 50, 94)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 250)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 195)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 32)           16256       concatenate_124[0][0]            
__________________________________________________________________________________________________
concatenate_125 (Concatenate)   (None, 445)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_126 (Concatenate)   (None, 477)          0           phraseRnn[0][0]                  
                                                                 concatenate_125[0][0]            
__________________________________________________________________________________________________
dense_83 (Dense)                (None, 53)           25334       concatenate_126[0][0]            
__________________________________________________________________________________________________
dense_84 (Dense)                (None, 4)            216         dense_83[0][0]                   
==================================================================================================
Total params: 1,881,725
Trainable params: 1,881,725
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 449s - loss: 0.0673 - acc: 0.9822 - val_loss: 0.0570 - val_acc: 0.9845
Epoch 2/40
 - 447s - loss: 0.0517 - acc: 0.9868 - val_loss: 0.0571 - val_acc: 0.9847
Epoch 3/40
 - 452s - loss: 0.0486 - acc: 0.9879 - val_loss: 0.0610 - val_acc: 0.9843
Epoch 4/40
 - 410s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0643 - val_acc: 0.9843
Epoch 5/40
 - 409s - loss: 0.0455 - acc: 0.9888 - val_loss: 0.0807 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 39.02 minutes 
==================================================================================================
	PARSING TIME: 6.8 minutes 
==================================================================================================
	Identification : 0.484
	P, R  : 0.445, 0.531

==================================================================================================
	XP Ends: 29/6 (23 h:1)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,480            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.087          ,50             ,5              ,93             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
37             ,88             ,True           ,True           ,45             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 480, True, 0.087, 50, 5, 93, 37, 88, True, True, 45
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (23h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 93)       1063734     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 88)        1006544     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 37)        5624        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_127 (Concatenate)   (None, 50, 98)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 440)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 185)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           19440       concatenate_127[0][0]            
__________________________________________________________________________________________________
concatenate_128 (Concatenate)   (None, 625)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_129 (Concatenate)   (None, 670)          0           phraseRnn[0][0]                  
                                                                 concatenate_128[0][0]            
__________________________________________________________________________________________________
dense_85 (Dense)                (None, 480)          322080      concatenate_129[0][0]            
__________________________________________________________________________________________________
dense_86 (Dense)                (None, 4)            1924        dense_85[0][0]                   
==================================================================================================
Total params: 2,420,106
Trainable params: 2,420,106
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 265s - loss: 12.0809 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 2/40
 - 263s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 3/40
 - 263s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 4/40
 - 263s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 5/40
 - 264s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 00005: early stopping
	TRAINING TIME: 23.55 minutes 
==================================================================================================
	PARSING TIME: 7.6 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (23 h:33)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (23h:33)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 93)       874293      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 88)        827288      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 37)        6253        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_130 (Concatenate)   (None, 50, 98)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 440)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 185)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           19440       concatenate_130[0][0]            
__________________________________________________________________________________________________
concatenate_131 (Concatenate)   (None, 625)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_132 (Concatenate)   (None, 670)          0           phraseRnn[0][0]                  
                                                                 concatenate_131[0][0]            
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 480)          322080      concatenate_132[0][0]            
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 4)            1924        dense_87[0][0]                   
==================================================================================================
Total params: 2,052,123
Trainable params: 2,052,123
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 179s - loss: 8.1814 - acc: 0.4917 - val_loss: 8.1531 - val_acc: 0.4937
Epoch 2/40
 - 178s - loss: 8.0877 - acc: 0.4975 - val_loss: 8.0821 - val_acc: 0.4982
Epoch 3/40
 - 176s - loss: 8.0634 - acc: 0.4994 - val_loss: 8.0801 - val_acc: 0.4985
Epoch 4/40
 - 177s - loss: 8.0602 - acc: 0.4999 - val_loss: 8.0808 - val_acc: 0.4984
Epoch 5/40
 - 174s - loss: 8.0598 - acc: 0.4999 - val_loss: 8.0811 - val_acc: 0.4983
Epoch 00005: early stopping
	TRAINING TIME: 15.8 minutes 
==================================================================================================
	PARSING TIME: 11.55 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (0 h:1)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (0h:1)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 93)       2052603     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 88)        1942248     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 37)        4033        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_133 (Concatenate)   (None, 50, 98)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 440)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 185)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           19440       concatenate_133[0][0]            
__________________________________________________________________________________________________
concatenate_134 (Concatenate)   (None, 625)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_135 (Concatenate)   (None, 670)          0           phraseRnn[0][0]                  
                                                                 concatenate_134[0][0]            
__________________________________________________________________________________________________
dense_89 (Dense)                (None, 480)          322080      concatenate_135[0][0]            
__________________________________________________________________________________________________
dense_90 (Dense)                (None, 4)            1924        dense_89[0][0]                   
==================================================================================================
Total params: 4,342,873
Trainable params: 4,342,873
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 345s - loss: 0.3157 - acc: 0.9701 - val_loss: 0.0669 - val_acc: 0.9827
Epoch 2/40
 - 377s - loss: 0.0550 - acc: 0.9858 - val_loss: 0.0599 - val_acc: 0.9841
Epoch 3/40
 - 379s - loss: 0.0474 - acc: 0.9883 - val_loss: 0.0647 - val_acc: 0.9835
Epoch 4/40
 - 375s - loss: 0.0452 - acc: 0.9890 - val_loss: 0.0721 - val_acc: 0.9841
Epoch 5/40
 - 378s - loss: 0.0438 - acc: 0.9893 - val_loss: 0.0900 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 33.8 minutes 
==================================================================================================
	PARSING TIME: 5.63 minutes 
==================================================================================================
	Identification : 0.482
	P, R  : 0.455, 0.512

==================================================================================================
	XP Ends: 30/6 (0 h:42)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,107            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.068          ,50             ,9              ,61             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
21             ,63             ,True           ,True           ,29             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 107, True, 0.068, 50, 9, 61, 21, 63, True, True, 29
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (0h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 61)       460245      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1368        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 63)        475335      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 21)        3192        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_136 (Concatenate)   (None, 50, 70)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 315)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 105)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 29)           8700        concatenate_136[0][0]            
__________________________________________________________________________________________________
concatenate_137 (Concatenate)   (None, 420)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_138 (Concatenate)   (None, 449)          0           phraseRnn[0][0]                  
                                                                 concatenate_137[0][0]            
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 107)          48150       concatenate_138[0][0]            
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 4)            432         dense_91[0][0]                   
==================================================================================================
Total params: 997,422
Trainable params: 997,422
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 278s - loss: 0.0649 - acc: 0.9831 - val_loss: 0.0554 - val_acc: 0.9859
Epoch 2/40
 - 279s - loss: 0.0494 - acc: 0.9878 - val_loss: 0.0548 - val_acc: 0.9861
Epoch 3/40
 - 277s - loss: 0.0464 - acc: 0.9888 - val_loss: 0.0661 - val_acc: 0.9861
Epoch 4/40
 - 282s - loss: 0.0449 - acc: 0.9893 - val_loss: 0.0615 - val_acc: 0.9859
Epoch 5/40
 - 279s - loss: 0.0441 - acc: 0.9895 - val_loss: 0.0666 - val_acc: 0.9860
Epoch 00005: early stopping
	TRAINING TIME: 24.68 minutes 
==================================================================================================
	PARSING TIME: 9.42 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.588, 0.557

==================================================================================================
	XP Ends: 30/6 (1 h:16)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (1h:16)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 61)       441701      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1521        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 63)        456183      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 21)        3549        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_139 (Concatenate)   (None, 50, 70)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 315)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 105)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 29)           8700        concatenate_139[0][0]            
__________________________________________________________________________________________________
concatenate_140 (Concatenate)   (None, 420)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_141 (Concatenate)   (None, 449)          0           phraseRnn[0][0]                  
                                                                 concatenate_140[0][0]            
__________________________________________________________________________________________________
dense_93 (Dense)                (None, 107)          48150       concatenate_141[0][0]            
__________________________________________________________________________________________________
dense_94 (Dense)                (None, 4)            432         dense_93[0][0]                   
==================================================================================================
Total params: 960,236
Trainable params: 960,236
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 190s - loss: 0.0728 - acc: 0.9804 - val_loss: 0.0595 - val_acc: 0.9845
Epoch 2/40
 - 191s - loss: 0.0516 - acc: 0.9870 - val_loss: 0.0601 - val_acc: 0.9850
Epoch 3/40
 - 207s - loss: 0.0480 - acc: 0.9883 - val_loss: 0.0631 - val_acc: 0.9850
Epoch 4/40
 - 206s - loss: 0.0464 - acc: 0.9887 - val_loss: 0.0729 - val_acc: 0.9848
Epoch 5/40
 - 206s - loss: 0.0457 - acc: 0.9888 - val_loss: 0.0740 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 17.63 minutes 
==================================================================================================
	PARSING TIME: 14.2 minutes 
==================================================================================================
	Identification : 0.53
	P, R  : 0.461, 0.622

==================================================================================================
	XP Ends: 30/6 (1 h:49)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (1h:49)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 61)       841373      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        981         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 63)        868959      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 21)        2289        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_142 (Concatenate)   (None, 50, 70)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 315)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 105)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 29)           8700        concatenate_142[0][0]            
__________________________________________________________________________________________________
concatenate_143 (Concatenate)   (None, 420)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_144 (Concatenate)   (None, 449)          0           phraseRnn[0][0]                  
                                                                 concatenate_143[0][0]            
__________________________________________________________________________________________________
dense_95 (Dense)                (None, 107)          48150       concatenate_144[0][0]            
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 4)            432         dense_95[0][0]                   
==================================================================================================
Total params: 1,770,884
Trainable params: 1,770,884
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 369s - loss: 0.0665 - acc: 0.9820 - val_loss: 0.0567 - val_acc: 0.9844
Epoch 2/40
 - 371s - loss: 0.0511 - acc: 0.9870 - val_loss: 0.0582 - val_acc: 0.9848
Epoch 3/40
 - 370s - loss: 0.0481 - acc: 0.9880 - val_loss: 0.0610 - val_acc: 0.9845
Epoch 4/40
 - 368s - loss: 0.0462 - acc: 0.9887 - val_loss: 0.0705 - val_acc: 0.9841
Epoch 5/40
 - 368s - loss: 0.0449 - acc: 0.9890 - val_loss: 0.0808 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 33.62 minutes 
==================================================================================================
	PARSING TIME: 5.58 minutes 
==================================================================================================
	Identification : 0.506
	P, R  : 0.462, 0.559

==================================================================================================
	XP Ends: 30/6 (2 h:29)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,68             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.032          ,50             ,47             ,81             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
28             ,76             ,False          ,True           ,97             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 68, True, 0.032, 50, 47, 81, 28, 76, False, True, 97
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (2h:29)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 81)       926478      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 47)       7144        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 76)        869288      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 28)        4256        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_145 (Concatenate)   (None, 50, 128)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 304)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 112)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 97)           65766       concatenate_145[0][0]            
__________________________________________________________________________________________________
concatenate_146 (Concatenate)   (None, 416)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_147 (Concatenate)   (None, 513)          0           phraseRnn[0][0]                  
                                                                 concatenate_146[0][0]            
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 68)           34952       concatenate_147[0][0]            
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 4)            276         dense_97[0][0]                   
==================================================================================================
Total params: 1,908,160
Trainable params: 1,908,160
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 294s - loss: 0.0645 - acc: 0.9828 - val_loss: 0.0534 - val_acc: 0.9862
Epoch 2/40
 - 294s - loss: 0.0494 - acc: 0.9879 - val_loss: 0.0528 - val_acc: 0.9865
Epoch 3/40
 - 294s - loss: 0.0466 - acc: 0.9888 - val_loss: 0.0556 - val_acc: 0.9864
Epoch 4/40
 - 309s - loss: 0.0452 - acc: 0.9891 - val_loss: 0.0595 - val_acc: 0.9862
Epoch 5/40
 - 308s - loss: 0.0444 - acc: 0.9893 - val_loss: 0.0661 - val_acc: 0.9862
Epoch 00005: early stopping
	TRAINING TIME: 26.52 minutes 
==================================================================================================
	PARSING TIME: 8.15 minutes 
==================================================================================================
	Identification : 0.549
	P, R  : 0.535, 0.564

==================================================================================================
	XP Ends: 30/6 (3 h:4)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (3h:4)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 81)       761481      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 47)       7943        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 76)        714476      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 28)        4732        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_148 (Concatenate)   (None, 50, 128)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 304)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 112)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 97)           65766       concatenate_148[0][0]            
__________________________________________________________________________________________________
concatenate_149 (Concatenate)   (None, 416)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_150 (Concatenate)   (None, 513)          0           phraseRnn[0][0]                  
                                                                 concatenate_149[0][0]            
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 68)           34952       concatenate_150[0][0]            
__________________________________________________________________________________________________
dense_100 (Dense)               (None, 4)            276         dense_99[0][0]                   
==================================================================================================
Total params: 1,589,626
Trainable params: 1,589,626
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 198s - loss: 0.0744 - acc: 0.9798 - val_loss: 0.0581 - val_acc: 0.9849
Epoch 2/40
 - 198s - loss: 0.0529 - acc: 0.9867 - val_loss: 0.0582 - val_acc: 0.9850
Epoch 3/40
 - 207s - loss: 0.0491 - acc: 0.9879 - val_loss: 0.0624 - val_acc: 0.9849
Epoch 4/40
 - 208s - loss: 0.0477 - acc: 0.9883 - val_loss: 0.0659 - val_acc: 0.9846
Epoch 5/40
 - 208s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0691 - val_acc: 0.9846
Epoch 00005: early stopping
	TRAINING TIME: 18.03 minutes 
==================================================================================================
	PARSING TIME: 12.57 minutes 
==================================================================================================
	Identification : 0.472
	P, R  : 0.379, 0.626

==================================================================================================
	XP Ends: 30/6 (3 h:35)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (3h:35)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 81)       1787751     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 47)       5123        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 76)        1677396     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 28)        3052        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_151 (Concatenate)   (None, 50, 128)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 304)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 112)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 97)           65766       concatenate_151[0][0]            
__________________________________________________________________________________________________
concatenate_152 (Concatenate)   (None, 416)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_153 (Concatenate)   (None, 513)          0           phraseRnn[0][0]                  
                                                                 concatenate_152[0][0]            
__________________________________________________________________________________________________
dense_101 (Dense)               (None, 68)           34952       concatenate_153[0][0]            
__________________________________________________________________________________________________
dense_102 (Dense)               (None, 4)            276         dense_101[0][0]                  
==================================================================================================
Total params: 3,574,316
Trainable params: 3,574,316
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 417s - loss: 0.0634 - acc: 0.9829 - val_loss: 0.0575 - val_acc: 0.9845
Epoch 2/40
 - 417s - loss: 0.0494 - acc: 0.9876 - val_loss: 0.0590 - val_acc: 0.9846
Epoch 3/40
 - 415s - loss: 0.0470 - acc: 0.9884 - val_loss: 0.0626 - val_acc: 0.9842
Epoch 4/40
 - 417s - loss: 0.0453 - acc: 0.9889 - val_loss: 0.0720 - val_acc: 0.9842
Epoch 5/40
 - 418s - loss: 0.0442 - acc: 0.9891 - val_loss: 0.0814 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 37.55 minutes 
==================================================================================================
	PARSING TIME: 5.43 minutes 
==================================================================================================
	Identification : 0.496
	P, R  : 0.449, 0.553

==================================================================================================
	XP Ends: 30/6 (4 h:19)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,27             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.044          ,50             ,19             ,35             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
22             ,35             ,False          ,True           ,74             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 27, True, 0.044, 50, 19, 35, 22, 35, False, True, 74
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (4h:19)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 35)       264075      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 19)       2888        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 35)        264075      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 22)        3344        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_154 (Concatenate)   (None, 50, 54)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 140)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 88)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 74)           28638       concatenate_154[0][0]            
__________________________________________________________________________________________________
concatenate_155 (Concatenate)   (None, 228)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_156 (Concatenate)   (None, 302)          0           phraseRnn[0][0]                  
                                                                 concatenate_155[0][0]            
__________________________________________________________________________________________________
dense_103 (Dense)               (None, 27)           8181        concatenate_156[0][0]            
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 4)            112         dense_103[0][0]                  
==================================================================================================
Total params: 571,313
Trainable params: 571,313
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 281s - loss: 0.0674 - acc: 0.9821 - val_loss: 0.0564 - val_acc: 0.9853
Epoch 2/40
 - 279s - loss: 0.0514 - acc: 0.9871 - val_loss: 0.0556 - val_acc: 0.9859
Epoch 3/40
 - 279s - loss: 0.0482 - acc: 0.9882 - val_loss: 0.0568 - val_acc: 0.9859
Epoch 4/40
 - 280s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0593 - val_acc: 0.9857
Epoch 5/40
 - 258s - loss: 0.0456 - acc: 0.9890 - val_loss: 0.0607 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 24.33 minutes 
==================================================================================================
	PARSING TIME: 7.58 minutes 
==================================================================================================
	Identification : 0.599
	P, R  : 0.71, 0.518

==================================================================================================
	XP Ends: 30/6 (4 h:52)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (4h:52)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 35)       253435      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 19)       3211        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 35)        253435      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 22)        3718        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_157 (Concatenate)   (None, 50, 54)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 140)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 88)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 74)           28638       concatenate_157[0][0]            
__________________________________________________________________________________________________
concatenate_158 (Concatenate)   (None, 228)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_159 (Concatenate)   (None, 302)          0           phraseRnn[0][0]                  
                                                                 concatenate_158[0][0]            
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 27)           8181        concatenate_159[0][0]            
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 4)            112         dense_105[0][0]                  
==================================================================================================
Total params: 550,730
Trainable params: 550,730
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 176s - loss: 0.0755 - acc: 0.9795 - val_loss: 0.0628 - val_acc: 0.9831
Epoch 2/40
 - 177s - loss: 0.0545 - acc: 0.9861 - val_loss: 0.0603 - val_acc: 0.9846
Epoch 3/40
 - 176s - loss: 0.0505 - acc: 0.9875 - val_loss: 0.0625 - val_acc: 0.9845
Epoch 4/40
 - 173s - loss: 0.0488 - acc: 0.9880 - val_loss: 0.0657 - val_acc: 0.9843
Epoch 5/40
 - 174s - loss: 0.0476 - acc: 0.9883 - val_loss: 0.0689 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 15.53 minutes 
==================================================================================================
	PARSING TIME: 12.07 minutes 
==================================================================================================
	Identification : 0.465
	P, R  : 0.366, 0.637

==================================================================================================
	XP Ends: 30/6 (5 h:20)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (5h:20)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 35)       482755      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 19)       2071        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 35)        482755      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 22)        2398        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_160 (Concatenate)   (None, 50, 54)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 140)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 88)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 74)           28638       concatenate_160[0][0]            
__________________________________________________________________________________________________
concatenate_161 (Concatenate)   (None, 228)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_162 (Concatenate)   (None, 302)          0           phraseRnn[0][0]                  
                                                                 concatenate_161[0][0]            
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 27)           8181        concatenate_162[0][0]            
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 4)            112         dense_107[0][0]                  
==================================================================================================
Total params: 1,006,910
Trainable params: 1,006,910
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 343s - loss: 0.0676 - acc: 0.9818 - val_loss: 0.0583 - val_acc: 0.9843
Epoch 2/40
 - 345s - loss: 0.0532 - acc: 0.9862 - val_loss: 0.0589 - val_acc: 0.9844
Epoch 3/40
 - 341s - loss: 0.0502 - acc: 0.9872 - val_loss: 0.0611 - val_acc: 0.9841
Epoch 4/40
 - 342s - loss: 0.0485 - acc: 0.9878 - val_loss: 0.0654 - val_acc: 0.9840
Epoch 5/40
 - 344s - loss: 0.0473 - acc: 0.9881 - val_loss: 0.0687 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 31.42 minutes 
==================================================================================================
	PARSING TIME: 5.33 minutes 
==================================================================================================
	Identification : 0.489
	P, R  : 0.429, 0.569

==================================================================================================
	XP Ends: 30/6 (5 h:58)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,265            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.038          ,50             ,5              ,162            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
26             ,49             ,True           ,True           ,341            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 265, True, 0.038, 50, 5, 162, 26, 49, True, True, 341
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (5h:58)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 162)      1222290     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 49)        369705      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 26)        3952        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_163 (Concatenate)   (None, 50, 167)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 245)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 130)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 341)          520707      concatenate_163[0][0]            
__________________________________________________________________________________________________
concatenate_164 (Concatenate)   (None, 375)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_165 (Concatenate)   (None, 716)          0           phraseRnn[0][0]                  
                                                                 concatenate_164[0][0]            
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 265)          190005      concatenate_165[0][0]            
__________________________________________________________________________________________________
dense_110 (Dense)               (None, 4)            1064        dense_109[0][0]                  
==================================================================================================
Total params: 2,308,483
Trainable params: 2,308,483
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 537s - loss: 12.0759 - acc: 0.2503 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 2/40
 - 537s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 3/40
 - 538s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 4/40
 - 537s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 5/40
 - 537s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 00005: early stopping
	TRAINING TIME: 46.35 minutes 
==================================================================================================
	PARSING TIME: 8.18 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (6 h:53)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (6h:53)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 162)      1173042     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 49)        354809      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 26)        4394        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_166 (Concatenate)   (None, 50, 167)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 245)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 130)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 341)          520707      concatenate_166[0][0]            
__________________________________________________________________________________________________
concatenate_167 (Concatenate)   (None, 375)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_168 (Concatenate)   (None, 716)          0           phraseRnn[0][0]                  
                                                                 concatenate_167[0][0]            
__________________________________________________________________________________________________
dense_111 (Dense)               (None, 265)          190005      concatenate_168[0][0]            
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 4)            1064        dense_111[0][0]                  
==================================================================================================
Total params: 2,244,866
Trainable params: 2,244,866
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 347s - loss: 0.1098 - acc: 0.9748 - val_loss: 0.0670 - val_acc: 0.9821
Epoch 2/40
 - 347s - loss: 0.0593 - acc: 0.9847 - val_loss: 0.0650 - val_acc: 0.9827
Epoch 3/40
 - 347s - loss: 0.0546 - acc: 0.9861 - val_loss: 0.0649 - val_acc: 0.9835
Epoch 4/40
 - 347s - loss: 0.0519 - acc: 0.9869 - val_loss: 0.0677 - val_acc: 0.9833
Epoch 5/40
 - 347s - loss: 0.0504 - acc: 0.9874 - val_loss: 0.0684 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 29.9 minutes 
==================================================================================================
	PARSING TIME: 12.37 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.403, 0.635

==================================================================================================
	XP Ends: 30/6 (7 h:36)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (7h:36)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 162)      2234466     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 49)        675857      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 26)        2834        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_169 (Concatenate)   (None, 50, 167)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 245)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 130)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 341)          520707      concatenate_169[0][0]            
__________________________________________________________________________________________________
concatenate_170 (Concatenate)   (None, 375)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_171 (Concatenate)   (None, 716)          0           phraseRnn[0][0]                  
                                                                 concatenate_170[0][0]            
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 265)          190005      concatenate_171[0][0]            
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 4)            1064        dense_113[0][0]                  
==================================================================================================
Total params: 3,625,478
Trainable params: 3,625,478
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 725s - loss: 12.0825 - acc: 0.2501 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 2/40
 - 724s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 3/40
 - 726s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 4/40
 - 724s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 5/40
 - 724s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 00005: early stopping
	TRAINING TIME: 63.35 minutes 
==================================================================================================
	PARSING TIME: 9.85 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (8 h:50)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,30             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.07           ,50             ,10             ,59             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
38             ,121            ,True           ,True           ,478            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 30, True, 0.07, 50, 10, 59, 38, 121, True, True, 478
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (8h:50)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 59)       674842      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 10)       1520        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 121)       1383998     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 38)        5776        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_172 (Concatenate)   (None, 50, 69)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 605)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 190)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 478)          785832      concatenate_172[0][0]            
__________________________________________________________________________________________________
concatenate_173 (Concatenate)   (None, 795)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_174 (Concatenate)   (None, 1273)         0           phraseRnn[0][0]                  
                                                                 concatenate_173[0][0]            
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 30)           38220       concatenate_174[0][0]            
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 4)            124         dense_115[0][0]                  
==================================================================================================
Total params: 2,890,312
Trainable params: 2,890,312
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 648s - loss: 12.0840 - acc: 0.2499 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 2/40
 - 649s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 3/40
 - 619s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 4/40
 - 619s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 5/40
 - 619s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 54.13 minutes 
==================================================================================================
	PARSING TIME: 17.57 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (10 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (10h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 59)       554659      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 10)       1690        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 121)       1137521     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 38)        6422        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_175 (Concatenate)   (None, 50, 69)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 605)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 190)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 478)          785832      concatenate_175[0][0]            
__________________________________________________________________________________________________
concatenate_176 (Concatenate)   (None, 795)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_177 (Concatenate)   (None, 1273)         0           phraseRnn[0][0]                  
                                                                 concatenate_176[0][0]            
__________________________________________________________________________________________________
dense_117 (Dense)               (None, 30)           38220       concatenate_177[0][0]            
__________________________________________________________________________________________________
dense_118 (Dense)               (None, 4)            124         dense_117[0][0]                  
==================================================================================================
Total params: 2,524,468
Trainable params: 2,524,468
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 419s - loss: 5.8612 - acc: 0.6280 - val_loss: 0.0664 - val_acc: 0.9820
Epoch 2/40
 - 419s - loss: 0.0615 - acc: 0.9837 - val_loss: 0.0688 - val_acc: 0.9846
Epoch 3/40
 - 419s - loss: 0.0527 - acc: 0.9867 - val_loss: 0.0604 - val_acc: 0.9849
Epoch 4/40
 - 419s - loss: 0.0500 - acc: 0.9876 - val_loss: 0.0622 - val_acc: 0.9845
Epoch 5/40
 - 419s - loss: 0.0485 - acc: 0.9881 - val_loss: 0.0632 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 35.98 minutes 
==================================================================================================
	PARSING TIME: 14.32 minutes 
==================================================================================================
	Identification : 0.492
	P, R  : 0.447, 0.548

==================================================================================================
	XP Ends: 30/6 (10 h:53)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (10h:53)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 59)       1302189     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 10)       1090        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 121)       2670591     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 38)        4142        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_178 (Concatenate)   (None, 50, 69)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 605)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 190)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 478)          785832      concatenate_178[0][0]            
__________________________________________________________________________________________________
concatenate_179 (Concatenate)   (None, 795)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_180 (Concatenate)   (None, 1273)         0           phraseRnn[0][0]                  
                                                                 concatenate_179[0][0]            
__________________________________________________________________________________________________
dense_119 (Dense)               (None, 30)           38220       concatenate_180[0][0]            
__________________________________________________________________________________________________
dense_120 (Dense)               (None, 4)            124         dense_119[0][0]                  
==================================================================================================
Total params: 4,802,188
Trainable params: 4,802,188
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 875s - loss: 12.0785 - acc: 0.2503 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 2/40
 - 837s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 3/40
 - 836s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 4/40
 - 876s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 5/40
 - 875s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 00005: early stopping
	TRAINING TIME: 74.57 minutes 
==================================================================================================
	PARSING TIME: 17.1 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.057

==================================================================================================
	XP Ends: 30/6 (12 h:25)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,186            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.014          ,50             ,12             ,57             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
28             ,109            ,True           ,True           ,487            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 186, True, 0.014, 50, 12, 57, 28, 109, True, True, 487
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (12h:25)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 57)       651966      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1824        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 109)       1246742     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 28)        4256        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_181 (Concatenate)   (None, 50, 69)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 545)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 140)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 487)          813777      concatenate_181[0][0]            
__________________________________________________________________________________________________
concatenate_182 (Concatenate)   (None, 685)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_183 (Concatenate)   (None, 1172)         0           phraseRnn[0][0]                  
                                                                 concatenate_182[0][0]            
__________________________________________________________________________________________________
dense_121 (Dense)               (None, 186)          218178      concatenate_183[0][0]            
__________________________________________________________________________________________________
dense_122 (Dense)               (None, 4)            748         dense_121[0][0]                  
==================================================================================================
Total params: 2,937,491
Trainable params: 2,937,491
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 662s - loss: 0.0891 - acc: 0.9775 - val_loss: 0.0565 - val_acc: 0.9854
Epoch 2/40
 - 664s - loss: 0.0515 - acc: 0.9872 - val_loss: 0.0555 - val_acc: 0.9859
Epoch 3/40
 - 663s - loss: 0.0478 - acc: 0.9884 - val_loss: 0.0577 - val_acc: 0.9858
Epoch 4/40
 - 663s - loss: 0.0460 - acc: 0.9889 - val_loss: 0.0595 - val_acc: 0.9858
Epoch 5/40
 - 634s - loss: 0.0450 - acc: 0.9892 - val_loss: 0.0630 - val_acc: 0.9857
Epoch 00005: early stopping
	TRAINING TIME: 56.37 minutes 
==================================================================================================
	PARSING TIME: 9.82 minutes 
==================================================================================================
	Identification : 0.532
	P, R  : 0.485, 0.59

==================================================================================================
	XP Ends: 30/6 (13 h:32)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (13h:32)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 57)       535857      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       2028        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 109)       1024709     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 28)        4732        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_184 (Concatenate)   (None, 50, 69)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 545)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 140)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 487)          813777      concatenate_184[0][0]            
__________________________________________________________________________________________________
concatenate_185 (Concatenate)   (None, 685)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_186 (Concatenate)   (None, 1172)         0           phraseRnn[0][0]                  
                                                                 concatenate_185[0][0]            
__________________________________________________________________________________________________
dense_123 (Dense)               (None, 186)          218178      concatenate_186[0][0]            
__________________________________________________________________________________________________
dense_124 (Dense)               (None, 4)            748         dense_123[0][0]                  
==================================================================================================
Total params: 2,600,029
Trainable params: 2,600,029
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 448s - loss: 0.1193 - acc: 0.9711 - val_loss: 0.0689 - val_acc: 0.9825
Epoch 2/40
 - 429s - loss: 0.0599 - acc: 0.9847 - val_loss: 0.0656 - val_acc: 0.9832
Epoch 3/40
 - 429s - loss: 0.0539 - acc: 0.9866 - val_loss: 0.0658 - val_acc: 0.9838
Epoch 4/40
 - 429s - loss: 0.0511 - acc: 0.9873 - val_loss: 0.0682 - val_acc: 0.9838
Epoch 5/40
 - 429s - loss: 0.0493 - acc: 0.9878 - val_loss: 0.0706 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 37.08 minutes 
==================================================================================================
	PARSING TIME: 14.72 minutes 
==================================================================================================
	Identification : 0.464
	P, R  : 0.383, 0.59

==================================================================================================
	XP Ends: 30/6 (14 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (14h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 57)       1258047     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1308        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 109)       2405739     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 28)        3052        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_187 (Concatenate)   (None, 50, 69)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 545)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 140)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 487)          813777      concatenate_187[0][0]            
__________________________________________________________________________________________________
concatenate_188 (Concatenate)   (None, 685)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_189 (Concatenate)   (None, 1172)         0           phraseRnn[0][0]                  
                                                                 concatenate_188[0][0]            
__________________________________________________________________________________________________
dense_125 (Dense)               (None, 186)          218178      concatenate_189[0][0]            
__________________________________________________________________________________________________
dense_126 (Dense)               (None, 4)            748         dense_125[0][0]                  
==================================================================================================
Total params: 4,700,849
Trainable params: 4,700,849
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 857s - loss: 0.0652 - acc: 0.9824 - val_loss: 0.0581 - val_acc: 0.9847
Epoch 2/40
 - 857s - loss: 0.0492 - acc: 0.9878 - val_loss: 0.0583 - val_acc: 0.9846
Epoch 3/40
 - 857s - loss: 0.0463 - acc: 0.9888 - val_loss: 0.0624 - val_acc: 0.9843
Epoch 4/40
 - 897s - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0675 - val_acc: 0.9841
Epoch 5/40
 - 896s - loss: 0.0438 - acc: 0.9893 - val_loss: 0.0788 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 75.68 minutes 
==================================================================================================
	PARSING TIME: 6.43 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.459, 0.543

==================================================================================================
	XP Ends: 30/6 (15 h:48)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,38             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.092          ,50             ,17             ,32             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
9              ,28             ,True           ,True           ,207            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 38, False, 0.092, 50, 17, 32, 9, 28, True, True, 207
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (15h:48)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 32)       241440      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2584        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 28)        211260      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         1368        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_190 (Concatenate)   (None, 50, 49)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 140)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 207)          212796      concatenate_190[0][0]            
__________________________________________________________________________________________________
concatenate_191 (Concatenate)   (None, 185)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_192 (Concatenate)   (None, 392)          0           phraseRnn[0][0]                  
                                                                 concatenate_191[0][0]            
__________________________________________________________________________________________________
dense_127 (Dense)               (None, 38)           14934       concatenate_192[0][0]            
__________________________________________________________________________________________________
dense_128 (Dense)               (None, 4)            156         dense_127[0][0]                  
==================================================================================================
Total params: 684,538
Trainable params: 684,538
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 432s - loss: 12.0742 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
## OAR [2019-06-30 16:03:43] Job 1985750 KILLED ##
