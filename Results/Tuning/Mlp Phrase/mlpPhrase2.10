Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_wHIyLa.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 3841/4043 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX 980 (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,39             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.142          ,50             ,5              ,28             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,27             ,True           ,True           ,67             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 39, True, 0.142, 50, 5, 28, 8, 27, True, True, 67
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (14h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 28)       320264      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 27)        308826      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 33)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 135)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 67)           20301       concatenate_1[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 175)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 242)          0           phraseRnn[0][0]                  
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 39)           9477        concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            160         dense_1[0][0]                    
==================================================================================================
Total params: 661,004
Trainable params: 661,004
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 140s - loss: 0.0744 - acc: 0.9812 - val_loss: 0.0568 - val_acc: 0.9855
Epoch 2/40
 - 134s - loss: 0.0499 - acc: 0.9876 - val_loss: 0.0551 - val_acc: 0.9863
Epoch 3/40
 - 139s - loss: 0.0472 - acc: 0.9886 - val_loss: 0.0578 - val_acc: 0.9858
Epoch 4/40
 - 141s - loss: 0.0470 - acc: 0.9886 - val_loss: 0.0588 - val_acc: 0.9861
Epoch 5/40
 - 135s - loss: 0.0455 - acc: 0.9890 - val_loss: 0.0624 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 13.9 minutes 
==================================================================================================
	PARSING TIME: 4.32 minutes 
==================================================================================================
	Identification : 0.523
	P, R  : 0.484, 0.57

==================================================================================================
	XP Ends: 28/6 (14 h:23)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (14h:23)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 28)       263228      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 27)        253827      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 50, 33)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 135)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 67)           20301       concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 175)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 242)          0           phraseRnn[0][0]                  
                                                                 concatenate_5[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 39)           9477        concatenate_6[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            160         dense_3[0][0]                    
==================================================================================================
Total params: 549,190
Trainable params: 549,190
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0913 - acc: 0.9770 - val_loss: 0.0628 - val_acc: 0.9838
Epoch 2/40
 - 96s - loss: 0.0542 - acc: 0.9864 - val_loss: 0.0595 - val_acc: 0.9850
Epoch 3/40
 - 92s - loss: 0.0499 - acc: 0.9877 - val_loss: 0.0643 - val_acc: 0.9837
Epoch 4/40
 - 92s - loss: 0.0482 - acc: 0.9882 - val_loss: 0.0641 - val_acc: 0.9850
Epoch 5/40
 - 92s - loss: 0.0472 - acc: 0.9884 - val_loss: 0.0670 - val_acc: 0.9849
Epoch 00005: early stopping
	TRAINING TIME: 8.23 minutes 
==================================================================================================
	PARSING TIME: 6.93 minutes 
==================================================================================================
	Identification : 0.483
	P, R  : 0.397, 0.617

==================================================================================================
	XP Ends: 28/6 (14 h:38)
==================================================================================================
/home/halsaied/miniconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.py:399: UserWarning: The graph doesn't contain a node that depends on the root element.
  "The graph doesn't contain a node " "that depends on the root element."
# Seed: 0
==================================================================================================
XP Starts: 28/6 (14h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 28)       617988      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 27)        595917      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 50, 33)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 135)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 67)           20301       concatenate_7[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 175)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 242)          0           phraseRnn[0][0]                  
                                                                 concatenate_8[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 39)           9477        concatenate_9[0][0]              
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            160         dense_5[0][0]                    
==================================================================================================
Total params: 1,245,260
Trainable params: 1,245,260
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 192s - loss: 0.0710 - acc: 0.9815 - val_loss: 0.0683 - val_acc: 0.9815
Epoch 2/40
 - 185s - loss: 0.0496 - acc: 0.9876 - val_loss: 0.0611 - val_acc: 0.9842
Epoch 3/40
 - 180s - loss: 0.0468 - acc: 0.9886 - val_loss: 0.0639 - val_acc: 0.9842
Epoch 4/40
 - 194s - loss: 0.0454 - acc: 0.9890 - val_loss: 0.0683 - val_acc: 0.9838
Epoch 5/40
 - 188s - loss: 0.0444 - acc: 0.9892 - val_loss: 0.0725 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 17.07 minutes 
==================================================================================================
	PARSING TIME: 2.9 minutes 
==================================================================================================
	Identification : 0.466
	P, R  : 0.403, 0.553

==================================================================================================
	XP Ends: 28/6 (14 h:59)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,404            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.178          ,50             ,49             ,29             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
16             ,39             ,False          ,True           ,334            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 404, False, 0.178, 50, 49, 29, 16, 39, False, True, 334
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (14h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 29)       331702      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       7448        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 39)        446082      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 16)        2432        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 50, 78)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 64)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 334)          551768      concatenate_10[0][0]             
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 220)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 554)          0           phraseRnn[0][0]                  
                                                                 concatenate_11[0][0]             
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 404)          224220      concatenate_12[0][0]             
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4)            1620        dense_7[0][0]                    
==================================================================================================
Total params: 1,565,272
Trainable params: 1,565,272
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 250s - loss: 12.0880 - acc: 0.2499 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 2/40
 - 249s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 3/40
 - 248s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 4/40
 - 249s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 5/40
 - 249s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 21.62 minutes 
==================================================================================================
	PARSING TIME: 11.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (15 h:32)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (15h:32)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 29)       272629      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       8281        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 39)        366639      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 16)        2704        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 50, 78)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 64)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 334)          551768      concatenate_13[0][0]             
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 220)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 554)          0           phraseRnn[0][0]                  
                                                                 concatenate_14[0][0]             
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 404)          224220      concatenate_15[0][0]             
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 4)            1620        dense_9[0][0]                    
==================================================================================================
Total params: 1,427,861
Trainable params: 1,427,861
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 169s - loss: 12.0898 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 2/40
 - 169s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 3/40
 - 169s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 4/40
 - 169s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 5/40
 - 169s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 00005: early stopping
	TRAINING TIME: 14.63 minutes 
==================================================================================================
	PARSING TIME: 16.32 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (16 h:3)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (16h:3)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 29)       640059      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       5341        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 39)        860769      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 16)        1744        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 50, 78)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 64)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 334)          551768      concatenate_16[0][0]             
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 220)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 554)          0           phraseRnn[0][0]                  
                                                                 concatenate_17[0][0]             
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 404)          224220      concatenate_18[0][0]             
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 4)            1620        dense_11[0][0]                   
==================================================================================================
Total params: 2,285,521
Trainable params: 2,285,521
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 336s - loss: 12.0838 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 2/40
 - 336s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 3/40
 - 335s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 4/40
 - 335s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 5/40
 - 336s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 00005: early stopping
	TRAINING TIME: 29.42 minutes 
==================================================================================================
	PARSING TIME: 3.75 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (16 h:37)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,37             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.121          ,50             ,24             ,109            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
14             ,184            ,True           ,True           ,493            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 37, False, 0.121, 50, 24, 109, 14, 184, True, True, 493
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (16h:37)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 109)      822405      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 24)       3648        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 184)       1388280     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 14)        2128        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 50, 133)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 920)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 70)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 493)          1236444     concatenate_19[0][0]             
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 990)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 1483)         0           phraseRnn[0][0]                  
                                                                 concatenate_20[0][0]             
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 37)           54908       concatenate_21[0][0]             
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 4)            152         dense_13[0][0]                   
==================================================================================================
Total params: 3,507,965
Trainable params: 3,507,965
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 391s - loss: 8.1555 - acc: 0.4936 - val_loss: 8.1030 - val_acc: 0.4969
Epoch 2/40
 - 392s - loss: 8.0730 - acc: 0.4987 - val_loss: 8.0721 - val_acc: 0.4990
Epoch 3/40
 - 392s - loss: 8.0593 - acc: 0.4999 - val_loss: 8.0709 - val_acc: 0.4991
Epoch 4/40
 - 392s - loss: 8.0586 - acc: 0.5000 - val_loss: 8.0713 - val_acc: 0.4991
Epoch 5/40
 - 392s - loss: 8.0583 - acc: 0.5000 - val_loss: 8.0708 - val_acc: 0.4991
Epoch 00005: early stopping
	TRAINING TIME: 33.55 minutes 
==================================================================================================
	PARSING TIME: 9.38 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (17 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (17h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 109)      789269      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 24)       4056        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 184)       1332344     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 14)        2366        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 50, 133)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 920)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 70)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 493)          1236444     concatenate_22[0][0]             
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 990)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 1483)         0           phraseRnn[0][0]                  
                                                                 concatenate_23[0][0]             
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 37)           54908       concatenate_24[0][0]             
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 4)            152         dense_15[0][0]                   
==================================================================================================
Total params: 3,419,539
Trainable params: 3,419,539
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 265s - loss: 12.0760 - acc: 0.2502 - val_loss: 12.0490 - val_acc: 0.2525
Epoch 2/40
 - 265s - loss: 12.0873 - acc: 0.2501 - val_loss: 12.0490 - val_acc: 0.2525
Epoch 3/40
 - 265s - loss: 12.0873 - acc: 0.2501 - val_loss: 12.0490 - val_acc: 0.2525
Epoch 4/40
 - 265s - loss: 12.0873 - acc: 0.2501 - val_loss: 12.0490 - val_acc: 0.2525
Epoch 5/40
 - 265s - loss: 12.0873 - acc: 0.2501 - val_loss: 12.0490 - val_acc: 0.2525
Epoch 00005: early stopping
	TRAINING TIME: 22.62 minutes 
==================================================================================================
	PARSING TIME: 27.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (18 h:11)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (18h:11)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 109)      1503437     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 24)       2616        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 184)       2537912     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 14)        1526        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 50, 133)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 920)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 70)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 493)          1236444     concatenate_25[0][0]             
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 990)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 1483)         0           phraseRnn[0][0]                  
                                                                 concatenate_26[0][0]             
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 37)           54908       concatenate_27[0][0]             
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 4)            152         dense_17[0][0]                   
==================================================================================================
Total params: 5,336,995
Trainable params: 5,336,995
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 526s - loss: 12.0865 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 2/40
 - 526s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 3/40
 - 526s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 4/40
 - 526s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 5/40
 - 526s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 00005: early stopping
	TRAINING TIME: 45.25 minutes 
==================================================================================================
	PARSING TIME: 6.17 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (19 h:3)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,77             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.019          ,50             ,9              ,69             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
46             ,157            ,True           ,True           ,38             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 77, True, 0.019, 50, 9, 69, 46, 157, True, True, 38
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (19h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 69)       789222      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1368        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 157)       1795766     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 46)        6992        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 50, 78)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 785)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 230)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 38)           13338       concatenate_28[0][0]             
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 1015)         0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 1053)         0           phraseRnn[0][0]                  
                                                                 concatenate_29[0][0]             
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 77)           81158       concatenate_30[0][0]             
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 4)            312         dense_19[0][0]                   
==================================================================================================
Total params: 2,688,156
Trainable params: 2,688,156
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 148s - loss: 0.0649 - acc: 0.9830 - val_loss: 0.0537 - val_acc: 0.9861
Epoch 2/40
 - 138s - loss: 0.0493 - acc: 0.9879 - val_loss: 0.0607 - val_acc: 0.9864
Epoch 3/40
 - 141s - loss: 0.0465 - acc: 0.9888 - val_loss: 0.0553 - val_acc: 0.9862
Epoch 4/40
 - 146s - loss: 0.0452 - acc: 0.9892 - val_loss: 0.0582 - val_acc: 0.9865
Epoch 5/40
 - 146s - loss: 0.0446 - acc: 0.9893 - val_loss: 0.0609 - val_acc: 0.9862
Epoch 00005: early stopping
	TRAINING TIME: 12.68 minutes 
==================================================================================================
	PARSING TIME: 4.52 minutes 
==================================================================================================
	Identification : 0.537
	P, R  : 0.504, 0.575

==================================================================================================
	XP Ends: 28/6 (19 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (19h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 69)       648669      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1521        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 157)       1475957     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 46)        7774        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 50, 78)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 785)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 230)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 38)           13338       concatenate_31[0][0]             
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 1015)         0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 1053)         0           phraseRnn[0][0]                  
                                                                 concatenate_32[0][0]             
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 77)           81158       concatenate_33[0][0]             
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 4)            312         dense_21[0][0]                   
==================================================================================================
Total params: 2,228,729
Trainable params: 2,228,729
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0744 - acc: 0.9797 - val_loss: 0.0590 - val_acc: 0.9844
Epoch 2/40
 - 94s - loss: 0.0527 - acc: 0.9868 - val_loss: 0.0584 - val_acc: 0.9850
Epoch 3/40
 - 94s - loss: 0.0492 - acc: 0.9880 - val_loss: 0.0616 - val_acc: 0.9849
Epoch 4/40
 - 93s - loss: 0.0476 - acc: 0.9884 - val_loss: 0.0659 - val_acc: 0.9846
Epoch 5/40
 - 94s - loss: 0.0467 - acc: 0.9885 - val_loss: 0.0721 - val_acc: 0.9844
Epoch 00005: early stopping
	TRAINING TIME: 8.28 minutes 
==================================================================================================
	PARSING TIME: 6.93 minutes 
==================================================================================================
	Identification : 0.479
	P, R  : 0.403, 0.59

==================================================================================================
	XP Ends: 28/6 (19 h:36)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (19h:36)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 69)       1522899     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        981         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 157)       3465147     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 46)        5014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 50, 78)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 785)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 230)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 38)           13338       concatenate_34[0][0]             
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 1015)         0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 1053)         0           phraseRnn[0][0]                  
                                                                 concatenate_35[0][0]             
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 77)           81158       concatenate_36[0][0]             
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 4)            312         dense_23[0][0]                   
==================================================================================================
Total params: 5,088,849
Trainable params: 5,088,849
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 198s - loss: 0.0635 - acc: 0.9830 - val_loss: 0.0597 - val_acc: 0.9848
Epoch 2/40
 - 193s - loss: 0.0489 - acc: 0.9878 - val_loss: 0.0593 - val_acc: 0.9846
Epoch 3/40
 - 195s - loss: 0.0462 - acc: 0.9888 - val_loss: 0.0635 - val_acc: 0.9843
Epoch 4/40
 - 185s - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0679 - val_acc: 0.9841
Epoch 5/40
 - 185s - loss: 0.0440 - acc: 0.9893 - val_loss: 0.0739 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 17.3 minutes 
==================================================================================================
	PARSING TIME: 3.02 minutes 
==================================================================================================
	Identification : 0.488
	P, R  : 0.424, 0.576

==================================================================================================
	XP Ends: 28/6 (19 h:57)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,163            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.083          ,50             ,13             ,62             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
31             ,136            ,True           ,True           ,35             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 163, False, 0.083, 50, 13, 62, 31, 136, True, True, 35
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (19h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 62)       467790      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1976        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 136)       1026120     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 31)        4712        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 50, 75)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 680)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 155)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 35)           15540       concatenate_37[0][0]             
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 835)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 870)          0           phraseRnn[0][0]                  
                                                                 concatenate_38[0][0]             
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 163)          141973      concatenate_39[0][0]             
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 4)            656         dense_25[0][0]                   
==================================================================================================
Total params: 1,658,767
Trainable params: 1,658,767
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 168s - loss: 0.0751 - acc: 0.9820 - val_loss: 0.0558 - val_acc: 0.9853
Epoch 2/40
 - 161s - loss: 0.0502 - acc: 0.9875 - val_loss: 0.0565 - val_acc: 0.9858
Epoch 3/40
 - 171s - loss: 0.0473 - acc: 0.9885 - val_loss: 0.0582 - val_acc: 0.9858
Epoch 4/40
 - 172s - loss: 0.0457 - acc: 0.9890 - val_loss: 0.0613 - val_acc: 0.9858
Epoch 5/40
 - 173s - loss: 0.0447 - acc: 0.9893 - val_loss: 0.0645 - val_acc: 0.9857
Epoch 00005: early stopping
	TRAINING TIME: 14.95 minutes 
==================================================================================================
	PARSING TIME: 5.58 minutes 
==================================================================================================
	Identification : 0.578
	P, R  : 0.625, 0.537

==================================================================================================
	XP Ends: 28/6 (20 h:17)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (20h:17)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 62)       448942      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       2197        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 136)       984776      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 31)        5239        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 50, 75)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 680)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 155)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 35)           15540       concatenate_40[0][0]             
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 835)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 870)          0           phraseRnn[0][0]                  
                                                                 concatenate_41[0][0]             
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 163)          141973      concatenate_42[0][0]             
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 4)            656         dense_27[0][0]                   
==================================================================================================
Total params: 1,599,323
Trainable params: 1,599,323
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0960 - acc: 0.9785 - val_loss: 0.0605 - val_acc: 0.9842
Epoch 2/40
 - 110s - loss: 0.0530 - acc: 0.9866 - val_loss: 0.0611 - val_acc: 0.9839
Epoch 3/40
 - 114s - loss: 0.0496 - acc: 0.9877 - val_loss: 0.0637 - val_acc: 0.9845
Epoch 4/40
 - 109s - loss: 0.0478 - acc: 0.9882 - val_loss: 0.0674 - val_acc: 0.9844
Epoch 5/40
 - 110s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0715 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 9.7 minutes 
==================================================================================================
	PARSING TIME: 8.55 minutes 
==================================================================================================
	Identification : 0.531
	P, R  : 0.45, 0.649

==================================================================================================
	XP Ends: 28/6 (20 h:36)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (20h:36)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 62)       855166      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1417        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 136)       1875848     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 31)        3379        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 50, 75)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 680)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 155)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 35)           15540       concatenate_43[0][0]             
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 835)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 870)          0           phraseRnn[0][0]                  
                                                                 concatenate_44[0][0]             
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 163)          141973      concatenate_45[0][0]             
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 4)            656         dense_29[0][0]                   
==================================================================================================
Total params: 2,893,979
Trainable params: 2,893,979
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 251s - loss: 0.0681 - acc: 0.9820 - val_loss: 0.0563 - val_acc: 0.9847
Epoch 2/40
 - 226s - loss: 0.0512 - acc: 0.9870 - val_loss: 0.0587 - val_acc: 0.9843
Epoch 3/40
 - 254s - loss: 0.0480 - acc: 0.9882 - val_loss: 0.0608 - val_acc: 0.9846
Epoch 4/40
 - 228s - loss: 0.0463 - acc: 0.9887 - val_loss: 0.0690 - val_acc: 0.9843
Epoch 5/40
 - 231s - loss: 0.0451 - acc: 0.9890 - val_loss: 0.0791 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 21.27 minutes 
==================================================================================================
	PARSING TIME: 3.83 minutes 
==================================================================================================
	Identification : 0.468
	P, R  : 0.417, 0.533

==================================================================================================
	XP Ends: 28/6 (21 h:2)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,70             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.066          ,50             ,30             ,29             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
49             ,121            ,False          ,True           ,473            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 70, True, 0.066, 50, 30, 29, 49, 121, False, True, 473
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (21h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 29)       218805      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 30)       4560        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 121)       912945      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 49)        7448        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 50, 59)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 484)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 196)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 473)          756327      concatenate_46[0][0]             
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 680)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 1153)         0           phraseRnn[0][0]                  
                                                                 concatenate_47[0][0]             
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 70)           80780       concatenate_48[0][0]             
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 4)            284         dense_31[0][0]                   
==================================================================================================
Total params: 1,981,149
Trainable params: 1,981,149
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 273s - loss: 4.1449 - acc: 0.7365 - val_loss: 4.0053 - val_acc: 0.7479
Epoch 2/40
 - 273s - loss: 4.0482 - acc: 0.7461 - val_loss: 4.0050 - val_acc: 0.7479
Epoch 3/40
 - 273s - loss: 4.0457 - acc: 0.7470 - val_loss: 4.0056 - val_acc: 0.7481
Epoch 4/40
 - 273s - loss: 4.0444 - acc: 0.7474 - val_loss: 4.0067 - val_acc: 0.7473
Epoch 5/40
 - 273s - loss: 4.0437 - acc: 0.7478 - val_loss: 4.0097 - val_acc: 0.7472
Epoch 00005: early stopping
	TRAINING TIME: 23.5 minutes 
==================================================================================================
	PARSING TIME: 6.28 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (21 h:32)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (21h:32)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 29)       209989      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 30)       5070        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 121)       876161      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 49)        8281        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 50, 59)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 484)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 196)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 473)          756327      concatenate_49[0][0]             
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 680)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 1153)         0           phraseRnn[0][0]                  
                                                                 concatenate_50[0][0]             
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 70)           80780       concatenate_51[0][0]             
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 4)            284         dense_33[0][0]                   
==================================================================================================
Total params: 1,936,892
Trainable params: 1,936,892
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 185s - loss: 12.0723 - acc: 0.2506 - val_loss: 12.1251 - val_acc: 0.2477
Epoch 2/40
 - 185s - loss: 12.0797 - acc: 0.2506 - val_loss: 12.1251 - val_acc: 0.2477
Epoch 3/40
 - 185s - loss: 12.0797 - acc: 0.2506 - val_loss: 12.1251 - val_acc: 0.2477
Epoch 4/40
 - 185s - loss: 12.0797 - acc: 0.2506 - val_loss: 12.1251 - val_acc: 0.2477
Epoch 5/40
 - 185s - loss: 12.0797 - acc: 0.2506 - val_loss: 12.1251 - val_acc: 0.2477
Epoch 00005: early stopping
	TRAINING TIME: 15.9 minutes 
==================================================================================================
	PARSING TIME: 17.73 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (22 h:6)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (22h:6)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 29)       399997      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 30)       3270        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 121)       1668953     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 49)        5341        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 50, 59)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 484)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 196)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 473)          756327      concatenate_52[0][0]             
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 680)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 1153)         0           phraseRnn[0][0]                  
                                                                 concatenate_53[0][0]             
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 70)           80780       concatenate_54[0][0]             
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 4)            284         dense_35[0][0]                   
==================================================================================================
Total params: 2,914,952
Trainable params: 2,914,952
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 369s - loss: 12.0841 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 2/40
 - 369s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 3/40
 - 369s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 4/40
 - 369s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 5/40
 - 369s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 00005: early stopping
	TRAINING TIME: 32.12 minutes 
==================================================================================================
	PARSING TIME: 4.15 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (22 h:42)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,76             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.121          ,50             ,7              ,146            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
14             ,114            ,True           ,False          ,398            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 76, False, 0.121, 50, 7, 146, 14, 114, True, False, 398
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (22h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 146)      1669948     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 114)       1303932     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 14)        2128        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 50, 153)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 456)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 56)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 398)          878784      concatenate_55[0][0]             
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 512)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 910)          0           phraseRnn[0][0]                  
                                                                 concatenate_56[0][0]             
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 76)           69236       concatenate_57[0][0]             
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 4)            308         dense_37[0][0]                   
==================================================================================================
Total params: 3,925,400
Trainable params: 3,925,400
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 318s - loss: 8.1510 - acc: 0.4941 - val_loss: 8.1395 - val_acc: 0.4946
Epoch 2/40
 - 318s - loss: 8.0997 - acc: 0.4974 - val_loss: 8.1253 - val_acc: 0.4959
Epoch 3/40
 - 318s - loss: 8.0877 - acc: 0.4980 - val_loss: 8.1072 - val_acc: 0.4968
Epoch 4/40
 - 318s - loss: 8.0660 - acc: 0.4994 - val_loss: 8.0963 - val_acc: 0.4977
Epoch 5/40
 - 318s - loss: 8.0618 - acc: 0.4998 - val_loss: 8.0927 - val_acc: 0.4979
Epoch 00005: early stopping
	TRAINING TIME: 27.33 minutes 
==================================================================================================
	PARSING TIME: 7.4 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 28/6 (23 h:18)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 28/6 (23h:18)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 146)      1372546     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 114)       1071714     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 14)        2366        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 50, 153)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 456)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 56)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 398)          878784      concatenate_58[0][0]             
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 512)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 910)          0           phraseRnn[0][0]                  
                                                                 concatenate_59[0][0]             
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 76)           69236       concatenate_60[0][0]             
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 4)            308         dense_39[0][0]                   
==================================================================================================
Total params: 3,396,137
Trainable params: 3,396,137
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 215s - loss: 12.0899 - acc: 0.2496 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 2/40
 - 215s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 3/40
 - 215s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 4/40
 - 215s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 5/40
 - 215s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 00005: early stopping
	TRAINING TIME: 18.48 minutes 
==================================================================================================
	PARSING TIME: 22.57 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.013

==================================================================================================
	XP Ends: 28/6 (23 h:59)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 28/6 (23h:59)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 146)      3222366     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 114)       2516094     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 14)        1526        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_61 (Concatenate)    (None, 50, 153)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 456)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 56)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 398)          878784      concatenate_61[0][0]             
__________________________________________________________________________________________________
concatenate_62 (Concatenate)    (None, 512)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_63 (Concatenate)    (None, 910)          0           phraseRnn[0][0]                  
                                                                 concatenate_62[0][0]             
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 76)           69236       concatenate_63[0][0]             
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 4)            308         dense_41[0][0]                   
==================================================================================================
Total params: 6,689,077
Trainable params: 6,689,077
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 433s - loss: 12.0891 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 2/40
 - 433s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 3/40
 - 433s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 4/40
 - 433s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 5/40
 - 433s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 37.53 minutes 
==================================================================================================
	PARSING TIME: 10.17 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.024

==================================================================================================
	XP Ends: 29/6 (0 h:47)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,162            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.054          ,50             ,12             ,54             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
24             ,61             ,False          ,True           ,28             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 162, True, 0.054, 50, 12, 54, 24, 61, False, True, 28
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (0h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 54)       407430      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1824        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 61)        460245      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        3648        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_64 (Concatenate)    (None, 50, 66)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 244)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 28)           7980        concatenate_64[0][0]             
__________________________________________________________________________________________________
concatenate_65 (Concatenate)    (None, 340)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 368)          0           phraseRnn[0][0]                  
                                                                 concatenate_65[0][0]             
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 162)          59778       concatenate_66[0][0]             
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 4)            652         dense_43[0][0]                   
==================================================================================================
Total params: 941,557
Trainable params: 941,557
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 137s - loss: 0.0645 - acc: 0.9832 - val_loss: 0.0550 - val_acc: 0.9860
Epoch 2/40
 - 137s - loss: 0.0501 - acc: 0.9876 - val_loss: 0.0547 - val_acc: 0.9861
Epoch 3/40
 - 136s - loss: 0.0471 - acc: 0.9885 - val_loss: 0.0574 - val_acc: 0.9860
Epoch 4/40
 - 136s - loss: 0.0455 - acc: 0.9890 - val_loss: 0.0638 - val_acc: 0.9857
Epoch 5/40
 - 136s - loss: 0.0444 - acc: 0.9893 - val_loss: 0.0660 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 12.1 minutes 
==================================================================================================
	PARSING TIME: 4.25 minutes 
==================================================================================================
	Identification : 0.587
	P, R  : 0.699, 0.506

==================================================================================================
	XP Ends: 29/6 (1 h:4)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (1h:4)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 54)       391014      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       2028        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 61)        441701      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        4056        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_67 (Concatenate)    (None, 50, 66)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 244)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 28)           7980        concatenate_67[0][0]             
__________________________________________________________________________________________________
concatenate_68 (Concatenate)    (None, 340)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_69 (Concatenate)    (None, 368)          0           phraseRnn[0][0]                  
                                                                 concatenate_68[0][0]             
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 162)          59778       concatenate_69[0][0]             
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 4)            652         dense_45[0][0]                   
==================================================================================================
Total params: 907,209
Trainable params: 907,209
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0728 - acc: 0.9804 - val_loss: 0.0597 - val_acc: 0.9845
Epoch 2/40
 - 93s - loss: 0.0523 - acc: 0.9868 - val_loss: 0.0607 - val_acc: 0.9846
Epoch 3/40
 - 93s - loss: 0.0487 - acc: 0.9880 - val_loss: 0.0662 - val_acc: 0.9848
Epoch 4/40
 - 93s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0711 - val_acc: 0.9845
Epoch 5/40
 - 93s - loss: 0.0460 - acc: 0.9886 - val_loss: 0.0757 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 8.25 minutes 
==================================================================================================
	PARSING TIME: 6.55 minutes 
==================================================================================================
	Identification : 0.538
	P, R  : 0.461, 0.647

==================================================================================================
	XP Ends: 29/6 (1 h:19)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (1h:19)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 54)       744822      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1308        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 61)        841373      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        2616        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_70 (Concatenate)    (None, 50, 66)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 244)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 28)           7980        concatenate_70[0][0]             
__________________________________________________________________________________________________
concatenate_71 (Concatenate)    (None, 340)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_72 (Concatenate)    (None, 368)          0           phraseRnn[0][0]                  
                                                                 concatenate_71[0][0]             
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 162)          59778       concatenate_72[0][0]             
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 4)            652         dense_47[0][0]                   
==================================================================================================
Total params: 1,658,529
Trainable params: 1,658,529
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 182s - loss: 0.0655 - acc: 0.9823 - val_loss: 0.0566 - val_acc: 0.9846
Epoch 2/40
 - 182s - loss: 0.0521 - acc: 0.9865 - val_loss: 0.0568 - val_acc: 0.9849
Epoch 3/40
 - 182s - loss: 0.0492 - acc: 0.9875 - val_loss: 0.0609 - val_acc: 0.9843
Epoch 4/40
 - 181s - loss: 0.0474 - acc: 0.9881 - val_loss: 0.0650 - val_acc: 0.9845
Epoch 5/40
 - 181s - loss: 0.0462 - acc: 0.9886 - val_loss: 0.0718 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 16.48 minutes 
==================================================================================================
	PARSING TIME: 2.92 minutes 
==================================================================================================
	Identification : 0.464
	P, R  : 0.386, 0.582

==================================================================================================
	XP Ends: 29/6 (1 h:39)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,167            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.028          ,50             ,48             ,96             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
11             ,76             ,True           ,True           ,31             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 167, True, 0.028, 50, 48, 96, 11, 76, True, True, 31
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (1h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 96)       724320      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 48)       7296        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 76)        573420      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1672        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_73 (Concatenate)    (None, 50, 144)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 380)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 31)           16368       concatenate_73[0][0]             
__________________________________________________________________________________________________
concatenate_74 (Concatenate)    (None, 435)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_75 (Concatenate)    (None, 466)          0           phraseRnn[0][0]                  
                                                                 concatenate_74[0][0]             
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 167)          77989       concatenate_75[0][0]             
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 4)            672         dense_49[0][0]                   
==================================================================================================
Total params: 1,401,737
Trainable params: 1,401,737
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 138s - loss: 0.0643 - acc: 0.9831 - val_loss: 0.0544 - val_acc: 0.9860
Epoch 2/40
 - 137s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0559 - val_acc: 0.9860
Epoch 3/40
 - 138s - loss: 0.0466 - acc: 0.9888 - val_loss: 0.0584 - val_acc: 0.9858
Epoch 4/40
 - 138s - loss: 0.0453 - acc: 0.9892 - val_loss: 0.0602 - val_acc: 0.9859
Epoch 5/40
 - 138s - loss: 0.0444 - acc: 0.9894 - val_loss: 0.0646 - val_acc: 0.9857
Epoch 00005: early stopping
	TRAINING TIME: 12.25 minutes 
==================================================================================================
	PARSING TIME: 4.23 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.755, 0.479

==================================================================================================
	XP Ends: 29/6 (1 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (1h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 96)       695136      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 48)       8112        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 76)        550316      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1859        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_76 (Concatenate)    (None, 50, 144)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 380)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 31)           16368       concatenate_76[0][0]             
__________________________________________________________________________________________________
concatenate_77 (Concatenate)    (None, 435)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_78 (Concatenate)    (None, 466)          0           phraseRnn[0][0]                  
                                                                 concatenate_77[0][0]             
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 167)          77989       concatenate_78[0][0]             
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 4)            672         dense_51[0][0]                   
==================================================================================================
Total params: 1,350,452
Trainable params: 1,350,452
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0725 - acc: 0.9802 - val_loss: 0.0588 - val_acc: 0.9845
Epoch 2/40
 - 94s - loss: 0.0520 - acc: 0.9870 - val_loss: 0.0583 - val_acc: 0.9849
Epoch 3/40
 - 94s - loss: 0.0484 - acc: 0.9881 - val_loss: 0.0616 - val_acc: 0.9849
Epoch 4/40
 - 94s - loss: 0.0470 - acc: 0.9886 - val_loss: 0.0648 - val_acc: 0.9848
Epoch 5/40
 - 94s - loss: 0.0460 - acc: 0.9888 - val_loss: 0.0758 - val_acc: 0.9829
Epoch 00005: early stopping
	TRAINING TIME: 8.32 minutes 
==================================================================================================
	PARSING TIME: 6.9 minutes 
==================================================================================================
	Identification : 0.364
	P, R  : 0.252, 0.656

==================================================================================================
	XP Ends: 29/6 (2 h:11)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (2h:11)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 96)       1324128     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 48)       5232        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 76)        1048268     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1199        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_79 (Concatenate)    (None, 50, 144)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 380)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 31)           16368       concatenate_79[0][0]             
__________________________________________________________________________________________________
concatenate_80 (Concatenate)    (None, 435)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_81 (Concatenate)    (None, 466)          0           phraseRnn[0][0]                  
                                                                 concatenate_80[0][0]             
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 167)          77989       concatenate_81[0][0]             
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 4)            672         dense_53[0][0]                   
==================================================================================================
Total params: 2,473,856
Trainable params: 2,473,856
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 185s - loss: 0.0653 - acc: 0.9823 - val_loss: 0.0566 - val_acc: 0.9849
Epoch 2/40
 - 185s - loss: 0.0514 - acc: 0.9869 - val_loss: 0.0578 - val_acc: 0.9846
Epoch 3/40
 - 185s - loss: 0.0485 - acc: 0.9879 - val_loss: 0.0607 - val_acc: 0.9843
Epoch 4/40
 - 185s - loss: 0.0467 - acc: 0.9885 - val_loss: 0.0651 - val_acc: 0.9843
Epoch 5/40
 - 185s - loss: 0.0456 - acc: 0.9889 - val_loss: 0.0701 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 16.87 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0.489
	P, R  : 0.479, 0.5

==================================================================================================
	XP Ends: 29/6 (2 h:31)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,77             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.011          ,50             ,5              ,36             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
20             ,32             ,False          ,False          ,51             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 77, True, 0.011, 50, 5, 36, 20, 32, False, False, 51
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (2h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 36)       271620      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 32)        241440      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 20)        3040        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_82 (Concatenate)    (None, 50, 41)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 96)           0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 60)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 51)           14229       concatenate_82[0][0]             
__________________________________________________________________________________________________
concatenate_83 (Concatenate)    (None, 156)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_84 (Concatenate)    (None, 207)          0           phraseRnn[0][0]                  
                                                                 concatenate_83[0][0]             
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 77)           16016       concatenate_84[0][0]             
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 4)            312         dense_55[0][0]                   
==================================================================================================
Total params: 547,417
Trainable params: 547,417
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 137s - loss: 0.0786 - acc: 0.9794 - val_loss: 0.0652 - val_acc: 0.9830
Epoch 2/40
 - 137s - loss: 0.0588 - acc: 0.9850 - val_loss: 0.0630 - val_acc: 0.9846
Epoch 3/40
 - 136s - loss: 0.0541 - acc: 0.9864 - val_loss: 0.0636 - val_acc: 0.9844
Epoch 4/40
 - 137s - loss: 0.0515 - acc: 0.9873 - val_loss: 0.0642 - val_acc: 0.9845
Epoch 5/40
 - 137s - loss: 0.0498 - acc: 0.9877 - val_loss: 0.0665 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 12.13 minutes 
==================================================================================================
	PARSING TIME: 4.18 minutes 
==================================================================================================
	Identification : 0.592
	P, R  : 0.784, 0.476

==================================================================================================
	XP Ends: 29/6 (2 h:48)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (2h:48)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 36)       260676      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 32)        231712      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 20)        3380        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 50, 41)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 96)           0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 60)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 51)           14229       concatenate_85[0][0]             
__________________________________________________________________________________________________
concatenate_86 (Concatenate)    (None, 156)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_87 (Concatenate)    (None, 207)          0           phraseRnn[0][0]                  
                                                                 concatenate_86[0][0]             
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 77)           16016       concatenate_87[0][0]             
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 4)            312         dense_57[0][0]                   
==================================================================================================
Total params: 527,170
Trainable params: 527,170
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0899 - acc: 0.9759 - val_loss: 0.0712 - val_acc: 0.9815
Epoch 2/40
 - 93s - loss: 0.0640 - acc: 0.9833 - val_loss: 0.0686 - val_acc: 0.9823
Epoch 3/40
 - 92s - loss: 0.0589 - acc: 0.9847 - val_loss: 0.0685 - val_acc: 0.9829
Epoch 4/40
 - 91s - loss: 0.0561 - acc: 0.9854 - val_loss: 0.0702 - val_acc: 0.9824
Epoch 5/40
 - 91s - loss: 0.0542 - acc: 0.9860 - val_loss: 0.0716 - val_acc: 0.9827
Epoch 00005: early stopping
	TRAINING TIME: 8.12 minutes 
==================================================================================================
	PARSING TIME: 6.65 minutes 
==================================================================================================
	Identification : 0.403
	P, R  : 0.297, 0.627

==================================================================================================
	XP Ends: 29/6 (3 h:3)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (3h:3)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 36)       496548      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 32)        441376      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 20)        2180        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_88 (Concatenate)    (None, 50, 41)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 96)           0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 60)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 51)           14229       concatenate_88[0][0]             
__________________________________________________________________________________________________
concatenate_89 (Concatenate)    (None, 156)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_90 (Concatenate)    (None, 207)          0           phraseRnn[0][0]                  
                                                                 concatenate_89[0][0]             
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 77)           16016       concatenate_90[0][0]             
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 4)            312         dense_59[0][0]                   
==================================================================================================
Total params: 971,206
Trainable params: 971,206
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 181s - loss: 0.0785 - acc: 0.9790 - val_loss: 0.0643 - val_acc: 0.9824
Epoch 2/40
 - 181s - loss: 0.0591 - acc: 0.9842 - val_loss: 0.0636 - val_acc: 0.9827
Epoch 3/40
 - 180s - loss: 0.0553 - acc: 0.9855 - val_loss: 0.0650 - val_acc: 0.9833
Epoch 4/40
 - 181s - loss: 0.0533 - acc: 0.9862 - val_loss: 0.0672 - val_acc: 0.9831
Epoch 5/40
 - 180s - loss: 0.0518 - acc: 0.9866 - val_loss: 0.0703 - val_acc: 0.9830
Epoch 00005: early stopping
	TRAINING TIME: 16.4 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0.459
	P, R  : 0.407, 0.527

==================================================================================================
	XP Ends: 29/6 (3 h:23)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,147            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.011          ,50             ,5              ,105            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
41             ,25             ,False          ,True           ,115            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 147, False, 0.011, 50, 5, 105, 41, 25, False, True, 115
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (3h:23)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 105)      792225      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 25)        188625      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 41)        6232        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_91 (Concatenate)    (None, 50, 110)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 100)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 164)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 115)          103960      concatenate_91[0][0]             
__________________________________________________________________________________________________
concatenate_92 (Concatenate)    (None, 264)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_93 (Concatenate)    (None, 379)          0           phraseRnn[0][0]                  
                                                                 concatenate_92[0][0]             
__________________________________________________________________________________________________
dense_61 (Dense)                (None, 147)          55860       concatenate_93[0][0]             
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 4)            592         dense_61[0][0]                   
==================================================================================================
Total params: 1,148,254
Trainable params: 1,148,254
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 167s - loss: 0.0749 - acc: 0.9804 - val_loss: 0.0624 - val_acc: 0.9837
Epoch 2/40
 - 167s - loss: 0.0562 - acc: 0.9857 - val_loss: 0.0601 - val_acc: 0.9850
Epoch 3/40
 - 166s - loss: 0.0517 - acc: 0.9872 - val_loss: 0.0607 - val_acc: 0.9851
Epoch 4/40
 - 166s - loss: 0.0492 - acc: 0.9879 - val_loss: 0.0625 - val_acc: 0.9851
Epoch 5/40
 - 166s - loss: 0.0477 - acc: 0.9885 - val_loss: 0.0637 - val_acc: 0.9852
Epoch 00005: early stopping
	TRAINING TIME: 14.73 minutes 
==================================================================================================
	PARSING TIME: 5.27 minutes 
==================================================================================================
	Identification : 0.535
	P, R  : 0.538, 0.533

==================================================================================================
	XP Ends: 29/6 (3 h:43)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (3h:43)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 105)      760305      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 25)        181025      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 41)        6929        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_94 (Concatenate)    (None, 50, 110)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 100)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 164)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 115)          103960      concatenate_94[0][0]             
__________________________________________________________________________________________________
concatenate_95 (Concatenate)    (None, 264)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_96 (Concatenate)    (None, 379)          0           phraseRnn[0][0]                  
                                                                 concatenate_95[0][0]             
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 147)          55860       concatenate_96[0][0]             
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 4)            592         dense_63[0][0]                   
==================================================================================================
Total params: 1,109,516
Trainable params: 1,109,516
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0828 - acc: 0.9775 - val_loss: 0.0677 - val_acc: 0.9819
Epoch 2/40
 - 110s - loss: 0.0602 - acc: 0.9845 - val_loss: 0.0751 - val_acc: 0.9823
Epoch 3/40
 - 110s - loss: 0.0553 - acc: 0.9859 - val_loss: 0.0664 - val_acc: 0.9834
Epoch 4/40
 - 110s - loss: 0.0523 - acc: 0.9870 - val_loss: 0.0682 - val_acc: 0.9832
Epoch 5/40
 - 109s - loss: 0.0506 - acc: 0.9874 - val_loss: 0.0703 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 9.67 minutes 
==================================================================================================
	PARSING TIME: 8.13 minutes 
==================================================================================================
	Identification : 0.463
	P, R  : 0.365, 0.633

==================================================================================================
	XP Ends: 29/6 (4 h:1)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (4h:1)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 105)      1448265     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 25)        344825      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 41)        4469        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_97 (Concatenate)    (None, 50, 110)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 100)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 164)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 115)          103960      concatenate_97[0][0]             
__________________________________________________________________________________________________
concatenate_98 (Concatenate)    (None, 264)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_99 (Concatenate)    (None, 379)          0           phraseRnn[0][0]                  
                                                                 concatenate_98[0][0]             
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 147)          55860       concatenate_99[0][0]             
__________________________________________________________________________________________________
dense_66 (Dense)                (None, 4)            592         dense_65[0][0]                   
==================================================================================================
Total params: 1,958,516
Trainable params: 1,958,516
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 219s - loss: 0.0748 - acc: 0.9798 - val_loss: 0.0626 - val_acc: 0.9830
Epoch 2/40
 - 218s - loss: 0.0567 - acc: 0.9851 - val_loss: 0.0607 - val_acc: 0.9838
Epoch 3/40
 - 218s - loss: 0.0529 - acc: 0.9865 - val_loss: 0.0626 - val_acc: 0.9836
Epoch 4/40
 - 218s - loss: 0.0508 - acc: 0.9871 - val_loss: 0.0661 - val_acc: 0.9833
Epoch 5/40
 - 218s - loss: 0.0495 - acc: 0.9875 - val_loss: 0.0674 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 19.62 minutes 
==================================================================================================
	PARSING TIME: 3.62 minutes 
==================================================================================================
	Identification : 0.485
	P, R  : 0.406, 0.602

==================================================================================================
	XP Ends: 29/6 (4 h:25)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,103            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.012          ,50             ,14             ,58             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
6              ,34             ,True           ,False          ,124            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 103, True, 0.012, 50, 14, 58, 6, 34, True, False, 124
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (4h:25)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 58)       437610      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2128        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 34)        256530      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 6)         912         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_100 (Concatenate)   (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 136)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 24)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 124)          73284       concatenate_100[0][0]            
__________________________________________________________________________________________________
concatenate_101 (Concatenate)   (None, 160)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_102 (Concatenate)   (None, 284)          0           phraseRnn[0][0]                  
                                                                 concatenate_101[0][0]            
__________________________________________________________________________________________________
dense_67 (Dense)                (None, 103)          29355       concatenate_102[0][0]            
__________________________________________________________________________________________________
dense_68 (Dense)                (None, 4)            416         dense_67[0][0]                   
==================================================================================================
Total params: 800,235
Trainable params: 800,235
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 139s - loss: 0.0783 - acc: 0.9797 - val_loss: 0.0641 - val_acc: 0.9837
Epoch 2/40
 - 139s - loss: 0.0561 - acc: 0.9859 - val_loss: 0.0621 - val_acc: 0.9850
Epoch 3/40
 - 139s - loss: 0.0516 - acc: 0.9872 - val_loss: 0.0623 - val_acc: 0.9850
Epoch 4/40
 - 139s - loss: 0.0494 - acc: 0.9879 - val_loss: 0.0668 - val_acc: 0.9849
Epoch 5/40
 - 139s - loss: 0.0481 - acc: 0.9883 - val_loss: 0.0654 - val_acc: 0.9849
Epoch 00005: early stopping
	TRAINING TIME: 12.35 minutes 
==================================================================================================
	PARSING TIME: 4.25 minutes 
==================================================================================================
	Identification : 0.583
	P, R  : 0.777, 0.467

==================================================================================================
	XP Ends: 29/6 (4 h:42)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (4h:42)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 58)       419978      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2366        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 34)        246194      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 6)         1014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_103 (Concatenate)   (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 136)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 24)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 124)          73284       concatenate_103[0][0]            
__________________________________________________________________________________________________
concatenate_104 (Concatenate)   (None, 160)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_105 (Concatenate)   (None, 284)          0           phraseRnn[0][0]                  
                                                                 concatenate_104[0][0]            
__________________________________________________________________________________________________
dense_69 (Dense)                (None, 103)          29355       concatenate_105[0][0]            
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 4)            416         dense_69[0][0]                   
==================================================================================================
Total params: 772,607
Trainable params: 772,607
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0925 - acc: 0.9752 - val_loss: 0.0815 - val_acc: 0.9782
Epoch 2/40
 - 95s - loss: 0.0621 - acc: 0.9838 - val_loss: 0.0694 - val_acc: 0.9824
Epoch 3/40
 - 94s - loss: 0.0567 - acc: 0.9854 - val_loss: 0.0694 - val_acc: 0.9829
Epoch 4/40
 - 94s - loss: 0.0539 - acc: 0.9863 - val_loss: 0.0711 - val_acc: 0.9827
Epoch 5/40
 - 94s - loss: 0.0520 - acc: 0.9869 - val_loss: 0.0795 - val_acc: 0.9801
Epoch 00005: early stopping
	TRAINING TIME: 8.33 minutes 
==================================================================================================
	PARSING TIME: 6.98 minutes 
==================================================================================================
	Identification : 0.367
	P, R  : 0.255, 0.653

==================================================================================================
	XP Ends: 29/6 (4 h:58)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (4h:58)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 58)       799994      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       1526        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 34)        468962      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 6)         654         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_106 (Concatenate)   (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 136)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 24)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 124)          73284       concatenate_106[0][0]            
__________________________________________________________________________________________________
concatenate_107 (Concatenate)   (None, 160)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_108 (Concatenate)   (None, 284)          0           phraseRnn[0][0]                  
                                                                 concatenate_107[0][0]            
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 103)          29355       concatenate_108[0][0]            
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 4)            416         dense_71[0][0]                   
==================================================================================================
Total params: 1,374,191
Trainable params: 1,374,191
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 185s - loss: 0.0781 - acc: 0.9791 - val_loss: 0.0693 - val_acc: 0.9809
Epoch 2/40
 - 185s - loss: 0.0571 - acc: 0.9852 - val_loss: 0.0626 - val_acc: 0.9834
Epoch 3/40
 - 185s - loss: 0.0531 - acc: 0.9864 - val_loss: 0.0650 - val_acc: 0.9830
Epoch 4/40
 - 185s - loss: 0.0510 - acc: 0.9871 - val_loss: 0.0670 - val_acc: 0.9832
Epoch 5/40
 - 185s - loss: 0.0494 - acc: 0.9876 - val_loss: 0.0696 - val_acc: 0.9830
Epoch 00005: early stopping
	TRAINING TIME: 16.83 minutes 
==================================================================================================
	PARSING TIME: 2.85 minutes 
==================================================================================================
	Identification : 0.489
	P, R  : 0.465, 0.516

==================================================================================================
	XP Ends: 29/6 (5 h:18)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,156            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.011          ,50             ,47             ,42             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,26             ,True           ,False          ,181            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 156, False, 0.011, 50, 47, 42, 8, 26, True, False, 181
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (5h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 42)       480396      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 47)       7144        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 26)        297388      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_109 (Concatenate)   (None, 50, 89)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 104)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 181)          196204      concatenate_109[0][0]            
__________________________________________________________________________________________________
concatenate_110 (Concatenate)   (None, 136)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_111 (Concatenate)   (None, 317)          0           phraseRnn[0][0]                  
                                                                 concatenate_110[0][0]            
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 156)          49608       concatenate_111[0][0]            
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 4)            628         dense_73[0][0]                   
==================================================================================================
Total params: 1,032,584
Trainable params: 1,032,584
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 170s - loss: 0.0824 - acc: 0.9785 - val_loss: 0.0640 - val_acc: 0.9835
Epoch 2/40
 - 169s - loss: 0.0578 - acc: 0.9855 - val_loss: 0.0621 - val_acc: 0.9846
Epoch 3/40
 - 167s - loss: 0.0523 - acc: 0.9870 - val_loss: 0.0782 - val_acc: 0.9846
Epoch 4/40
 - 168s - loss: 0.0495 - acc: 0.9879 - val_loss: 0.0666 - val_acc: 0.9842
Epoch 5/40
 - 168s - loss: 0.0478 - acc: 0.9884 - val_loss: 0.0675 - val_acc: 0.9844
Epoch 00005: early stopping
	TRAINING TIME: 14.92 minutes 
==================================================================================================
	PARSING TIME: 5.4 minutes 
==================================================================================================
	Identification : 0.509
	P, R  : 0.451, 0.585

==================================================================================================
	XP Ends: 29/6 (5 h:38)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (5h:38)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 42)       394842      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 47)       7943        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 26)        244426      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_112 (Concatenate)   (None, 50, 89)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 104)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 181)          196204      concatenate_112[0][0]            
__________________________________________________________________________________________________
concatenate_113 (Concatenate)   (None, 136)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_114 (Concatenate)   (None, 317)          0           phraseRnn[0][0]                  
                                                                 concatenate_113[0][0]            
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 156)          49608       concatenate_114[0][0]            
__________________________________________________________________________________________________
dense_76 (Dense)                (None, 4)            628         dense_75[0][0]                   
==================================================================================================
Total params: 895,003
Trainable params: 895,003
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 111s - loss: 0.0960 - acc: 0.9737 - val_loss: 0.0705 - val_acc: 0.9804
Epoch 2/40
 - 111s - loss: 0.0623 - acc: 0.9840 - val_loss: 0.0678 - val_acc: 0.9826
Epoch 3/40
 - 111s - loss: 0.0563 - acc: 0.9857 - val_loss: 0.0691 - val_acc: 0.9823
Epoch 4/40
 - 111s - loss: 0.0533 - acc: 0.9866 - val_loss: 0.0721 - val_acc: 0.9820
Epoch 5/40
 - 111s - loss: 0.0513 - acc: 0.9872 - val_loss: 0.0743 - val_acc: 0.9821
Epoch 00005: early stopping
	TRAINING TIME: 9.8 minutes 
==================================================================================================
	PARSING TIME: 8.33 minutes 
==================================================================================================
	Identification : 0.401
	P, R  : 0.304, 0.588

==================================================================================================
	XP Ends: 29/6 (5 h:57)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (5h:57)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 42)       926982      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 47)       5123        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 26)        573846      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_115 (Concatenate)   (None, 50, 89)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 104)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 181)          196204      concatenate_115[0][0]            
__________________________________________________________________________________________________
concatenate_116 (Concatenate)   (None, 136)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_117 (Concatenate)   (None, 317)          0           phraseRnn[0][0]                  
                                                                 concatenate_116[0][0]            
__________________________________________________________________________________________________
dense_77 (Dense)                (None, 156)          49608       concatenate_117[0][0]            
__________________________________________________________________________________________________
dense_78 (Dense)                (None, 4)            628         dense_77[0][0]                   
==================================================================================================
Total params: 1,753,263
Trainable params: 1,753,263
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 262s - loss: 0.0767 - acc: 0.9792 - val_loss: 0.0661 - val_acc: 0.9817
Epoch 2/40
 - 220s - loss: 0.0545 - acc: 0.9859 - val_loss: 0.0645 - val_acc: 0.9828
Epoch 3/40
 - 220s - loss: 0.0499 - acc: 0.9876 - val_loss: 0.0674 - val_acc: 0.9828
Epoch 4/40
 - 220s - loss: 0.0476 - acc: 0.9883 - val_loss: 0.0714 - val_acc: 0.9826
Epoch 5/40
 - 220s - loss: 0.0461 - acc: 0.9887 - val_loss: 0.0758 - val_acc: 0.9823
Epoch 00005: early stopping
	TRAINING TIME: 20.55 minutes 
==================================================================================================
	PARSING TIME: 3.57 minutes 
==================================================================================================
	Identification : 0.498
	P, R  : 0.435, 0.582

==================================================================================================
	XP Ends: 29/6 (6 h:21)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,100            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.039          ,50             ,8              ,107            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
34             ,96             ,True           ,True           ,283            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 100, False, 0.039, 50, 8, 107, 34, 96, True, True, 283
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (6h:21)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 107)      807315      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 96)        724320      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 34)        5168        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_118 (Concatenate)   (None, 50, 115)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 480)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 170)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 283)          451668      concatenate_118[0][0]            
__________________________________________________________________________________________________
concatenate_119 (Concatenate)   (None, 650)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_120 (Concatenate)   (None, 933)          0           phraseRnn[0][0]                  
                                                                 concatenate_119[0][0]            
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 100)          93400       concatenate_120[0][0]            
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 4)            404         dense_79[0][0]                   
==================================================================================================
Total params: 2,083,491
Trainable params: 2,083,491
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 222s - loss: 12.0731 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 2/40
 - 222s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 3/40
 - 222s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 4/40
 - 222s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 5/40
 - 222s - loss: 12.0792 - acc: 0.2506 - val_loss: 12.1262 - val_acc: 0.2477
Epoch 00005: early stopping
	TRAINING TIME: 19.37 minutes 
==================================================================================================
	PARSING TIME: 10.2 minutes 
==================================================================================================
	Identification : 0.0
	P, R  : 0.0, 0.001

==================================================================================================
	XP Ends: 29/6 (6 h:51)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (6h:51)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 107)      774787      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 96)        695136      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 34)        5746        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_121 (Concatenate)   (None, 50, 115)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 480)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 170)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 283)          451668      concatenate_121[0][0]            
__________________________________________________________________________________________________
concatenate_122 (Concatenate)   (None, 650)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_123 (Concatenate)   (None, 933)          0           phraseRnn[0][0]                  
                                                                 concatenate_122[0][0]            
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 100)          93400       concatenate_123[0][0]            
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 4)            404         dense_81[0][0]                   
==================================================================================================
Total params: 2,022,493
Trainable params: 2,022,493
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 150s - loss: 12.0823 - acc: 0.2497 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 2/40
 - 150s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 3/40
 - 150s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 4/40
 - 150s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 5/40
 - 150s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 00005: early stopping
	TRAINING TIME: 13.1 minutes 
==================================================================================================
	PARSING TIME: 15.58 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (7 h:20)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (7h:20)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 107)      1475851     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 96)        1324128     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 34)        3706        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_124 (Concatenate)   (None, 50, 115)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 480)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 170)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 283)          451668      concatenate_124[0][0]            
__________________________________________________________________________________________________
concatenate_125 (Concatenate)   (None, 650)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_126 (Concatenate)   (None, 933)          0           phraseRnn[0][0]                  
                                                                 concatenate_125[0][0]            
__________________________________________________________________________________________________
dense_83 (Dense)                (None, 100)          93400       concatenate_126[0][0]            
__________________________________________________________________________________________________
dense_84 (Dense)                (None, 4)            404         dense_83[0][0]                   
==================================================================================================
Total params: 3,350,029
Trainable params: 3,350,029
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 301s - loss: 0.0733 - acc: 0.9806 - val_loss: 0.0579 - val_acc: 0.9843
Epoch 2/40
 - 301s - loss: 0.0537 - acc: 0.9860 - val_loss: 0.0585 - val_acc: 0.9842
Epoch 3/40
 - 301s - loss: 0.0506 - acc: 0.9872 - val_loss: 0.0597 - val_acc: 0.9843
Epoch 4/40
 - 301s - loss: 0.0488 - acc: 0.9878 - val_loss: 0.0641 - val_acc: 0.9843
Epoch 5/40
 - 301s - loss: 0.0476 - acc: 0.9882 - val_loss: 0.0671 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 26.57 minutes 
==================================================================================================
	PARSING TIME: 3.62 minutes 
==================================================================================================
	Identification : 0.49
	P, R  : 0.505, 0.476

==================================================================================================
	XP Ends: 29/6 (7 h:51)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,222            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.096          ,50             ,7              ,26             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
24             ,49             ,False          ,True           ,307            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 222, True, 0.096, 50, 7, 26, 24, 49, False, True, 307
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (7h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 26)       297388      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 49)        560462      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        3648        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_127 (Concatenate)   (None, 50, 33)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 196)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 307)          314061      concatenate_127[0][0]            
__________________________________________________________________________________________________
concatenate_128 (Concatenate)   (None, 292)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_129 (Concatenate)   (None, 599)          0           phraseRnn[0][0]                  
                                                                 concatenate_128[0][0]            
__________________________________________________________________________________________________
dense_85 (Dense)                (None, 222)          133200      concatenate_129[0][0]            
__________________________________________________________________________________________________
dense_86 (Dense)                (None, 4)            892         dense_85[0][0]                   
==================================================================================================
Total params: 1,310,715
Trainable params: 1,310,715
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 170s - loss: 12.0810 - acc: 0.2502 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 2/40
 - 170s - loss: 12.0844 - acc: 0.2503 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 3/40
 - 170s - loss: 12.0844 - acc: 0.2503 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 4/40
 - 170s - loss: 12.0844 - acc: 0.2503 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 5/40
 - 170s - loss: 12.0844 - acc: 0.2503 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 00005: early stopping
	TRAINING TIME: 14.95 minutes 
==================================================================================================
	PARSING TIME: 7.68 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (8 h:14)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (8h:14)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 26)       244426      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 49)        460649      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        4056        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_130 (Concatenate)   (None, 50, 33)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 196)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 307)          314061      concatenate_130[0][0]            
__________________________________________________________________________________________________
concatenate_131 (Concatenate)   (None, 292)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_132 (Concatenate)   (None, 599)          0           phraseRnn[0][0]                  
                                                                 concatenate_131[0][0]            
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 222)          133200      concatenate_132[0][0]            
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 4)            892         dense_87[0][0]                   
==================================================================================================
Total params: 1,158,467
Trainable params: 1,158,467
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 116s - loss: 12.0945 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 2/40
 - 116s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 3/40
 - 116s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 4/40
 - 116s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 5/40
 - 116s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 00005: early stopping
	TRAINING TIME: 10.17 minutes 
==================================================================================================
	PARSING TIME: 11.98 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (8 h:37)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (8h:37)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 26)       573846      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 49)        1081479     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        2616        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_133 (Concatenate)   (None, 50, 33)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 196)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 307)          314061      concatenate_133[0][0]            
__________________________________________________________________________________________________
concatenate_134 (Concatenate)   (None, 292)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_135 (Concatenate)   (None, 599)          0           phraseRnn[0][0]                  
                                                                 concatenate_134[0][0]            
__________________________________________________________________________________________________
dense_89 (Dense)                (None, 222)          133200      concatenate_135[0][0]            
__________________________________________________________________________________________________
dense_90 (Dense)                (None, 4)            892         dense_89[0][0]                   
==================================================================================================
Total params: 2,106,857
Trainable params: 2,106,857
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 231s - loss: 12.0883 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 2/40
 - 232s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 3/40
 - 232s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 4/40
 - 231s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 5/40
 - 231s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 20.77 minutes 
==================================================================================================
	PARSING TIME: 6.88 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.045

==================================================================================================
	XP Ends: 29/6 (9 h:5)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,165            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.115          ,50             ,15             ,176            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,109            ,True           ,True           ,45             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 165, True, 0.115, 50, 15, 176, 10, 109, True, True, 45
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (9h:5)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 176)      1327920     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       2280        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 109)       822405      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_136 (Concatenate)   (None, 50, 191)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 545)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           31995       concatenate_136[0][0]            
__________________________________________________________________________________________________
concatenate_137 (Concatenate)   (None, 595)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_138 (Concatenate)   (None, 640)          0           phraseRnn[0][0]                  
                                                                 concatenate_137[0][0]            
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 165)          105765      concatenate_138[0][0]            
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 4)            664         dense_91[0][0]                   
==================================================================================================
Total params: 2,292,549
Trainable params: 2,292,549
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 139s - loss: 0.0859 - acc: 0.9809 - val_loss: 0.0577 - val_acc: 0.9855
Epoch 2/40
 - 140s - loss: 0.0503 - acc: 0.9875 - val_loss: 0.0568 - val_acc: 0.9858
Epoch 3/40
 - 139s - loss: 0.0469 - acc: 0.9887 - val_loss: 0.0588 - val_acc: 0.9859
Epoch 4/40
 - 140s - loss: 0.0454 - acc: 0.9891 - val_loss: 0.0636 - val_acc: 0.9858
Epoch 5/40
 - 139s - loss: 0.0445 - acc: 0.9893 - val_loss: 0.0664 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 12.43 minutes 
==================================================================================================
	PARSING TIME: 4.33 minutes 
==================================================================================================
	Identification : 0.596
	P, R  : 0.73, 0.504

==================================================================================================
	XP Ends: 29/6 (9 h:22)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (9h:22)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 176)      1274416     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       2535        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 109)       789269      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_139 (Concatenate)   (None, 50, 191)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 545)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           31995       concatenate_139[0][0]            
__________________________________________________________________________________________________
concatenate_140 (Concatenate)   (None, 595)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_141 (Concatenate)   (None, 640)          0           phraseRnn[0][0]                  
                                                                 concatenate_140[0][0]            
__________________________________________________________________________________________________
dense_93 (Dense)                (None, 165)          105765      concatenate_141[0][0]            
__________________________________________________________________________________________________
dense_94 (Dense)                (None, 4)            664         dense_93[0][0]                   
==================================================================================================
Total params: 2,206,334
Trainable params: 2,206,334
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 95s - loss: 0.1217 - acc: 0.9763 - val_loss: 0.0624 - val_acc: 0.9837
Epoch 2/40
 - 95s - loss: 0.0531 - acc: 0.9866 - val_loss: 0.0616 - val_acc: 0.9843
Epoch 3/40
 - 94s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0641 - val_acc: 0.9841
Epoch 4/40
 - 94s - loss: 0.0476 - acc: 0.9884 - val_loss: 0.0689 - val_acc: 0.9843
Epoch 5/40
 - 94s - loss: 0.0466 - acc: 0.9886 - val_loss: 0.0727 - val_acc: 0.9844
Epoch 00005: early stopping
	TRAINING TIME: 8.37 minutes 
==================================================================================================
	PARSING TIME: 6.58 minutes 
==================================================================================================
	Identification : 0.521
	P, R  : 0.436, 0.646

==================================================================================================
	XP Ends: 29/6 (9 h:37)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (9h:37)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 176)      2427568     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       1635        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 109)       1503437     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_142 (Concatenate)   (None, 50, 191)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 545)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 50)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           31995       concatenate_142[0][0]            
__________________________________________________________________________________________________
concatenate_143 (Concatenate)   (None, 595)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_144 (Concatenate)   (None, 640)          0           phraseRnn[0][0]                  
                                                                 concatenate_143[0][0]            
__________________________________________________________________________________________________
dense_95 (Dense)                (None, 165)          105765      concatenate_144[0][0]            
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 4)            664         dense_95[0][0]                   
==================================================================================================
Total params: 4,072,154
Trainable params: 4,072,154
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 187s - loss: 0.0935 - acc: 0.9796 - val_loss: 0.0585 - val_acc: 0.9842
Epoch 2/40
 - 187s - loss: 0.0519 - acc: 0.9867 - val_loss: 0.0598 - val_acc: 0.9844
Epoch 3/40
 - 186s - loss: 0.0487 - acc: 0.9878 - val_loss: 0.0618 - val_acc: 0.9842
Epoch 4/40
 - 185s - loss: 0.0469 - acc: 0.9884 - val_loss: 0.0681 - val_acc: 0.9840
Epoch 5/40
 - 186s - loss: 0.0455 - acc: 0.9889 - val_loss: 0.0759 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 16.95 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0.484
	P, R  : 0.443, 0.533

==================================================================================================
	XP Ends: 29/6 (9 h:57)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,368            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.023          ,50             ,25             ,37             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
48             ,86             ,True           ,False          ,129            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 368, False, 0.023, 50, 25, 37, 48, 86, True, False, 129
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (9h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 37)       279165      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       3800        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 86)        648870      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 48)        7296        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_145 (Concatenate)   (None, 50, 62)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 344)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 192)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 129)          99072       concatenate_145[0][0]            
__________________________________________________________________________________________________
concatenate_146 (Concatenate)   (None, 536)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_147 (Concatenate)   (None, 665)          0           phraseRnn[0][0]                  
                                                                 concatenate_146[0][0]            
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 368)          245088      concatenate_147[0][0]            
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 4)            1476        dense_97[0][0]                   
==================================================================================================
Total params: 1,284,767
Trainable params: 1,284,767
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 164s - loss: 0.0660 - acc: 0.9827 - val_loss: 0.0565 - val_acc: 0.9852
Epoch 2/40
 - 164s - loss: 0.0513 - acc: 0.9871 - val_loss: 0.0565 - val_acc: 0.9857
Epoch 3/40
 - 164s - loss: 0.0483 - acc: 0.9881 - val_loss: 0.0585 - val_acc: 0.9852
Epoch 4/40
 - 164s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0626 - val_acc: 0.9856
Epoch 5/40
 - 164s - loss: 0.0455 - acc: 0.9890 - val_loss: 0.0673 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 14.48 minutes 
==================================================================================================
	PARSING TIME: 5.37 minutes 
==================================================================================================
	Identification : 0.569
	P, R  : 0.613, 0.531

==================================================================================================
	XP Ends: 29/6 (10 h:18)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (10h:18)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 37)       267917      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       4225        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 86)        622726      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 48)        8112        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_148 (Concatenate)   (None, 50, 62)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 344)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 192)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 129)          99072       concatenate_148[0][0]            
__________________________________________________________________________________________________
concatenate_149 (Concatenate)   (None, 536)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_150 (Concatenate)   (None, 665)          0           phraseRnn[0][0]                  
                                                                 concatenate_149[0][0]            
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 368)          245088      concatenate_150[0][0]            
__________________________________________________________________________________________________
dense_100 (Dense)               (None, 4)            1476        dense_99[0][0]                   
==================================================================================================
Total params: 1,248,616
Trainable params: 1,248,616
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 113s - loss: 0.0738 - acc: 0.9799 - val_loss: 0.0637 - val_acc: 0.9833
Epoch 2/40
 - 112s - loss: 0.0548 - acc: 0.9859 - val_loss: 0.0620 - val_acc: 0.9839
Epoch 3/40
 - 112s - loss: 0.0507 - acc: 0.9872 - val_loss: 0.0658 - val_acc: 0.9835
Epoch 4/40
 - 112s - loss: 0.0484 - acc: 0.9880 - val_loss: 0.0702 - val_acc: 0.9834
Epoch 5/40
 - 112s - loss: 0.0471 - acc: 0.9883 - val_loss: 0.0782 - val_acc: 0.9831
Epoch 00005: early stopping
	TRAINING TIME: 9.92 minutes 
==================================================================================================
	PARSING TIME: 8.25 minutes 
==================================================================================================
	Identification : 0.464
	P, R  : 0.376, 0.606

==================================================================================================
	XP Ends: 29/6 (10 h:36)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (10h:36)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 37)       510341      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       2725        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 86)        1186198     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 48)        5232        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_151 (Concatenate)   (None, 50, 62)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 344)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 192)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 129)          99072       concatenate_151[0][0]            
__________________________________________________________________________________________________
concatenate_152 (Concatenate)   (None, 536)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_153 (Concatenate)   (None, 665)          0           phraseRnn[0][0]                  
                                                                 concatenate_152[0][0]            
__________________________________________________________________________________________________
dense_101 (Dense)               (None, 368)          245088      concatenate_153[0][0]            
__________________________________________________________________________________________________
dense_102 (Dense)               (None, 4)            1476        dense_101[0][0]                  
==================================================================================================
Total params: 2,050,132
Trainable params: 2,050,132
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 220s - loss: 0.0669 - acc: 0.9819 - val_loss: 0.0573 - val_acc: 0.9843
Epoch 2/40
 - 220s - loss: 0.0530 - acc: 0.9862 - val_loss: 0.0579 - val_acc: 0.9840
Epoch 3/40
 - 219s - loss: 0.0499 - acc: 0.9874 - val_loss: 0.0609 - val_acc: 0.9837
Epoch 4/40
 - 220s - loss: 0.0480 - acc: 0.9880 - val_loss: 0.0669 - val_acc: 0.9835
Epoch 5/40
 - 220s - loss: 0.0466 - acc: 0.9884 - val_loss: 0.0767 - val_acc: 0.9832
Epoch 00005: early stopping
	TRAINING TIME: 19.83 minutes 
==================================================================================================
	PARSING TIME: 3.53 minutes 
==================================================================================================
	Identification : 0.47
	P, R  : 0.436, 0.51

==================================================================================================
	XP Ends: 29/6 (11 h:0)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,427            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.164          ,50             ,46             ,47             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
18             ,121            ,True           ,True           ,150            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 427, True, 0.164, 50, 46, 47, 18, 121, True, True, 150
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (11h:0)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 47)       537586      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 46)       6992        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 121)       1383998     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 18)        2736        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_154 (Concatenate)   (None, 50, 93)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 605)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 90)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 150)          109800      concatenate_154[0][0]            
__________________________________________________________________________________________________
concatenate_155 (Concatenate)   (None, 695)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_156 (Concatenate)   (None, 845)          0           phraseRnn[0][0]                  
                                                                 concatenate_155[0][0]            
__________________________________________________________________________________________________
dense_103 (Dense)               (None, 427)          361242      concatenate_156[0][0]            
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 4)            1712        dense_103[0][0]                  
==================================================================================================
Total params: 2,404,066
Trainable params: 2,404,066
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 139s - loss: 8.0970 - acc: 0.4975 - val_loss: 8.0630 - val_acc: 0.4998
Epoch 2/40
 - 139s - loss: 8.0624 - acc: 0.4998 - val_loss: 8.0630 - val_acc: 0.4998
Epoch 3/40
 - 139s - loss: 8.0624 - acc: 0.4998 - val_loss: 8.0630 - val_acc: 0.4998
Epoch 4/40
 - 139s - loss: 8.0624 - acc: 0.4998 - val_loss: 8.0630 - val_acc: 0.4998
Epoch 5/40
 - 139s - loss: 8.0624 - acc: 0.4998 - val_loss: 8.0630 - val_acc: 0.4998
Epoch 00005: early stopping
	TRAINING TIME: 12.32 minutes 
==================================================================================================
	PARSING TIME: 7.58 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (11 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (11h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 47)       441847      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 46)       7774        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 121)       1137521     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 18)        3042        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_157 (Concatenate)   (None, 50, 93)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 605)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 90)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 150)          109800      concatenate_157[0][0]            
__________________________________________________________________________________________________
concatenate_158 (Concatenate)   (None, 695)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_159 (Concatenate)   (None, 845)          0           phraseRnn[0][0]                  
                                                                 concatenate_158[0][0]            
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 427)          361242      concatenate_159[0][0]            
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 4)            1712        dense_105[0][0]                  
==================================================================================================
Total params: 2,062,938
Trainable params: 2,062,938
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 96s - loss: 12.0700 - acc: 0.2509 - val_loss: 12.1241 - val_acc: 0.2478
Epoch 2/40
 - 95s - loss: 12.0797 - acc: 0.2506 - val_loss: 12.1241 - val_acc: 0.2478
Epoch 3/40
 - 95s - loss: 12.0797 - acc: 0.2506 - val_loss: 12.1241 - val_acc: 0.2478
Epoch 4/40
 - 95s - loss: 12.0797 - acc: 0.2506 - val_loss: 12.1241 - val_acc: 0.2478
Epoch 5/40
 - 95s - loss: 12.0797 - acc: 0.2506 - val_loss: 12.1241 - val_acc: 0.2478
Epoch 00005: early stopping
	TRAINING TIME: 8.4 minutes 
==================================================================================================
	PARSING TIME: 12.03 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (11 h:41)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (11h:41)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 47)       1037337     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 46)       5014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 121)       2670591     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 18)        1962        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_160 (Concatenate)   (None, 50, 93)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 605)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 90)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 150)          109800      concatenate_160[0][0]            
__________________________________________________________________________________________________
concatenate_161 (Concatenate)   (None, 695)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_162 (Concatenate)   (None, 845)          0           phraseRnn[0][0]                  
                                                                 concatenate_161[0][0]            
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 427)          361242      concatenate_162[0][0]            
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 4)            1712        dense_107[0][0]                  
==================================================================================================
Total params: 4,187,658
Trainable params: 4,187,658
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 188s - loss: 8.0715 - acc: 0.4991 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 2/40
 - 188s - loss: 8.0655 - acc: 0.4996 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 3/40
 - 188s - loss: 8.0655 - acc: 0.4996 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 4/40
 - 188s - loss: 8.0655 - acc: 0.4996 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 5/40
 - 187s - loss: 8.0655 - acc: 0.4996 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 00005: early stopping
	TRAINING TIME: 17.08 minutes 
==================================================================================================
	PARSING TIME: 5.0 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (12 h:3)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,40             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.036          ,50             ,12             ,121            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
21             ,39             ,True           ,True           ,33             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 40, False, 0.036, 50, 12, 121, 21, 39, True, True, 33
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (12h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 121)      1383998     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1824        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 39)        446082      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 21)        3192        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_163 (Concatenate)   (None, 50, 133)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 195)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 105)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 33)           22044       concatenate_163[0][0]            
__________________________________________________________________________________________________
concatenate_164 (Concatenate)   (None, 300)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_165 (Concatenate)   (None, 333)          0           phraseRnn[0][0]                  
                                                                 concatenate_164[0][0]            
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 40)           13360       concatenate_165[0][0]            
__________________________________________________________________________________________________
dense_110 (Dense)               (None, 4)            164         dense_109[0][0]                  
==================================================================================================
Total params: 1,870,664
Trainable params: 1,870,664
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 164s - loss: 0.0660 - acc: 0.9825 - val_loss: 0.0533 - val_acc: 0.9865
Epoch 2/40
 - 164s - loss: 0.0493 - acc: 0.9878 - val_loss: 0.0536 - val_acc: 0.9865
Epoch 3/40
 - 164s - loss: 0.0463 - acc: 0.9889 - val_loss: 0.0558 - val_acc: 0.9864
Epoch 4/40
 - 163s - loss: 0.0451 - acc: 0.9892 - val_loss: 0.0581 - val_acc: 0.9862
Epoch 5/40
 - 163s - loss: 0.0445 - acc: 0.9893 - val_loss: 0.0620 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 14.53 minutes 
==================================================================================================
	PARSING TIME: 5.37 minutes 
==================================================================================================
	Identification : 0.522
	P, R  : 0.482, 0.57

==================================================================================================
	XP Ends: 29/6 (12 h:24)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (12h:24)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 121)      1137521     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       2028        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 39)        366639      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 21)        3549        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_166 (Concatenate)   (None, 50, 133)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 195)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 105)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 33)           22044       concatenate_166[0][0]            
__________________________________________________________________________________________________
concatenate_167 (Concatenate)   (None, 300)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_168 (Concatenate)   (None, 333)          0           phraseRnn[0][0]                  
                                                                 concatenate_167[0][0]            
__________________________________________________________________________________________________
dense_111 (Dense)               (None, 40)           13360       concatenate_168[0][0]            
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 4)            164         dense_111[0][0]                  
==================================================================================================
Total params: 1,545,305
Trainable params: 1,545,305
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0751 - acc: 0.9794 - val_loss: 0.0600 - val_acc: 0.9841
Epoch 2/40
 - 110s - loss: 0.0531 - acc: 0.9865 - val_loss: 0.0579 - val_acc: 0.9850
Epoch 3/40
 - 110s - loss: 0.0492 - acc: 0.9879 - val_loss: 0.0597 - val_acc: 0.9850
Epoch 4/40
 - 110s - loss: 0.0477 - acc: 0.9884 - val_loss: 0.0634 - val_acc: 0.9848
Epoch 5/40
 - 110s - loss: 0.0469 - acc: 0.9885 - val_loss: 0.0685 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 9.67 minutes 
==================================================================================================
	PARSING TIME: 8.35 minutes 
==================================================================================================
	Identification : 0.434
	P, R  : 0.339, 0.602

==================================================================================================
	XP Ends: 29/6 (12 h:42)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (12h:42)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 121)      2670591     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 12)       1308        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 39)        860769      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 21)        2289        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_169 (Concatenate)   (None, 50, 133)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 195)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 105)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 33)           22044       concatenate_169[0][0]            
__________________________________________________________________________________________________
concatenate_170 (Concatenate)   (None, 300)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_171 (Concatenate)   (None, 333)          0           phraseRnn[0][0]                  
                                                                 concatenate_170[0][0]            
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 40)           13360       concatenate_171[0][0]            
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 4)            164         dense_113[0][0]                  
==================================================================================================
Total params: 3,570,525
Trainable params: 3,570,525
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 221s - loss: 0.0642 - acc: 0.9829 - val_loss: 0.0577 - val_acc: 0.9845
Epoch 2/40
 - 221s - loss: 0.0489 - acc: 0.9879 - val_loss: 0.0583 - val_acc: 0.9846
Epoch 3/40
 - 221s - loss: 0.0461 - acc: 0.9889 - val_loss: 0.0615 - val_acc: 0.9845
Epoch 4/40
 - 221s - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0665 - val_acc: 0.9843
Epoch 5/40
 - 221s - loss: 0.0439 - acc: 0.9894 - val_loss: 0.0722 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 19.97 minutes 
==================================================================================================
	PARSING TIME: 3.55 minutes 
==================================================================================================
	Identification : 0.471
	P, R  : 0.406, 0.561

==================================================================================================
	XP Ends: 29/6 (13 h:6)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,30             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.091          ,50             ,23             ,53             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
6              ,108            ,True           ,True           ,80             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 30, False, 0.091, 50, 23, 53, 6, 108, True, True, 80
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (13h:6)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       399885      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 23)       3496        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 108)       814860      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         912         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_172 (Concatenate)   (None, 50, 76)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 540)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 80)           50240       concatenate_172[0][0]            
__________________________________________________________________________________________________
concatenate_173 (Concatenate)   (None, 570)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_174 (Concatenate)   (None, 650)          0           phraseRnn[0][0]                  
                                                                 concatenate_173[0][0]            
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 30)           19530       concatenate_174[0][0]            
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 4)            124         dense_115[0][0]                  
==================================================================================================
Total params: 1,289,047
Trainable params: 1,289,047
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 164s - loss: 0.0709 - acc: 0.9819 - val_loss: 0.0569 - val_acc: 0.9855
Epoch 2/40
 - 164s - loss: 0.0506 - acc: 0.9873 - val_loss: 0.0573 - val_acc: 0.9857
Epoch 3/40
 - 163s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0579 - val_acc: 0.9858
Epoch 4/40
 - 162s - loss: 0.0463 - acc: 0.9888 - val_loss: 0.0616 - val_acc: 0.9855
Epoch 5/40
 - 162s - loss: 0.0453 - acc: 0.9891 - val_loss: 0.0633 - val_acc: 0.9856
Epoch 00005: early stopping
	TRAINING TIME: 14.37 minutes 
==================================================================================================
	PARSING TIME: 5.22 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.738, 0.496

==================================================================================================
	XP Ends: 29/6 (13 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (13h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       383773      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 23)       3887        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 108)       782028      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         1014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_175 (Concatenate)   (None, 50, 76)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 540)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 80)           50240       concatenate_175[0][0]            
__________________________________________________________________________________________________
concatenate_176 (Concatenate)   (None, 570)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_177 (Concatenate)   (None, 650)          0           phraseRnn[0][0]                  
                                                                 concatenate_176[0][0]            
__________________________________________________________________________________________________
dense_117 (Dense)               (None, 30)           19530       concatenate_177[0][0]            
__________________________________________________________________________________________________
dense_118 (Dense)               (None, 4)            124         dense_117[0][0]                  
==================================================================================================
Total params: 1,240,596
Trainable params: 1,240,596
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 0.0829 - acc: 0.9786 - val_loss: 0.0683 - val_acc: 0.9833
Epoch 2/40
 - 109s - loss: 0.0533 - acc: 0.9864 - val_loss: 0.0624 - val_acc: 0.9841
Epoch 3/40
 - 109s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0625 - val_acc: 0.9843
Epoch 4/40
 - 109s - loss: 0.0477 - acc: 0.9883 - val_loss: 0.0666 - val_acc: 0.9843
Epoch 5/40
 - 110s - loss: 0.0466 - acc: 0.9886 - val_loss: 0.0719 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 9.65 minutes 
==================================================================================================
	PARSING TIME: 8.15 minutes 
==================================================================================================
	Identification : 0.506
	P, R  : 0.431, 0.613

==================================================================================================
	XP Ends: 29/6 (13 h:44)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (13h:44)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       731029      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 23)       2507        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 108)       1489644     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         654         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_178 (Concatenate)   (None, 50, 76)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 540)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 80)           50240       concatenate_178[0][0]            
__________________________________________________________________________________________________
concatenate_179 (Concatenate)   (None, 570)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_180 (Concatenate)   (None, 650)          0           phraseRnn[0][0]                  
                                                                 concatenate_179[0][0]            
__________________________________________________________________________________________________
dense_119 (Dense)               (None, 30)           19530       concatenate_180[0][0]            
__________________________________________________________________________________________________
dense_120 (Dense)               (None, 4)            124         dense_119[0][0]                  
==================================================================================================
Total params: 2,293,728
Trainable params: 2,293,728
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 219s - loss: 0.0710 - acc: 0.9811 - val_loss: 0.0584 - val_acc: 0.9842
Epoch 2/40
 - 219s - loss: 0.0526 - acc: 0.9864 - val_loss: 0.0595 - val_acc: 0.9842
Epoch 3/40
 - 218s - loss: 0.0492 - acc: 0.9876 - val_loss: 0.0627 - val_acc: 0.9840
Epoch 4/40
 - 217s - loss: 0.0475 - acc: 0.9883 - val_loss: 0.0658 - val_acc: 0.9837
Epoch 5/40
 - 217s - loss: 0.0462 - acc: 0.9887 - val_loss: 0.0693 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 19.65 minutes 
==================================================================================================
	PARSING TIME: 3.55 minutes 
==================================================================================================
	Identification : 0.481
	P, R  : 0.59, 0.406

==================================================================================================
	XP Ends: 29/6 (14 h:8)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,37             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.078          ,50             ,34             ,30             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
11             ,35             ,True           ,True           ,27             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 37, True, 0.078, 50, 34, 30, 11, 35, True, True, 27
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (14h:8)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 30)       226350      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 34)       5168        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 35)        264075      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1672        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_181 (Concatenate)   (None, 50, 64)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 175)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 27)           7452        concatenate_181[0][0]            
__________________________________________________________________________________________________
concatenate_182 (Concatenate)   (None, 230)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_183 (Concatenate)   (None, 257)          0           phraseRnn[0][0]                  
                                                                 concatenate_182[0][0]            
__________________________________________________________________________________________________
dense_121 (Dense)               (None, 37)           9546        concatenate_183[0][0]            
__________________________________________________________________________________________________
dense_122 (Dense)               (None, 4)            152         dense_121[0][0]                  
==================================================================================================
Total params: 514,415
Trainable params: 514,415
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 137s - loss: 0.0645 - acc: 0.9831 - val_loss: 0.0553 - val_acc: 0.9856
Epoch 2/40
 - 137s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0553 - val_acc: 0.9861
Epoch 3/40
 - 137s - loss: 0.0466 - acc: 0.9888 - val_loss: 0.0564 - val_acc: 0.9863
Epoch 4/40
 - 137s - loss: 0.0451 - acc: 0.9892 - val_loss: 0.0596 - val_acc: 0.9861
Epoch 5/40
 - 137s - loss: 0.0443 - acc: 0.9894 - val_loss: 0.0634 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 12.17 minutes 
==================================================================================================
	PARSING TIME: 4.28 minutes 
==================================================================================================
	Identification : 0.546
	P, R  : 0.545, 0.548

==================================================================================================
	XP Ends: 29/6 (14 h:25)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (14h:25)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 30)       217230      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 34)       5746        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 35)        253435      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1859        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_184 (Concatenate)   (None, 50, 64)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 175)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 27)           7452        concatenate_184[0][0]            
__________________________________________________________________________________________________
concatenate_185 (Concatenate)   (None, 230)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_186 (Concatenate)   (None, 257)          0           phraseRnn[0][0]                  
                                                                 concatenate_185[0][0]            
__________________________________________________________________________________________________
dense_123 (Dense)               (None, 37)           9546        concatenate_186[0][0]            
__________________________________________________________________________________________________
dense_124 (Dense)               (None, 4)            152         dense_123[0][0]                  
==================================================================================================
Total params: 495,420
Trainable params: 495,420
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0731 - acc: 0.9803 - val_loss: 0.0606 - val_acc: 0.9839
Epoch 2/40
 - 93s - loss: 0.0523 - acc: 0.9869 - val_loss: 0.0592 - val_acc: 0.9847
Epoch 3/40
 - 93s - loss: 0.0485 - acc: 0.9881 - val_loss: 0.0624 - val_acc: 0.9847
Epoch 4/40
 - 92s - loss: 0.0470 - acc: 0.9886 - val_loss: 0.0650 - val_acc: 0.9847
Epoch 5/40
 - 92s - loss: 0.0462 - acc: 0.9887 - val_loss: 0.0704 - val_acc: 0.9845
Epoch 00005: early stopping
	TRAINING TIME: 8.22 minutes 
==================================================================================================
	PARSING TIME: 6.47 minutes 
==================================================================================================
	Identification : 0.56
	P, R  : 0.525, 0.599

==================================================================================================
	XP Ends: 29/6 (14 h:40)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (14h:40)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 30)       413790      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 34)       3706        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 35)        482755      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 11)        1199        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_187 (Concatenate)   (None, 50, 64)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 175)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 55)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 27)           7452        concatenate_187[0][0]            
__________________________________________________________________________________________________
concatenate_188 (Concatenate)   (None, 230)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_189 (Concatenate)   (None, 257)          0           phraseRnn[0][0]                  
                                                                 concatenate_188[0][0]            
__________________________________________________________________________________________________
dense_125 (Dense)               (None, 37)           9546        concatenate_189[0][0]            
__________________________________________________________________________________________________
dense_126 (Dense)               (None, 4)            152         dense_125[0][0]                  
==================================================================================================
Total params: 918,600
Trainable params: 918,600
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 181s - loss: 0.0660 - acc: 0.9823 - val_loss: 0.0575 - val_acc: 0.9845
Epoch 2/40
 - 181s - loss: 0.0516 - acc: 0.9868 - val_loss: 0.0576 - val_acc: 0.9845
Epoch 3/40
 - 181s - loss: 0.0484 - acc: 0.9880 - val_loss: 0.0611 - val_acc: 0.9843
Epoch 4/40
 - 181s - loss: 0.0467 - acc: 0.9885 - val_loss: 0.0663 - val_acc: 0.9840
Epoch 5/40
 - 181s - loss: 0.0454 - acc: 0.9889 - val_loss: 0.0739 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 16.55 minutes 
==================================================================================================
	PARSING TIME: 2.9 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.462, 0.529

==================================================================================================
	XP Ends: 29/6 (15 h:0)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,47             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.123          ,50             ,7              ,90             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
38             ,28             ,True           ,True           ,70             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 47, False, 0.123, 50, 7, 90, 38, 28, True, True, 70
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (15h:0)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 90)       1029420     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 28)        320264      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 38)        5776        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_190 (Concatenate)   (None, 50, 97)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 140)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 190)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 70)           47040       concatenate_190[0][0]            
__________________________________________________________________________________________________
concatenate_191 (Concatenate)   (None, 330)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_192 (Concatenate)   (None, 400)          0           phraseRnn[0][0]                  
                                                                 concatenate_191[0][0]            
__________________________________________________________________________________________________
dense_127 (Dense)               (None, 47)           18847       concatenate_192[0][0]            
__________________________________________________________________________________________________
dense_128 (Dense)               (None, 4)            192         dense_127[0][0]                  
==================================================================================================
Total params: 1,422,603
Trainable params: 1,422,603
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 162s - loss: 0.0714 - acc: 0.9819 - val_loss: 0.0535 - val_acc: 0.9862
Epoch 2/40
 - 162s - loss: 0.0497 - acc: 0.9877 - val_loss: 0.0541 - val_acc: 0.9863
Epoch 3/40
 - 162s - loss: 0.0472 - acc: 0.9885 - val_loss: 0.0567 - val_acc: 0.9863
Epoch 4/40
 - 162s - loss: 0.0456 - acc: 0.9890 - val_loss: 0.0592 - val_acc: 0.9863
Epoch 5/40
 - 163s - loss: 0.0449 - acc: 0.9892 - val_loss: 0.0640 - val_acc: 0.9863
Epoch 00005: early stopping
	TRAINING TIME: 14.35 minutes 
==================================================================================================
	PARSING TIME: 5.4 minutes 
==================================================================================================
	Identification : 0.507
	P, R  : 0.444, 0.59

==================================================================================================
	XP Ends: 29/6 (15 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (15h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 90)       846090      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 28)        263228      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 38)        6422        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_193 (Concatenate)   (None, 50, 97)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 140)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 190)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 70)           47040       concatenate_193[0][0]            
__________________________________________________________________________________________________
concatenate_194 (Concatenate)   (None, 330)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_195 (Concatenate)   (None, 400)          0           phraseRnn[0][0]                  
                                                                 concatenate_194[0][0]            
__________________________________________________________________________________________________
dense_129 (Dense)               (None, 47)           18847       concatenate_195[0][0]            
__________________________________________________________________________________________________
dense_130 (Dense)               (None, 4)            192         dense_129[0][0]                  
==================================================================================================
Total params: 1,183,002
Trainable params: 1,183,002
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 112s - loss: 0.0865 - acc: 0.9785 - val_loss: 0.0593 - val_acc: 0.9846
Epoch 2/40
 - 112s - loss: 0.0536 - acc: 0.9865 - val_loss: 0.0608 - val_acc: 0.9844
Epoch 3/40
 - 112s - loss: 0.0493 - acc: 0.9879 - val_loss: 0.0612 - val_acc: 0.9849
Epoch 4/40
 - 111s - loss: 0.0476 - acc: 0.9883 - val_loss: 0.0640 - val_acc: 0.9850
Epoch 5/40
 - 111s - loss: 0.0465 - acc: 0.9886 - val_loss: 0.0742 - val_acc: 0.9851
Epoch 00005: early stopping
	TRAINING TIME: 9.88 minutes 
==================================================================================================
	PARSING TIME: 8.22 minutes 
==================================================================================================
	Identification : 0.432
	P, R  : 0.33, 0.624

==================================================================================================
	XP Ends: 29/6 (15 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (15h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 90)       1986390     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 28)        617988      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 38)        4142        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_196 (Concatenate)   (None, 50, 97)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 140)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 190)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 70)           47040       concatenate_196[0][0]            
__________________________________________________________________________________________________
concatenate_197 (Concatenate)   (None, 330)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_198 (Concatenate)   (None, 400)          0           phraseRnn[0][0]                  
                                                                 concatenate_197[0][0]            
__________________________________________________________________________________________________
dense_131 (Dense)               (None, 47)           18847       concatenate_198[0][0]            
__________________________________________________________________________________________________
dense_132 (Dense)               (None, 4)            192         dense_131[0][0]                  
==================================================================================================
Total params: 2,675,362
Trainable params: 2,675,362
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 220s - loss: 0.0695 - acc: 0.9823 - val_loss: 0.0583 - val_acc: 0.9842
Epoch 2/40
 - 220s - loss: 0.0492 - acc: 0.9877 - val_loss: 0.0598 - val_acc: 0.9844
Epoch 3/40
 - 220s - loss: 0.0464 - acc: 0.9887 - val_loss: 0.0645 - val_acc: 0.9841
Epoch 4/40
 - 220s - loss: 0.0448 - acc: 0.9891 - val_loss: 0.0756 - val_acc: 0.9840
Epoch 5/40
 - 220s - loss: 0.0437 - acc: 0.9893 - val_loss: 0.0841 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 19.9 minutes 
==================================================================================================
	PARSING TIME: 3.53 minutes 
==================================================================================================
	Identification : 0.477
	P, R  : 0.437, 0.525

==================================================================================================
	XP Ends: 29/6 (16 h:2)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,184            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.049          ,50             ,19             ,33             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
12             ,39             ,True           ,False          ,148            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 184, True, 0.049, 50, 19, 33, 12, 39, True, False, 148
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (16h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 33)       248985      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 19)       2888        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 39)        294255      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 12)        1824        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_199 (Concatenate)   (None, 50, 52)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 48)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 148)          89244       concatenate_199[0][0]            
__________________________________________________________________________________________________
concatenate_200 (Concatenate)   (None, 204)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_201 (Concatenate)   (None, 352)          0           phraseRnn[0][0]                  
                                                                 concatenate_200[0][0]            
__________________________________________________________________________________________________
dense_133 (Dense)               (None, 184)          64952       concatenate_201[0][0]            
__________________________________________________________________________________________________
dense_134 (Dense)               (None, 4)            740         dense_133[0][0]                  
==================================================================================================
Total params: 702,888
Trainable params: 702,888
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 139s - loss: 0.0963 - acc: 0.9791 - val_loss: 1.2554 - val_acc: 0.7450
Epoch 2/40
 - 139s - loss: 0.0538 - acc: 0.9863 - val_loss: 0.0585 - val_acc: 0.9848
Epoch 3/40
 - 139s - loss: 0.0502 - acc: 0.9876 - val_loss: 0.0597 - val_acc: 0.9848
Epoch 4/40
 - 139s - loss: 0.0483 - acc: 0.9882 - val_loss: 0.0613 - val_acc: 0.9849
Epoch 5/40
 - 139s - loss: 0.0470 - acc: 0.9885 - val_loss: 0.0637 - val_acc: 0.9848
Epoch 6/40
 - 139s - loss: 0.0461 - acc: 0.9888 - val_loss: 0.0650 - val_acc: 0.9850
Epoch 00006: early stopping
	TRAINING TIME: 14.72 minutes 
==================================================================================================
	PARSING TIME: 4.28 minutes 
==================================================================================================
	Identification : 0.591
	P, R  : 0.736, 0.494

==================================================================================================
	XP Ends: 29/6 (16 h:21)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (16h:21)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 33)       238953      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 19)       3211        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 39)        282399      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 12)        2028        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_202 (Concatenate)   (None, 50, 52)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 48)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 148)          89244       concatenate_202[0][0]            
__________________________________________________________________________________________________
concatenate_203 (Concatenate)   (None, 204)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_204 (Concatenate)   (None, 352)          0           phraseRnn[0][0]                  
                                                                 concatenate_203[0][0]            
__________________________________________________________________________________________________
dense_135 (Dense)               (None, 184)          64952       concatenate_204[0][0]            
__________________________________________________________________________________________________
dense_136 (Dense)               (None, 4)            740         dense_135[0][0]                  
==================================================================================================
Total params: 681,527
Trainable params: 681,527
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 95s - loss: 0.0865 - acc: 0.9780 - val_loss: 0.0621 - val_acc: 0.9834
Epoch 2/40
 - 95s - loss: 0.0558 - acc: 0.9855 - val_loss: 0.0616 - val_acc: 0.9838
Epoch 3/40
 - 95s - loss: 0.0513 - acc: 0.9870 - val_loss: 0.0653 - val_acc: 0.9840
Epoch 4/40
 - 94s - loss: 0.0489 - acc: 0.9878 - val_loss: 0.0674 - val_acc: 0.9838
Epoch 5/40
 - 94s - loss: 0.0474 - acc: 0.9883 - val_loss: 0.0779 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 8.38 minutes 
==================================================================================================
	PARSING TIME: 6.63 minutes 
==================================================================================================
	Identification : 0.478
	P, R  : 0.387, 0.624

==================================================================================================
	XP Ends: 29/6 (16 h:37)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (16h:37)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 33)       455169      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 19)       2071        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 39)        537927      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 12)        1308        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_205 (Concatenate)   (None, 50, 52)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 48)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 148)          89244       concatenate_205[0][0]            
__________________________________________________________________________________________________
concatenate_206 (Concatenate)   (None, 204)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_207 (Concatenate)   (None, 352)          0           phraseRnn[0][0]                  
                                                                 concatenate_206[0][0]            
__________________________________________________________________________________________________
dense_137 (Dense)               (None, 184)          64952       concatenate_207[0][0]            
__________________________________________________________________________________________________
dense_138 (Dense)               (None, 4)            740         dense_137[0][0]                  
==================================================================================================
Total params: 1,151,411
Trainable params: 1,151,411
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 183s - loss: 0.0710 - acc: 0.9808 - val_loss: 0.0591 - val_acc: 0.9835
Epoch 2/40
 - 183s - loss: 0.0544 - acc: 0.9856 - val_loss: 0.0594 - val_acc: 0.9840
Epoch 3/40
 - 183s - loss: 0.0514 - acc: 0.9868 - val_loss: 0.0610 - val_acc: 0.9837
Epoch 4/40
 - 183s - loss: 0.0493 - acc: 0.9875 - val_loss: 0.0655 - val_acc: 0.9837
Epoch 5/40
 - 183s - loss: 0.0479 - acc: 0.9879 - val_loss: 0.0732 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 16.75 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.501, 0.486

==================================================================================================
	XP Ends: 29/6 (16 h:57)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,88             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.142          ,50             ,17             ,73             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
23             ,77             ,True           ,True           ,485            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 88, True, 0.142, 50, 17, 73, 23, 77, True, True, 485
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (16h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 73)       550785      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2584        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 77)        580965      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 23)        3496        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_208 (Concatenate)   (None, 50, 90)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 385)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 115)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 485)          838080      concatenate_208[0][0]            
__________________________________________________________________________________________________
concatenate_209 (Concatenate)   (None, 500)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_210 (Concatenate)   (None, 985)          0           phraseRnn[0][0]                  
                                                                 concatenate_209[0][0]            
__________________________________________________________________________________________________
dense_139 (Dense)               (None, 88)           86768       concatenate_210[0][0]            
__________________________________________________________________________________________________
dense_140 (Dense)               (None, 4)            356         dense_139[0][0]                  
==================================================================================================
Total params: 2,063,034
Trainable params: 2,063,034
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 295s - loss: 12.0959 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 2/40
 - 295s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 3/40
 - 295s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 4/40
 - 295s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 5/40
 - 295s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 00005: early stopping
	TRAINING TIME: 25.42 minutes 
==================================================================================================
	PARSING TIME: 12.95 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (17 h:36)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (17h:36)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 73)       528593      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2873        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 77)        557557      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 23)        3887        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_211 (Concatenate)   (None, 50, 90)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 385)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 115)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 485)          838080      concatenate_211[0][0]            
__________________________________________________________________________________________________
concatenate_212 (Concatenate)   (None, 500)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_213 (Concatenate)   (None, 985)          0           phraseRnn[0][0]                  
                                                                 concatenate_212[0][0]            
__________________________________________________________________________________________________
dense_141 (Dense)               (None, 88)           86768       concatenate_213[0][0]            
__________________________________________________________________________________________________
dense_142 (Dense)               (None, 4)            356         dense_141[0][0]                  
==================================================================================================
Total params: 2,018,114
Trainable params: 2,018,114
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 201s - loss: 12.0901 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 2/40
 - 201s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 3/40
 - 201s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 4/40
 - 201s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 5/40
 - 201s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 00005: early stopping
	TRAINING TIME: 17.27 minutes 
==================================================================================================
	PARSING TIME: 10.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (18 h:3)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (18h:3)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 73)       1006889     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       1853        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 77)        1062061     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 23)        2507        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_214 (Concatenate)   (None, 50, 90)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 385)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 115)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 485)          838080      concatenate_214[0][0]            
__________________________________________________________________________________________________
concatenate_215 (Concatenate)   (None, 500)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_216 (Concatenate)   (None, 985)          0           phraseRnn[0][0]                  
                                                                 concatenate_215[0][0]            
__________________________________________________________________________________________________
dense_143 (Dense)               (None, 88)           86768       concatenate_216[0][0]            
__________________________________________________________________________________________________
dense_144 (Dense)               (None, 4)            356         dense_143[0][0]                  
==================================================================================================
Total params: 2,998,514
Trainable params: 2,998,514
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 400s - loss: 12.0869 - acc: 0.2499 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 2/40
 - 400s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 3/40
 - 400s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 4/40
 - 400s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 5/40
 - 400s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 00005: early stopping
	TRAINING TIME: 34.83 minutes 
==================================================================================================
	PARSING TIME: 4.48 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 29/6 (18 h:43)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,33             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.026          ,50             ,17             ,64             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
33             ,37             ,True           ,False          ,99             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 33, False, 0.026, 50, 17, 64, 33, 37, True, False, 99
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (18h:43)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 64)       482880      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2584        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 37)        279165      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 33)        5016        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_217 (Concatenate)   (None, 50, 81)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 148)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 132)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 99)           71676       concatenate_217[0][0]            
__________________________________________________________________________________________________
concatenate_218 (Concatenate)   (None, 280)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_219 (Concatenate)   (None, 379)          0           phraseRnn[0][0]                  
                                                                 concatenate_218[0][0]            
__________________________________________________________________________________________________
dense_145 (Dense)               (None, 33)           12540       concatenate_219[0][0]            
__________________________________________________________________________________________________
dense_146 (Dense)               (None, 4)            136         dense_145[0][0]                  
==================================================================================================
Total params: 853,997
Trainable params: 853,997
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 163s - loss: 0.0690 - acc: 0.9819 - val_loss: 0.0588 - val_acc: 0.9849
Epoch 2/40
 - 162s - loss: 0.0532 - acc: 0.9866 - val_loss: 0.0577 - val_acc: 0.9853
Epoch 3/40
 - 162s - loss: 0.0496 - acc: 0.9879 - val_loss: 0.0600 - val_acc: 0.9853
Epoch 4/40
 - 162s - loss: 0.0478 - acc: 0.9883 - val_loss: 0.0620 - val_acc: 0.9851
Epoch 5/40
 - 163s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0642 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 14.38 minutes 
==================================================================================================
	PARSING TIME: 5.32 minutes 
==================================================================================================
	Identification : 0.589
	P, R  : 0.764, 0.479

==================================================================================================
	XP Ends: 29/6 (19 h:3)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (19h:3)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 64)       463424      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2873        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 37)        267917      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 33)        5577        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_220 (Concatenate)   (None, 50, 81)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 148)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 132)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 99)           71676       concatenate_220[0][0]            
__________________________________________________________________________________________________
concatenate_221 (Concatenate)   (None, 280)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_222 (Concatenate)   (None, 379)          0           phraseRnn[0][0]                  
                                                                 concatenate_221[0][0]            
__________________________________________________________________________________________________
dense_147 (Dense)               (None, 33)           12540       concatenate_222[0][0]            
__________________________________________________________________________________________________
dense_148 (Dense)               (None, 4)            136         dense_147[0][0]                  
==================================================================================================
Total params: 824,143
Trainable params: 824,143
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0795 - acc: 0.9785 - val_loss: 0.0645 - val_acc: 0.9824
Epoch 2/40
 - 110s - loss: 0.0584 - acc: 0.9850 - val_loss: 0.0641 - val_acc: 0.9829
Epoch 3/40
 - 110s - loss: 0.0538 - acc: 0.9865 - val_loss: 0.0641 - val_acc: 0.9836
Epoch 4/40
 - 110s - loss: 0.0514 - acc: 0.9870 - val_loss: 0.0671 - val_acc: 0.9835
Epoch 5/40
 - 110s - loss: 0.0498 - acc: 0.9875 - val_loss: 0.0698 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 9.67 minutes 
==================================================================================================
	PARSING TIME: 8.58 minutes 
==================================================================================================
	Identification : 0.405
	P, R  : 0.295, 0.644

==================================================================================================
	XP Ends: 29/6 (19 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (19h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 64)       882752      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       1853        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 37)        510341      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 33)        3597        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_223 (Concatenate)   (None, 50, 81)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 148)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 132)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 99)           71676       concatenate_223[0][0]            
__________________________________________________________________________________________________
concatenate_224 (Concatenate)   (None, 280)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_225 (Concatenate)   (None, 379)          0           phraseRnn[0][0]                  
                                                                 concatenate_224[0][0]            
__________________________________________________________________________________________________
dense_149 (Dense)               (None, 33)           12540       concatenate_225[0][0]            
__________________________________________________________________________________________________
dense_150 (Dense)               (None, 4)            136         dense_149[0][0]                  
==================================================================================================
Total params: 1,482,895
Trainable params: 1,482,895
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 220s - loss: 0.0688 - acc: 0.9815 - val_loss: 0.0587 - val_acc: 0.9843
Epoch 2/40
 - 220s - loss: 0.0541 - acc: 0.9859 - val_loss: 0.0586 - val_acc: 0.9839
Epoch 3/40
 - 220s - loss: 0.0509 - acc: 0.9871 - val_loss: 0.0615 - val_acc: 0.9832
Epoch 4/40
 - 220s - loss: 0.0490 - acc: 0.9878 - val_loss: 0.0640 - val_acc: 0.9833
Epoch 5/40
 - 220s - loss: 0.0477 - acc: 0.9881 - val_loss: 0.0675 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 19.88 minutes 
==================================================================================================
	PARSING TIME: 3.53 minutes 
==================================================================================================
	Identification : 0.485
	P, R  : 0.483, 0.488

==================================================================================================
	XP Ends: 29/6 (19 h:46)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,123            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.05           ,50             ,27             ,84             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
31             ,58             ,False          ,True           ,86             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 123, False, 0.05, 50, 27, 84, 31, 58, False, True, 86
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (19h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 84)       633780      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 27)       4104        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 58)        437610      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 31)        4712        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_226 (Concatenate)   (None, 50, 111)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 232)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 124)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 86)           68112       concatenate_226[0][0]            
__________________________________________________________________________________________________
concatenate_227 (Concatenate)   (None, 356)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_228 (Concatenate)   (None, 442)          0           phraseRnn[0][0]                  
                                                                 concatenate_227[0][0]            
__________________________________________________________________________________________________
dense_151 (Dense)               (None, 123)          54489       concatenate_228[0][0]            
__________________________________________________________________________________________________
dense_152 (Dense)               (None, 4)            496         dense_151[0][0]                  
==================================================================================================
Total params: 1,203,303
Trainable params: 1,203,303
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 164s - loss: 0.0715 - acc: 0.9821 - val_loss: 0.3851 - val_acc: 0.7506
Epoch 2/40
 - 165s - loss: 0.0521 - acc: 0.9868 - val_loss: 0.0564 - val_acc: 0.9856
Epoch 3/40
 - 164s - loss: 0.0486 - acc: 0.9880 - val_loss: 0.0574 - val_acc: 0.9856
Epoch 4/40
 - 163s - loss: 0.0467 - acc: 0.9886 - val_loss: 0.0594 - val_acc: 0.9857
Epoch 5/40
 - 163s - loss: 0.0454 - acc: 0.9890 - val_loss: 0.0632 - val_acc: 0.9856
Epoch 6/40
 - 163s - loss: 0.0446 - acc: 0.9892 - val_loss: 0.0686 - val_acc: 0.9856
Epoch 00006: early stopping
	TRAINING TIME: 17.18 minutes 
==================================================================================================
	PARSING TIME: 5.25 minutes 
==================================================================================================
	Identification : 0.587
	P, R  : 0.71, 0.501

==================================================================================================
	XP Ends: 29/6 (20 h:8)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (20h:8)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 84)       608244      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 27)       4563        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 58)        419978      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 31)        5239        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_229 (Concatenate)   (None, 50, 111)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 232)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 124)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 86)           68112       concatenate_229[0][0]            
__________________________________________________________________________________________________
concatenate_230 (Concatenate)   (None, 356)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_231 (Concatenate)   (None, 442)          0           phraseRnn[0][0]                  
                                                                 concatenate_230[0][0]            
__________________________________________________________________________________________________
dense_153 (Dense)               (None, 123)          54489       concatenate_231[0][0]            
__________________________________________________________________________________________________
dense_154 (Dense)               (None, 4)            496         dense_153[0][0]                  
==================================================================================================
Total params: 1,161,121
Trainable params: 1,161,121
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0732 - acc: 0.9802 - val_loss: 0.0597 - val_acc: 0.9845
Epoch 2/40
 - 110s - loss: 0.0527 - acc: 0.9867 - val_loss: 0.0588 - val_acc: 0.9849
Epoch 3/40
 - 110s - loss: 0.0489 - acc: 0.9880 - val_loss: 0.0618 - val_acc: 0.9849
Epoch 4/40
 - 110s - loss: 0.0476 - acc: 0.9883 - val_loss: 0.0658 - val_acc: 0.9851
Epoch 5/40
 - 110s - loss: 0.0466 - acc: 0.9886 - val_loss: 0.0694 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 9.7 minutes 
==================================================================================================
	PARSING TIME: 8.13 minutes 
==================================================================================================
	Identification : 0.508
	P, R  : 0.432, 0.615

==================================================================================================
	XP Ends: 29/6 (20 h:27)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (20h:27)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 84)       1158612     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 27)       2943        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 58)        799994      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 31)        3379        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_232 (Concatenate)   (None, 50, 111)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 232)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 124)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 86)           68112       concatenate_232[0][0]            
__________________________________________________________________________________________________
concatenate_233 (Concatenate)   (None, 356)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_234 (Concatenate)   (None, 442)          0           phraseRnn[0][0]                  
                                                                 concatenate_233[0][0]            
__________________________________________________________________________________________________
dense_155 (Dense)               (None, 123)          54489       concatenate_234[0][0]            
__________________________________________________________________________________________________
dense_156 (Dense)               (None, 4)            496         dense_155[0][0]                  
==================================================================================================
Total params: 2,088,025
Trainable params: 2,088,025
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 224s - loss: 0.0697 - acc: 0.9814 - val_loss: 0.0583 - val_acc: 0.9847
Epoch 2/40
 - 224s - loss: 0.0530 - acc: 0.9862 - val_loss: 0.0609 - val_acc: 0.9836
Epoch 3/40
 - 224s - loss: 0.0501 - acc: 0.9872 - val_loss: 0.0604 - val_acc: 0.9842
Epoch 4/40
 - 224s - loss: 0.0483 - acc: 0.9879 - val_loss: 0.0657 - val_acc: 0.9841
Epoch 5/40
 - 223s - loss: 0.0470 - acc: 0.9883 - val_loss: 0.0706 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 20.17 minutes 
==================================================================================================
	PARSING TIME: 3.52 minutes 
==================================================================================================
	Identification : 0.469
	P, R  : 0.496, 0.445

==================================================================================================
	XP Ends: 29/6 (20 h:51)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,50             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.04           ,50             ,28             ,75             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
22             ,61             ,True           ,False          ,92             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 50, True, 0.04, 50, 28, 75, 22, 61, True, False, 92
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (20h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 75)       857850      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 28)       4256        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 61)        697718      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 22)        3344        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_235 (Concatenate)   (None, 50, 103)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 244)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 88)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 92)           54096       concatenate_235[0][0]            
__________________________________________________________________________________________________
concatenate_236 (Concatenate)   (None, 332)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_237 (Concatenate)   (None, 424)          0           phraseRnn[0][0]                  
                                                                 concatenate_236[0][0]            
__________________________________________________________________________________________________
dense_157 (Dense)               (None, 50)           21250       concatenate_237[0][0]            
__________________________________________________________________________________________________
dense_158 (Dense)               (None, 4)            204         dense_157[0][0]                  
==================================================================================================
Total params: 1,638,718
Trainable params: 1,638,718
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 140s - loss: 0.0651 - acc: 0.9827 - val_loss: 0.0549 - val_acc: 0.9858
Epoch 2/40
 - 139s - loss: 0.0500 - acc: 0.9876 - val_loss: 0.0541 - val_acc: 0.9862
Epoch 3/40
 - 139s - loss: 0.0472 - acc: 0.9885 - val_loss: 0.0564 - val_acc: 0.9860
Epoch 4/40
 - 139s - loss: 0.0457 - acc: 0.9890 - val_loss: 0.0600 - val_acc: 0.9859
Epoch 5/40
 - 139s - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0629 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 12.38 minutes 
==================================================================================================
	PARSING TIME: 4.3 minutes 
==================================================================================================
	Identification : 0.544
	P, R  : 0.537, 0.551

==================================================================================================
	XP Ends: 29/6 (21 h:8)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (21h:8)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 75)       705075      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 28)       4732        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 61)        573461      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 22)        3718        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_238 (Concatenate)   (None, 50, 103)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 244)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 88)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 92)           54096       concatenate_238[0][0]            
__________________________________________________________________________________________________
concatenate_239 (Concatenate)   (None, 332)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_240 (Concatenate)   (None, 424)          0           phraseRnn[0][0]                  
                                                                 concatenate_239[0][0]            
__________________________________________________________________________________________________
dense_159 (Dense)               (None, 50)           21250       concatenate_240[0][0]            
__________________________________________________________________________________________________
dense_160 (Dense)               (None, 4)            204         dense_159[0][0]                  
==================================================================================================
Total params: 1,362,536
Trainable params: 1,362,536
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0747 - acc: 0.9794 - val_loss: 0.0961 - val_acc: 0.9708
Epoch 2/40
 - 94s - loss: 0.0546 - acc: 0.9861 - val_loss: 0.0597 - val_acc: 0.9844
Epoch 3/40
 - 94s - loss: 0.0502 - acc: 0.9875 - val_loss: 0.0639 - val_acc: 0.9836
Epoch 4/40
 - 93s - loss: 0.0483 - acc: 0.9881 - val_loss: 0.0684 - val_acc: 0.9834
Epoch 5/40
 - 93s - loss: 0.0471 - acc: 0.9884 - val_loss: 0.0745 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 8.28 minutes 
==================================================================================================
	PARSING TIME: 6.68 minutes 
==================================================================================================
	Identification : 0.409
	P, R  : 0.309, 0.604

==================================================================================================
	XP Ends: 29/6 (21 h:23)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (21h:23)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 75)       1655325     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 28)       3052        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 61)        1346331     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 22)        2398        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_241 (Concatenate)   (None, 50, 103)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 244)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 88)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 92)           54096       concatenate_241[0][0]            
__________________________________________________________________________________________________
concatenate_242 (Concatenate)   (None, 332)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_243 (Concatenate)   (None, 424)          0           phraseRnn[0][0]                  
                                                                 concatenate_242[0][0]            
__________________________________________________________________________________________________
dense_161 (Dense)               (None, 50)           21250       concatenate_243[0][0]            
__________________________________________________________________________________________________
dense_162 (Dense)               (None, 4)            204         dense_161[0][0]                  
==================================================================================================
Total params: 3,082,656
Trainable params: 3,082,656
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 185s - loss: 0.0634 - acc: 0.9830 - val_loss: 0.0580 - val_acc: 0.9843
Epoch 2/40
 - 185s - loss: 0.0498 - acc: 0.9875 - val_loss: 0.0601 - val_acc: 0.9840
Epoch 3/40
 - 185s - loss: 0.0469 - acc: 0.9885 - val_loss: 0.0646 - val_acc: 0.9835
Epoch 4/40
 - 185s - loss: 0.0452 - acc: 0.9890 - val_loss: 0.0696 - val_acc: 0.9832
Epoch 5/40
 - 185s - loss: 0.0441 - acc: 0.9892 - val_loss: 0.0829 - val_acc: 0.9833
Epoch 00005: early stopping
	TRAINING TIME: 16.85 minutes 
==================================================================================================
	PARSING TIME: 2.82 minutes 
==================================================================================================
	Identification : 0.496
	P, R  : 0.453, 0.547

==================================================================================================
	XP Ends: 29/6 (21 h:43)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,423            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.044          ,50             ,8              ,110            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
21             ,57             ,False          ,False          ,50             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 423, False, 0.044, 50, 8, 110, 21, 57, False, False, 50
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (21h:43)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 110)      829950      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 57)        430065      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 21)        3192        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_244 (Concatenate)   (None, 50, 118)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 171)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 63)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 50)           33800       concatenate_244[0][0]            
__________________________________________________________________________________________________
concatenate_245 (Concatenate)   (None, 234)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_246 (Concatenate)   (None, 284)          0           phraseRnn[0][0]                  
                                                                 concatenate_245[0][0]            
__________________________________________________________________________________________________
dense_163 (Dense)               (None, 423)          120555      concatenate_246[0][0]            
__________________________________________________________________________________________________
dense_164 (Dense)               (None, 4)            1696        dense_163[0][0]                  
==================================================================================================
Total params: 1,420,474
Trainable params: 1,420,474
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 162s - loss: 0.0664 - acc: 0.9826 - val_loss: 0.0566 - val_acc: 0.9854
Epoch 2/40
 - 162s - loss: 0.0514 - acc: 0.9871 - val_loss: 0.0713 - val_acc: 0.9857
Epoch 3/40
 - 162s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0599 - val_acc: 0.9855
Epoch 4/40
 - 162s - loss: 0.0459 - acc: 0.9889 - val_loss: 0.0633 - val_acc: 0.9851
Epoch 5/40
 - 162s - loss: 0.0446 - acc: 0.9893 - val_loss: 0.0679 - val_acc: 0.9855
Epoch 00005: early stopping
	TRAINING TIME: 14.32 minutes 
==================================================================================================
	PARSING TIME: 5.37 minutes 
==================================================================================================
	Identification : 0.566
	P, R  : 0.581, 0.552

==================================================================================================
	XP Ends: 29/6 (22 h:3)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (22h:3)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 110)      796510      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 57)        412737      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 21)        3549        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_247 (Concatenate)   (None, 50, 118)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 171)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 63)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 50)           33800       concatenate_247[0][0]            
__________________________________________________________________________________________________
concatenate_248 (Concatenate)   (None, 234)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_249 (Concatenate)   (None, 284)          0           phraseRnn[0][0]                  
                                                                 concatenate_248[0][0]            
__________________________________________________________________________________________________
dense_165 (Dense)               (None, 423)          120555      concatenate_249[0][0]            
__________________________________________________________________________________________________
dense_166 (Dense)               (None, 4)            1696        dense_165[0][0]                  
==================================================================================================
Total params: 1,370,199
Trainable params: 1,370,199
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 113s - loss: 0.0741 - acc: 0.9800 - val_loss: 0.0636 - val_acc: 0.9831
Epoch 2/40
 - 113s - loss: 0.0546 - acc: 0.9859 - val_loss: 0.0628 - val_acc: 0.9843
Epoch 3/40
 - 112s - loss: 0.0505 - acc: 0.9873 - val_loss: 0.0660 - val_acc: 0.9834
Epoch 4/40
 - 111s - loss: 0.0484 - acc: 0.9880 - val_loss: 0.0701 - val_acc: 0.9838
Epoch 5/40
 - 111s - loss: 0.0469 - acc: 0.9884 - val_loss: 0.0798 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 9.9 minutes 
==================================================================================================
	PARSING TIME: 8.28 minutes 
==================================================================================================
	Identification : 0.472
	P, R  : 0.386, 0.606

==================================================================================================
	XP Ends: 29/6 (22 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (22h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 110)      1517230     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 57)        786201      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 21)        2289        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_250 (Concatenate)   (None, 50, 118)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 171)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 63)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 50)           33800       concatenate_250[0][0]            
__________________________________________________________________________________________________
concatenate_251 (Concatenate)   (None, 234)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_252 (Concatenate)   (None, 284)          0           phraseRnn[0][0]                  
                                                                 concatenate_251[0][0]            
__________________________________________________________________________________________________
dense_167 (Dense)               (None, 423)          120555      concatenate_252[0][0]            
__________________________________________________________________________________________________
dense_168 (Dense)               (None, 4)            1696        dense_167[0][0]                  
==================================================================================================
Total params: 2,462,643
Trainable params: 2,462,643
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 219s - loss: 0.0669 - acc: 0.9816 - val_loss: 0.0582 - val_acc: 0.9841
Epoch 2/40
 - 219s - loss: 0.0539 - acc: 0.9858 - val_loss: 0.0591 - val_acc: 0.9838
Epoch 3/40
 - 220s - loss: 0.0510 - acc: 0.9866 - val_loss: 0.0633 - val_acc: 0.9836
Epoch 4/40
 - 219s - loss: 0.0487 - acc: 0.9874 - val_loss: 0.0722 - val_acc: 0.9833
Epoch 5/40
 - 219s - loss: 0.0470 - acc: 0.9880 - val_loss: 0.0817 - val_acc: 0.9832
Epoch 00005: early stopping
	TRAINING TIME: 19.75 minutes 
==================================================================================================
	PARSING TIME: 3.63 minutes 
==================================================================================================
	Identification : 0.48
	P, R  : 0.427, 0.549

==================================================================================================
	XP Ends: 29/6 (22 h:46)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,253            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.011          ,50             ,13             ,131            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
9              ,33             ,False          ,True           ,86             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 253, False, 0.011, 50, 13, 131, 9, 33, False, True, 86
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (22h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 131)      1498378     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1976        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 33)        377454      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 9)         1368        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_253 (Concatenate)   (None, 50, 144)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 132)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 36)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 86)           79464       concatenate_253[0][0]            
__________________________________________________________________________________________________
concatenate_254 (Concatenate)   (None, 168)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_255 (Concatenate)   (None, 254)          0           phraseRnn[0][0]                  
                                                                 concatenate_254[0][0]            
__________________________________________________________________________________________________
dense_169 (Dense)               (None, 253)          64515       concatenate_255[0][0]            
__________________________________________________________________________________________________
dense_170 (Dense)               (None, 4)            1016        dense_169[0][0]                  
==================================================================================================
Total params: 2,024,171
Trainable params: 2,024,171
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 163s - loss: 0.0770 - acc: 0.9796 - val_loss: 0.0597 - val_acc: 0.9847
Epoch 2/40
 - 163s - loss: 0.0542 - acc: 0.9865 - val_loss: 0.0577 - val_acc: 0.9854
Epoch 3/40
 - 163s - loss: 0.0496 - acc: 0.9879 - val_loss: 0.0588 - val_acc: 0.9856
Epoch 4/40
 - 163s - loss: 0.0473 - acc: 0.9886 - val_loss: 0.0615 - val_acc: 0.9851
Epoch 5/40
 - 164s - loss: 0.0460 - acc: 0.9889 - val_loss: 0.0632 - val_acc: 0.9853
Epoch 00005: early stopping
	TRAINING TIME: 14.48 minutes 
==================================================================================================
	PARSING TIME: 5.42 minutes 
==================================================================================================
	Identification : 0.528
	P, R  : 0.501, 0.558

==================================================================================================
	XP Ends: 29/6 (23 h:6)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 29/6 (23h:6)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 131)      1231531     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       2197        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 33)        310233      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 9)         1521        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_256 (Concatenate)   (None, 50, 144)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 132)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 36)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 86)           79464       concatenate_256[0][0]            
__________________________________________________________________________________________________
concatenate_257 (Concatenate)   (None, 168)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_258 (Concatenate)   (None, 254)          0           phraseRnn[0][0]                  
                                                                 concatenate_257[0][0]            
__________________________________________________________________________________________________
dense_171 (Dense)               (None, 253)          64515       concatenate_258[0][0]            
__________________________________________________________________________________________________
dense_172 (Dense)               (None, 4)            1016        dense_171[0][0]                  
==================================================================================================
Total params: 1,690,477
Trainable params: 1,690,477
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 113s - loss: 0.0872 - acc: 0.9760 - val_loss: 0.0637 - val_acc: 0.9831
Epoch 2/40
 - 113s - loss: 0.0583 - acc: 0.9850 - val_loss: 0.0631 - val_acc: 0.9839
Epoch 3/40
 - 113s - loss: 0.0531 - acc: 0.9868 - val_loss: 0.0642 - val_acc: 0.9834
Epoch 4/40
 - 113s - loss: 0.0505 - acc: 0.9876 - val_loss: 0.0666 - val_acc: 0.9835
Epoch 5/40
 - 112s - loss: 0.0490 - acc: 0.9879 - val_loss: 0.0700 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 9.98 minutes 
==================================================================================================
	PARSING TIME: 8.13 minutes 
==================================================================================================
	Identification : 0.44
	P, R  : 0.342, 0.618

==================================================================================================
	XP Ends: 29/6 (23 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (23h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 131)      2891301     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1417        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 33)        728343      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 9)         981         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_259 (Concatenate)   (None, 50, 144)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 132)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 36)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 86)           79464       concatenate_259[0][0]            
__________________________________________________________________________________________________
concatenate_260 (Concatenate)   (None, 168)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_261 (Concatenate)   (None, 254)          0           phraseRnn[0][0]                  
                                                                 concatenate_260[0][0]            
__________________________________________________________________________________________________
dense_173 (Dense)               (None, 253)          64515       concatenate_261[0][0]            
__________________________________________________________________________________________________
dense_174 (Dense)               (None, 4)            1016        dense_173[0][0]                  
==================================================================================================
Total params: 3,767,037
Trainable params: 3,767,037
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 222s - loss: 0.0736 - acc: 0.9799 - val_loss: 0.0625 - val_acc: 0.9832
Epoch 2/40
 - 222s - loss: 0.0525 - acc: 0.9867 - val_loss: 0.0629 - val_acc: 0.9836
Epoch 3/40
 - 222s - loss: 0.0487 - acc: 0.9879 - val_loss: 0.0651 - val_acc: 0.9836
Epoch 4/40
 - 223s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0694 - val_acc: 0.9832
Epoch 5/40
 - 222s - loss: 0.0457 - acc: 0.9888 - val_loss: 0.0732 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 20.02 minutes 
==================================================================================================
	PARSING TIME: 3.62 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.443, 0.565

==================================================================================================
	XP Ends: 29/6 (23 h:49)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,75             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.033          ,50             ,23             ,44             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
13             ,47             ,False          ,True           ,343            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 75, False, 0.033, 50, 23, 44, 13, 47, False, True, 343
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 29/6 (23h:49)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 44)       331980      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 23)       3496        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 47)        354615      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 13)        1976        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_262 (Concatenate)   (None, 50, 67)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 188)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 52)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 343)          563892      concatenate_262[0][0]            
__________________________________________________________________________________________________
concatenate_263 (Concatenate)   (None, 240)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_264 (Concatenate)   (None, 583)          0           phraseRnn[0][0]                  
                                                                 concatenate_263[0][0]            
__________________________________________________________________________________________________
dense_175 (Dense)               (None, 75)           43800       concatenate_264[0][0]            
__________________________________________________________________________________________________
dense_176 (Dense)               (None, 4)            304         dense_175[0][0]                  
==================================================================================================
Total params: 1,300,063
Trainable params: 1,300,063
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 246s - loss: 12.0811 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 2/40
 - 246s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 3/40
 - 246s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 4/40
 - 246s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 5/40
 - 246s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 00005: early stopping
	TRAINING TIME: 21.42 minutes 
==================================================================================================
	PARSING TIME: 10.53 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (0 h:21)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (0h:21)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 44)       318604      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 23)       3887        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 47)        340327      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 13)        2197        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_265 (Concatenate)   (None, 50, 67)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 188)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 52)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 343)          563892      concatenate_265[0][0]            
__________________________________________________________________________________________________
concatenate_266 (Concatenate)   (None, 240)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_267 (Concatenate)   (None, 583)          0           phraseRnn[0][0]                  
                                                                 concatenate_266[0][0]            
__________________________________________________________________________________________________
dense_177 (Dense)               (None, 75)           43800       concatenate_267[0][0]            
__________________________________________________________________________________________________
dense_178 (Dense)               (None, 4)            304         dense_177[0][0]                  
==================================================================================================
Total params: 1,273,011
Trainable params: 1,273,011
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 166s - loss: 0.0995 - acc: 0.9750 - val_loss: 0.0648 - val_acc: 0.9834
Epoch 2/40
 - 166s - loss: 0.0575 - acc: 0.9852 - val_loss: 0.0630 - val_acc: 0.9838
Epoch 3/40
 - 166s - loss: 0.0524 - acc: 0.9869 - val_loss: 0.0643 - val_acc: 0.9836
Epoch 4/40
 - 166s - loss: 0.0501 - acc: 0.9876 - val_loss: 0.0658 - val_acc: 0.9837
Epoch 5/40
 - 166s - loss: 0.0487 - acc: 0.9880 - val_loss: 0.0698 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 14.37 minutes 
==================================================================================================
	PARSING TIME: 9.0 minutes 
==================================================================================================
	Identification : 0.546
	P, R  : 0.487, 0.62

==================================================================================================
	XP Ends: 30/6 (0 h:45)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (0h:45)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 44)       606892      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 23)       2507        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 47)        648271      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 13)        1417        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_268 (Concatenate)   (None, 50, 67)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 188)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 52)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 343)          563892      concatenate_268[0][0]            
__________________________________________________________________________________________________
concatenate_269 (Concatenate)   (None, 240)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_270 (Concatenate)   (None, 583)          0           phraseRnn[0][0]                  
                                                                 concatenate_269[0][0]            
__________________________________________________________________________________________________
dense_179 (Dense)               (None, 75)           43800       concatenate_270[0][0]            
__________________________________________________________________________________________________
dense_180 (Dense)               (None, 4)            304         dense_179[0][0]                  
==================================================================================================
Total params: 1,867,083
Trainable params: 1,867,083
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 332s - loss: 12.0845 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 2/40
 - 332s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 3/40
 - 332s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 4/40
 - 332s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 5/40
 - 332s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 00005: early stopping
	TRAINING TIME: 29.18 minutes 
==================================================================================================
	PARSING TIME: 3.73 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (1 h:18)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,123            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.016          ,50             ,11             ,143            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
15             ,152            ,True           ,True           ,62             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 123, False, 0.016, 50, 11, 143, 15, 152, True, True, 62
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (1h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 143)      1635634     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1672        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 152)       1738576     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 15)        2280        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_271 (Concatenate)   (None, 50, 154)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 760)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 75)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 62)           53816       concatenate_271[0][0]            
__________________________________________________________________________________________________
concatenate_272 (Concatenate)   (None, 835)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_273 (Concatenate)   (None, 897)          0           phraseRnn[0][0]                  
                                                                 concatenate_272[0][0]            
__________________________________________________________________________________________________
dense_181 (Dense)               (None, 123)          110454      concatenate_273[0][0]            
__________________________________________________________________________________________________
dense_182 (Dense)               (None, 4)            496         dense_181[0][0]                  
==================================================================================================
Total params: 3,542,928
Trainable params: 3,542,928
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 167s - loss: 0.0654 - acc: 0.9828 - val_loss: 0.2896 - val_acc: 0.8903
Epoch 2/40
 - 167s - loss: 0.0492 - acc: 0.9880 - val_loss: 0.0543 - val_acc: 0.9861
Epoch 3/40
 - 165s - loss: 0.0465 - acc: 0.9888 - val_loss: 0.0549 - val_acc: 0.9863
Epoch 4/40
 - 165s - loss: 0.0452 - acc: 0.9891 - val_loss: 0.0582 - val_acc: 0.9861
Epoch 5/40
 - 165s - loss: 0.0445 - acc: 0.9893 - val_loss: 0.0612 - val_acc: 0.9861
Epoch 6/40
 - 165s - loss: 0.0440 - acc: 0.9894 - val_loss: 0.0643 - val_acc: 0.9861
Epoch 00006: early stopping
	TRAINING TIME: 17.48 minutes 
==================================================================================================
	PARSING TIME: 5.35 minutes 
==================================================================================================
	Identification : 0.547
	P, R  : 0.582, 0.516

==================================================================================================
	XP Ends: 30/6 (1 h:41)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (1h:41)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 143)      1344343     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1859        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 152)       1428952     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 15)        2535        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_274 (Concatenate)   (None, 50, 154)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 760)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 75)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 62)           53816       concatenate_274[0][0]            
__________________________________________________________________________________________________
concatenate_275 (Concatenate)   (None, 835)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_276 (Concatenate)   (None, 897)          0           phraseRnn[0][0]                  
                                                                 concatenate_275[0][0]            
__________________________________________________________________________________________________
dense_183 (Dense)               (None, 123)          110454      concatenate_276[0][0]            
__________________________________________________________________________________________________
dense_184 (Dense)               (None, 4)            496         dense_183[0][0]                  
==================================================================================================
Total params: 2,942,455
Trainable params: 2,942,455
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 111s - loss: 0.0753 - acc: 0.9798 - val_loss: 0.0588 - val_acc: 0.9847
Epoch 2/40
 - 111s - loss: 0.0527 - acc: 0.9869 - val_loss: 0.0585 - val_acc: 0.9852
Epoch 3/40
 - 111s - loss: 0.0492 - acc: 0.9880 - val_loss: 0.0616 - val_acc: 0.9846
Epoch 4/40
 - 111s - loss: 0.0477 - acc: 0.9883 - val_loss: 0.0655 - val_acc: 0.9845
Epoch 5/40
 - 111s - loss: 0.0467 - acc: 0.9885 - val_loss: 0.0708 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 9.78 minutes 
==================================================================================================
	PARSING TIME: 8.25 minutes 
==================================================================================================
	Identification : 0.427
	P, R  : 0.336, 0.586

==================================================================================================
	XP Ends: 30/6 (2 h:0)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (2h:0)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 143)      3156153     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1199        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 152)       3354792     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 15)        1635        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_277 (Concatenate)   (None, 50, 154)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 760)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 75)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 62)           53816       concatenate_277[0][0]            
__________________________________________________________________________________________________
concatenate_278 (Concatenate)   (None, 835)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_279 (Concatenate)   (None, 897)          0           phraseRnn[0][0]                  
                                                                 concatenate_278[0][0]            
__________________________________________________________________________________________________
dense_185 (Dense)               (None, 123)          110454      concatenate_279[0][0]            
__________________________________________________________________________________________________
dense_186 (Dense)               (None, 4)            496         dense_185[0][0]                  
==================================================================================================
Total params: 6,678,545
Trainable params: 6,678,545
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 226s - loss: 0.0645 - acc: 0.9828 - val_loss: 0.0583 - val_acc: 0.9849
Epoch 2/40
 - 227s - loss: 0.0488 - acc: 0.9879 - val_loss: 0.0593 - val_acc: 0.9847
Epoch 3/40
 - 226s - loss: 0.0462 - acc: 0.9888 - val_loss: 0.0626 - val_acc: 0.9845
Epoch 4/40
 - 227s - loss: 0.0447 - acc: 0.9892 - val_loss: 0.0726 - val_acc: 0.9841
Epoch 5/40
 - 226s - loss: 0.0435 - acc: 0.9893 - val_loss: 0.0810 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 20.43 minutes 
==================================================================================================
	PARSING TIME: 3.53 minutes 
==================================================================================================
	Identification : 0.47
	P, R  : 0.405, 0.561

==================================================================================================
	XP Ends: 30/6 (2 h:24)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,197            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.021          ,50             ,7              ,89             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
33             ,120            ,True           ,True           ,215            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 197, True, 0.021, 50, 7, 89, 33, 120, True, True, 215
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (2h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 89)       671505      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 120)       905400      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 33)        5016        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_280 (Concatenate)   (None, 50, 96)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 600)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 165)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 215)          201240      concatenate_280[0][0]            
__________________________________________________________________________________________________
concatenate_281 (Concatenate)   (None, 765)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_282 (Concatenate)   (None, 980)          0           phraseRnn[0][0]                  
                                                                 concatenate_281[0][0]            
__________________________________________________________________________________________________
dense_187 (Dense)               (None, 197)          193257      concatenate_282[0][0]            
__________________________________________________________________________________________________
dense_188 (Dense)               (None, 4)            792         dense_187[0][0]                  
==================================================================================================
Total params: 1,978,274
Trainable params: 1,978,274
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 141s - loss: 0.0820 - acc: 0.9801 - val_loss: 0.0582 - val_acc: 0.9847
Epoch 2/40
 - 141s - loss: 0.0520 - acc: 0.9869 - val_loss: 0.0562 - val_acc: 0.9857
Epoch 3/40
 - 141s - loss: 0.0485 - acc: 0.9881 - val_loss: 0.0581 - val_acc: 0.9854
Epoch 4/40
 - 141s - loss: 0.0467 - acc: 0.9886 - val_loss: 0.0600 - val_acc: 0.9857
Epoch 5/40
 - 141s - loss: 0.0456 - acc: 0.9889 - val_loss: 0.0661 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 12.57 minutes 
==================================================================================================
	PARSING TIME: 4.3 minutes 
==================================================================================================
	Identification : 0.573
	P, R  : 0.623, 0.53

==================================================================================================
	XP Ends: 30/6 (2 h:41)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (2h:41)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 89)       644449      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 120)       868920      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 33)        5577        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_283 (Concatenate)   (None, 50, 96)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 600)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 165)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 215)          201240      concatenate_283[0][0]            
__________________________________________________________________________________________________
concatenate_284 (Concatenate)   (None, 765)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_285 (Concatenate)   (None, 980)          0           phraseRnn[0][0]                  
                                                                 concatenate_284[0][0]            
__________________________________________________________________________________________________
dense_189 (Dense)               (None, 197)          193257      concatenate_285[0][0]            
__________________________________________________________________________________________________
dense_190 (Dense)               (None, 4)            792         dense_189[0][0]                  
==================================================================================================
Total params: 1,915,418
Trainable params: 1,915,418
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 96s - loss: 0.0734 - acc: 0.9802 - val_loss: 0.0598 - val_acc: 0.9845
Epoch 2/40
 - 96s - loss: 0.0523 - acc: 0.9868 - val_loss: 0.0593 - val_acc: 0.9847
Epoch 3/40
 - 96s - loss: 0.0486 - acc: 0.9882 - val_loss: 0.0623 - val_acc: 0.9850
Epoch 4/40
 - 96s - loss: 0.0471 - acc: 0.9885 - val_loss: 0.0657 - val_acc: 0.9846
Epoch 5/40
 - 96s - loss: 0.0462 - acc: 0.9887 - val_loss: 0.0698 - val_acc: 0.9845
Epoch 00005: early stopping
	TRAINING TIME: 8.47 minutes 
==================================================================================================
	PARSING TIME: 6.57 minutes 
==================================================================================================
	Identification : 0.511
	P, R  : 0.426, 0.638

==================================================================================================
	XP Ends: 30/6 (2 h:57)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (2h:57)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 89)       1227577     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 120)       1655160     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 33)        3597        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_286 (Concatenate)   (None, 50, 96)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 600)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 165)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 215)          201240      concatenate_286[0][0]            
__________________________________________________________________________________________________
concatenate_287 (Concatenate)   (None, 765)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_288 (Concatenate)   (None, 980)          0           phraseRnn[0][0]                  
                                                                 concatenate_287[0][0]            
__________________________________________________________________________________________________
dense_191 (Dense)               (None, 197)          193257      concatenate_288[0][0]            
__________________________________________________________________________________________________
dense_192 (Dense)               (None, 4)            792         dense_191[0][0]                  
==================================================================================================
Total params: 3,282,386
Trainable params: 3,282,386
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 191s - loss: 0.0722 - acc: 0.9811 - val_loss: 0.0586 - val_acc: 0.9839
Epoch 2/40
 - 191s - loss: 0.0522 - acc: 0.9866 - val_loss: 0.0588 - val_acc: 0.9842
Epoch 3/40
 - 191s - loss: 0.0490 - acc: 0.9878 - val_loss: 0.0604 - val_acc: 0.9840
Epoch 4/40
 - 191s - loss: 0.0472 - acc: 0.9884 - val_loss: 0.0655 - val_acc: 0.9839
Epoch 5/40
 - 191s - loss: 0.0459 - acc: 0.9887 - val_loss: 0.0733 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 17.4 minutes 
==================================================================================================
	PARSING TIME: 3.4 minutes 
==================================================================================================
	Identification : 0.505
	P, R  : 0.45, 0.576

==================================================================================================
	XP Ends: 30/6 (3 h:18)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,46             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.014          ,50             ,49             ,173            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,33             ,True           ,False          ,161            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 46, True, 0.014, 50, 49, 173, 8, 33, True, False, 161
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (3h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 173)      1305285     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       7448        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 33)        248985      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_289 (Concatenate)   (None, 50, 222)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 132)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 161)          185472      concatenate_289[0][0]            
__________________________________________________________________________________________________
concatenate_290 (Concatenate)   (None, 164)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_291 (Concatenate)   (None, 325)          0           phraseRnn[0][0]                  
                                                                 concatenate_290[0][0]            
__________________________________________________________________________________________________
dense_193 (Dense)               (None, 46)           14996       concatenate_291[0][0]            
__________________________________________________________________________________________________
dense_194 (Dense)               (None, 4)            188         dense_193[0][0]                  
==================================================================================================
Total params: 1,763,590
Trainable params: 1,763,590
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 142s - loss: 0.0790 - acc: 0.9794 - val_loss: 0.0632 - val_acc: 0.9840
Epoch 2/40
 - 142s - loss: 0.0559 - acc: 0.9860 - val_loss: 0.0616 - val_acc: 0.9849
Epoch 3/40
 - 142s - loss: 0.0516 - acc: 0.9873 - val_loss: 0.0624 - val_acc: 0.9850
Epoch 4/40
 - 142s - loss: 0.0494 - acc: 0.9879 - val_loss: 0.0639 - val_acc: 0.9848
Epoch 5/40
 - 142s - loss: 0.0481 - acc: 0.9883 - val_loss: 0.0652 - val_acc: 0.9848
Epoch 00005: early stopping
	TRAINING TIME: 12.57 minutes 
==================================================================================================
	PARSING TIME: 4.25 minutes 
==================================================================================================
	Identification : 0.587
	P, R  : 0.76, 0.478

==================================================================================================
	XP Ends: 30/6 (3 h:35)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (3h:35)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 173)      1252693     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       8281        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 33)        238953      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_292 (Concatenate)   (None, 50, 222)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 132)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 161)          185472      concatenate_292[0][0]            
__________________________________________________________________________________________________
concatenate_293 (Concatenate)   (None, 164)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_294 (Concatenate)   (None, 325)          0           phraseRnn[0][0]                  
                                                                 concatenate_293[0][0]            
__________________________________________________________________________________________________
dense_195 (Dense)               (None, 46)           14996       concatenate_294[0][0]            
__________________________________________________________________________________________________
dense_196 (Dense)               (None, 4)            188         dense_195[0][0]                  
==================================================================================================
Total params: 1,701,935
Trainable params: 1,701,935
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 96s - loss: 0.0911 - acc: 0.9755 - val_loss: 0.0743 - val_acc: 0.9808
Epoch 2/40
 - 96s - loss: 0.0613 - acc: 0.9841 - val_loss: 0.0689 - val_acc: 0.9826
Epoch 3/40
 - 96s - loss: 0.0563 - acc: 0.9855 - val_loss: 0.0684 - val_acc: 0.9830
Epoch 4/40
 - 96s - loss: 0.0536 - acc: 0.9864 - val_loss: 0.0702 - val_acc: 0.9828
Epoch 5/40
 - 96s - loss: 0.0519 - acc: 0.9869 - val_loss: 0.0713 - val_acc: 0.9829
Epoch 00005: early stopping
	TRAINING TIME: 8.47 minutes 
==================================================================================================
	PARSING TIME: 6.57 minutes 
==================================================================================================
	Identification : 0.549
	P, R  : 0.568, 0.532

==================================================================================================
	XP Ends: 30/6 (3 h:51)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (3h:51)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 173)      2386189     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 49)       5341        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 33)        455169      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_295 (Concatenate)   (None, 50, 222)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 132)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 161)          185472      concatenate_295[0][0]            
__________________________________________________________________________________________________
concatenate_296 (Concatenate)   (None, 164)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_297 (Concatenate)   (None, 325)          0           phraseRnn[0][0]                  
                                                                 concatenate_296[0][0]            
__________________________________________________________________________________________________
dense_197 (Dense)               (None, 46)           14996       concatenate_297[0][0]            
__________________________________________________________________________________________________
dense_198 (Dense)               (None, 4)            188         dense_197[0][0]                  
==================================================================================================
Total params: 3,048,227
Trainable params: 3,048,227
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 191s - loss: 0.0785 - acc: 0.9790 - val_loss: 0.0633 - val_acc: 0.9830
Epoch 2/40
 - 191s - loss: 0.0569 - acc: 0.9851 - val_loss: 0.0630 - val_acc: 0.9833
Epoch 3/40
 - 191s - loss: 0.0530 - acc: 0.9864 - val_loss: 0.0646 - val_acc: 0.9832
Epoch 4/40
 - 191s - loss: 0.0510 - acc: 0.9871 - val_loss: 0.0665 - val_acc: 0.9832
Epoch 5/40
 - 190s - loss: 0.0495 - acc: 0.9876 - val_loss: 0.0705 - val_acc: 0.9829
Epoch 00005: early stopping
	TRAINING TIME: 17.32 minutes 
==================================================================================================
	PARSING TIME: 2.88 minutes 
==================================================================================================
	Identification : 0.464
	P, R  : 0.505, 0.429

==================================================================================================
	XP Ends: 30/6 (4 h:11)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,86             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.053          ,50             ,21             ,36             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
39             ,139            ,True           ,False          ,81             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 86, False, 0.053, 50, 21, 36, 39, 139, True, False, 81
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (4h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 36)       271620      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 21)       3192        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 139)       1048755     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 39)        5928        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_298 (Concatenate)   (None, 50, 57)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 556)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 156)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 81)           45036       concatenate_298[0][0]            
__________________________________________________________________________________________________
concatenate_299 (Concatenate)   (None, 712)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_300 (Concatenate)   (None, 793)          0           phraseRnn[0][0]                  
                                                                 concatenate_299[0][0]            
__________________________________________________________________________________________________
dense_199 (Dense)               (None, 86)           68284       concatenate_300[0][0]            
__________________________________________________________________________________________________
dense_200 (Dense)               (None, 4)            348         dense_199[0][0]                  
==================================================================================================
Total params: 1,443,163
Trainable params: 1,443,163
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 167s - loss: 0.0679 - acc: 0.9823 - val_loss: 0.0569 - val_acc: 0.9852
Epoch 2/40
 - 166s - loss: 0.0515 - acc: 0.9871 - val_loss: 0.0566 - val_acc: 0.9855
Epoch 3/40
 - 165s - loss: 0.0485 - acc: 0.9881 - val_loss: 0.0584 - val_acc: 0.9853
Epoch 4/40
 - 165s - loss: 0.0470 - acc: 0.9885 - val_loss: 0.0608 - val_acc: 0.9856
Epoch 5/40
 - 165s - loss: 0.0459 - acc: 0.9888 - val_loss: 0.0660 - val_acc: 0.9854
Epoch 00005: early stopping
	TRAINING TIME: 14.72 minutes 
==================================================================================================
	PARSING TIME: 5.27 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.616, 0.542

==================================================================================================
	XP Ends: 30/6 (4 h:32)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (4h:32)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 36)       260676      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 21)       3549        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 139)       1006499     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 39)        6591        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_301 (Concatenate)   (None, 50, 57)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 556)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 156)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 81)           45036       concatenate_301[0][0]            
__________________________________________________________________________________________________
concatenate_302 (Concatenate)   (None, 712)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_303 (Concatenate)   (None, 793)          0           phraseRnn[0][0]                  
                                                                 concatenate_302[0][0]            
__________________________________________________________________________________________________
dense_201 (Dense)               (None, 86)           68284       concatenate_303[0][0]            
__________________________________________________________________________________________________
dense_202 (Dense)               (None, 4)            348         dense_201[0][0]                  
==================================================================================================
Total params: 1,390,983
Trainable params: 1,390,983
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0756 - acc: 0.9794 - val_loss: 0.0627 - val_acc: 0.9832
Epoch 2/40
 - 110s - loss: 0.0565 - acc: 0.9852 - val_loss: 0.0631 - val_acc: 0.9829
Epoch 3/40
 - 110s - loss: 0.0526 - acc: 0.9865 - val_loss: 0.0664 - val_acc: 0.9827
Epoch 4/40
 - 110s - loss: 0.0507 - acc: 0.9871 - val_loss: 0.0673 - val_acc: 0.9835
Epoch 5/40
 - 110s - loss: 0.0490 - acc: 0.9876 - val_loss: 0.0736 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 9.68 minutes 
==================================================================================================
	PARSING TIME: 8.13 minutes 
==================================================================================================
	Identification : 0.491
	P, R  : 0.426, 0.58

==================================================================================================
	XP Ends: 30/6 (4 h:50)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (4h:50)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 36)       496548      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 21)       2289        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 139)       1917227     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 39)        4251        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_304 (Concatenate)   (None, 50, 57)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 556)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 156)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 81)           45036       concatenate_304[0][0]            
__________________________________________________________________________________________________
concatenate_305 (Concatenate)   (None, 712)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_306 (Concatenate)   (None, 793)          0           phraseRnn[0][0]                  
                                                                 concatenate_305[0][0]            
__________________________________________________________________________________________________
dense_203 (Dense)               (None, 86)           68284       concatenate_306[0][0]            
__________________________________________________________________________________________________
dense_204 (Dense)               (None, 4)            348         dense_203[0][0]                  
==================================================================================================
Total params: 2,533,983
Trainable params: 2,533,983
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 220s - loss: 0.0686 - acc: 0.9817 - val_loss: 0.0578 - val_acc: 0.9840
Epoch 2/40
 - 220s - loss: 0.0536 - acc: 0.9859 - val_loss: 0.0609 - val_acc: 0.9836
Epoch 3/40
 - 220s - loss: 0.0511 - acc: 0.9869 - val_loss: 0.0615 - val_acc: 0.9839
Epoch 4/40
 - 220s - loss: 0.0486 - acc: 0.9878 - val_loss: 0.0651 - val_acc: 0.9837
Epoch 5/40
 - 220s - loss: 0.0470 - acc: 0.9882 - val_loss: 0.0718 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 19.8 minutes 
==================================================================================================
	PARSING TIME: 3.58 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.467, 0.531

==================================================================================================
	XP Ends: 30/6 (5 h:14)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,54             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.071          ,50             ,11             ,40             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
7              ,50             ,True           ,True           ,449            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 54, True, 0.071, 50, 11, 40, 7, 50, True, True, 449
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (5h:14)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 40)       301800      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1672        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 50)        377250      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1064        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_307 (Concatenate)   (None, 50, 51)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 250)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 449)          674847      concatenate_307[0][0]            
__________________________________________________________________________________________________
concatenate_308 (Concatenate)   (None, 285)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_309 (Concatenate)   (None, 734)          0           phraseRnn[0][0]                  
                                                                 concatenate_308[0][0]            
__________________________________________________________________________________________________
dense_205 (Dense)               (None, 54)           39690       concatenate_309[0][0]            
__________________________________________________________________________________________________
dense_206 (Dense)               (None, 4)            220         dense_205[0][0]                  
==================================================================================================
Total params: 1,396,543
Trainable params: 1,396,543
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 258s - loss: 12.0814 - acc: 0.2501 - val_loss: 12.0911 - val_acc: 0.2498
Epoch 2/40
 - 258s - loss: 12.0875 - acc: 0.2501 - val_loss: 12.0911 - val_acc: 0.2498
Epoch 3/40
 - 258s - loss: 12.0875 - acc: 0.2501 - val_loss: 12.0911 - val_acc: 0.2498
Epoch 4/40
 - 258s - loss: 12.0875 - acc: 0.2501 - val_loss: 12.0911 - val_acc: 0.2498
Epoch 5/40
 - 258s - loss: 12.0875 - acc: 0.2501 - val_loss: 12.0911 - val_acc: 0.2498
Epoch 00005: early stopping
	TRAINING TIME: 22.33 minutes 
==================================================================================================
	PARSING TIME: 10.97 minutes 
==================================================================================================
	Identification : 0.001
	P, R  : 0.001, 0.001

==================================================================================================
	XP Ends: 30/6 (5 h:47)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (5h:47)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 40)       289640      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1859        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 50)        362050      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1183        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_310 (Concatenate)   (None, 50, 51)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 250)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 449)          674847      concatenate_310[0][0]            
__________________________________________________________________________________________________
concatenate_311 (Concatenate)   (None, 285)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_312 (Concatenate)   (None, 734)          0           phraseRnn[0][0]                  
                                                                 concatenate_311[0][0]            
__________________________________________________________________________________________________
dense_207 (Dense)               (None, 54)           39690       concatenate_312[0][0]            
__________________________________________________________________________________________________
dense_208 (Dense)               (None, 4)            220         dense_207[0][0]                  
==================================================================================================
Total params: 1,369,489
Trainable params: 1,369,489
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 176s - loss: 12.0725 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 2/40
 - 176s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 3/40
 - 176s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 4/40
 - 176s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 5/40
 - 176s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 00005: early stopping
	TRAINING TIME: 15.18 minutes 
==================================================================================================
	PARSING TIME: 17.7 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (6 h:21)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (6h:21)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 40)       551720      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1199        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 50)        689650      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         763         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_313 (Concatenate)   (None, 50, 51)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 250)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 449)          674847      concatenate_313[0][0]            
__________________________________________________________________________________________________
concatenate_314 (Concatenate)   (None, 285)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_315 (Concatenate)   (None, 734)          0           phraseRnn[0][0]                  
                                                                 concatenate_314[0][0]            
__________________________________________________________________________________________________
dense_209 (Dense)               (None, 54)           39690       concatenate_315[0][0]            
__________________________________________________________________________________________________
dense_210 (Dense)               (None, 4)            220         dense_209[0][0]                  
==================================================================================================
Total params: 1,958,089
Trainable params: 1,958,089
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 352s - loss: 12.0848 - acc: 0.2500 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 2/40
 - 352s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 3/40
 - 352s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 4/40
 - 352s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 5/40
 - 352s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 00005: early stopping
	TRAINING TIME: 30.83 minutes 
==================================================================================================
	PARSING TIME: 10.32 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.047

==================================================================================================
	XP Ends: 30/6 (7 h:2)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,208            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.069          ,50             ,8              ,28             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
25             ,113            ,True           ,True           ,33             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 208, True, 0.069, 50, 8, 28, 25, 113, True, True, 33
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (7h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 28)       320264      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 113)       1292494     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        3800        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_316 (Concatenate)   (None, 50, 36)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 565)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 33)           6930        concatenate_316[0][0]            
__________________________________________________________________________________________________
concatenate_317 (Concatenate)   (None, 690)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_318 (Concatenate)   (None, 723)          0           phraseRnn[0][0]                  
                                                                 concatenate_317[0][0]            
__________________________________________________________________________________________________
dense_211 (Dense)               (None, 208)          150592      concatenate_318[0][0]            
__________________________________________________________________________________________________
dense_212 (Dense)               (None, 4)            836         dense_211[0][0]                  
==================================================================================================
Total params: 1,776,132
Trainable params: 1,776,132
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 138s - loss: 0.0676 - acc: 0.9830 - val_loss: 0.0542 - val_acc: 0.9862
Epoch 2/40
 - 138s - loss: 0.0485 - acc: 0.9881 - val_loss: 0.0543 - val_acc: 0.9860
Epoch 3/40
 - 138s - loss: 0.0460 - acc: 0.9890 - val_loss: 0.0577 - val_acc: 0.9860
Epoch 4/40
 - 138s - loss: 0.0450 - acc: 0.9892 - val_loss: 0.0601 - val_acc: 0.9863
Epoch 5/40
 - 138s - loss: 0.0441 - acc: 0.9894 - val_loss: 0.0690 - val_acc: 0.9861
Epoch 00005: early stopping
	TRAINING TIME: 12.23 minutes 
==================================================================================================
	PARSING TIME: 4.32 minutes 
==================================================================================================
	Identification : 0.535
	P, R  : 0.486, 0.594

==================================================================================================
	XP Ends: 30/6 (7 h:19)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (7h:19)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 28)       263228      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 113)       1062313     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        4225        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_319 (Concatenate)   (None, 50, 36)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 565)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 33)           6930        concatenate_319[0][0]            
__________________________________________________________________________________________________
concatenate_320 (Concatenate)   (None, 690)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_321 (Concatenate)   (None, 723)          0           phraseRnn[0][0]                  
                                                                 concatenate_320[0][0]            
__________________________________________________________________________________________________
dense_213 (Dense)               (None, 208)          150592      concatenate_321[0][0]            
__________________________________________________________________________________________________
dense_214 (Dense)               (None, 4)            836         dense_213[0][0]                  
==================================================================================================
Total params: 1,489,476
Trainable params: 1,489,476
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0782 - acc: 0.9799 - val_loss: 0.0573 - val_acc: 0.9850
Epoch 2/40
 - 94s - loss: 0.0514 - acc: 0.9872 - val_loss: 0.0600 - val_acc: 0.9852
Epoch 3/40
 - 93s - loss: 0.0480 - acc: 0.9883 - val_loss: 0.0608 - val_acc: 0.9855
Epoch 4/40
 - 93s - loss: 0.0469 - acc: 0.9885 - val_loss: 0.0659 - val_acc: 0.9852
Epoch 5/40
 - 93s - loss: 0.0463 - acc: 0.9886 - val_loss: 0.0721 - val_acc: 0.9852
Epoch 00005: early stopping
	TRAINING TIME: 8.28 minutes 
==================================================================================================
	PARSING TIME: 6.55 minutes 
==================================================================================================
	Identification : 0.488
	P, R  : 0.393, 0.644

==================================================================================================
	XP Ends: 30/6 (7 h:34)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (7h:34)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 28)       617988      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 113)       2494023     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        2725        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_322 (Concatenate)   (None, 50, 36)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 565)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 33)           6930        concatenate_322[0][0]            
__________________________________________________________________________________________________
concatenate_323 (Concatenate)   (None, 690)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_324 (Concatenate)   (None, 723)          0           phraseRnn[0][0]                  
                                                                 concatenate_323[0][0]            
__________________________________________________________________________________________________
dense_215 (Dense)               (None, 208)          150592      concatenate_324[0][0]            
__________________________________________________________________________________________________
dense_216 (Dense)               (None, 4)            836         dense_215[0][0]                  
==================================================================================================
Total params: 3,273,966
Trainable params: 3,273,966
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 188s - loss: 0.0642 - acc: 0.9833 - val_loss: 0.0579 - val_acc: 0.9847
Epoch 2/40
 - 188s - loss: 0.0483 - acc: 0.9881 - val_loss: 0.0594 - val_acc: 0.9841
Epoch 3/40
 - 188s - loss: 0.0456 - acc: 0.9890 - val_loss: 0.0649 - val_acc: 0.9847
Epoch 4/40
 - 188s - loss: 0.0441 - acc: 0.9893 - val_loss: 0.0804 - val_acc: 0.9840
Epoch 5/40
 - 188s - loss: 0.0431 - acc: 0.9894 - val_loss: 0.0903 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 17.22 minutes 
==================================================================================================
	PARSING TIME: 2.83 minutes 
==================================================================================================
	Identification : 0.486
	P, R  : 0.458, 0.518

==================================================================================================
	XP Ends: 30/6 (7 h:55)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,203            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.09           ,50             ,17             ,30             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
27             ,59             ,False          ,True           ,349            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 203, False, 0.09, 50, 17, 30, 27, 59, False, True, 349
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (7h:55)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 30)       226350      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2584        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 59)        445155      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 27)        4104        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_325 (Concatenate)   (None, 50, 47)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 236)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 108)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 349)          554212      concatenate_325[0][0]            
__________________________________________________________________________________________________
concatenate_326 (Concatenate)   (None, 344)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_327 (Concatenate)   (None, 693)          0           phraseRnn[0][0]                  
                                                                 concatenate_326[0][0]            
__________________________________________________________________________________________________
dense_217 (Dense)               (None, 203)          140882      concatenate_327[0][0]            
__________________________________________________________________________________________________
dense_218 (Dense)               (None, 4)            816         dense_217[0][0]                  
==================================================================================================
Total params: 1,374,103
Trainable params: 1,374,103
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 249s - loss: 12.0955 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 2/40
 - 250s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 3/40
 - 250s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 4/40
 - 250s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 5/40
 - 250s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 00005: early stopping
	TRAINING TIME: 21.7 minutes 
==================================================================================================
	PARSING TIME: 11.35 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (8 h:28)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (8h:28)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 30)       217230      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2873        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 59)        427219      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 27)        4563        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_328 (Concatenate)   (None, 50, 47)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 236)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 108)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 349)          554212      concatenate_328[0][0]            
__________________________________________________________________________________________________
concatenate_329 (Concatenate)   (None, 344)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_330 (Concatenate)   (None, 693)          0           phraseRnn[0][0]                  
                                                                 concatenate_329[0][0]            
__________________________________________________________________________________________________
dense_219 (Dense)               (None, 203)          140882      concatenate_330[0][0]            
__________________________________________________________________________________________________
dense_220 (Dense)               (None, 4)            816         dense_219[0][0]                  
==================================================================================================
Total params: 1,347,795
Trainable params: 1,347,795
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 169s - loss: 12.0716 - acc: 0.2507 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 2/40
 - 169s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 3/40
 - 169s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 4/40
 - 169s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 5/40
 - 169s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 00005: early stopping
	TRAINING TIME: 14.7 minutes 
==================================================================================================
	PARSING TIME: 17.37 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (9 h:1)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (9h:1)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 30)       413790      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       1853        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 59)        813787      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 27)        2943        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_331 (Concatenate)   (None, 50, 47)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 236)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 108)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 349)          554212      concatenate_331[0][0]            
__________________________________________________________________________________________________
concatenate_332 (Concatenate)   (None, 344)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_333 (Concatenate)   (None, 693)          0           phraseRnn[0][0]                  
                                                                 concatenate_332[0][0]            
__________________________________________________________________________________________________
dense_221 (Dense)               (None, 203)          140882      concatenate_333[0][0]            
__________________________________________________________________________________________________
dense_222 (Dense)               (None, 4)            816         dense_221[0][0]                  
==================================================================================================
Total params: 1,928,283
Trainable params: 1,928,283
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 339s - loss: 12.0907 - acc: 0.2496 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 2/40
 - 339s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 3/40
 - 339s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 4/40
 - 339s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 5/40
 - 339s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 00005: early stopping
	TRAINING TIME: 29.7 minutes 
==================================================================================================
	PARSING TIME: 3.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (9 h:35)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,354            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.087          ,50             ,18             ,31             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,158            ,False          ,True           ,71             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 354, False, 0.087, 50, 18, 31, 10, 158, False, True, 71
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (9h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       354578      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       2736        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 158)       1807204     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_334 (Concatenate)   (None, 50, 49)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 632)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 71)           34364       concatenate_334[0][0]            
__________________________________________________________________________________________________
concatenate_335 (Concatenate)   (None, 672)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_336 (Concatenate)   (None, 743)          0           phraseRnn[0][0]                  
                                                                 concatenate_335[0][0]            
__________________________________________________________________________________________________
dense_223 (Dense)               (None, 354)          263376      concatenate_336[0][0]            
__________________________________________________________________________________________________
dense_224 (Dense)               (None, 4)            1420        dense_223[0][0]                  
==================================================================================================
Total params: 2,465,198
Trainable params: 2,465,198
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 163s - loss: 4.3201 - acc: 0.7316 - val_loss: 4.3240 - val_acc: 0.7317
Epoch 2/40
 - 163s - loss: 4.3095 - acc: 0.7326 - val_loss: 4.3240 - val_acc: 0.7317
Epoch 3/40
 - 163s - loss: 4.3095 - acc: 0.7326 - val_loss: 4.3240 - val_acc: 0.7317
Epoch 4/40
 - 163s - loss: 4.3095 - acc: 0.7326 - val_loss: 4.3240 - val_acc: 0.7317
Epoch 5/40
 - 163s - loss: 4.3095 - acc: 0.7326 - val_loss: 4.3240 - val_acc: 0.7317
Epoch 00005: early stopping
	TRAINING TIME: 14.45 minutes 
==================================================================================================
	PARSING TIME: 5.13 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (9 h:55)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (9h:55)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       291431      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       3042        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 158)       1485358     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_337 (Concatenate)   (None, 50, 49)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 632)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 71)           34364       concatenate_337[0][0]            
__________________________________________________________________________________________________
concatenate_338 (Concatenate)   (None, 672)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_339 (Concatenate)   (None, 743)          0           phraseRnn[0][0]                  
                                                                 concatenate_338[0][0]            
__________________________________________________________________________________________________
dense_225 (Dense)               (None, 354)          263376      concatenate_339[0][0]            
__________________________________________________________________________________________________
dense_226 (Dense)               (None, 4)            1420        dense_225[0][0]                  
==================================================================================================
Total params: 2,080,681
Trainable params: 2,080,681
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 12.0872 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 2/40
 - 110s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 3/40
 - 110s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 4/40
 - 110s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 5/40
 - 110s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 00005: early stopping
	TRAINING TIME: 9.72 minutes 
==================================================================================================
	PARSING TIME: 20.72 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.076

==================================================================================================
	XP Ends: 30/6 (10 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (10h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       684201      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       1962        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 158)       3487218     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_340 (Concatenate)   (None, 50, 49)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 632)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 71)           34364       concatenate_340[0][0]            
__________________________________________________________________________________________________
concatenate_341 (Concatenate)   (None, 672)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_342 (Concatenate)   (None, 743)          0           phraseRnn[0][0]                  
                                                                 concatenate_341[0][0]            
__________________________________________________________________________________________________
dense_227 (Dense)               (None, 354)          263376      concatenate_342[0][0]            
__________________________________________________________________________________________________
dense_228 (Dense)               (None, 4)            1420        dense_227[0][0]                  
==================================================================================================
Total params: 4,473,631
Trainable params: 4,473,631
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 222s - loss: 12.0894 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 2/40
 - 222s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 3/40
 - 222s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 4/40
 - 222s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 5/40
 - 222s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 20.02 minutes 
==================================================================================================
	PARSING TIME: 6.52 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (10 h:52)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,269            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.023          ,50             ,22             ,193            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
35             ,44             ,True           ,False          ,98             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 269, True, 0.023, 50, 22, 193, 35, 44, True, False, 98
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (10h:52)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 193)      1456185     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       3344        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 44)        331980      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 35)        5320        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_343 (Concatenate)   (None, 50, 215)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 176)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 140)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 98)           92316       concatenate_343[0][0]            
__________________________________________________________________________________________________
concatenate_344 (Concatenate)   (None, 316)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_345 (Concatenate)   (None, 414)          0           phraseRnn[0][0]                  
                                                                 concatenate_344[0][0]            
__________________________________________________________________________________________________
dense_229 (Dense)               (None, 269)          111635      concatenate_345[0][0]            
__________________________________________________________________________________________________
dense_230 (Dense)               (None, 4)            1080        dense_229[0][0]                  
==================================================================================================
Total params: 2,001,860
Trainable params: 2,001,860
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 140s - loss: 0.0657 - acc: 0.9827 - val_loss: 0.0578 - val_acc: 0.9849
Epoch 2/40
 - 140s - loss: 0.0518 - acc: 0.9869 - val_loss: 0.0571 - val_acc: 0.9857
Epoch 3/40
 - 140s - loss: 0.0480 - acc: 0.9882 - val_loss: 0.0579 - val_acc: 0.9857
Epoch 4/40
 - 140s - loss: 0.0463 - acc: 0.9888 - val_loss: 0.0603 - val_acc: 0.9856
Epoch 5/40
 - 140s - loss: 0.0450 - acc: 0.9892 - val_loss: 0.0647 - val_acc: 0.9853
Epoch 00005: early stopping
	TRAINING TIME: 12.5 minutes 
==================================================================================================
	PARSING TIME: 4.25 minutes 
==================================================================================================
	Identification : 0.581
	P, R  : 0.745, 0.476

==================================================================================================
	XP Ends: 30/6 (11 h:9)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (11h:9)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 193)      1397513     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       3718        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 44)        318604      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 35)        5915        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_346 (Concatenate)   (None, 50, 215)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 176)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 140)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 98)           92316       concatenate_346[0][0]            
__________________________________________________________________________________________________
concatenate_347 (Concatenate)   (None, 316)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_348 (Concatenate)   (None, 414)          0           phraseRnn[0][0]                  
                                                                 concatenate_347[0][0]            
__________________________________________________________________________________________________
dense_231 (Dense)               (None, 269)          111635      concatenate_348[0][0]            
__________________________________________________________________________________________________
dense_232 (Dense)               (None, 4)            1080        dense_231[0][0]                  
==================================================================================================
Total params: 1,930,781
Trainable params: 1,930,781
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 96s - loss: 0.0755 - acc: 0.9795 - val_loss: 0.0622 - val_acc: 0.9834
Epoch 2/40
 - 96s - loss: 0.0559 - acc: 0.9856 - val_loss: 0.0624 - val_acc: 0.9837
Epoch 3/40
 - 96s - loss: 0.0511 - acc: 0.9870 - val_loss: 0.0640 - val_acc: 0.9837
Epoch 4/40
 - 95s - loss: 0.0488 - acc: 0.9879 - val_loss: 0.0677 - val_acc: 0.9837
Epoch 5/40
 - 95s - loss: 0.0474 - acc: 0.9883 - val_loss: 0.0732 - val_acc: 0.9833
Epoch 00005: early stopping
	TRAINING TIME: 8.43 minutes 
==================================================================================================
	PARSING TIME: 6.87 minutes 
==================================================================================================
	Identification : 0.444
	P, R  : 0.349, 0.611

==================================================================================================
	XP Ends: 30/6 (11 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (11h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 193)      2662049     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       2398        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 44)        606892      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 35)        3815        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_349 (Concatenate)   (None, 50, 215)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 176)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 140)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 98)           92316       concatenate_349[0][0]            
__________________________________________________________________________________________________
concatenate_350 (Concatenate)   (None, 316)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_351 (Concatenate)   (None, 414)          0           phraseRnn[0][0]                  
                                                                 concatenate_350[0][0]            
__________________________________________________________________________________________________
dense_233 (Dense)               (None, 269)          111635      concatenate_351[0][0]            
__________________________________________________________________________________________________
dense_234 (Dense)               (None, 4)            1080        dense_233[0][0]                  
==================================================================================================
Total params: 3,480,185
Trainable params: 3,480,185
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 196s - loss: 0.0666 - acc: 0.9818 - val_loss: 0.0579 - val_acc: 0.9840
Epoch 2/40
 - 192s - loss: 0.0532 - acc: 0.9861 - val_loss: 0.0581 - val_acc: 0.9840
Epoch 3/40
 - 192s - loss: 0.0501 - acc: 0.9873 - val_loss: 0.0627 - val_acc: 0.9835
Epoch 4/40
 - 191s - loss: 0.0481 - acc: 0.9880 - val_loss: 0.0686 - val_acc: 0.9831
Epoch 5/40
 - 192s - loss: 0.0466 - acc: 0.9884 - val_loss: 0.0727 - val_acc: 0.9832
Epoch 00005: early stopping
	TRAINING TIME: 17.55 minutes 
==================================================================================================
	PARSING TIME: 2.9 minutes 
==================================================================================================
	Identification : 0.495
	P, R  : 0.441, 0.563

==================================================================================================
	XP Ends: 30/6 (11 h:46)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,109            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.021          ,50             ,43             ,145            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
24             ,95             ,False          ,True           ,33             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 109, False, 0.021, 50, 43, 145, 24, 95, False, True, 33
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (11h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 145)      1658510     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 43)       6536        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 95)        1086610     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        3648        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_352 (Concatenate)   (None, 50, 188)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 380)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 33)           29304       concatenate_352[0][0]            
__________________________________________________________________________________________________
concatenate_353 (Concatenate)   (None, 476)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_354 (Concatenate)   (None, 509)          0           phraseRnn[0][0]                  
                                                                 concatenate_353[0][0]            
__________________________________________________________________________________________________
dense_235 (Dense)               (None, 109)          55590       concatenate_354[0][0]            
__________________________________________________________________________________________________
dense_236 (Dense)               (None, 4)            440         dense_235[0][0]                  
==================================================================================================
Total params: 2,840,638
Trainable params: 2,840,638
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 165s - loss: 0.0652 - acc: 0.9827 - val_loss: 0.0538 - val_acc: 0.9862
Epoch 2/40
 - 164s - loss: 0.0496 - acc: 0.9878 - val_loss: 0.0540 - val_acc: 0.9863
Epoch 3/40
 - 165s - loss: 0.0467 - acc: 0.9888 - val_loss: 0.0558 - val_acc: 0.9862
Epoch 4/40
 - 165s - loss: 0.0454 - acc: 0.9891 - val_loss: 0.0589 - val_acc: 0.9861
Epoch 5/40
 - 165s - loss: 0.0447 - acc: 0.9893 - val_loss: 0.0634 - val_acc: 0.9857
Epoch 00005: early stopping
	TRAINING TIME: 14.63 minutes 
==================================================================================================
	PARSING TIME: 5.38 minutes 
==================================================================================================
	Identification : 0.512
	P, R  : 0.607, 0.443

==================================================================================================
	XP Ends: 30/6 (12 h:6)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (12h:6)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 145)      1363145     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 43)       7267        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 95)        893095      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        4056        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_355 (Concatenate)   (None, 50, 188)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 380)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 33)           29304       concatenate_355[0][0]            
__________________________________________________________________________________________________
concatenate_356 (Concatenate)   (None, 476)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_357 (Concatenate)   (None, 509)          0           phraseRnn[0][0]                  
                                                                 concatenate_356[0][0]            
__________________________________________________________________________________________________
dense_237 (Dense)               (None, 109)          55590       concatenate_357[0][0]            
__________________________________________________________________________________________________
dense_238 (Dense)               (None, 4)            440         dense_237[0][0]                  
==================================================================================================
Total params: 2,352,897
Trainable params: 2,352,897
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 113s - loss: 0.0751 - acc: 0.9794 - val_loss: 0.0595 - val_acc: 0.9843
Epoch 2/40
 - 113s - loss: 0.0532 - acc: 0.9867 - val_loss: 0.0583 - val_acc: 0.9849
Epoch 3/40
 - 113s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0601 - val_acc: 0.9849
Epoch 4/40
 - 113s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0639 - val_acc: 0.9844
Epoch 5/40
 - 113s - loss: 0.0470 - acc: 0.9885 - val_loss: 0.0692 - val_acc: 0.9845
Epoch 00005: early stopping
	TRAINING TIME: 10.02 minutes 
==================================================================================================
	PARSING TIME: 8.22 minutes 
==================================================================================================
	Identification : 0.446
	P, R  : 0.346, 0.626

==================================================================================================
	XP Ends: 30/6 (12 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (12h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 145)      3200295     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 43)       4687        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 95)        2096745     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 24)        2616        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_358 (Concatenate)   (None, 50, 188)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 380)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 33)           29304       concatenate_358[0][0]            
__________________________________________________________________________________________________
concatenate_359 (Concatenate)   (None, 476)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_360 (Concatenate)   (None, 509)          0           phraseRnn[0][0]                  
                                                                 concatenate_359[0][0]            
__________________________________________________________________________________________________
dense_239 (Dense)               (None, 109)          55590       concatenate_360[0][0]            
__________________________________________________________________________________________________
dense_240 (Dense)               (None, 4)            440         dense_239[0][0]                  
==================================================================================================
Total params: 5,389,677
Trainable params: 5,389,677
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 229s - loss: 0.0639 - acc: 0.9829 - val_loss: 0.0583 - val_acc: 0.9843
Epoch 2/40
 - 229s - loss: 0.0498 - acc: 0.9874 - val_loss: 0.0588 - val_acc: 0.9845
Epoch 3/40
 - 229s - loss: 0.0473 - acc: 0.9883 - val_loss: 0.0624 - val_acc: 0.9845
Epoch 4/40
 - 229s - loss: 0.0458 - acc: 0.9888 - val_loss: 0.0672 - val_acc: 0.9843
Epoch 5/40
 - 229s - loss: 0.0446 - acc: 0.9890 - val_loss: 0.0726 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 20.6 minutes 
==================================================================================================
	PARSING TIME: 3.55 minutes 
==================================================================================================
	Identification : 0.47
	P, R  : 0.41, 0.551

==================================================================================================
	XP Ends: 30/6 (12 h:49)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,241            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.097          ,50             ,6              ,80             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
32             ,134            ,True           ,True           ,44             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 241, True, 0.097, 50, 6, 80, 32, 134, True, True, 44
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (12h:49)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 80)       915040      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 134)       1532692     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 32)        4864        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_361 (Concatenate)   (None, 50, 86)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 670)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 160)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 44)           17292       concatenate_361[0][0]            
__________________________________________________________________________________________________
concatenate_362 (Concatenate)   (None, 830)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_363 (Concatenate)   (None, 874)          0           phraseRnn[0][0]                  
                                                                 concatenate_362[0][0]            
__________________________________________________________________________________________________
dense_241 (Dense)               (None, 241)          210875      concatenate_363[0][0]            
__________________________________________________________________________________________________
dense_242 (Dense)               (None, 4)            968         dense_241[0][0]                  
==================================================================================================
Total params: 2,682,643
Trainable params: 2,682,643
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 139s - loss: 0.1667 - acc: 0.9762 - val_loss: 0.1682 - val_acc: 0.9340
Epoch 2/40
 - 139s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0550 - val_acc: 0.9864
Epoch 3/40
 - 139s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0568 - val_acc: 0.9863
Epoch 4/40
 - 139s - loss: 0.0452 - acc: 0.9891 - val_loss: 0.0630 - val_acc: 0.9862
Epoch 5/40
 - 139s - loss: 0.0444 - acc: 0.9892 - val_loss: 0.0703 - val_acc: 0.9863
Epoch 00005: early stopping
	TRAINING TIME: 12.48 minutes 
==================================================================================================
	PARSING TIME: 4.3 minutes 
==================================================================================================
	Identification : 0.545
	P, R  : 0.499, 0.6

==================================================================================================
	XP Ends: 30/6 (13 h:7)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (13h:7)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 80)       752080      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 134)       1259734     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 32)        5408        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_364 (Concatenate)   (None, 50, 86)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 670)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 160)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 44)           17292       concatenate_364[0][0]            
__________________________________________________________________________________________________
concatenate_365 (Concatenate)   (None, 830)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_366 (Concatenate)   (None, 874)          0           phraseRnn[0][0]                  
                                                                 concatenate_365[0][0]            
__________________________________________________________________________________________________
dense_243 (Dense)               (None, 241)          210875      concatenate_366[0][0]            
__________________________________________________________________________________________________
dense_244 (Dense)               (None, 4)            968         dense_243[0][0]                  
==================================================================================================
Total params: 2,247,371
Trainable params: 2,247,371
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 95s - loss: 0.1057 - acc: 0.9771 - val_loss: 0.0610 - val_acc: 0.9848
Epoch 2/40
 - 95s - loss: 0.0527 - acc: 0.9869 - val_loss: 0.0594 - val_acc: 0.9849
Epoch 3/40
 - 94s - loss: 0.0489 - acc: 0.9880 - val_loss: 0.0619 - val_acc: 0.9849
Epoch 4/40
 - 94s - loss: 0.0474 - acc: 0.9884 - val_loss: 0.0675 - val_acc: 0.9853
Epoch 5/40
 - 94s - loss: 0.0466 - acc: 0.9886 - val_loss: 0.0780 - val_acc: 0.9852
Epoch 00005: early stopping
	TRAINING TIME: 8.37 minutes 
==================================================================================================
	PARSING TIME: 6.57 minutes 
==================================================================================================
	Identification : 0.451
	P, R  : 0.355, 0.617

==================================================================================================
	XP Ends: 30/6 (13 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (13h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 80)       1765680     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 134)       2957514     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 32)        3488        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_367 (Concatenate)   (None, 50, 86)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 670)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 160)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 44)           17292       concatenate_367[0][0]            
__________________________________________________________________________________________________
concatenate_368 (Concatenate)   (None, 830)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_369 (Concatenate)   (None, 874)          0           phraseRnn[0][0]                  
                                                                 concatenate_368[0][0]            
__________________________________________________________________________________________________
dense_245 (Dense)               (None, 241)          210875      concatenate_369[0][0]            
__________________________________________________________________________________________________
dense_246 (Dense)               (None, 4)            968         dense_245[0][0]                  
==================================================================================================
Total params: 4,956,471
Trainable params: 4,956,471
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 187s - loss: 0.0823 - acc: 0.9817 - val_loss: 0.0612 - val_acc: 0.9842
Epoch 2/40
 - 187s - loss: 0.0489 - acc: 0.9880 - val_loss: 0.0609 - val_acc: 0.9844
Epoch 3/40
 - 188s - loss: 0.0462 - acc: 0.9888 - val_loss: 0.0657 - val_acc: 0.9844
Epoch 4/40
 - 187s - loss: 0.0446 - acc: 0.9892 - val_loss: 0.0782 - val_acc: 0.9842
Epoch 5/40
 - 187s - loss: 0.0435 - acc: 0.9893 - val_loss: 0.0892 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 17.08 minutes 
==================================================================================================
	PARSING TIME: 2.92 minutes 
==================================================================================================
	Identification : 0.472
	P, R  : 0.401, 0.573

==================================================================================================
	XP Ends: 30/6 (13 h:42)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,27             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.031          ,50             ,39             ,86             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
35             ,28             ,True           ,False          ,25             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 27, True, 0.031, 50, 39, 86, 35, 28, True, False, 25
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (13h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 86)       983668      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 39)       5928        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 28)        320264      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 35)        5320        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_370 (Concatenate)   (None, 50, 125)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 112)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 140)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 25)           11325       concatenate_370[0][0]            
__________________________________________________________________________________________________
concatenate_371 (Concatenate)   (None, 252)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_372 (Concatenate)   (None, 277)          0           phraseRnn[0][0]                  
                                                                 concatenate_371[0][0]            
__________________________________________________________________________________________________
dense_247 (Dense)               (None, 27)           7506        concatenate_372[0][0]            
__________________________________________________________________________________________________
dense_248 (Dense)               (None, 4)            112         dense_247[0][0]                  
==================================================================================================
Total params: 1,334,123
Trainable params: 1,334,123
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 139s - loss: 0.0687 - acc: 0.9819 - val_loss: 0.0566 - val_acc: 0.9854
Epoch 2/40
 - 140s - loss: 0.0522 - acc: 0.9870 - val_loss: 0.0566 - val_acc: 0.9854
Epoch 3/40
 - 140s - loss: 0.0487 - acc: 0.9880 - val_loss: 0.0570 - val_acc: 0.9857
Epoch 4/40
 - 140s - loss: 0.0470 - acc: 0.9886 - val_loss: 0.0655 - val_acc: 0.9853
Epoch 5/40
 - 140s - loss: 0.0459 - acc: 0.9890 - val_loss: 0.0625 - val_acc: 0.9855
Epoch 00005: early stopping
	TRAINING TIME: 12.47 minutes 
==================================================================================================
	PARSING TIME: 4.42 minutes 
==================================================================================================
	Identification : 0.503
	P, R  : 0.433, 0.6

==================================================================================================
	XP Ends: 30/6 (14 h:0)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (14h:0)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 86)       808486      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 39)       6591        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 28)        263228      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 35)        5915        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_373 (Concatenate)   (None, 50, 125)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 112)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 140)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 25)           11325       concatenate_373[0][0]            
__________________________________________________________________________________________________
concatenate_374 (Concatenate)   (None, 252)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_375 (Concatenate)   (None, 277)          0           phraseRnn[0][0]                  
                                                                 concatenate_374[0][0]            
__________________________________________________________________________________________________
dense_249 (Dense)               (None, 27)           7506        concatenate_375[0][0]            
__________________________________________________________________________________________________
dense_250 (Dense)               (None, 4)            112         dense_249[0][0]                  
==================================================================================================
Total params: 1,103,163
Trainable params: 1,103,163
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0798 - acc: 0.9779 - val_loss: 0.0623 - val_acc: 0.9838
Epoch 2/40
 - 94s - loss: 0.0574 - acc: 0.9854 - val_loss: 0.0617 - val_acc: 0.9838
Epoch 3/40
 - 94s - loss: 0.0525 - acc: 0.9869 - val_loss: 0.0643 - val_acc: 0.9839
Epoch 4/40
 - 93s - loss: 0.0500 - acc: 0.9877 - val_loss: 0.0685 - val_acc: 0.9832
Epoch 5/40
 - 93s - loss: 0.0485 - acc: 0.9880 - val_loss: 0.0731 - val_acc: 0.9830
Epoch 00005: early stopping
	TRAINING TIME: 8.32 minutes 
==================================================================================================
	PARSING TIME: 6.63 minutes 
==================================================================================================
	Identification : 0.391
	P, R  : 0.3, 0.562

==================================================================================================
	XP Ends: 30/6 (14 h:15)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (14h:15)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 86)       1898106     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 39)       4251        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 28)        617988      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 35)        3815        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_376 (Concatenate)   (None, 50, 125)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 112)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 140)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 25)           11325       concatenate_376[0][0]            
__________________________________________________________________________________________________
concatenate_377 (Concatenate)   (None, 252)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_378 (Concatenate)   (None, 277)          0           phraseRnn[0][0]                  
                                                                 concatenate_377[0][0]            
__________________________________________________________________________________________________
dense_251 (Dense)               (None, 27)           7506        concatenate_378[0][0]            
__________________________________________________________________________________________________
dense_252 (Dense)               (None, 4)            112         dense_251[0][0]                  
==================================================================================================
Total params: 2,543,103
Trainable params: 2,543,103
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 187s - loss: 0.0660 - acc: 0.9822 - val_loss: 0.0628 - val_acc: 0.9832
Epoch 2/40
 - 186s - loss: 0.0510 - acc: 0.9869 - val_loss: 0.0605 - val_acc: 0.9839
Epoch 3/40
 - 186s - loss: 0.0477 - acc: 0.9883 - val_loss: 0.0648 - val_acc: 0.9830
Epoch 4/40
 - 186s - loss: 0.0460 - acc: 0.9888 - val_loss: 0.0719 - val_acc: 0.9833
Epoch 5/40
 - 186s - loss: 0.0444 - acc: 0.9891 - val_loss: 0.0814 - val_acc: 0.9829
Epoch 00005: early stopping
	TRAINING TIME: 17.03 minutes 
==================================================================================================
	PARSING TIME: 2.83 minutes 
==================================================================================================
	Identification : 0.478
	P, R  : 0.45, 0.51

==================================================================================================
	XP Ends: 30/6 (14 h:35)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,74             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.144          ,50             ,9              ,25             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
14             ,32             ,True           ,True           ,192            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 74, True, 0.144, 50, 9, 25, 14, 32, True, True, 192
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (14h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       285950      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1368        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 32)        366016      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 14)        2128        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_379 (Concatenate)   (None, 50, 34)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 160)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 70)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 192)          130752      concatenate_379[0][0]            
__________________________________________________________________________________________________
concatenate_380 (Concatenate)   (None, 230)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_381 (Concatenate)   (None, 422)          0           phraseRnn[0][0]                  
                                                                 concatenate_380[0][0]            
__________________________________________________________________________________________________
dense_253 (Dense)               (None, 74)           31302       concatenate_381[0][0]            
__________________________________________________________________________________________________
dense_254 (Dense)               (None, 4)            300         dense_253[0][0]                  
==================================================================================================
Total params: 817,816
Trainable params: 817,816
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 12.0880 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 2/40
 - 136s - loss: 12.0925 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 3/40
 - 136s - loss: 12.0925 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 4/40
 - 136s - loss: 12.0925 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 5/40
 - 136s - loss: 12.0925 - acc: 0.2498 - val_loss: 12.0730 - val_acc: 0.2510
Epoch 00005: early stopping
	TRAINING TIME: 12.2 minutes 
==================================================================================================
	PARSING TIME: 7.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (14 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (14h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       235025      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1521        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 32)        300832      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 14)        2366        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_382 (Concatenate)   (None, 50, 34)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 160)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 70)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 192)          130752      concatenate_382[0][0]            
__________________________________________________________________________________________________
concatenate_383 (Concatenate)   (None, 230)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_384 (Concatenate)   (None, 422)          0           phraseRnn[0][0]                  
                                                                 concatenate_383[0][0]            
__________________________________________________________________________________________________
dense_255 (Dense)               (None, 74)           31302       concatenate_384[0][0]            
__________________________________________________________________________________________________
dense_256 (Dense)               (None, 4)            300         dense_255[0][0]                  
==================================================================================================
Total params: 702,098
Trainable params: 702,098
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 95s - loss: 12.0913 - acc: 0.2493 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 2/40
 - 94s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 3/40
 - 94s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 4/40
 - 94s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 5/40
 - 94s - loss: 12.1013 - acc: 0.2492 - val_loss: 12.0377 - val_acc: 0.2532
Epoch 00005: early stopping
	TRAINING TIME: 8.35 minutes 
==================================================================================================
	PARSING TIME: 11.85 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (15 h:16)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (15h:16)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       551775      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        981         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 32)        706272      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 14)        1526        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_385 (Concatenate)   (None, 50, 34)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 160)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 70)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 192)          130752      concatenate_385[0][0]            
__________________________________________________________________________________________________
concatenate_386 (Concatenate)   (None, 230)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_387 (Concatenate)   (None, 422)          0           phraseRnn[0][0]                  
                                                                 concatenate_386[0][0]            
__________________________________________________________________________________________________
dense_257 (Dense)               (None, 74)           31302       concatenate_387[0][0]            
__________________________________________________________________________________________________
dense_258 (Dense)               (None, 4)            300         dense_257[0][0]                  
==================================================================================================
Total params: 1,422,908
Trainable params: 1,422,908
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 184s - loss: 0.4807 - acc: 0.9694 - val_loss: 0.4524 - val_acc: 0.9711
Epoch 2/40
 - 184s - loss: 0.3711 - acc: 0.9730 - val_loss: 0.0772 - val_acc: 0.9797
Epoch 3/40
 - 184s - loss: 0.0613 - acc: 0.9841 - val_loss: 0.0609 - val_acc: 0.9839
Epoch 4/40
 - 184s - loss: 0.0500 - acc: 0.9876 - val_loss: 0.0615 - val_acc: 0.9838
Epoch 5/40
 - 184s - loss: 0.0474 - acc: 0.9884 - val_loss: 0.0660 - val_acc: 0.9837
Epoch 6/40
 - 184s - loss: 0.0460 - acc: 0.9888 - val_loss: 0.0689 - val_acc: 0.9837
Epoch 00006: early stopping
	TRAINING TIME: 19.87 minutes 
==================================================================================================
	PARSING TIME: 2.78 minutes 
==================================================================================================
	Identification : 0.479
	P, R  : 0.493, 0.465

==================================================================================================
	XP Ends: 30/6 (15 h:39)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,298            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.079          ,50             ,16             ,31             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
32             ,52             ,False          ,False          ,95             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 298, True, 0.079, 50, 16, 31, 32, 52, False, False, 95
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 30/6 (15h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       233895      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 16)       2432        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 52)        392340      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 32)        4864        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_388 (Concatenate)   (None, 50, 47)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 95)           40755       concatenate_388[0][0]            
__________________________________________________________________________________________________
concatenate_389 (Concatenate)   (None, 252)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_390 (Concatenate)   (None, 347)          0           phraseRnn[0][0]                  
                                                                 concatenate_389[0][0]            
__________________________________________________________________________________________________
dense_259 (Dense)               (None, 298)          103704      concatenate_390[0][0]            
__________________________________________________________________________________________________
dense_260 (Dense)               (None, 4)            1196        dense_259[0][0]                  
==================================================================================================
Total params: 779,186
Trainable params: 779,186
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 137s - loss: 12.0795 - acc: 0.2502 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 2/40
 - 137s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 3/40
 - 137s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 4/40
 - 137s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 5/40
 - 138s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 00005: early stopping
	TRAINING TIME: 12.35 minutes 
==================================================================================================
	PARSING TIME: 4.05 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 30/6 (15 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 30/6 (15h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       224471      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 16)       2704        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 52)        376532      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 32)        5408        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_391 (Concatenate)   (None, 50, 47)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 156)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 96)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 95)           40755       concatenate_391[0][0]            
__________________________________________________________________________________________________
concatenate_392 (Concatenate)   (None, 252)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_393 (Concatenate)   (None, 347)          0           phraseRnn[0][0]                  
                                                                 concatenate_392[0][0]            
__________________________________________________________________________________________________
dense_261 (Dense)               (None, 298)          103704      concatenate_393[0][0]            
__________________________________________________________________________________________________
dense_262 (Dense)               (None, 4)            1196        dense_261[0][0]                  
==================================================================================================
Total params: 754,770
Trainable params: 754,770
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 12.0841 - acc: 0.2498 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 2/40
 - 93s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 3/40
 - 93s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
## OAR [2019-06-30 16:03:43] Job 1985755 KILLED ##
