Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_8_gfXw.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 3841/4043 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX 980 (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,30             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.15           ,50             ,13             ,153            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
46             ,112            ,False          ,True           ,363            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 30, True, 0.15, 50, 13, 153, 46, 112, False, True, 363
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (13h:36)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 153)      1154385     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1976        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 112)       845040      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 46)        6992        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 166)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 448)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 184)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 363)          577170      concatenate_1[0][0]              
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 632)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 995)          0           phraseRnn[0][0]                  
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 30)           29880       concatenate_3[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            124         dense_1[0][0]                    
==================================================================================================
Total params: 2,615,567
Trainable params: 2,615,567
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 229s - loss: 12.0766 - acc: 0.2503 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 2/40
 - 229s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 3/40
 - 229s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 4/40
 - 229s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 5/40
 - 229s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 00005: early stopping
	TRAINING TIME: 21.13 minutes 
==================================================================================================
	PARSING TIME: 5.12 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (14 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (14h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 153)      1107873     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       2197        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 112)       810992      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 46)        7774        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 50, 166)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 448)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 184)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 363)          577170      concatenate_4[0][0]              
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 632)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 995)          0           phraseRnn[0][0]                  
                                                                 concatenate_5[0][0]              
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 30)           29880       concatenate_6[0][0]              
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            124         dense_3[0][0]                    
==================================================================================================
Total params: 2,536,010
Trainable params: 2,536,010
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 156s - loss: 8.0414 - acc: 0.5006 - val_loss: 8.1258 - val_acc: 0.4959
Epoch 2/40
 - 156s - loss: 7.8787 - acc: 0.5112 - val_loss: 4.5252 - val_acc: 0.7192
Epoch 3/40
 - 156s - loss: 2.7037 - acc: 0.8203 - val_loss: 0.0801 - val_acc: 0.9804
Epoch 4/40
 - 156s - loss: 0.0694 - acc: 0.9830 - val_loss: 0.0708 - val_acc: 0.9824
Epoch 5/40
 - 156s - loss: 0.0570 - acc: 0.9856 - val_loss: 0.0710 - val_acc: 0.9831
Epoch 6/40
 - 156s - loss: 0.0527 - acc: 0.9867 - val_loss: 0.0991 - val_acc: 0.9834
Epoch 7/40
 - 156s - loss: 0.0506 - acc: 0.9873 - val_loss: 0.0747 - val_acc: 0.9829
Epoch 00007: early stopping
	TRAINING TIME: 18.6 minutes 
==================================================================================================
	PARSING TIME: 8.43 minutes 
==================================================================================================
	Identification : 0.482
	P, R  : 0.382, 0.653

==================================================================================================
	XP Ends: 1/7 (14 h:29)
==================================================================================================
/home/halsaied/miniconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.py:399: UserWarning: The graph doesn't contain a node that depends on the root element.
  "The graph doesn't contain a node " "that depends on the root element."
# Seed: 0
==================================================================================================
XP Starts: 1/7 (14h:30)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 153)      2110329     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1417        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 112)       1544816     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 46)        5014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 50, 166)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 448)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 184)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 363)          577170      concatenate_7[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 632)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 995)          0           phraseRnn[0][0]                  
                                                                 concatenate_8[0][0]              
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 30)           29880       concatenate_9[0][0]              
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            124         dense_5[0][0]                    
==================================================================================================
Total params: 4,268,750
Trainable params: 4,268,750
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 310s - loss: 12.0845 - acc: 0.2501 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 2/40
 - 310s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 3/40
 - 310s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 4/40
 - 310s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 5/40
 - 310s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 00005: early stopping
	TRAINING TIME: 27.15 minutes 
==================================================================================================
	PARSING TIME: 3.47 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (15 h:0)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,47             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.043          ,50             ,15             ,52             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,144            ,True           ,True           ,87             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 47, True, 0.043, 50, 15, 52, 8, 144, True, True, 87
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (15h:1)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 52)       392340      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       2280        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 144)       1086480     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 50, 67)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 720)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 87)           40455       concatenate_10[0][0]             
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 760)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 847)          0           phraseRnn[0][0]                  
                                                                 concatenate_11[0][0]             
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 47)           39856       concatenate_12[0][0]             
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4)            192         dense_7[0][0]                    
==================================================================================================
Total params: 1,562,819
Trainable params: 1,562,819
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 0.0648 - acc: 0.9829 - val_loss: 0.0552 - val_acc: 0.9856
Epoch 2/40
 - 136s - loss: 0.0495 - acc: 0.9877 - val_loss: 0.0556 - val_acc: 0.9860
Epoch 3/40
 - 136s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0572 - val_acc: 0.9861
Epoch 4/40
 - 136s - loss: 0.0451 - acc: 0.9891 - val_loss: 0.0601 - val_acc: 0.9859
Epoch 5/40
 - 136s - loss: 0.0444 - acc: 0.9894 - val_loss: 0.0645 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 12.05 minutes 
==================================================================================================
	PARSING TIME: 4.08 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.763, 0.475

==================================================================================================
	XP Ends: 1/7 (15 h:17)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (15h:17)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 52)       376532      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       2535        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 144)       1042704     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 50, 67)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 720)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 87)           40455       concatenate_13[0][0]             
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 760)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 847)          0           phraseRnn[0][0]                  
                                                                 concatenate_14[0][0]             
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 47)           39856       concatenate_15[0][0]             
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 4)            192         dense_9[0][0]                    
==================================================================================================
Total params: 1,503,626
Trainable params: 1,503,626
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0754 - acc: 0.9796 - val_loss: 0.0621 - val_acc: 0.9840
Epoch 2/40
 - 93s - loss: 0.0522 - acc: 0.9869 - val_loss: 0.0594 - val_acc: 0.9849
Epoch 3/40
 - 93s - loss: 0.0488 - acc: 0.9880 - val_loss: 0.0611 - val_acc: 0.9849
Epoch 4/40
 - 92s - loss: 0.0473 - acc: 0.9885 - val_loss: 0.0650 - val_acc: 0.9846
Epoch 5/40
 - 92s - loss: 0.0465 - acc: 0.9886 - val_loss: 0.0682 - val_acc: 0.9845
Epoch 00005: early stopping
	TRAINING TIME: 8.18 minutes 
==================================================================================================
	PARSING TIME: 6.25 minutes 
==================================================================================================
	Identification : 0.52
	P, R  : 0.442, 0.631

==================================================================================================
	XP Ends: 1/7 (15 h:32)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (15h:32)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 52)       717236      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 15)       1635        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 144)       1986192     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 50, 67)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 720)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 87)           40455       concatenate_16[0][0]             
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 760)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 847)          0           phraseRnn[0][0]                  
                                                                 concatenate_17[0][0]             
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 47)           39856       concatenate_18[0][0]             
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 4)            192         dense_11[0][0]                   
==================================================================================================
Total params: 2,786,438
Trainable params: 2,786,438
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 184s - loss: 0.0662 - acc: 0.9819 - val_loss: 0.0574 - val_acc: 0.9848
Epoch 2/40
 - 185s - loss: 0.0513 - acc: 0.9869 - val_loss: 0.0580 - val_acc: 0.9845
Epoch 3/40
 - 182s - loss: 0.0481 - acc: 0.9881 - val_loss: 0.0613 - val_acc: 0.9845
Epoch 4/40
 - 182s - loss: 0.0464 - acc: 0.9887 - val_loss: 0.0664 - val_acc: 0.9843
Epoch 5/40
 - 182s - loss: 0.0452 - acc: 0.9890 - val_loss: 0.0734 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 16.62 minutes 
==================================================================================================
	PARSING TIME: 2.73 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.476, 0.52

==================================================================================================
	XP Ends: 1/7 (15 h:52)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,391            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.06           ,50             ,10             ,179            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
6              ,96             ,True           ,True           ,291            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 391, True, 0.06, 50, 10, 179, 6, 96, True, True, 291
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (15h:52)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 179)      1350555     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 10)       1520        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 96)        724320      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         912         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 50, 189)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 480)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 291)          419913      concatenate_19[0][0]             
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 801)          0           phraseRnn[0][0]                  
                                                                 concatenate_20[0][0]             
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 391)          313582      concatenate_21[0][0]             
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 4)            1568        dense_13[0][0]                   
==================================================================================================
Total params: 2,812,370
Trainable params: 2,812,370
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 191s - loss: 12.0772 - acc: 0.2504 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 2/40
 - 191s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 3/40
 - 191s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 4/40
 - 191s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 5/40
 - 191s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 00005: early stopping
	TRAINING TIME: 16.7 minutes 
==================================================================================================
	PARSING TIME: 4.37 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (16 h:13)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (16h:13)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 179)      1296139     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 10)       1690        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 96)        695136      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         1014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 50, 189)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 480)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 291)          419913      concatenate_22[0][0]             
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 801)          0           phraseRnn[0][0]                  
                                                                 concatenate_23[0][0]             
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 391)          313582      concatenate_24[0][0]             
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 4)            1568        dense_15[0][0]                   
==================================================================================================
Total params: 2,729,042
Trainable params: 2,729,042
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 129s - loss: 12.0853 - acc: 0.2497 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 2/40
 - 129s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 3/40
 - 129s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 4/40
 - 129s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 5/40
 - 129s - loss: 12.0954 - acc: 0.2496 - val_loss: 12.0614 - val_acc: 0.2517
Epoch 00005: early stopping
	TRAINING TIME: 11.25 minutes 
==================================================================================================
	PARSING TIME: 12.97 minutes 
==================================================================================================
	Identification : 0.032
	P, R  : 0.018, 0.145

==================================================================================================
	XP Ends: 1/7 (16 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (16h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 179)      2468947     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 10)       1090        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 96)        1324128     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 6)         654         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 50, 189)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 480)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 291)          419913      concatenate_25[0][0]             
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 801)          0           phraseRnn[0][0]                  
                                                                 concatenate_26[0][0]             
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 391)          313582      concatenate_27[0][0]             
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 4)            1568        dense_17[0][0]                   
==================================================================================================
Total params: 4,529,882
Trainable params: 4,529,882
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 259s - loss: 12.0815 - acc: 0.2503 - val_loss: 12.0978 - val_acc: 0.2494
Epoch 2/40
 - 259s - loss: 12.0865 - acc: 0.2501 - val_loss: 12.0978 - val_acc: 0.2494
Epoch 3/40
 - 259s - loss: 12.0865 - acc: 0.2501 - val_loss: 12.0978 - val_acc: 0.2494
Epoch 4/40
 - 259s - loss: 12.0865 - acc: 0.2501 - val_loss: 12.0978 - val_acc: 0.2494
Epoch 5/40
 - 259s - loss: 12.0865 - acc: 0.2501 - val_loss: 12.0978 - val_acc: 0.2494
Epoch 00005: early stopping
	TRAINING TIME: 22.95 minutes 
==================================================================================================
	PARSING TIME: 5.52 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (17 h:6)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,80             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.071          ,50             ,26             ,65             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
6              ,40             ,False          ,False          ,31             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 80, True, 0.071, 50, 26, 65, 6, 40, False, False, 31
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (17h:6)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 65)       490425      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 26)       3952        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 40)        301800      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 6)         912         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 120)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 18)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 31)           11439       concatenate_28[0][0]             
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 138)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 169)          0           phraseRnn[0][0]                  
                                                                 concatenate_29[0][0]             
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 80)           13600       concatenate_30[0][0]             
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 4)            324         dense_19[0][0]                   
==================================================================================================
Total params: 822,452
Trainable params: 822,452
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 137s - loss: 0.0655 - acc: 0.9826 - val_loss: 0.0566 - val_acc: 0.9853
Epoch 2/40
 - 137s - loss: 0.0515 - acc: 0.9871 - val_loss: 0.0578 - val_acc: 0.9855
Epoch 3/40
 - 136s - loss: 0.0482 - acc: 0.9882 - val_loss: 0.0594 - val_acc: 0.9855
Epoch 4/40
 - 136s - loss: 0.0465 - acc: 0.9887 - val_loss: 0.0628 - val_acc: 0.9855
Epoch 5/40
 - 136s - loss: 0.0453 - acc: 0.9891 - val_loss: 0.0663 - val_acc: 0.9855
Epoch 00005: early stopping
	TRAINING TIME: 12.07 minutes 
==================================================================================================
	PARSING TIME: 4.08 minutes 
==================================================================================================
	Identification : 0.581
	P, R  : 0.747, 0.476

==================================================================================================
	XP Ends: 1/7 (17 h:23)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (17h:23)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 65)       470665      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 26)       4394        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 40)        289640      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 6)         1014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 120)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 18)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 31)           11439       concatenate_31[0][0]             
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 138)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 169)          0           phraseRnn[0][0]                  
                                                                 concatenate_32[0][0]             
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 80)           13600       concatenate_33[0][0]             
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 4)            324         dense_21[0][0]                   
==================================================================================================
Total params: 791,076
Trainable params: 791,076
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 91s - loss: 0.0759 - acc: 0.9789 - val_loss: 0.0617 - val_acc: 0.9835
Epoch 2/40
 - 91s - loss: 0.0552 - acc: 0.9857 - val_loss: 0.0623 - val_acc: 0.9840
Epoch 3/40
 - 91s - loss: 0.0508 - acc: 0.9872 - val_loss: 0.0653 - val_acc: 0.9838
Epoch 4/40
 - 93s - loss: 0.0487 - acc: 0.9879 - val_loss: 0.0690 - val_acc: 0.9839
Epoch 5/40
 - 90s - loss: 0.0472 - acc: 0.9883 - val_loss: 0.0799 - val_acc: 0.9823
Epoch 00005: early stopping
	TRAINING TIME: 8.08 minutes 
==================================================================================================
	PARSING TIME: 6.53 minutes 
==================================================================================================
	Identification : 0.392
	P, R  : 0.294, 0.586

==================================================================================================
	XP Ends: 1/7 (17 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (17h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 65)       896545      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 26)       2834        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 40)        551720      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 6)         654         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 50, 91)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 120)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 18)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 31)           11439       concatenate_34[0][0]             
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 138)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 169)          0           phraseRnn[0][0]                  
                                                                 concatenate_35[0][0]             
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 80)           13600       concatenate_36[0][0]             
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 4)            324         dense_23[0][0]                   
==================================================================================================
Total params: 1,477,116
Trainable params: 1,477,116
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 179s - loss: 0.0691 - acc: 0.9814 - val_loss: 0.0595 - val_acc: 0.9840
Epoch 2/40
 - 178s - loss: 0.0545 - acc: 0.9855 - val_loss: 0.0598 - val_acc: 0.9840
Epoch 3/40
 - 178s - loss: 0.0517 - acc: 0.9866 - val_loss: 0.0618 - val_acc: 0.9836
Epoch 4/40
 - 178s - loss: 0.0497 - acc: 0.9872 - val_loss: 0.0662 - val_acc: 0.9836
Epoch 5/40
 - 178s - loss: 0.0480 - acc: 0.9877 - val_loss: 0.0756 - val_acc: 0.9832
Epoch 00005: early stopping
	TRAINING TIME: 16.18 minutes 
==================================================================================================
	PARSING TIME: 2.78 minutes 
==================================================================================================
	Identification : 0.467
	P, R  : 0.42, 0.527

==================================================================================================
	XP Ends: 1/7 (17 h:57)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,208            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.021          ,50             ,25             ,67             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
21             ,67             ,True           ,False          ,215            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 208, False, 0.021, 50, 25, 67, 21, 67, True, False, 215
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (17h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 67)       505515      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       3800        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 67)        505515      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 21)        3192        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 50, 92)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 268)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 84)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 215)          264880      concatenate_37[0][0]             
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 352)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 567)          0           phraseRnn[0][0]                  
                                                                 concatenate_38[0][0]             
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 208)          118144      concatenate_39[0][0]             
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 4)            836         dense_25[0][0]                   
==================================================================================================
Total params: 1,401,882
Trainable params: 1,401,882
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 167s - loss: 0.0658 - acc: 0.9827 - val_loss: 0.0572 - val_acc: 0.9853
Epoch 2/40
 - 167s - loss: 0.0513 - acc: 0.9872 - val_loss: 0.0563 - val_acc: 0.9856
Epoch 3/40
 - 167s - loss: 0.0482 - acc: 0.9883 - val_loss: 0.0585 - val_acc: 0.9854
Epoch 4/40
 - 167s - loss: 0.0465 - acc: 0.9887 - val_loss: 0.0631 - val_acc: 0.9857
Epoch 5/40
 - 167s - loss: 0.0455 - acc: 0.9890 - val_loss: 0.0672 - val_acc: 0.9851
Epoch 00005: early stopping
	TRAINING TIME: 14.78 minutes 
==================================================================================================
	PARSING TIME: 5.22 minutes 
==================================================================================================
	Identification : 0.578
	P, R  : 0.692, 0.496

==================================================================================================
	XP Ends: 1/7 (18 h:18)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (18h:18)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 67)       485147      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       4225        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 67)        485147      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 21)        3549        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 50, 92)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 268)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 84)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 215)          264880      concatenate_40[0][0]             
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 352)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 567)          0           phraseRnn[0][0]                  
                                                                 concatenate_41[0][0]             
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 208)          118144      concatenate_42[0][0]             
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 4)            836         dense_27[0][0]                   
==================================================================================================
Total params: 1,361,928
Trainable params: 1,361,928
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 113s - loss: 0.0945 - acc: 0.9753 - val_loss: 0.0703 - val_acc: 0.9814
Epoch 2/40
 - 113s - loss: 0.0626 - acc: 0.9836 - val_loss: 0.0679 - val_acc: 0.9819
Epoch 3/40
 - 113s - loss: 0.0584 - acc: 0.9848 - val_loss: 0.0703 - val_acc: 0.9821
Epoch 4/40
 - 113s - loss: 0.0559 - acc: 0.9855 - val_loss: 0.0702 - val_acc: 0.9825
Epoch 5/40
 - 113s - loss: 0.0540 - acc: 0.9861 - val_loss: 0.0727 - val_acc: 0.9826
Epoch 00005: early stopping
	TRAINING TIME: 9.98 minutes 
==================================================================================================
	PARSING TIME: 8.0 minutes 
==================================================================================================
	Identification : 0.466
	P, R  : 0.367, 0.637

==================================================================================================
	XP Ends: 1/7 (18 h:36)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (18h:36)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 67)       924131      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       2725        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 67)        924131      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 21)        2289        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 50, 92)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 268)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 84)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 215)          264880      concatenate_43[0][0]             
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 352)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 567)          0           phraseRnn[0][0]                  
                                                                 concatenate_44[0][0]             
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 208)          118144      concatenate_45[0][0]             
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 4)            836         dense_29[0][0]                   
==================================================================================================
Total params: 2,237,136
Trainable params: 2,237,136
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 265s - loss: 0.0723 - acc: 0.9804 - val_loss: 0.0600 - val_acc: 0.9837
Epoch 2/40
 - 228s - loss: 0.0554 - acc: 0.9854 - val_loss: 0.0587 - val_acc: 0.9839
Epoch 3/40
 - 228s - loss: 0.0519 - acc: 0.9866 - val_loss: 0.0616 - val_acc: 0.9835
Epoch 4/40
 - 227s - loss: 0.0498 - acc: 0.9873 - val_loss: 0.0671 - val_acc: 0.9836
Epoch 5/40
 - 228s - loss: 0.0483 - acc: 0.9877 - val_loss: 0.0719 - val_acc: 0.9833
Epoch 00005: early stopping
	TRAINING TIME: 21.05 minutes 
==================================================================================================
	PARSING TIME: 3.53 minutes 
==================================================================================================
	Identification : 0.46
	P, R  : 0.549, 0.396

==================================================================================================
	XP Ends: 1/7 (19 h:1)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,227            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.067          ,50             ,25             ,163            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,41             ,True           ,True           ,35             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 227, False, 0.067, 50, 25, 163, 8, 41, True, True, 35
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (19h:1)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 163)      1229835     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       3800        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 41)        309345      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 50, 188)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 205)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 35)           31360       concatenate_46[0][0]             
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 245)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 280)          0           phraseRnn[0][0]                  
                                                                 concatenate_47[0][0]             
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 227)          63787       concatenate_48[0][0]             
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 4)            912         dense_31[0][0]                   
==================================================================================================
Total params: 1,640,255
Trainable params: 1,640,255
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 161s - loss: 0.0663 - acc: 0.9828 - val_loss: 0.0548 - val_acc: 0.9858
Epoch 2/40
 - 161s - loss: 0.0494 - acc: 0.9878 - val_loss: 0.0550 - val_acc: 0.9862
Epoch 3/40
 - 161s - loss: 0.0463 - acc: 0.9889 - val_loss: 0.0576 - val_acc: 0.9862
Epoch 4/40
 - 161s - loss: 0.0449 - acc: 0.9893 - val_loss: 0.0605 - val_acc: 0.9862
Epoch 5/40
 - 161s - loss: 0.0440 - acc: 0.9894 - val_loss: 0.0688 - val_acc: 0.9861
Epoch 00005: early stopping
	TRAINING TIME: 14.08 minutes 
==================================================================================================
	PARSING TIME: 5.17 minutes 
==================================================================================================
	Identification : 0.562
	P, R  : 0.569, 0.555

==================================================================================================
	XP Ends: 1/7 (19 h:21)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (19h:21)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 163)      1180283     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       4225        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 41)        296881      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 50, 188)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 205)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 35)           31360       concatenate_49[0][0]             
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 245)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 280)          0           phraseRnn[0][0]                  
                                                                 concatenate_50[0][0]             
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 227)          63787       concatenate_51[0][0]             
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 4)            912         dense_33[0][0]                   
==================================================================================================
Total params: 1,578,800
Trainable params: 1,578,800
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 0.0768 - acc: 0.9795 - val_loss: 0.0596 - val_acc: 0.9844
Epoch 2/40
 - 109s - loss: 0.0516 - acc: 0.9871 - val_loss: 0.0594 - val_acc: 0.9849
Epoch 3/40
 - 110s - loss: 0.0482 - acc: 0.9883 - val_loss: 0.0616 - val_acc: 0.9849
Epoch 4/40
 - 109s - loss: 0.0468 - acc: 0.9886 - val_loss: 0.0653 - val_acc: 0.9848
Epoch 5/40
 - 109s - loss: 0.0460 - acc: 0.9888 - val_loss: 0.0698 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 9.65 minutes 
==================================================================================================
	PARSING TIME: 7.92 minutes 
==================================================================================================
	Identification : 0.491
	P, R  : 0.408, 0.617

==================================================================================================
	XP Ends: 1/7 (19 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (19h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 163)      2248259     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       2725        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 41)        565513      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 50, 188)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 205)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 35)           31360       concatenate_52[0][0]             
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 245)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 280)          0           phraseRnn[0][0]                  
                                                                 concatenate_53[0][0]             
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 227)          63787       concatenate_54[0][0]             
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 4)            912         dense_35[0][0]                   
==================================================================================================
Total params: 2,913,428
Trainable params: 2,913,428
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 221s - loss: 0.0660 - acc: 0.9822 - val_loss: 0.0560 - val_acc: 0.9848
Epoch 2/40
 - 222s - loss: 0.0511 - acc: 0.9870 - val_loss: 0.0577 - val_acc: 0.9844
Epoch 3/40
 - 222s - loss: 0.0480 - acc: 0.9881 - val_loss: 0.0617 - val_acc: 0.9844
Epoch 4/40
 - 221s - loss: 0.0461 - acc: 0.9887 - val_loss: 0.0707 - val_acc: 0.9841
Epoch 5/40
 - 219s - loss: 0.0450 - acc: 0.9890 - val_loss: 0.0792 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 19.83 minutes 
==================================================================================================
	PARSING TIME: 3.43 minutes 
==================================================================================================
	Identification : 0.48
	P, R  : 0.418, 0.563

==================================================================================================
	XP Ends: 1/7 (20 h:2)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,313            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.093          ,50             ,6              ,44             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
9              ,80             ,True           ,True           ,255            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 313, True, 0.093, 50, 6, 44, 9, 80, True, True, 255
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (20h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 44)       331980      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 80)        603600      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         1368        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 50, 50)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 400)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 255)          234090      concatenate_55[0][0]             
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 445)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 700)          0           phraseRnn[0][0]                  
                                                                 concatenate_56[0][0]             
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 313)          219413      concatenate_57[0][0]             
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 4)            1256        dense_37[0][0]                   
==================================================================================================
Total params: 1,392,619
Trainable params: 1,392,619
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 140s - loss: 12.0836 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 2/40
 - 140s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 3/40
 - 140s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 4/40
 - 140s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 5/40
 - 140s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 00005: early stopping
	TRAINING TIME: 12.43 minutes 
==================================================================================================
	PARSING TIME: 7.18 minutes 
==================================================================================================
	Identification : 0.001
	P, R  : 0.001, 0.001

==================================================================================================
	XP Ends: 1/7 (20 h:22)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (20h:22)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 44)       318604      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 80)        579280      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         1521        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 50, 50)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 400)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 255)          234090      concatenate_58[0][0]             
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 445)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 700)          0           phraseRnn[0][0]                  
                                                                 concatenate_59[0][0]             
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 313)          219413      concatenate_60[0][0]             
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 4)            1256        dense_39[0][0]                   
==================================================================================================
Total params: 1,355,178
Trainable params: 1,355,178
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 96s - loss: 12.0734 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 2/40
 - 96s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 3/40
 - 95s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 4/40
 - 95s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 5/40
 - 95s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 00005: early stopping
	TRAINING TIME: 8.42 minutes 
==================================================================================================
	PARSING TIME: 11.45 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (20 h:42)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (20h:42)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 44)       606892      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 80)        1103440     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         981         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_61 (Concatenate)    (None, 50, 50)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 400)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 255)          234090      concatenate_61[0][0]             
__________________________________________________________________________________________________
concatenate_62 (Concatenate)    (None, 445)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_63 (Concatenate)    (None, 700)          0           phraseRnn[0][0]                  
                                                                 concatenate_62[0][0]             
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 313)          219413      concatenate_63[0][0]             
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 4)            1256        dense_41[0][0]                   
==================================================================================================
Total params: 2,166,726
Trainable params: 2,166,726
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 189s - loss: 12.0849 - acc: 0.2501 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 2/40
 - 189s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 3/40
 - 189s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 4/40
 - 189s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 5/40
 - 189s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 00005: early stopping
	TRAINING TIME: 17.15 minutes 
==================================================================================================
	PARSING TIME: 2.58 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (21 h:2)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,489            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.127          ,50             ,41             ,31             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
49             ,94             ,False          ,True           ,439            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 489, True, 0.127, 50, 41, 31, 49, 94, False, True, 439
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (21h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       233895      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 41)       6232        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 94)        709230      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 49)        7448        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_64 (Concatenate)    (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 376)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 196)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 439)          674304      concatenate_64[0][0]             
__________________________________________________________________________________________________
concatenate_65 (Concatenate)    (None, 572)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 1011)         0           phraseRnn[0][0]                  
                                                                 concatenate_65[0][0]             
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 489)          494868      concatenate_66[0][0]             
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 4)            1960        dense_43[0][0]                   
==================================================================================================
Total params: 2,127,937
Trainable params: 2,127,937
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 243s - loss: 12.0832 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 2/40
 - 243s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 3/40
 - 243s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 4/40
 - 243s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 5/40
 - 243s - loss: 12.0867 - acc: 0.2501 - val_loss: 12.0959 - val_acc: 0.2495
Epoch 00005: early stopping
	TRAINING TIME: 21.03 minutes 
==================================================================================================
	PARSING TIME: 5.5 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (21 h:29)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (21h:29)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       224471      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 41)       6929        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 94)        680654      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 49)        8281        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_67 (Concatenate)    (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 376)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 196)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 439)          674304      concatenate_67[0][0]             
__________________________________________________________________________________________________
concatenate_68 (Concatenate)    (None, 572)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_69 (Concatenate)    (None, 1011)         0           phraseRnn[0][0]                  
                                                                 concatenate_68[0][0]             
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 489)          494868      concatenate_69[0][0]             
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 4)            1960        dense_45[0][0]                   
==================================================================================================
Total params: 2,091,467
Trainable params: 2,091,467
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 164s - loss: 12.0775 - acc: 0.2504 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 2/40
 - 164s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 3/40
 - 164s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 4/40
 - 164s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 5/40
 - 164s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 00005: early stopping
	TRAINING TIME: 14.17 minutes 
==================================================================================================
	PARSING TIME: 16.13 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (22 h:0)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (22h:0)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       427583      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 41)       4469        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 94)        1296542     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 49)        5341        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_70 (Concatenate)    (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 376)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 196)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 439)          674304      concatenate_70[0][0]             
__________________________________________________________________________________________________
concatenate_71 (Concatenate)    (None, 572)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_72 (Concatenate)    (None, 1011)         0           phraseRnn[0][0]                  
                                                                 concatenate_71[0][0]             
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 489)          494868      concatenate_72[0][0]             
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 4)            1960        dense_47[0][0]                   
==================================================================================================
Total params: 2,905,067
Trainable params: 2,905,067
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 328s - loss: 12.0869 - acc: 0.2499 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 2/40
 - 328s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 3/40
 - 328s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 4/40
 - 328s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 5/40
 - 328s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 00005: early stopping
	TRAINING TIME: 28.67 minutes 
==================================================================================================
	PARSING TIME: 6.63 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 1/7 (22 h:36)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,112            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.027          ,50             ,6              ,55             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
23             ,31             ,True           ,True           ,28             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 112, False, 0.027, 50, 6, 55, 23, 31, True, True, 28
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (22h:36)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 55)       414975      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 31)        233895      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 23)        3496        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_73 (Concatenate)    (None, 50, 61)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 155)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 115)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 28)           10080       concatenate_73[0][0]             
__________________________________________________________________________________________________
concatenate_74 (Concatenate)    (None, 270)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_75 (Concatenate)    (None, 298)          0           phraseRnn[0][0]                  
                                                                 concatenate_74[0][0]             
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 112)          33488       concatenate_75[0][0]             
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 4)            452         dense_49[0][0]                   
==================================================================================================
Total params: 697,298
Trainable params: 697,298
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 161s - loss: 0.0652 - acc: 0.9830 - val_loss: 0.0556 - val_acc: 0.9858
Epoch 2/40
 - 161s - loss: 0.0507 - acc: 0.9874 - val_loss: 0.0557 - val_acc: 0.9858
Epoch 3/40
 - 161s - loss: 0.0474 - acc: 0.9886 - val_loss: 0.0576 - val_acc: 0.9860
Epoch 4/40
 - 159s - loss: 0.0459 - acc: 0.9890 - val_loss: 0.0590 - val_acc: 0.9860
Epoch 5/40
 - 159s - loss: 0.0450 - acc: 0.9892 - val_loss: 0.0623 - val_acc: 0.9858
Epoch 00005: early stopping
	TRAINING TIME: 14.13 minutes 
==================================================================================================
	PARSING TIME: 5.25 minutes 
==================================================================================================
	Identification : 0.564
	P, R  : 0.631, 0.51

==================================================================================================
	XP Ends: 1/7 (22 h:56)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (22h:56)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 55)       398255      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 31)        224471      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 23)        3887        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_76 (Concatenate)    (None, 50, 61)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 155)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 115)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 28)           10080       concatenate_76[0][0]             
__________________________________________________________________________________________________
concatenate_77 (Concatenate)    (None, 270)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_78 (Concatenate)    (None, 298)          0           phraseRnn[0][0]                  
                                                                 concatenate_77[0][0]             
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 112)          33488       concatenate_78[0][0]             
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 4)            452         dense_51[0][0]                   
==================================================================================================
Total params: 671,647
Trainable params: 671,647
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 113s - loss: 0.0742 - acc: 0.9803 - val_loss: 0.0615 - val_acc: 0.9838
Epoch 2/40
 - 113s - loss: 0.0544 - acc: 0.9863 - val_loss: 0.0597 - val_acc: 0.9848
Epoch 3/40
 - 114s - loss: 0.0502 - acc: 0.9876 - val_loss: 0.0619 - val_acc: 0.9844
Epoch 4/40
 - 113s - loss: 0.0483 - acc: 0.9882 - val_loss: 0.0641 - val_acc: 0.9845
Epoch 5/40
 - 113s - loss: 0.0471 - acc: 0.9885 - val_loss: 0.0672 - val_acc: 0.9845
Epoch 00005: early stopping
	TRAINING TIME: 9.95 minutes 
==================================================================================================
	PARSING TIME: 8.35 minutes 
==================================================================================================
	Identification : 0.443
	P, R  : 0.332, 0.665

==================================================================================================
	XP Ends: 1/7 (23 h:14)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (23h:14)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 55)       758615      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 31)        427583      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 23)        2507        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_79 (Concatenate)    (None, 50, 61)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 155)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 115)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 28)           10080       concatenate_79[0][0]             
__________________________________________________________________________________________________
concatenate_80 (Concatenate)    (None, 270)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_81 (Concatenate)    (None, 298)          0           phraseRnn[0][0]                  
                                                                 concatenate_80[0][0]             
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 112)          33488       concatenate_81[0][0]             
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 4)            452         dense_53[0][0]                   
==================================================================================================
Total params: 1,233,379
Trainable params: 1,233,379
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 215s - loss: 0.0657 - acc: 0.9822 - val_loss: 0.0569 - val_acc: 0.9847
Epoch 2/40
 - 215s - loss: 0.0520 - acc: 0.9866 - val_loss: 0.0581 - val_acc: 0.9844
Epoch 3/40
 - 213s - loss: 0.0490 - acc: 0.9878 - val_loss: 0.0603 - val_acc: 0.9844
Epoch 4/40
 - 213s - loss: 0.0472 - acc: 0.9884 - val_loss: 0.0644 - val_acc: 0.9843
Epoch 5/40
 - 212s - loss: 0.0459 - acc: 0.9888 - val_loss: 0.0700 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 19.2 minutes 
==================================================================================================
	PARSING TIME: 3.42 minutes 
==================================================================================================
	Identification : 0.494
	P, R  : 0.433, 0.575

==================================================================================================
	XP Ends: 1/7 (23 h:37)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,178            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.027          ,50             ,11             ,53             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
27             ,64             ,False          ,True           ,83             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 178, False, 0.027, 50, 11, 53, 27, 64, False, True, 83
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 1/7 (23h:37)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       399885      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1672        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 64)        482880      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 27)        4104        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_82 (Concatenate)    (None, 50, 64)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 256)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 108)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 83)           49136       concatenate_82[0][0]             
__________________________________________________________________________________________________
concatenate_83 (Concatenate)    (None, 364)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_84 (Concatenate)    (None, 447)          0           phraseRnn[0][0]                  
                                                                 concatenate_83[0][0]             
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 178)          79744       concatenate_84[0][0]             
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 4)            716         dense_55[0][0]                   
==================================================================================================
Total params: 1,018,137
Trainable params: 1,018,137
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 162s - loss: 0.0643 - acc: 0.9831 - val_loss: 0.0553 - val_acc: 0.9855
Epoch 2/40
 - 160s - loss: 0.0499 - acc: 0.9877 - val_loss: 0.0547 - val_acc: 0.9861
Epoch 3/40
 - 160s - loss: 0.0470 - acc: 0.9886 - val_loss: 0.0576 - val_acc: 0.9862
Epoch 4/40
 - 158s - loss: 0.0455 - acc: 0.9891 - val_loss: 0.0603 - val_acc: 0.9861
Epoch 5/40
 - 158s - loss: 0.0446 - acc: 0.9893 - val_loss: 0.0653 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 14.08 minutes 
==================================================================================================
	PARSING TIME: 5.13 minutes 
==================================================================================================
	Identification : 0.566
	P, R  : 0.615, 0.524

==================================================================================================
	XP Ends: 1/7 (23 h:57)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 1/7 (23h:57)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       383773      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1859        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 64)        463424      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 27)        4563        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 50, 64)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 256)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 108)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 83)           49136       concatenate_85[0][0]             
__________________________________________________________________________________________________
concatenate_86 (Concatenate)    (None, 364)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_87 (Concatenate)    (None, 447)          0           phraseRnn[0][0]                  
                                                                 concatenate_86[0][0]             
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 178)          79744       concatenate_87[0][0]             
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 4)            716         dense_57[0][0]                   
==================================================================================================
Total params: 983,215
Trainable params: 983,215
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 0.0739 - acc: 0.9799 - val_loss: 0.0638 - val_acc: 0.9828
Epoch 2/40
 - 109s - loss: 0.0532 - acc: 0.9865 - val_loss: 0.0593 - val_acc: 0.9847
Epoch 3/40
 - 110s - loss: 0.0495 - acc: 0.9878 - val_loss: 0.0608 - val_acc: 0.9851
Epoch 4/40
 - 109s - loss: 0.0477 - acc: 0.9883 - val_loss: 0.0660 - val_acc: 0.9850
Epoch 5/40
 - 109s - loss: 0.0466 - acc: 0.9885 - val_loss: 0.0706 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 9.65 minutes 
==================================================================================================
	PARSING TIME: 7.9 minutes 
==================================================================================================
	Identification : 0.507
	P, R  : 0.416, 0.649

==================================================================================================
	XP Ends: 2/7 (0 h:15)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (0h:15)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       731029      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1199        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 64)        882752      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 27)        2943        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_88 (Concatenate)    (None, 50, 64)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 256)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 108)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 83)           49136       concatenate_88[0][0]             
__________________________________________________________________________________________________
concatenate_89 (Concatenate)    (None, 364)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_90 (Concatenate)    (None, 447)          0           phraseRnn[0][0]                  
                                                                 concatenate_89[0][0]             
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 178)          79744       concatenate_90[0][0]             
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 4)            716         dense_59[0][0]                   
==================================================================================================
Total params: 1,747,519
Trainable params: 1,747,519
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 216s - loss: 0.0661 - acc: 0.9820 - val_loss: 0.0569 - val_acc: 0.9847
Epoch 2/40
 - 216s - loss: 0.0526 - acc: 0.9864 - val_loss: 0.0602 - val_acc: 0.9840
Epoch 3/40
 - 216s - loss: 0.0499 - acc: 0.9874 - val_loss: 0.0594 - val_acc: 0.9843
Epoch 4/40
 - 216s - loss: 0.0481 - acc: 0.9880 - val_loss: 0.0629 - val_acc: 0.9841
Epoch 5/40
 - 215s - loss: 0.0469 - acc: 0.9884 - val_loss: 0.0682 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 19.35 minutes 
==================================================================================================
	PARSING TIME: 3.45 minutes 
==================================================================================================
	Identification : 0.466
	P, R  : 0.507, 0.431

==================================================================================================
	XP Ends: 2/7 (0 h:38)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,438            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.037          ,50             ,11             ,31             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
39             ,173            ,False          ,True           ,160            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 438, False, 0.037, 50, 11, 31, 39, 173, False, True, 160
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (0h:38)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       233895      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1672        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 173)       1305285     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 39)        5928        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_91 (Concatenate)    (None, 50, 42)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 692)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 156)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 160)          129920      concatenate_91[0][0]             
__________________________________________________________________________________________________
concatenate_92 (Concatenate)    (None, 848)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_93 (Concatenate)    (None, 1008)         0           phraseRnn[0][0]                  
                                                                 concatenate_92[0][0]             
__________________________________________________________________________________________________
dense_61 (Dense)                (None, 438)          441942      concatenate_93[0][0]             
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 4)            1756        dense_61[0][0]                   
==================================================================================================
Total params: 2,120,398
Trainable params: 2,120,398
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 160s - loss: 0.0755 - acc: 0.9820 - val_loss: 0.0556 - val_acc: 0.9856
Epoch 2/40
 - 160s - loss: 0.0504 - acc: 0.9875 - val_loss: 0.0561 - val_acc: 0.9860
Epoch 3/40
 - 160s - loss: 0.0473 - acc: 0.9884 - val_loss: 0.0581 - val_acc: 0.9859
Epoch 4/40
 - 161s - loss: 0.0456 - acc: 0.9889 - val_loss: 0.0630 - val_acc: 0.9858
Epoch 5/40
 - 160s - loss: 0.0446 - acc: 0.9893 - val_loss: 0.0687 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 14.22 minutes 
==================================================================================================
	PARSING TIME: 5.18 minutes 
==================================================================================================
	Identification : 0.591
	P, R  : 0.653, 0.539

==================================================================================================
	XP Ends: 2/7 (0 h:58)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (0h:58)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       224471      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1859        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 173)       1252693     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 39)        6591        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_94 (Concatenate)    (None, 50, 42)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 692)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 156)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 160)          129920      concatenate_94[0][0]             
__________________________________________________________________________________________________
concatenate_95 (Concatenate)    (None, 848)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_96 (Concatenate)    (None, 1008)         0           phraseRnn[0][0]                  
                                                                 concatenate_95[0][0]             
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 438)          441942      concatenate_96[0][0]             
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 4)            1756        dense_63[0][0]                   
==================================================================================================
Total params: 2,059,232
Trainable params: 2,059,232
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 12.0697 - acc: 0.2508 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 2/40
 - 109s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 3/40
 - 109s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 4/40
 - 109s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 5/40
 - 109s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 00005: early stopping
	TRAINING TIME: 9.6 minutes 
==================================================================================================
	PARSING TIME: 18.48 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.264

==================================================================================================
	XP Ends: 2/7 (1 h:26)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (1h:26)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       427583      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1199        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 173)       2386189     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 39)        4251        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_97 (Concatenate)    (None, 50, 42)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 692)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 156)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 160)          129920      concatenate_97[0][0]             
__________________________________________________________________________________________________
concatenate_98 (Concatenate)    (None, 848)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_99 (Concatenate)    (None, 1008)         0           phraseRnn[0][0]                  
                                                                 concatenate_98[0][0]             
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 438)          441942      concatenate_99[0][0]             
__________________________________________________________________________________________________
dense_66 (Dense)                (None, 4)            1756        dense_65[0][0]                   
==================================================================================================
Total params: 3,392,840
Trainable params: 3,392,840
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 218s - loss: 12.0839 - acc: 0.2501 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 2/40
 - 218s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 3/40
 - 218s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 4/40
 - 218s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 5/40
 - 217s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 00005: early stopping
	TRAINING TIME: 19.62 minutes 
==================================================================================================
	PARSING TIME: 5.95 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (1 h:52)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,32             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.078          ,50             ,7              ,34             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
30             ,88             ,False          ,True           ,106            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 32, False, 0.078, 50, 7, 34, 30, 88, False, True, 106
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (1h:52)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 34)       256530      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 88)        663960      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 30)        4560        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_100 (Concatenate)   (None, 50, 41)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 352)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 120)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 106)          62752       concatenate_100[0][0]            
__________________________________________________________________________________________________
concatenate_101 (Concatenate)   (None, 472)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_102 (Concatenate)   (None, 578)          0           phraseRnn[0][0]                  
                                                                 concatenate_101[0][0]            
__________________________________________________________________________________________________
dense_67 (Dense)                (None, 32)           18528       concatenate_102[0][0]            
__________________________________________________________________________________________________
dense_68 (Dense)                (None, 4)            132         dense_67[0][0]                   
==================================================================================================
Total params: 1,007,526
Trainable params: 1,007,526
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 160s - loss: 0.0657 - acc: 0.9827 - val_loss: 0.0559 - val_acc: 0.9855
Epoch 2/40
 - 160s - loss: 0.0513 - acc: 0.9871 - val_loss: 0.0563 - val_acc: 0.9858
Epoch 3/40
 - 160s - loss: 0.0482 - acc: 0.9881 - val_loss: 0.0584 - val_acc: 0.9859
Epoch 4/40
 - 160s - loss: 0.0464 - acc: 0.9887 - val_loss: 0.0640 - val_acc: 0.9858
Epoch 5/40
 - 158s - loss: 0.0452 - acc: 0.9891 - val_loss: 0.0675 - val_acc: 0.9859
Epoch 00005: early stopping
	TRAINING TIME: 14.08 minutes 
==================================================================================================
	PARSING TIME: 5.12 minutes 
==================================================================================================
	Identification : 0.575
	P, R  : 0.609, 0.545

==================================================================================================
	XP Ends: 2/7 (2 h:12)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (2h:12)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 34)       246194      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 88)        637208      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 30)        5070        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_103 (Concatenate)   (None, 50, 41)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 352)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 120)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 106)          62752       concatenate_103[0][0]            
__________________________________________________________________________________________________
concatenate_104 (Concatenate)   (None, 472)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_105 (Concatenate)   (None, 578)          0           phraseRnn[0][0]                  
                                                                 concatenate_104[0][0]            
__________________________________________________________________________________________________
dense_69 (Dense)                (None, 32)           18528       concatenate_105[0][0]            
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 4)            132         dense_69[0][0]                   
==================================================================================================
Total params: 971,067
Trainable params: 971,067
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 113s - loss: 0.0761 - acc: 0.9796 - val_loss: 0.0605 - val_acc: 0.9840
Epoch 2/40
 - 114s - loss: 0.0534 - acc: 0.9862 - val_loss: 0.0605 - val_acc: 0.9844
Epoch 3/40
 - 113s - loss: 0.0498 - acc: 0.9877 - val_loss: 0.0627 - val_acc: 0.9847
Epoch 4/40
 - 112s - loss: 0.0480 - acc: 0.9882 - val_loss: 0.0659 - val_acc: 0.9844
Epoch 5/40
 - 113s - loss: 0.0470 - acc: 0.9885 - val_loss: 0.0699 - val_acc: 0.9844
Epoch 00005: early stopping
	TRAINING TIME: 9.92 minutes 
==================================================================================================
	PARSING TIME: 7.95 minutes 
==================================================================================================
	Identification : 0.527
	P, R  : 0.46, 0.617

==================================================================================================
	XP Ends: 2/7 (2 h:30)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (2h:30)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 34)       468962      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 88)        1213784     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 30)        3270        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_106 (Concatenate)   (None, 50, 41)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 352)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 120)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 106)          62752       concatenate_106[0][0]            
__________________________________________________________________________________________________
concatenate_107 (Concatenate)   (None, 472)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_108 (Concatenate)   (None, 578)          0           phraseRnn[0][0]                  
                                                                 concatenate_107[0][0]            
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 32)           18528       concatenate_108[0][0]            
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 4)            132         dense_71[0][0]                   
==================================================================================================
Total params: 1,768,191
Trainable params: 1,768,191
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 215s - loss: 0.0727 - acc: 0.9810 - val_loss: 0.0589 - val_acc: 0.9839
Epoch 2/40
 - 215s - loss: 0.0545 - acc: 0.9856 - val_loss: 0.0617 - val_acc: 0.9834
Epoch 3/40
 - 213s - loss: 0.0520 - acc: 0.9864 - val_loss: 0.0614 - val_acc: 0.9840
Epoch 4/40
 - 213s - loss: 0.0504 - acc: 0.9870 - val_loss: 0.0644 - val_acc: 0.9836
Epoch 5/40
 - 213s - loss: 0.0490 - acc: 0.9874 - val_loss: 0.0779 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 19.3 minutes 
==================================================================================================
	PARSING TIME: 3.4 minutes 
==================================================================================================
	Identification : 0.482
	P, R  : 0.487, 0.478

==================================================================================================
	XP Ends: 2/7 (2 h:53)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,87             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.016          ,50             ,13             ,25             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
7              ,52             ,True           ,True           ,202            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 87, True, 0.016, 50, 13, 25, 7, 52, True, True, 202
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (2h:53)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       188625      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1976        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 52)        392340      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1064        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_109 (Concatenate)   (None, 50, 38)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 260)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 202)          146046      concatenate_109[0][0]            
__________________________________________________________________________________________________
concatenate_110 (Concatenate)   (None, 295)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_111 (Concatenate)   (None, 497)          0           phraseRnn[0][0]                  
                                                                 concatenate_110[0][0]            
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 87)           43326       concatenate_111[0][0]            
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 4)            352         dense_73[0][0]                   
==================================================================================================
Total params: 773,729
Trainable params: 773,729
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 135s - loss: 0.0723 - acc: 0.9811 - val_loss: 0.0587 - val_acc: 0.9848
Epoch 2/40
 - 135s - loss: 0.0528 - acc: 0.9868 - val_loss: 0.0581 - val_acc: 0.9853
Epoch 3/40
 - 135s - loss: 0.0489 - acc: 0.9880 - val_loss: 0.0597 - val_acc: 0.9855
Epoch 4/40
 - 135s - loss: 0.0470 - acc: 0.9887 - val_loss: 0.0625 - val_acc: 0.9852
Epoch 5/40
 - 135s - loss: 0.0458 - acc: 0.9890 - val_loss: 0.0648 - val_acc: 0.9851
Epoch 00005: early stopping
	TRAINING TIME: 12.07 minutes 
==================================================================================================
	PARSING TIME: 4.1 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.741, 0.484

==================================================================================================
	XP Ends: 2/7 (3 h:10)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (3h:10)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       181025      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       2197        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 52)        376532      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1183        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_112 (Concatenate)   (None, 50, 38)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 260)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 202)          146046      concatenate_112[0][0]            
__________________________________________________________________________________________________
concatenate_113 (Concatenate)   (None, 295)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_114 (Concatenate)   (None, 497)          0           phraseRnn[0][0]                  
                                                                 concatenate_113[0][0]            
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 87)           43326       concatenate_114[0][0]            
__________________________________________________________________________________________________
dense_76 (Dense)                (None, 4)            352         dense_75[0][0]                   
==================================================================================================
Total params: 750,661
Trainable params: 750,661
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0829 - acc: 0.9777 - val_loss: 0.0721 - val_acc: 0.9809
Epoch 2/40
 - 93s - loss: 0.0567 - acc: 0.9854 - val_loss: 0.0626 - val_acc: 0.9840
Epoch 3/40
 - 92s - loss: 0.0521 - acc: 0.9870 - val_loss: 0.0640 - val_acc: 0.9839
Epoch 4/40
 - 92s - loss: 0.0498 - acc: 0.9877 - val_loss: 0.0655 - val_acc: 0.9840
Epoch 5/40
 - 92s - loss: 0.0485 - acc: 0.9881 - val_loss: 0.0681 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 8.17 minutes 
==================================================================================================
	PARSING TIME: 6.32 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.416, 0.618

==================================================================================================
	XP Ends: 2/7 (3 h:24)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (3h:24)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       344825      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 13)       1417        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 52)        717236      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         763         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_115 (Concatenate)   (None, 50, 38)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 260)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 202)          146046      concatenate_115[0][0]            
__________________________________________________________________________________________________
concatenate_116 (Concatenate)   (None, 295)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_117 (Concatenate)   (None, 497)          0           phraseRnn[0][0]                  
                                                                 concatenate_116[0][0]            
__________________________________________________________________________________________________
dense_77 (Dense)                (None, 87)           43326       concatenate_117[0][0]            
__________________________________________________________________________________________________
dense_78 (Dense)                (None, 4)            352         dense_77[0][0]                   
==================================================================================================
Total params: 1,253,965
Trainable params: 1,253,965
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 195s - loss: 0.0729 - acc: 0.9805 - val_loss: 0.0614 - val_acc: 0.9835
Epoch 2/40
 - 180s - loss: 0.0541 - acc: 0.9861 - val_loss: 0.0615 - val_acc: 0.9832
Epoch 3/40
 - 180s - loss: 0.0504 - acc: 0.9874 - val_loss: 0.0617 - val_acc: 0.9836
Epoch 4/40
 - 180s - loss: 0.0485 - acc: 0.9881 - val_loss: 0.0653 - val_acc: 0.9836
Epoch 5/40
 - 180s - loss: 0.0472 - acc: 0.9884 - val_loss: 0.0685 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 16.65 minutes 
==================================================================================================
	PARSING TIME: 2.72 minutes 
==================================================================================================
	Identification : 0.491
	P, R  : 0.501, 0.482

==================================================================================================
	XP Ends: 2/7 (3 h:44)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,233            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.022          ,50             ,9              ,52             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
45             ,40             ,True           ,True           ,54             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 233, False, 0.022, 50, 9, 52, 45, 40, True, True, 54
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (3h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 52)       594776      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1368        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 40)        457520      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 45)        6840        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_118 (Concatenate)   (None, 50, 61)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 200)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 225)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 54)           25056       concatenate_118[0][0]            
__________________________________________________________________________________________________
concatenate_119 (Concatenate)   (None, 425)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_120 (Concatenate)   (None, 479)          0           phraseRnn[0][0]                  
                                                                 concatenate_119[0][0]            
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 233)          111840      concatenate_120[0][0]            
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 4)            936         dense_79[0][0]                   
==================================================================================================
Total params: 1,198,336
Trainable params: 1,198,336
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 161s - loss: 0.0654 - acc: 0.9830 - val_loss: 0.0538 - val_acc: 0.9863
Epoch 2/40
 - 159s - loss: 0.0490 - acc: 0.9880 - val_loss: 0.0532 - val_acc: 0.9865
Epoch 3/40
 - 159s - loss: 0.0463 - acc: 0.9889 - val_loss: 0.0558 - val_acc: 0.9865
Epoch 4/40
 - 159s - loss: 0.0450 - acc: 0.9892 - val_loss: 0.0595 - val_acc: 0.9864
Epoch 5/40
 - 159s - loss: 0.0443 - acc: 0.9894 - val_loss: 0.0626 - val_acc: 0.9864
Epoch 00005: early stopping
	TRAINING TIME: 14.15 minutes 
==================================================================================================
	PARSING TIME: 5.25 minutes 
==================================================================================================
	Identification : 0.505
	P, R  : 0.436, 0.601

==================================================================================================
	XP Ends: 2/7 (4 h:4)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (4h:4)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 52)       488852      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        1521        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 40)        376040      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 45)        7605        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_121 (Concatenate)   (None, 50, 61)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 200)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 225)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 54)           25056       concatenate_121[0][0]            
__________________________________________________________________________________________________
concatenate_122 (Concatenate)   (None, 425)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_123 (Concatenate)   (None, 479)          0           phraseRnn[0][0]                  
                                                                 concatenate_122[0][0]            
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 233)          111840      concatenate_123[0][0]            
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 4)            936         dense_81[0][0]                   
==================================================================================================
Total params: 1,011,850
Trainable params: 1,011,850
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 108s - loss: 0.0743 - acc: 0.9794 - val_loss: 0.0777 - val_acc: 0.9795
Epoch 2/40
 - 108s - loss: 0.0532 - acc: 0.9866 - val_loss: 0.0579 - val_acc: 0.9853
Epoch 3/40
 - 107s - loss: 0.0493 - acc: 0.9879 - val_loss: 0.0609 - val_acc: 0.9851
Epoch 4/40
 - 108s - loss: 0.0476 - acc: 0.9883 - val_loss: 0.0660 - val_acc: 0.9850
Epoch 5/40
 - 108s - loss: 0.0465 - acc: 0.9885 - val_loss: 0.0734 - val_acc: 0.9849
Epoch 00005: early stopping
	TRAINING TIME: 9.48 minutes 
==================================================================================================
	PARSING TIME: 7.9 minutes 
==================================================================================================
	Identification : 0.479
	P, R  : 0.391, 0.617

==================================================================================================
	XP Ends: 2/7 (4 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (4h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 52)       1147692     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 9)        981         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 40)        882840      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 45)        4905        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_124 (Concatenate)   (None, 50, 61)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 200)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 225)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 54)           25056       concatenate_124[0][0]            
__________________________________________________________________________________________________
concatenate_125 (Concatenate)   (None, 425)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_126 (Concatenate)   (None, 479)          0           phraseRnn[0][0]                  
                                                                 concatenate_125[0][0]            
__________________________________________________________________________________________________
dense_83 (Dense)                (None, 233)          111840      concatenate_126[0][0]            
__________________________________________________________________________________________________
dense_84 (Dense)                (None, 4)            936         dense_83[0][0]                   
==================================================================================================
Total params: 2,174,250
Trainable params: 2,174,250
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 216s - loss: 0.0635 - acc: 0.9829 - val_loss: 0.0576 - val_acc: 0.9844
Epoch 2/40
 - 216s - loss: 0.0490 - acc: 0.9878 - val_loss: 0.0593 - val_acc: 0.9845
Epoch 3/40
 - 214s - loss: 0.0462 - acc: 0.9888 - val_loss: 0.0654 - val_acc: 0.9832
Epoch 4/40
 - 214s - loss: 0.0445 - acc: 0.9892 - val_loss: 0.0741 - val_acc: 0.9840
Epoch 5/40
 - 214s - loss: 0.0434 - acc: 0.9893 - val_loss: 0.0814 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 19.33 minutes 
==================================================================================================
	PARSING TIME: 3.5 minutes 
==================================================================================================
	Identification : 0.484
	P, R  : 0.411, 0.59

==================================================================================================
	XP Ends: 2/7 (4 h:45)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,40             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.1            ,50             ,25             ,32             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
22             ,144            ,False          ,True           ,496            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 40, True, 0.1, 50, 25, 32, 22, 144, False, True, 496
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (4h:45)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 32)       366016      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       3800        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 144)       1647072     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 22)        3344        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_127 (Concatenate)   (None, 50, 57)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 576)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 88)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 496)          824352      concatenate_127[0][0]            
__________________________________________________________________________________________________
concatenate_128 (Concatenate)   (None, 664)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_129 (Concatenate)   (None, 1160)         0           phraseRnn[0][0]                  
                                                                 concatenate_128[0][0]            
__________________________________________________________________________________________________
dense_85 (Dense)                (None, 40)           46440       concatenate_129[0][0]            
__________________________________________________________________________________________________
dense_86 (Dense)                (None, 4)            164         dense_85[0][0]                   
==================================================================================================
Total params: 2,891,188
Trainable params: 2,891,188
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 269s - loss: 12.0812 - acc: 0.2503 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 2/40
 - 269s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 3/40
 - 269s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 4/40
 - 269s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 5/40
 - 269s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 00005: early stopping
	TRAINING TIME: 23.22 minutes 
==================================================================================================
	PARSING TIME: 6.18 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (5 h:15)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (5h:15)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 32)       300832      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       4225        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 144)       1353744     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 22)        3718        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_130 (Concatenate)   (None, 50, 57)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 576)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 88)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 496)          824352      concatenate_130[0][0]            
__________________________________________________________________________________________________
concatenate_131 (Concatenate)   (None, 664)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_132 (Concatenate)   (None, 1160)         0           phraseRnn[0][0]                  
                                                                 concatenate_131[0][0]            
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 40)           46440       concatenate_132[0][0]            
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 4)            164         dense_87[0][0]                   
==================================================================================================
Total params: 2,533,475
Trainable params: 2,533,475
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 182s - loss: 11.8606 - acc: 0.2635 - val_loss: 11.8463 - val_acc: 0.2650
Epoch 2/40
 - 182s - loss: 11.8730 - acc: 0.2634 - val_loss: 11.8463 - val_acc: 0.2650
Epoch 3/40
 - 182s - loss: 11.8730 - acc: 0.2634 - val_loss: 11.8463 - val_acc: 0.2650
Epoch 4/40
 - 182s - loss: 11.8730 - acc: 0.2634 - val_loss: 11.8463 - val_acc: 0.2650
Epoch 5/40
 - 182s - loss: 11.8730 - acc: 0.2634 - val_loss: 11.8463 - val_acc: 0.2650
Epoch 00005: early stopping
	TRAINING TIME: 15.7 minutes 
==================================================================================================
	PARSING TIME: 17.75 minutes 
==================================================================================================
	Identification : 0.0
	P, R  : 0.0, 0.002

==================================================================================================
	XP Ends: 2/7 (5 h:49)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (5h:49)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 32)       706272      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 25)       2725        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 144)       3178224     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 22)        2398        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_133 (Concatenate)   (None, 50, 57)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 576)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 88)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 496)          824352      concatenate_133[0][0]            
__________________________________________________________________________________________________
concatenate_134 (Concatenate)   (None, 664)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_135 (Concatenate)   (None, 1160)         0           phraseRnn[0][0]                  
                                                                 concatenate_134[0][0]            
__________________________________________________________________________________________________
dense_89 (Dense)                (None, 40)           46440       concatenate_135[0][0]            
__________________________________________________________________________________________________
dense_90 (Dense)                (None, 4)            164         dense_89[0][0]                   
==================================================================================================
Total params: 4,760,575
Trainable params: 4,760,575
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 366s - loss: 12.0883 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 2/40
 - 366s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 3/40
 - 366s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 4/40
 - 366s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 5/40
 - 366s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0755 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 31.93 minutes 
==================================================================================================
	PARSING TIME: 10.88 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.067

==================================================================================================
	XP Ends: 2/7 (6 h:32)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,246            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.14           ,50             ,18             ,113            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
32             ,117            ,True           ,True           ,489            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 246, False, 0.14, 50, 18, 113, 32, 117, True, True, 489
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (6h:32)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 113)      1292494     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       2736        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 117)       1338246     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 32)        4864        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_136 (Concatenate)   (None, 50, 131)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 585)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 160)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 489)          1214676     concatenate_136[0][0]            
__________________________________________________________________________________________________
concatenate_137 (Concatenate)   (None, 745)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_138 (Concatenate)   (None, 1234)         0           phraseRnn[0][0]                  
                                                                 concatenate_137[0][0]            
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 246)          303810      concatenate_138[0][0]            
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 4)            988         dense_91[0][0]                   
==================================================================================================
Total params: 4,157,814
Trainable params: 4,157,814
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 377s - loss: 12.0838 - acc: 0.2501 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 2/40
 - 377s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 3/40
 - 377s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 4/40
 - 377s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 5/40
 - 377s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 00005: early stopping
	TRAINING TIME: 32.32 minutes 
==================================================================================================
	PARSING TIME: 8.98 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (7 h:13)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (7h:13)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 113)      1062313     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       3042        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 117)       1099917     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 32)        5408        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_139 (Concatenate)   (None, 50, 131)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 585)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 160)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 489)          1214676     concatenate_139[0][0]            
__________________________________________________________________________________________________
concatenate_140 (Concatenate)   (None, 745)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_141 (Concatenate)   (None, 1234)         0           phraseRnn[0][0]                  
                                                                 concatenate_140[0][0]            
__________________________________________________________________________________________________
dense_93 (Dense)                (None, 246)          303810      concatenate_141[0][0]            
__________________________________________________________________________________________________
dense_94 (Dense)                (None, 4)            988         dense_93[0][0]                   
==================================================================================================
Total params: 3,690,154
Trainable params: 3,690,154
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 255s - loss: 12.0878 - acc: 0.2498 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 2/40
 - 255s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 3/40
 - 255s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 4/40
 - 255s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 5/40
 - 255s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 00005: early stopping
	TRAINING TIME: 21.75 minutes 
==================================================================================================
	PARSING TIME: 25.35 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (8 h:1)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (8h:1)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 113)      2494023     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       1962        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 117)       2582307     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 32)        3488        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_142 (Concatenate)   (None, 50, 131)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 585)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 160)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 489)          1214676     concatenate_142[0][0]            
__________________________________________________________________________________________________
concatenate_143 (Concatenate)   (None, 745)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_144 (Concatenate)   (None, 1234)         0           phraseRnn[0][0]                  
                                                                 concatenate_143[0][0]            
__________________________________________________________________________________________________
dense_95 (Dense)                (None, 246)          303810      concatenate_144[0][0]            
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 4)            988         dense_95[0][0]                   
==================================================================================================
Total params: 6,601,254
Trainable params: 6,601,254
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 509s - loss: 12.0835 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 2/40
 - 509s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 3/40
 - 509s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 4/40
 - 509s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 5/40
 - 509s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 00005: early stopping
	TRAINING TIME: 43.9 minutes 
==================================================================================================
	PARSING TIME: 11.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (8 h:56)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,99             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.032          ,50             ,22             ,88             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,33             ,True           ,False          ,134            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 99, False, 0.032, 50, 22, 88, 8, 33, True, False, 134
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (8h:56)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 88)       663960      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       3344        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 33)        248985      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_145 (Concatenate)   (None, 50, 110)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 132)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 134)          131320      concatenate_145[0][0]            
__________________________________________________________________________________________________
concatenate_146 (Concatenate)   (None, 164)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_147 (Concatenate)   (None, 298)          0           phraseRnn[0][0]                  
                                                                 concatenate_146[0][0]            
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 99)           29601       concatenate_147[0][0]            
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 4)            400         dense_97[0][0]                   
==================================================================================================
Total params: 1,078,826
Trainable params: 1,078,826
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 165s - loss: 0.0677 - acc: 0.9823 - val_loss: 0.0576 - val_acc: 0.9854
Epoch 2/40
 - 164s - loss: 0.0516 - acc: 0.9871 - val_loss: 0.0568 - val_acc: 0.9855
Epoch 3/40
 - 164s - loss: 0.0484 - acc: 0.9882 - val_loss: 0.0581 - val_acc: 0.9855
Epoch 4/40
 - 164s - loss: 0.0467 - acc: 0.9887 - val_loss: 0.0629 - val_acc: 0.9853
Epoch 5/40
 - 164s - loss: 0.0457 - acc: 0.9890 - val_loss: 0.0648 - val_acc: 0.9852
Epoch 00005: early stopping
	TRAINING TIME: 14.58 minutes 
==================================================================================================
	PARSING TIME: 5.12 minutes 
==================================================================================================
	Identification : 0.587
	P, R  : 0.767, 0.476

==================================================================================================
	XP Ends: 2/7 (9 h:17)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (9h:17)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 88)       637208      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       3718        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 33)        238953      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_148 (Concatenate)   (None, 50, 110)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 132)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 134)          131320      concatenate_148[0][0]            
__________________________________________________________________________________________________
concatenate_149 (Concatenate)   (None, 164)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_150 (Concatenate)   (None, 298)          0           phraseRnn[0][0]                  
                                                                 concatenate_149[0][0]            
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 99)           29601       concatenate_150[0][0]            
__________________________________________________________________________________________________
dense_100 (Dense)               (None, 4)            400         dense_99[0][0]                   
==================================================================================================
Total params: 1,042,552
Trainable params: 1,042,552
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0775 - acc: 0.9787 - val_loss: 0.0646 - val_acc: 0.9826
Epoch 2/40
 - 111s - loss: 0.0562 - acc: 0.9854 - val_loss: 0.0654 - val_acc: 0.9838
Epoch 3/40
 - 110s - loss: 0.0518 - acc: 0.9870 - val_loss: 0.0635 - val_acc: 0.9837
Epoch 4/40
 - 110s - loss: 0.0494 - acc: 0.9877 - val_loss: 0.0671 - val_acc: 0.9837
Epoch 5/40
 - 110s - loss: 0.0478 - acc: 0.9882 - val_loss: 0.0703 - val_acc: 0.9830
Epoch 00005: early stopping
	TRAINING TIME: 9.75 minutes 
==================================================================================================
	PARSING TIME: 8.0 minutes 
==================================================================================================
	Identification : 0.439
	P, R  : 0.34, 0.62

==================================================================================================
	XP Ends: 2/7 (9 h:35)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (9h:35)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 88)       1213784     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 22)       2398        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 33)        455169      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_151 (Concatenate)   (None, 50, 110)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 132)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 134)          131320      concatenate_151[0][0]            
__________________________________________________________________________________________________
concatenate_152 (Concatenate)   (None, 164)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_153 (Concatenate)   (None, 298)          0           phraseRnn[0][0]                  
                                                                 concatenate_152[0][0]            
__________________________________________________________________________________________________
dense_101 (Dense)               (None, 99)           29601       concatenate_153[0][0]            
__________________________________________________________________________________________________
dense_102 (Dense)               (None, 4)            400         dense_101[0][0]                  
==================================================================================================
Total params: 1,833,544
Trainable params: 1,833,544
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 217s - loss: 0.0743 - acc: 0.9801 - val_loss: 0.0680 - val_acc: 0.9811
Epoch 2/40
 - 255s - loss: 0.0556 - acc: 0.9854 - val_loss: 0.0619 - val_acc: 0.9832
Epoch 3/40
 - 217s - loss: 0.0526 - acc: 0.9865 - val_loss: 0.0619 - val_acc: 0.9833
Epoch 4/40
 - 215s - loss: 0.0502 - acc: 0.9873 - val_loss: 0.0655 - val_acc: 0.9834
Epoch 5/40
 - 215s - loss: 0.0487 - acc: 0.9878 - val_loss: 0.0682 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 20.08 minutes 
==================================================================================================
	PARSING TIME: 3.47 minutes 
==================================================================================================
	Identification : 0.49
	P, R  : 0.488, 0.492

==================================================================================================
	XP Ends: 2/7 (9 h:59)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,66             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.132          ,50             ,7              ,105            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
23             ,34             ,False          ,True           ,95             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 66, True, 0.132, 50, 7, 105, 23, 34, False, True, 95
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (9h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 105)      1200990     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 34)        388892      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 23)        3496        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_154 (Concatenate)   (None, 50, 112)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 136)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 92)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 95)           59280       concatenate_154[0][0]            
__________________________________________________________________________________________________
concatenate_155 (Concatenate)   (None, 228)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_156 (Concatenate)   (None, 323)          0           phraseRnn[0][0]                  
                                                                 concatenate_155[0][0]            
__________________________________________________________________________________________________
dense_103 (Dense)               (None, 66)           21384       concatenate_156[0][0]            
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 4)            268         dense_103[0][0]                  
==================================================================================================
Total params: 1,675,374
Trainable params: 1,675,374
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 138s - loss: 8.0549 - acc: 0.4999 - val_loss: 8.0601 - val_acc: 0.4999
Epoch 2/40
 - 137s - loss: 8.0589 - acc: 0.5000 - val_loss: 8.0601 - val_acc: 0.4999
Epoch 3/40
 - 136s - loss: 8.0589 - acc: 0.5000 - val_loss: 8.0601 - val_acc: 0.4999
Epoch 4/40
 - 136s - loss: 8.0589 - acc: 0.5000 - val_loss: 8.0601 - val_acc: 0.4999
Epoch 5/40
 - 136s - loss: 8.0589 - acc: 0.5000 - val_loss: 8.0601 - val_acc: 0.4999
Epoch 00005: early stopping
	TRAINING TIME: 12.13 minutes 
==================================================================================================
	PARSING TIME: 7.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (10 h:18)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (10h:18)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 105)      987105      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 34)        319634      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 23)        3887        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_157 (Concatenate)   (None, 50, 112)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 136)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 92)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 95)           59280       concatenate_157[0][0]            
__________________________________________________________________________________________________
concatenate_158 (Concatenate)   (None, 228)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_159 (Concatenate)   (None, 323)          0           phraseRnn[0][0]                  
                                                                 concatenate_158[0][0]            
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 66)           21384       concatenate_159[0][0]            
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 4)            268         dense_105[0][0]                  
==================================================================================================
Total params: 1,392,741
Trainable params: 1,392,741
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0985 - acc: 0.9770 - val_loss: 0.0600 - val_acc: 0.9846
Epoch 2/40
 - 93s - loss: 0.0540 - acc: 0.9864 - val_loss: 0.0589 - val_acc: 0.9848
Epoch 3/40
 - 92s - loss: 0.0502 - acc: 0.9876 - val_loss: 0.0610 - val_acc: 0.9849
Epoch 4/40
 - 92s - loss: 0.0484 - acc: 0.9882 - val_loss: 0.0676 - val_acc: 0.9845
Epoch 5/40
 - 92s - loss: 0.0471 - acc: 0.9884 - val_loss: 0.0718 - val_acc: 0.9844
Epoch 00005: early stopping
	TRAINING TIME: 8.15 minutes 
==================================================================================================
	PARSING TIME: 6.78 minutes 
==================================================================================================
	Identification : 0.476
	P, R  : 0.403, 0.582

==================================================================================================
	XP Ends: 2/7 (10 h:34)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (10h:34)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 105)      2317455     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 34)        750414      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 23)        2507        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_160 (Concatenate)   (None, 50, 112)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 136)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 92)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 95)           59280       concatenate_160[0][0]            
__________________________________________________________________________________________________
concatenate_161 (Concatenate)   (None, 228)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_162 (Concatenate)   (None, 323)          0           phraseRnn[0][0]                  
                                                                 concatenate_161[0][0]            
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 66)           21384       concatenate_162[0][0]            
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 4)            268         dense_107[0][0]                  
==================================================================================================
Total params: 3,152,071
Trainable params: 3,152,071
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 182s - loss: 0.0704 - acc: 0.9815 - val_loss: 0.0605 - val_acc: 0.9838
Epoch 2/40
 - 182s - loss: 0.0507 - acc: 0.9871 - val_loss: 0.0615 - val_acc: 0.9840
Epoch 3/40
 - 182s - loss: 0.0483 - acc: 0.9880 - val_loss: 0.0650 - val_acc: 0.9841
Epoch 4/40
 - 181s - loss: 0.0466 - acc: 0.9884 - val_loss: 0.0743 - val_acc: 0.9836
Epoch 5/40
 - 181s - loss: 0.0454 - acc: 0.9887 - val_loss: 0.0795 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 16.58 minutes 
==================================================================================================
	PARSING TIME: 2.73 minutes 
==================================================================================================
	Identification : 0.505
	P, R  : 0.446, 0.582

==================================================================================================
	XP Ends: 2/7 (10 h:53)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,77             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.159          ,50             ,11             ,149            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
25             ,98             ,True           ,True           ,30             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 77, True, 0.159, 50, 11, 149, 25, 98, True, True, 30
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (10h:53)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 149)      1704262     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1672        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 98)        1120924     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        3800        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_163 (Concatenate)   (None, 50, 160)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 490)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 30)           17190       concatenate_163[0][0]            
__________________________________________________________________________________________________
concatenate_164 (Concatenate)   (None, 615)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_165 (Concatenate)   (None, 645)          0           phraseRnn[0][0]                  
                                                                 concatenate_164[0][0]            
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 77)           49742       concatenate_165[0][0]            
__________________________________________________________________________________________________
dense_110 (Dense)               (None, 4)            312         dense_109[0][0]                  
==================================================================================================
Total params: 2,897,902
Trainable params: 2,897,902
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 145s - loss: 8.0788 - acc: 0.4980 - val_loss: 8.0885 - val_acc: 0.4979
Epoch 2/40
 - 142s - loss: 8.0542 - acc: 0.5002 - val_loss: 8.0882 - val_acc: 0.4981
Epoch 3/40
 - 139s - loss: 8.0536 - acc: 0.5003 - val_loss: 8.0881 - val_acc: 0.4980
Epoch 4/40
 - 143s - loss: 8.0536 - acc: 0.5003 - val_loss: 8.0882 - val_acc: 0.4980
Epoch 5/40
 - 140s - loss: 8.0535 - acc: 0.5003 - val_loss: 8.0882 - val_acc: 0.4980
Epoch 00005: early stopping
	TRAINING TIME: 12.57 minutes 
==================================================================================================
	PARSING TIME: 4.2 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (11 h:11)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (11h:11)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 149)      1400749     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1859        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 98)        921298      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        4225        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_166 (Concatenate)   (None, 50, 160)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 490)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 30)           17190       concatenate_166[0][0]            
__________________________________________________________________________________________________
concatenate_167 (Concatenate)   (None, 615)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_168 (Concatenate)   (None, 645)          0           phraseRnn[0][0]                  
                                                                 concatenate_167[0][0]            
__________________________________________________________________________________________________
dense_111 (Dense)               (None, 77)           49742       concatenate_168[0][0]            
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 4)            312         dense_111[0][0]                  
==================================================================================================
Total params: 2,395,375
Trainable params: 2,395,375
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 96s - loss: 0.1192 - acc: 0.9757 - val_loss: 0.0595 - val_acc: 0.9849
Epoch 2/40
 - 95s - loss: 0.0539 - acc: 0.9865 - val_loss: 0.0600 - val_acc: 0.9849
Epoch 3/40
 - 99s - loss: 0.0495 - acc: 0.9879 - val_loss: 0.0628 - val_acc: 0.9851
Epoch 4/40
 - 93s - loss: 0.0478 - acc: 0.9883 - val_loss: 0.0661 - val_acc: 0.9850
Epoch 5/40
 - 97s - loss: 0.0470 - acc: 0.9884 - val_loss: 0.0715 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 8.47 minutes 
==================================================================================================
	PARSING TIME: 6.58 minutes 
==================================================================================================
	Identification : 0.491
	P, R  : 0.427, 0.577

==================================================================================================
	XP Ends: 2/7 (11 h:26)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (11h:26)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 149)      3288579     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1199        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 98)        2162958     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 25)        2725        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_169 (Concatenate)   (None, 50, 160)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 490)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 125)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 30)           17190       concatenate_169[0][0]            
__________________________________________________________________________________________________
concatenate_170 (Concatenate)   (None, 615)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_171 (Concatenate)   (None, 645)          0           phraseRnn[0][0]                  
                                                                 concatenate_170[0][0]            
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 77)           49742       concatenate_171[0][0]            
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 4)            312         dense_113[0][0]                  
==================================================================================================
Total params: 5,522,705
Trainable params: 5,522,705
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 186s - loss: 0.1548 - acc: 0.9763 - val_loss: 0.0642 - val_acc: 0.9822
Epoch 2/40
 - 186s - loss: 0.0503 - acc: 0.9876 - val_loss: 0.0632 - val_acc: 0.9832
Epoch 3/40
 - 186s - loss: 0.0469 - acc: 0.9887 - val_loss: 0.0663 - val_acc: 0.9832
Epoch 4/40
 - 185s - loss: 0.0456 - acc: 0.9890 - val_loss: 0.0733 - val_acc: 0.9834
Epoch 5/40
 - 184s - loss: 0.0445 - acc: 0.9892 - val_loss: 0.0893 - val_acc: 0.9828
Epoch 00005: early stopping
	TRAINING TIME: 16.85 minutes 
==================================================================================================
	PARSING TIME: 2.72 minutes 
==================================================================================================
	Identification : 0.487
	P, R  : 0.432, 0.559

==================================================================================================
	XP Ends: 2/7 (11 h:46)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,165            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.097          ,50             ,8              ,25             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
18             ,49             ,True           ,True           ,170            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 165, False, 0.097, 50, 8, 25, 18, 49, True, True, 170
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (11h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       285950      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 49)        560462      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 18)        2736        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_172 (Concatenate)   (None, 50, 33)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 245)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 90)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 170)          138720      concatenate_172[0][0]            
__________________________________________________________________________________________________
concatenate_173 (Concatenate)   (None, 335)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_174 (Concatenate)   (None, 505)          0           phraseRnn[0][0]                  
                                                                 concatenate_173[0][0]            
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 165)          83490       concatenate_174[0][0]            
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 4)            664         dense_115[0][0]                  
==================================================================================================
Total params: 1,073,238
Trainable params: 1,073,238
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 165s - loss: 12.0866 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 2/40
 - 163s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 3/40
 - 163s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 4/40
 - 163s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 5/40
 - 164s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 14.53 minutes 
==================================================================================================
	PARSING TIME: 9.57 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (12 h:11)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (12h:11)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       235025      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 49)        460649      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 18)        3042        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_175 (Concatenate)   (None, 50, 33)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 245)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 90)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 170)          138720      concatenate_175[0][0]            
__________________________________________________________________________________________________
concatenate_176 (Concatenate)   (None, 335)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_177 (Concatenate)   (None, 505)          0           phraseRnn[0][0]                  
                                                                 concatenate_176[0][0]            
__________________________________________________________________________________________________
dense_117 (Dense)               (None, 165)          83490       concatenate_177[0][0]            
__________________________________________________________________________________________________
dense_118 (Dense)               (None, 4)            664         dense_117[0][0]                  
==================================================================================================
Total params: 922,942
Trainable params: 922,942
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 112s - loss: 12.0859 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 2/40
 - 111s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 3/40
 - 111s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 4/40
 - 112s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 5/40
 - 112s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 00005: early stopping
	TRAINING TIME: 9.85 minutes 
==================================================================================================
	PARSING TIME: 13.87 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (12 h:35)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (12h:35)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 25)       551775      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 49)        1081479     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 18)        1962        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_178 (Concatenate)   (None, 50, 33)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 245)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 90)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 170)          138720      concatenate_178[0][0]            
__________________________________________________________________________________________________
concatenate_179 (Concatenate)   (None, 335)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_180 (Concatenate)   (None, 505)          0           phraseRnn[0][0]                  
                                                                 concatenate_179[0][0]            
__________________________________________________________________________________________________
dense_119 (Dense)               (None, 165)          83490       concatenate_180[0][0]            
__________________________________________________________________________________________________
dense_120 (Dense)               (None, 4)            664         dense_119[0][0]                  
==================================================================================================
Total params: 1,858,962
Trainable params: 1,858,962
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 217s - loss: 12.0830 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 2/40
 - 217s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 3/40
 - 217s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 4/40
 - 216s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 5/40
 - 214s - loss: 12.0853 - acc: 0.2502 - val_loss: 12.1017 - val_acc: 0.2492
Epoch 00005: early stopping
	TRAINING TIME: 19.52 minutes 
==================================================================================================
	PARSING TIME: 3.23 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (12 h:58)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,33             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.051          ,50             ,6              ,60             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
6              ,90             ,False          ,True           ,78             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 33, True, 0.051, 50, 6, 60, 6, 90, False, True, 78
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (12h:58)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 60)       686280      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 90)        1029420     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 6)         912         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_181 (Concatenate)   (None, 50, 66)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 360)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 24)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 78)           33930       concatenate_181[0][0]            
__________________________________________________________________________________________________
concatenate_182 (Concatenate)   (None, 384)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_183 (Concatenate)   (None, 462)          0           phraseRnn[0][0]                  
                                                                 concatenate_182[0][0]            
__________________________________________________________________________________________________
dense_121 (Dense)               (None, 33)           15279       concatenate_183[0][0]            
__________________________________________________________________________________________________
dense_122 (Dense)               (None, 4)            136         dense_121[0][0]                  
==================================================================================================
Total params: 1,766,869
Trainable params: 1,766,869
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 0.0727 - acc: 0.9810 - val_loss: 0.0553 - val_acc: 0.9855
Epoch 2/40
 - 135s - loss: 0.0505 - acc: 0.9876 - val_loss: 0.0564 - val_acc: 0.9857
Epoch 3/40
 - 138s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0572 - val_acc: 0.9858
Epoch 4/40
 - 140s - loss: 0.0464 - acc: 0.9888 - val_loss: 0.0597 - val_acc: 0.9858
Epoch 5/40
 - 137s - loss: 0.0453 - acc: 0.9891 - val_loss: 0.0634 - val_acc: 0.9856
Epoch 00005: early stopping
	TRAINING TIME: 12.2 minutes 
==================================================================================================
	PARSING TIME: 4.38 minutes 
==================================================================================================
	Identification : 0.536
	P, R  : 0.635, 0.463

==================================================================================================
	XP Ends: 2/7 (13 h:15)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (13h:15)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 60)       564060      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 90)        846090      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 6)         1014        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_184 (Concatenate)   (None, 50, 66)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 360)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 24)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 78)           33930       concatenate_184[0][0]            
__________________________________________________________________________________________________
concatenate_185 (Concatenate)   (None, 384)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_186 (Concatenate)   (None, 462)          0           phraseRnn[0][0]                  
                                                                 concatenate_185[0][0]            
__________________________________________________________________________________________________
dense_123 (Dense)               (None, 33)           15279       concatenate_186[0][0]            
__________________________________________________________________________________________________
dense_124 (Dense)               (None, 4)            136         dense_123[0][0]                  
==================================================================================================
Total params: 1,461,523
Trainable params: 1,461,523
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 99s - loss: 0.0765 - acc: 0.9786 - val_loss: 0.0590 - val_acc: 0.9843
Epoch 2/40
 - 98s - loss: 0.0531 - acc: 0.9867 - val_loss: 0.0592 - val_acc: 0.9845
Epoch 3/40
 - 97s - loss: 0.0492 - acc: 0.9880 - val_loss: 0.0608 - val_acc: 0.9849
Epoch 4/40
 - 97s - loss: 0.0476 - acc: 0.9884 - val_loss: 0.0645 - val_acc: 0.9847
Epoch 5/40
 - 97s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0689 - val_acc: 0.9846
Epoch 00005: early stopping
	TRAINING TIME: 8.62 minutes 
==================================================================================================
	PARSING TIME: 6.62 minutes 
==================================================================================================
	Identification : 0.497
	P, R  : 0.433, 0.584

==================================================================================================
	XP Ends: 2/7 (13 h:30)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (13h:30)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 60)       1324260     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 90)        1986390     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 6)         654         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_187 (Concatenate)   (None, 50, 66)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 360)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 24)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 78)           33930       concatenate_187[0][0]            
__________________________________________________________________________________________________
concatenate_188 (Concatenate)   (None, 384)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_189 (Concatenate)   (None, 462)          0           phraseRnn[0][0]                  
                                                                 concatenate_188[0][0]            
__________________________________________________________________________________________________
dense_125 (Dense)               (None, 33)           15279       concatenate_189[0][0]            
__________________________________________________________________________________________________
dense_126 (Dense)               (None, 4)            136         dense_125[0][0]                  
==================================================================================================
Total params: 3,361,303
Trainable params: 3,361,303
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 187s - loss: 0.0646 - acc: 0.9825 - val_loss: 0.0588 - val_acc: 0.9844
Epoch 2/40
 - 190s - loss: 0.0493 - acc: 0.9875 - val_loss: 0.0594 - val_acc: 0.9843
Epoch 3/40
 - 184s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0629 - val_acc: 0.9841
Epoch 4/40
 - 191s - loss: 0.0454 - acc: 0.9889 - val_loss: 0.0688 - val_acc: 0.9838
Epoch 5/40
 - 183s - loss: 0.0443 - acc: 0.9892 - val_loss: 0.0719 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 16.97 minutes 
==================================================================================================
	PARSING TIME: 2.8 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.456, 0.492

==================================================================================================
	XP Ends: 2/7 (13 h:51)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,47             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.049          ,50             ,7              ,106            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
16             ,86             ,True           ,True           ,61             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 47, True, 0.049, 50, 7, 106, 16, 86, True, True, 61
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (13h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 106)      799770      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 86)        648870      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 16)        2432        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_190 (Concatenate)   (None, 50, 113)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 430)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 80)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 61)           32025       concatenate_190[0][0]            
__________________________________________________________________________________________________
concatenate_191 (Concatenate)   (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_192 (Concatenate)   (None, 571)          0           phraseRnn[0][0]                  
                                                                 concatenate_191[0][0]            
__________________________________________________________________________________________________
dense_127 (Dense)               (None, 47)           26884       concatenate_192[0][0]            
__________________________________________________________________________________________________
dense_128 (Dense)               (None, 4)            192         dense_127[0][0]                  
==================================================================================================
Total params: 1,511,237
Trainable params: 1,511,237
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 0.0646 - acc: 0.9830 - val_loss: 0.0548 - val_acc: 0.9857
Epoch 2/40
 - 135s - loss: 0.0498 - acc: 0.9877 - val_loss: 0.0564 - val_acc: 0.9856
Epoch 3/40
 - 136s - loss: 0.0468 - acc: 0.9887 - val_loss: 0.0579 - val_acc: 0.9856
Epoch 4/40
 - 136s - loss: 0.0453 - acc: 0.9891 - val_loss: 0.0609 - val_acc: 0.9858
Epoch 5/40
 - 135s - loss: 0.0443 - acc: 0.9894 - val_loss: 0.0661 - val_acc: 0.9853
Epoch 00005: early stopping
	TRAINING TIME: 12.1 minutes 
==================================================================================================
	PARSING TIME: 4.08 minutes 
==================================================================================================
	Identification : 0.596
	P, R  : 0.752, 0.494

==================================================================================================
	XP Ends: 2/7 (14 h:7)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (14h:7)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 106)      767546      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 86)        622726      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 16)        2704        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_193 (Concatenate)   (None, 50, 113)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 430)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 80)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 61)           32025       concatenate_193[0][0]            
__________________________________________________________________________________________________
concatenate_194 (Concatenate)   (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_195 (Concatenate)   (None, 571)          0           phraseRnn[0][0]                  
                                                                 concatenate_194[0][0]            
__________________________________________________________________________________________________
dense_129 (Dense)               (None, 47)           26884       concatenate_195[0][0]            
__________________________________________________________________________________________________
dense_130 (Dense)               (None, 4)            192         dense_129[0][0]                  
==================================================================================================
Total params: 1,453,260
Trainable params: 1,453,260
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 96s - loss: 0.0721 - acc: 0.9806 - val_loss: 0.0590 - val_acc: 0.9844
Epoch 2/40
 - 93s - loss: 0.0519 - acc: 0.9869 - val_loss: 0.0591 - val_acc: 0.9846
Epoch 3/40
 - 93s - loss: 0.0482 - acc: 0.9882 - val_loss: 0.0609 - val_acc: 0.9849
Epoch 4/40
 - 93s - loss: 0.0468 - acc: 0.9886 - val_loss: 0.0640 - val_acc: 0.9847
Epoch 5/40
 - 92s - loss: 0.0460 - acc: 0.9888 - val_loss: 0.0698 - val_acc: 0.9846
Epoch 00005: early stopping
	TRAINING TIME: 8.3 minutes 
==================================================================================================
	PARSING TIME: 6.27 minutes 
==================================================================================================
	Identification : 0.505
	P, R  : 0.431, 0.609

==================================================================================================
	XP Ends: 2/7 (14 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (14h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 106)      1462058     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 86)        1186198     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 16)        1744        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_196 (Concatenate)   (None, 50, 113)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 430)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 80)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 61)           32025       concatenate_196[0][0]            
__________________________________________________________________________________________________
concatenate_197 (Concatenate)   (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_198 (Concatenate)   (None, 571)          0           phraseRnn[0][0]                  
                                                                 concatenate_197[0][0]            
__________________________________________________________________________________________________
dense_131 (Dense)               (None, 47)           26884       concatenate_198[0][0]            
__________________________________________________________________________________________________
dense_132 (Dense)               (None, 4)            192         dense_131[0][0]                  
==================================================================================================
Total params: 2,709,864
Trainable params: 2,709,864
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 182s - loss: 0.0652 - acc: 0.9822 - val_loss: 0.0598 - val_acc: 0.9836
Epoch 2/40
 - 182s - loss: 0.0513 - acc: 0.9869 - val_loss: 0.0581 - val_acc: 0.9847
Epoch 3/40
 - 182s - loss: 0.0484 - acc: 0.9880 - val_loss: 0.0603 - val_acc: 0.9844
Epoch 4/40
 - 182s - loss: 0.0466 - acc: 0.9886 - val_loss: 0.0654 - val_acc: 0.9840
Epoch 5/40
 - 182s - loss: 0.0455 - acc: 0.9889 - val_loss: 0.0694 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 16.58 minutes 
==================================================================================================
	PARSING TIME: 2.72 minutes 
==================================================================================================
	Identification : 0.502
	P, R  : 0.471, 0.537

==================================================================================================
	XP Ends: 2/7 (14 h:42)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,100            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.048          ,50             ,18             ,198            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
39             ,27             ,True           ,True           ,151            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 100, False, 0.048, 50, 18, 198, 39, 27, True, True, 151
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (14h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 198)      1493910     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       2736        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 27)        203715      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 39)        5928        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_199 (Concatenate)   (None, 50, 216)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 135)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 195)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 151)          222272      concatenate_199[0][0]            
__________________________________________________________________________________________________
concatenate_200 (Concatenate)   (None, 330)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_201 (Concatenate)   (None, 481)          0           phraseRnn[0][0]                  
                                                                 concatenate_200[0][0]            
__________________________________________________________________________________________________
dense_133 (Dense)               (None, 100)          48200       concatenate_201[0][0]            
__________________________________________________________________________________________________
dense_134 (Dense)               (None, 4)            404         dense_133[0][0]                  
==================================================================================================
Total params: 1,977,165
Trainable params: 1,977,165
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 164s - loss: 0.0729 - acc: 0.9819 - val_loss: 0.0562 - val_acc: 0.9855
Epoch 2/40
 - 164s - loss: 0.0510 - acc: 0.9872 - val_loss: 0.0558 - val_acc: 0.9859
Epoch 3/40
 - 164s - loss: 0.0476 - acc: 0.9884 - val_loss: 0.0566 - val_acc: 0.9861
Epoch 4/40
 - 164s - loss: 0.0458 - acc: 0.9889 - val_loss: 0.0591 - val_acc: 0.9859
Epoch 5/40
 - 164s - loss: 0.0447 - acc: 0.9892 - val_loss: 0.0637 - val_acc: 0.9856
Epoch 00005: early stopping
	TRAINING TIME: 14.47 minutes 
==================================================================================================
	PARSING TIME: 5.22 minutes 
==================================================================================================
	Identification : 0.54
	P, R  : 0.511, 0.572

==================================================================================================
	XP Ends: 2/7 (15 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (15h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 198)      1433718     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       3042        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 27)        195507      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 39)        6591        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_202 (Concatenate)   (None, 50, 216)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 135)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 195)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 151)          222272      concatenate_202[0][0]            
__________________________________________________________________________________________________
concatenate_203 (Concatenate)   (None, 330)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_204 (Concatenate)   (None, 481)          0           phraseRnn[0][0]                  
                                                                 concatenate_203[0][0]            
__________________________________________________________________________________________________
dense_135 (Dense)               (None, 100)          48200       concatenate_204[0][0]            
__________________________________________________________________________________________________
dense_136 (Dense)               (None, 4)            404         dense_135[0][0]                  
==================================================================================================
Total params: 1,909,734
Trainable params: 1,909,734
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 111s - loss: 0.0753 - acc: 0.9799 - val_loss: 0.0616 - val_acc: 0.9838
Epoch 2/40
 - 111s - loss: 0.0530 - acc: 0.9867 - val_loss: 0.0711 - val_acc: 0.9845
Epoch 3/40
 - 111s - loss: 0.0491 - acc: 0.9879 - val_loss: 0.0622 - val_acc: 0.9848
Epoch 4/40
 - 111s - loss: 0.0473 - acc: 0.9885 - val_loss: 0.0659 - val_acc: 0.9849
Epoch 5/40
 - 111s - loss: 0.0463 - acc: 0.9887 - val_loss: 0.0711 - val_acc: 0.9849
Epoch 00005: early stopping
	TRAINING TIME: 9.75 minutes 
==================================================================================================
	PARSING TIME: 8.2 minutes 
==================================================================================================
	Identification : 0.483
	P, R  : 0.39, 0.633

==================================================================================================
	XP Ends: 2/7 (15 h:20)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (15h:20)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 198)      2731014     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       1962        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 27)        372411      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 39)        4251        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_205 (Concatenate)   (None, 50, 216)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 135)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 195)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 151)          222272      concatenate_205[0][0]            
__________________________________________________________________________________________________
concatenate_206 (Concatenate)   (None, 330)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_207 (Concatenate)   (None, 481)          0           phraseRnn[0][0]                  
                                                                 concatenate_206[0][0]            
__________________________________________________________________________________________________
dense_137 (Dense)               (None, 100)          48200       concatenate_207[0][0]            
__________________________________________________________________________________________________
dense_138 (Dense)               (None, 4)            404         dense_137[0][0]                  
==================================================================================================
Total params: 3,380,514
Trainable params: 3,380,514
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 224s - loss: 0.0708 - acc: 0.9813 - val_loss: 0.0574 - val_acc: 0.9845
Epoch 2/40
 - 224s - loss: 0.0525 - acc: 0.9865 - val_loss: 0.0569 - val_acc: 0.9845
Epoch 3/40
 - 224s - loss: 0.0493 - acc: 0.9876 - val_loss: 0.0624 - val_acc: 0.9835
Epoch 4/40
 - 224s - loss: 0.0476 - acc: 0.9883 - val_loss: 0.0637 - val_acc: 0.9841
Epoch 5/40
 - 224s - loss: 0.0463 - acc: 0.9886 - val_loss: 0.0707 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 20.23 minutes 
==================================================================================================
	PARSING TIME: 3.5 minutes 
==================================================================================================
	Identification : 0.487
	P, R  : 0.407, 0.606

==================================================================================================
	XP Ends: 2/7 (15 h:44)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,244            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.085          ,50             ,18             ,66             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
10             ,27             ,False          ,False          ,138            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 244, True, 0.085, 50, 18, 66, 10, 27, False, False, 138
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (15h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 66)       754908      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       2736        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 27)        308826      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 10)        1520        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_208 (Concatenate)   (None, 50, 84)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 81)           0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 138)          92322       concatenate_208[0][0]            
__________________________________________________________________________________________________
concatenate_209 (Concatenate)   (None, 111)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_210 (Concatenate)   (None, 249)          0           phraseRnn[0][0]                  
                                                                 concatenate_209[0][0]            
__________________________________________________________________________________________________
dense_139 (Dense)               (None, 244)          61000       concatenate_210[0][0]            
__________________________________________________________________________________________________
dense_140 (Dense)               (None, 4)            980         dense_139[0][0]                  
==================================================================================================
Total params: 1,222,292
Trainable params: 1,222,292
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 141s - loss: 12.0794 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 2/40
 - 148s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 3/40
 - 148s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 4/40
 - 148s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 5/40
 - 149s - loss: 12.0857 - acc: 0.2502 - val_loss: 12.0999 - val_acc: 0.2493
Epoch 00005: early stopping
	TRAINING TIME: 12.97 minutes 
==================================================================================================
	PARSING TIME: 4.13 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (16 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (16h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 66)       620466      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       3042        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 27)        253827      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 10)        1690        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_211 (Concatenate)   (None, 50, 84)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 81)           0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 138)          92322       concatenate_211[0][0]            
__________________________________________________________________________________________________
concatenate_212 (Concatenate)   (None, 111)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_213 (Concatenate)   (None, 249)          0           phraseRnn[0][0]                  
                                                                 concatenate_212[0][0]            
__________________________________________________________________________________________________
dense_141 (Dense)               (None, 244)          61000       concatenate_213[0][0]            
__________________________________________________________________________________________________
dense_142 (Dense)               (None, 4)            980         dense_141[0][0]                  
==================================================================================================
Total params: 1,033,327
Trainable params: 1,033,327
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 12.0893 - acc: 0.2493 - val_loss: 12.0407 - val_acc: 0.2530
Epoch 2/40
 - 93s - loss: 12.1028 - acc: 0.2491 - val_loss: 12.0407 - val_acc: 0.2530
Epoch 3/40
 - 93s - loss: 12.1028 - acc: 0.2491 - val_loss: 12.0407 - val_acc: 0.2530
Epoch 4/40
 - 92s - loss: 12.1028 - acc: 0.2491 - val_loss: 12.0407 - val_acc: 0.2530
Epoch 5/40
 - 92s - loss: 12.1028 - acc: 0.2491 - val_loss: 12.0407 - val_acc: 0.2530
Epoch 00005: early stopping
	TRAINING TIME: 8.17 minutes 
==================================================================================================
	PARSING TIME: 11.35 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (16 h:22)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (16h:22)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 66)       1456686     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       1962        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 27)        595917      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 10)        1090        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_214 (Concatenate)   (None, 50, 84)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 81)           0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 30)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 138)          92322       concatenate_214[0][0]            
__________________________________________________________________________________________________
concatenate_215 (Concatenate)   (None, 111)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_216 (Concatenate)   (None, 249)          0           phraseRnn[0][0]                  
                                                                 concatenate_215[0][0]            
__________________________________________________________________________________________________
dense_143 (Dense)               (None, 244)          61000       concatenate_216[0][0]            
__________________________________________________________________________________________________
dense_144 (Dense)               (None, 4)            980         dense_143[0][0]                  
==================================================================================================
Total params: 2,209,957
Trainable params: 2,209,957
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 182s - loss: 0.1163 - acc: 0.9770 - val_loss: 0.0749 - val_acc: 0.9790
Epoch 2/40
 - 182s - loss: 0.0551 - acc: 0.9854 - val_loss: 0.0632 - val_acc: 0.9830
Epoch 3/40
 - 182s - loss: 0.0520 - acc: 0.9862 - val_loss: 0.0644 - val_acc: 0.9831
Epoch 4/40
 - 181s - loss: 0.0506 - acc: 0.9867 - val_loss: 0.0766 - val_acc: 0.9796
Epoch 5/40
 - 180s - loss: 0.0497 - acc: 0.9869 - val_loss: 0.0770 - val_acc: 0.9815
Epoch 00005: early stopping
	TRAINING TIME: 16.5 minutes 
==================================================================================================
	PARSING TIME: 2.82 minutes 
==================================================================================================
	Identification : 0.484
	P, R  : 0.404, 0.604

==================================================================================================
	XP Ends: 2/7 (16 h:41)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,184            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.133          ,50             ,7              ,38             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
7              ,31             ,False          ,True           ,61             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 184, False, 0.133, 50, 7, 38, 7, 31, False, True, 61
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (16h:41)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 38)       434644      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 31)        354578      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 7)         1064        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_217 (Concatenate)   (None, 50, 45)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 124)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 28)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 61)           26108       concatenate_217[0][0]            
__________________________________________________________________________________________________
concatenate_218 (Concatenate)   (None, 152)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_219 (Concatenate)   (None, 213)          0           phraseRnn[0][0]                  
                                                                 concatenate_218[0][0]            
__________________________________________________________________________________________________
dense_145 (Dense)               (None, 184)          39376       concatenate_219[0][0]            
__________________________________________________________________________________________________
dense_146 (Dense)               (None, 4)            740         dense_145[0][0]                  
==================================================================================================
Total params: 857,574
Trainable params: 857,574
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 159s - loss: 0.0816 - acc: 0.9817 - val_loss: 0.0553 - val_acc: 0.9858
Epoch 2/40
 - 159s - loss: 0.0499 - acc: 0.9877 - val_loss: 0.0540 - val_acc: 0.9862
Epoch 3/40
 - 159s - loss: 0.0472 - acc: 0.9885 - val_loss: 0.0578 - val_acc: 0.9861
Epoch 4/40
 - 159s - loss: 0.0457 - acc: 0.9890 - val_loss: 0.0636 - val_acc: 0.9856
Epoch 5/40
 - 160s - loss: 0.0446 - acc: 0.9892 - val_loss: 0.0698 - val_acc: 0.9860
Epoch 00005: early stopping
	TRAINING TIME: 14.12 minutes 
==================================================================================================
	PARSING TIME: 5.25 minutes 
==================================================================================================
	Identification : 0.528
	P, R  : 0.488, 0.576

==================================================================================================
	XP Ends: 2/7 (17 h:1)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (17h:1)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 38)       357238      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 31)        291431      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 7)         1183        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_220 (Concatenate)   (None, 50, 45)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 124)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 28)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 61)           26108       concatenate_220[0][0]            
__________________________________________________________________________________________________
concatenate_221 (Concatenate)   (None, 152)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_222 (Concatenate)   (None, 213)          0           phraseRnn[0][0]                  
                                                                 concatenate_221[0][0]            
__________________________________________________________________________________________________
dense_147 (Dense)               (None, 184)          39376       concatenate_222[0][0]            
__________________________________________________________________________________________________
dense_148 (Dense)               (None, 4)            740         dense_147[0][0]                  
==================================================================================================
Total params: 717,259
Trainable params: 717,259
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 108s - loss: 4.2398 - acc: 0.7248 - val_loss: 0.0934 - val_acc: 0.9833
Epoch 2/40
 - 108s - loss: 0.0576 - acc: 0.9853 - val_loss: 0.0574 - val_acc: 0.9851
Epoch 3/40
 - 108s - loss: 0.0514 - acc: 0.9871 - val_loss: 0.0593 - val_acc: 0.9853
Epoch 4/40
 - 108s - loss: 0.0489 - acc: 0.9879 - val_loss: 0.0645 - val_acc: 0.9847
Epoch 5/40
 - 108s - loss: 0.0474 - acc: 0.9882 - val_loss: 0.0702 - val_acc: 0.9851
Epoch 00005: early stopping
	TRAINING TIME: 9.53 minutes 
==================================================================================================
	PARSING TIME: 7.88 minutes 
==================================================================================================
	Identification : 0.475
	P, R  : 0.383, 0.626

==================================================================================================
	XP Ends: 2/7 (17 h:19)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (17h:19)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 38)       838698      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 31)        684201      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 7)         763         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_223 (Concatenate)   (None, 50, 45)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 124)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 28)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 61)           26108       concatenate_223[0][0]            
__________________________________________________________________________________________________
concatenate_224 (Concatenate)   (None, 152)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_225 (Concatenate)   (None, 213)          0           phraseRnn[0][0]                  
                                                                 concatenate_224[0][0]            
__________________________________________________________________________________________________
dense_149 (Dense)               (None, 184)          39376       concatenate_225[0][0]            
__________________________________________________________________________________________________
dense_150 (Dense)               (None, 4)            740         dense_149[0][0]                  
==================================================================================================
Total params: 1,590,649
Trainable params: 1,590,649
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 215s - loss: 12.0817 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 2/40
 - 215s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 3/40
 - 215s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 4/40
 - 215s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 5/40
 - 213s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 00005: early stopping
	TRAINING TIME: 19.32 minutes 
==================================================================================================
	PARSING TIME: 9.0 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.043

==================================================================================================
	XP Ends: 2/7 (17 h:48)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,228            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.08           ,50             ,5              ,94             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
45             ,51             ,True           ,True           ,142            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 228, True, 0.08, 50, 5, 94, 45, 51, True, True, 142
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (17h:48)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 94)       709230      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 51)        384795      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 45)        6840        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_226 (Concatenate)   (None, 50, 99)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 255)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 225)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 142)          103092      concatenate_226[0][0]            
__________________________________________________________________________________________________
concatenate_227 (Concatenate)   (None, 480)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_228 (Concatenate)   (None, 622)          0           phraseRnn[0][0]                  
                                                                 concatenate_227[0][0]            
__________________________________________________________________________________________________
dense_151 (Dense)               (None, 228)          142044      concatenate_228[0][0]            
__________________________________________________________________________________________________
dense_152 (Dense)               (None, 4)            916         dense_151[0][0]                  
==================================================================================================
Total params: 1,347,677
Trainable params: 1,347,677
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 137s - loss: 12.0804 - acc: 0.2502 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 2/40
 - 137s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 3/40
 - 138s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 4/40
 - 137s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 5/40
 - 137s - loss: 12.0880 - acc: 0.2500 - val_loss: 12.0907 - val_acc: 0.2499
Epoch 00005: early stopping
	TRAINING TIME: 12.18 minutes 
==================================================================================================
	PARSING TIME: 3.95 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (18 h:4)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (18h:4)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 94)       680654      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 51)        369291      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 45)        7605        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_229 (Concatenate)   (None, 50, 99)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 255)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 225)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 142)          103092      concatenate_229[0][0]            
__________________________________________________________________________________________________
concatenate_230 (Concatenate)   (None, 480)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_231 (Concatenate)   (None, 622)          0           phraseRnn[0][0]                  
                                                                 concatenate_230[0][0]            
__________________________________________________________________________________________________
dense_153 (Dense)               (None, 228)          142044      concatenate_231[0][0]            
__________________________________________________________________________________________________
dense_154 (Dense)               (None, 4)            916         dense_153[0][0]                  
==================================================================================================
Total params: 1,304,447
Trainable params: 1,304,447
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.7488 - acc: 0.9387 - val_loss: 0.0637 - val_acc: 0.9830
Epoch 2/40
 - 93s - loss: 0.0570 - acc: 0.9854 - val_loss: 0.0626 - val_acc: 0.9836
Epoch 3/40
 - 93s - loss: 0.0513 - acc: 0.9872 - val_loss: 0.0670 - val_acc: 0.9839
Epoch 4/40
 - 92s - loss: 0.0489 - acc: 0.9880 - val_loss: 0.0676 - val_acc: 0.9842
Epoch 5/40
 - 92s - loss: 0.0476 - acc: 0.9884 - val_loss: 0.0745 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 8.2 minutes 
==================================================================================================
	PARSING TIME: 6.3 minutes 
==================================================================================================
	Identification : 0.5
	P, R  : 0.424, 0.609

==================================================================================================
	XP Ends: 2/7 (18 h:19)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (18h:19)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 94)       1296542     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 51)        703443      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 45)        4905        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_232 (Concatenate)   (None, 50, 99)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 255)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 225)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 142)          103092      concatenate_232[0][0]            
__________________________________________________________________________________________________
concatenate_233 (Concatenate)   (None, 480)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_234 (Concatenate)   (None, 622)          0           phraseRnn[0][0]                  
                                                                 concatenate_233[0][0]            
__________________________________________________________________________________________________
dense_155 (Dense)               (None, 228)          142044      concatenate_234[0][0]            
__________________________________________________________________________________________________
dense_156 (Dense)               (None, 4)            916         dense_155[0][0]                  
==================================================================================================
Total params: 2,251,487
Trainable params: 2,251,487
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 181s - loss: 2.5559 - acc: 0.8302 - val_loss: 0.0595 - val_acc: 0.9839
Epoch 2/40
 - 181s - loss: 0.0554 - acc: 0.9855 - val_loss: 0.0605 - val_acc: 0.9839
Epoch 3/40
 - 181s - loss: 0.0504 - acc: 0.9872 - val_loss: 0.0600 - val_acc: 0.9839
Epoch 4/40
 - 181s - loss: 0.0484 - acc: 0.9880 - val_loss: 0.0636 - val_acc: 0.9840
Epoch 5/40
 - 181s - loss: 0.0468 - acc: 0.9885 - val_loss: 0.0730 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 16.55 minutes 
==================================================================================================
	PARSING TIME: 2.73 minutes 
==================================================================================================
	Identification : 0.503
	P, R  : 0.48, 0.529

==================================================================================================
	XP Ends: 2/7 (18 h:39)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,325            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.037          ,50             ,28             ,146            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
49             ,74             ,True           ,True           ,91             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 325, False, 0.037, 50, 28, 146, 49, 74, True, True, 91
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (18h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 146)      1101570     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 28)       4256        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 74)        558330      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 49)        7448        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_235 (Concatenate)   (None, 50, 174)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 370)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 245)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 91)           96824       concatenate_235[0][0]            
__________________________________________________________________________________________________
concatenate_236 (Concatenate)   (None, 615)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_237 (Concatenate)   (None, 706)          0           phraseRnn[0][0]                  
                                                                 concatenate_236[0][0]            
__________________________________________________________________________________________________
dense_157 (Dense)               (None, 325)          229775      concatenate_237[0][0]            
__________________________________________________________________________________________________
dense_158 (Dense)               (None, 4)            1304        dense_157[0][0]                  
==================================================================================================
Total params: 1,999,507
Trainable params: 1,999,507
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 161s - loss: 0.0716 - acc: 0.9819 - val_loss: 0.0566 - val_acc: 0.9854
Epoch 2/40
 - 161s - loss: 0.0515 - acc: 0.9871 - val_loss: 0.0562 - val_acc: 0.9857
Epoch 3/40
 - 161s - loss: 0.0487 - acc: 0.9880 - val_loss: 0.0591 - val_acc: 0.9858
Epoch 4/40
 - 161s - loss: 0.0471 - acc: 0.9885 - val_loss: 0.0627 - val_acc: 0.9856
Epoch 5/40
 - 161s - loss: 0.0459 - acc: 0.9888 - val_loss: 0.0673 - val_acc: 0.9854
Epoch 00005: early stopping
	TRAINING TIME: 14.28 minutes 
==================================================================================================
	PARSING TIME: 5.18 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.736, 0.487

==================================================================================================
	XP Ends: 2/7 (18 h:59)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (18h:59)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 146)      1057186     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 28)       4732        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 74)        535834      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 49)        8281        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_238 (Concatenate)   (None, 50, 174)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 370)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 245)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 91)           96824       concatenate_238[0][0]            
__________________________________________________________________________________________________
concatenate_239 (Concatenate)   (None, 615)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_240 (Concatenate)   (None, 706)          0           phraseRnn[0][0]                  
                                                                 concatenate_239[0][0]            
__________________________________________________________________________________________________
dense_159 (Dense)               (None, 325)          229775      concatenate_240[0][0]            
__________________________________________________________________________________________________
dense_160 (Dense)               (None, 4)            1304        dense_159[0][0]                  
==================================================================================================
Total params: 1,933,936
Trainable params: 1,933,936
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 0.0728 - acc: 0.9804 - val_loss: 0.0586 - val_acc: 0.9848
Epoch 2/40
 - 109s - loss: 0.0515 - acc: 0.9871 - val_loss: 0.0599 - val_acc: 0.9851
Epoch 3/40
 - 109s - loss: 0.0480 - acc: 0.9884 - val_loss: 0.0623 - val_acc: 0.9850
Epoch 4/40
 - 109s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0707 - val_acc: 0.9852
Epoch 5/40
 - 109s - loss: 0.0458 - acc: 0.9888 - val_loss: 0.0759 - val_acc: 0.9851
Epoch 00005: early stopping
	TRAINING TIME: 9.62 minutes 
==================================================================================================
	PARSING TIME: 8.1 minutes 
==================================================================================================
	Identification : 0.477
	P, R  : 0.372, 0.665

==================================================================================================
	XP Ends: 2/7 (19 h:17)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (19h:17)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 146)      2013778     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 28)       3052        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 74)        1020682     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 49)        5341        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_241 (Concatenate)   (None, 50, 174)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 370)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 245)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 91)           96824       concatenate_241[0][0]            
__________________________________________________________________________________________________
concatenate_242 (Concatenate)   (None, 615)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_243 (Concatenate)   (None, 706)          0           phraseRnn[0][0]                  
                                                                 concatenate_242[0][0]            
__________________________________________________________________________________________________
dense_161 (Dense)               (None, 325)          229775      concatenate_243[0][0]            
__________________________________________________________________________________________________
dense_162 (Dense)               (None, 4)            1304        dense_161[0][0]                  
==================================================================================================
Total params: 3,370,756
Trainable params: 3,370,756
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 220s - loss: 0.0649 - acc: 0.9824 - val_loss: 0.0565 - val_acc: 0.9845
Epoch 2/40
 - 220s - loss: 0.0511 - acc: 0.9869 - val_loss: 0.0587 - val_acc: 0.9841
Epoch 3/40
 - 219s - loss: 0.0482 - acc: 0.9880 - val_loss: 0.0617 - val_acc: 0.9843
Epoch 4/40
 - 219s - loss: 0.0463 - acc: 0.9886 - val_loss: 0.0682 - val_acc: 0.9842
Epoch 5/40
 - 217s - loss: 0.0450 - acc: 0.9890 - val_loss: 0.0790 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 19.78 minutes 
==================================================================================================
	PARSING TIME: 3.5 minutes 
==================================================================================================
	Identification : 0.503
	P, R  : 0.465, 0.547

==================================================================================================
	XP Ends: 2/7 (19 h:40)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,147            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.199          ,50             ,7              ,31             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
9              ,189            ,True           ,True           ,115            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 147, True, 0.199, 50, 7, 31, 9, 189, True, True, 115
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (19h:40)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       354578      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1064        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 189)       2161782     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         1368        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_244 (Concatenate)   (None, 50, 38)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 945)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 115)          53130       concatenate_244[0][0]            
__________________________________________________________________________________________________
concatenate_245 (Concatenate)   (None, 990)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_246 (Concatenate)   (None, 1105)         0           phraseRnn[0][0]                  
                                                                 concatenate_245[0][0]            
__________________________________________________________________________________________________
dense_163 (Dense)               (None, 147)          162582      concatenate_246[0][0]            
__________________________________________________________________________________________________
dense_164 (Dense)               (None, 4)            592         dense_163[0][0]                  
==================================================================================================
Total params: 2,735,096
Trainable params: 2,735,096
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 8.1150 - acc: 0.4963 - val_loss: 8.1353 - val_acc: 0.4953
Epoch 2/40
 - 136s - loss: 8.1043 - acc: 0.4972 - val_loss: 8.1353 - val_acc: 0.4953
Epoch 3/40
 - 136s - loss: 8.1043 - acc: 0.4972 - val_loss: 8.1353 - val_acc: 0.4953
Epoch 4/40
 - 136s - loss: 8.1043 - acc: 0.4972 - val_loss: 8.1353 - val_acc: 0.4953
Epoch 5/40
 - 136s - loss: 8.1043 - acc: 0.4972 - val_loss: 8.1353 - val_acc: 0.4953
Epoch 00005: early stopping
	TRAINING TIME: 12.12 minutes 
==================================================================================================
	PARSING TIME: 3.95 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (19 h:57)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (19h:57)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       291431      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        1183        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 189)       1776789     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         1521        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_247 (Concatenate)   (None, 50, 38)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 945)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 115)          53130       concatenate_247[0][0]            
__________________________________________________________________________________________________
concatenate_248 (Concatenate)   (None, 990)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_249 (Concatenate)   (None, 1105)         0           phraseRnn[0][0]                  
                                                                 concatenate_248[0][0]            
__________________________________________________________________________________________________
dense_165 (Dense)               (None, 147)          162582      concatenate_249[0][0]            
__________________________________________________________________________________________________
dense_166 (Dense)               (None, 4)            592         dense_165[0][0]                  
==================================================================================================
Total params: 2,287,228
Trainable params: 2,287,228
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 92s - loss: 12.0881 - acc: 0.2498 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 2/40
 - 93s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 3/40
 - 92s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 4/40
 - 92s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 5/40
 - 93s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 00005: early stopping
	TRAINING TIME: 8.17 minutes 
==================================================================================================
	PARSING TIME: 11.13 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (20 h:16)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (20h:16)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 31)       684201      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 7)        763         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 189)       4171419     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         981         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_250 (Concatenate)   (None, 50, 38)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 945)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 115)          53130       concatenate_250[0][0]            
__________________________________________________________________________________________________
concatenate_251 (Concatenate)   (None, 990)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_252 (Concatenate)   (None, 1105)         0           phraseRnn[0][0]                  
                                                                 concatenate_251[0][0]            
__________________________________________________________________________________________________
dense_167 (Dense)               (None, 147)          162582      concatenate_252[0][0]            
__________________________________________________________________________________________________
dense_168 (Dense)               (None, 4)            592         dense_167[0][0]                  
==================================================================================================
Total params: 5,073,668
Trainable params: 5,073,668
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 183s - loss: 8.0850 - acc: 0.4982 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 2/40
 - 183s - loss: 8.0655 - acc: 0.4996 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 3/40
 - 182s - loss: 8.0655 - acc: 0.4996 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 4/40
 - 182s - loss: 8.0655 - acc: 0.4996 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 5/40
 - 181s - loss: 8.0655 - acc: 0.4996 - val_loss: 8.0332 - val_acc: 0.5016
Epoch 00005: early stopping
	TRAINING TIME: 16.58 minutes 
==================================================================================================
	PARSING TIME: 4.75 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (20 h:38)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,376            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.069          ,50             ,20             ,52             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
7              ,113            ,True           ,True           ,26             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 376, False, 0.069, 50, 20, 52, 7, 113, True, True, 26
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (20h:38)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 52)       392340      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3040        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 113)       852585      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1064        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_253 (Concatenate)   (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 565)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 26)           10296       concatenate_253[0][0]            
__________________________________________________________________________________________________
concatenate_254 (Concatenate)   (None, 600)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_255 (Concatenate)   (None, 626)          0           phraseRnn[0][0]                  
                                                                 concatenate_254[0][0]            
__________________________________________________________________________________________________
dense_169 (Dense)               (None, 376)          235752      concatenate_255[0][0]            
__________________________________________________________________________________________________
dense_170 (Dense)               (None, 4)            1508        dense_169[0][0]                  
==================================================================================================
Total params: 1,496,585
Trainable params: 1,496,585
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 160s - loss: 0.0772 - acc: 0.9818 - val_loss: 0.0645 - val_acc: 0.9827
Epoch 2/40
 - 160s - loss: 0.0500 - acc: 0.9877 - val_loss: 0.0581 - val_acc: 0.9859
Epoch 3/40
 - 160s - loss: 0.0470 - acc: 0.9886 - val_loss: 0.0587 - val_acc: 0.9861
Epoch 4/40
 - 160s - loss: 0.0456 - acc: 0.9890 - val_loss: 0.0625 - val_acc: 0.9859
Epoch 5/40
 - 160s - loss: 0.0445 - acc: 0.9893 - val_loss: 0.0671 - val_acc: 0.9860
Epoch 00005: early stopping
	TRAINING TIME: 14.2 minutes 
==================================================================================================
	PARSING TIME: 5.08 minutes 
==================================================================================================
	Identification : 0.585
	P, R  : 0.633, 0.543

==================================================================================================
	XP Ends: 2/7 (20 h:58)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (20h:58)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 52)       376532      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3380        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 113)       818233      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         1183        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_256 (Concatenate)   (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 565)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 26)           10296       concatenate_256[0][0]            
__________________________________________________________________________________________________
concatenate_257 (Concatenate)   (None, 600)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_258 (Concatenate)   (None, 626)          0           phraseRnn[0][0]                  
                                                                 concatenate_257[0][0]            
__________________________________________________________________________________________________
dense_171 (Dense)               (None, 376)          235752      concatenate_258[0][0]            
__________________________________________________________________________________________________
dense_172 (Dense)               (None, 4)            1508        dense_171[0][0]                  
==================================================================================================
Total params: 1,446,884
Trainable params: 1,446,884
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 111s - loss: 0.0927 - acc: 0.9785 - val_loss: 0.0723 - val_acc: 0.9840
Epoch 2/40
 - 111s - loss: 0.0521 - acc: 0.9870 - val_loss: 0.0611 - val_acc: 0.9846
Epoch 3/40
 - 110s - loss: 0.0483 - acc: 0.9882 - val_loss: 0.0647 - val_acc: 0.9849
Epoch 4/40
 - 110s - loss: 0.0470 - acc: 0.9886 - val_loss: 0.0701 - val_acc: 0.9846
Epoch 5/40
 - 110s - loss: 0.0461 - acc: 0.9888 - val_loss: 0.0784 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 9.77 minutes 
==================================================================================================
	PARSING TIME: 8.03 minutes 
==================================================================================================
	Identification : 0.476
	P, R  : 0.372, 0.66

==================================================================================================
	XP Ends: 2/7 (21 h:16)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (21h:16)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 52)       717236      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       2180        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 113)       1558609     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 7)         763         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_259 (Concatenate)   (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 565)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 35)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 26)           10296       concatenate_259[0][0]            
__________________________________________________________________________________________________
concatenate_260 (Concatenate)   (None, 600)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_261 (Concatenate)   (None, 626)          0           phraseRnn[0][0]                  
                                                                 concatenate_260[0][0]            
__________________________________________________________________________________________________
dense_173 (Dense)               (None, 376)          235752      concatenate_261[0][0]            
__________________________________________________________________________________________________
dense_174 (Dense)               (None, 4)            1508        dense_173[0][0]                  
==================================================================================================
Total params: 2,526,344
Trainable params: 2,526,344
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 217s - loss: 0.0709 - acc: 0.9815 - val_loss: 0.0571 - val_acc: 0.9845
Epoch 2/40
 - 217s - loss: 0.0510 - acc: 0.9870 - val_loss: 0.0584 - val_acc: 0.9848
Epoch 3/40
 - 217s - loss: 0.0479 - acc: 0.9882 - val_loss: 0.0620 - val_acc: 0.9845
Epoch 4/40
 - 217s - loss: 0.0460 - acc: 0.9887 - val_loss: 0.0752 - val_acc: 0.9843
Epoch 5/40
 - 217s - loss: 0.0449 - acc: 0.9890 - val_loss: 0.0794 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 19.53 minutes 
==================================================================================================
	PARSING TIME: 3.5 minutes 
==================================================================================================
	Identification : 0.499
	P, R  : 0.442, 0.573

==================================================================================================
	XP Ends: 2/7 (21 h:40)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,91             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.13           ,50             ,5              ,37             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
36             ,106            ,False          ,False          ,145            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 91, False, 0.13, 50, 5, 37, 36, 106, False, False, 145
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (21h:40)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 37)       279165      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 106)       799770      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 36)        5472        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_262 (Concatenate)   (None, 50, 42)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 318)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 108)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 145)          109040      concatenate_262[0][0]            
__________________________________________________________________________________________________
concatenate_263 (Concatenate)   (None, 426)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_264 (Concatenate)   (None, 571)          0           phraseRnn[0][0]                  
                                                                 concatenate_263[0][0]            
__________________________________________________________________________________________________
dense_175 (Dense)               (None, 91)           52052       concatenate_264[0][0]            
__________________________________________________________________________________________________
dense_176 (Dense)               (None, 4)            368         dense_175[0][0]                  
==================================================================================================
Total params: 1,246,627
Trainable params: 1,246,627
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 160s - loss: 12.0943 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 2/40
 - 160s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 3/40
 - 160s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 4/40
 - 160s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 5/40
 - 160s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 00005: early stopping
	TRAINING TIME: 14.15 minutes 
==================================================================================================
	PARSING TIME: 9.53 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (22 h:4)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (22h:4)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 37)       267917      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 106)       767546      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 36)        6084        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_265 (Concatenate)   (None, 50, 42)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 318)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 108)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 145)          109040      concatenate_265[0][0]            
__________________________________________________________________________________________________
concatenate_266 (Concatenate)   (None, 426)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_267 (Concatenate)   (None, 571)          0           phraseRnn[0][0]                  
                                                                 concatenate_266[0][0]            
__________________________________________________________________________________________________
dense_177 (Dense)               (None, 91)           52052       concatenate_267[0][0]            
__________________________________________________________________________________________________
dense_178 (Dense)               (None, 4)            368         dense_177[0][0]                  
==================================================================================================
Total params: 1,203,852
Trainable params: 1,203,852
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 109s - loss: 12.0735 - acc: 0.2506 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 2/40
 - 109s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 3/40
 - 109s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 4/40
 - 110s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 5/40
 - 109s - loss: 12.0799 - acc: 0.2505 - val_loss: 12.1231 - val_acc: 0.2479
Epoch 00005: early stopping
	TRAINING TIME: 9.6 minutes 
==================================================================================================
	PARSING TIME: 20.58 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.076

==================================================================================================
	XP Ends: 2/7 (22 h:34)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (22h:34)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 37)       510341      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 106)       1462058     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 36)        3924        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_268 (Concatenate)   (None, 50, 42)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 318)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 108)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 145)          109040      concatenate_268[0][0]            
__________________________________________________________________________________________________
concatenate_269 (Concatenate)   (None, 426)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_270 (Concatenate)   (None, 571)          0           phraseRnn[0][0]                  
                                                                 concatenate_269[0][0]            
__________________________________________________________________________________________________
dense_179 (Dense)               (None, 91)           52052       concatenate_270[0][0]            
__________________________________________________________________________________________________
dense_180 (Dense)               (None, 4)            368         dense_179[0][0]                  
==================================================================================================
Total params: 2,138,328
Trainable params: 2,138,328
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 216s - loss: 12.0853 - acc: 0.2501 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 2/40
 - 216s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 3/40
 - 217s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 4/40
 - 217s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 5/40
 - 217s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 00005: early stopping
	TRAINING TIME: 19.5 minutes 
==================================================================================================
	PARSING TIME: 3.32 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 2/7 (22 h:57)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,48             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.013          ,50             ,8              ,53             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
9              ,93             ,True           ,True           ,72             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 48, False, 0.013, 50, 8, 53, 9, 93, True, True, 72
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (22h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       399885      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 93)        701685      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         1368        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_271 (Concatenate)   (None, 50, 61)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 465)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 72)           38592       concatenate_271[0][0]            
__________________________________________________________________________________________________
concatenate_272 (Concatenate)   (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_273 (Concatenate)   (None, 582)          0           phraseRnn[0][0]                  
                                                                 concatenate_272[0][0]            
__________________________________________________________________________________________________
dense_181 (Dense)               (None, 48)           27984       concatenate_273[0][0]            
__________________________________________________________________________________________________
dense_182 (Dense)               (None, 4)            196         dense_181[0][0]                  
==================================================================================================
Total params: 1,170,926
Trainable params: 1,170,926
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 161s - loss: 0.0743 - acc: 0.9808 - val_loss: 0.0602 - val_acc: 0.9842
Epoch 2/40
 - 160s - loss: 0.0535 - acc: 0.9867 - val_loss: 0.0594 - val_acc: 0.9853
Epoch 3/40
 - 160s - loss: 0.0496 - acc: 0.9879 - val_loss: 0.0612 - val_acc: 0.9852
Epoch 4/40
 - 160s - loss: 0.0476 - acc: 0.9885 - val_loss: 0.0621 - val_acc: 0.9855
Epoch 5/40
 - 161s - loss: 0.0463 - acc: 0.9889 - val_loss: 0.0640 - val_acc: 0.9852
Epoch 00005: early stopping
	TRAINING TIME: 14.22 minutes 
==================================================================================================
	PARSING TIME: 5.18 minutes 
==================================================================================================
	Identification : 0.585
	P, R  : 0.774, 0.47

==================================================================================================
	XP Ends: 2/7 (23 h:17)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 2/7 (23h:17)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       383773      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 93)        673413      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         1521        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_274 (Concatenate)   (None, 50, 61)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 465)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 72)           38592       concatenate_274[0][0]            
__________________________________________________________________________________________________
concatenate_275 (Concatenate)   (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_276 (Concatenate)   (None, 582)          0           phraseRnn[0][0]                  
                                                                 concatenate_275[0][0]            
__________________________________________________________________________________________________
dense_183 (Dense)               (None, 48)           27984       concatenate_276[0][0]            
__________________________________________________________________________________________________
dense_184 (Dense)               (None, 4)            196         dense_183[0][0]                  
==================================================================================================
Total params: 1,126,831
Trainable params: 1,126,831
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 111s - loss: 0.0842 - acc: 0.9779 - val_loss: 0.0665 - val_acc: 0.9828
Epoch 2/40
 - 111s - loss: 0.0574 - acc: 0.9854 - val_loss: 0.0650 - val_acc: 0.9837
Epoch 3/40
 - 111s - loss: 0.0527 - acc: 0.9869 - val_loss: 0.0659 - val_acc: 0.9837
Epoch 4/40
 - 110s - loss: 0.0504 - acc: 0.9876 - val_loss: 0.0678 - val_acc: 0.9838
Epoch 5/40
 - 110s - loss: 0.0489 - acc: 0.9880 - val_loss: 0.0706 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 9.8 minutes 
==================================================================================================
	PARSING TIME: 8.02 minutes 
==================================================================================================
	Identification : 0.443
	P, R  : 0.339, 0.638

==================================================================================================
	XP Ends: 2/7 (23 h:35)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (23h:35)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 53)       731029      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 93)        1282749     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 9)         981         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_277 (Concatenate)   (None, 50, 61)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 465)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 45)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 72)           38592       concatenate_277[0][0]            
__________________________________________________________________________________________________
concatenate_278 (Concatenate)   (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_279 (Concatenate)   (None, 582)          0           phraseRnn[0][0]                  
                                                                 concatenate_278[0][0]            
__________________________________________________________________________________________________
dense_185 (Dense)               (None, 48)           27984       concatenate_279[0][0]            
__________________________________________________________________________________________________
dense_186 (Dense)               (None, 4)            196         dense_185[0][0]                  
==================================================================================================
Total params: 2,082,403
Trainable params: 2,082,403
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 216s - loss: 0.0740 - acc: 0.9803 - val_loss: 0.0616 - val_acc: 0.9836
Epoch 2/40
 - 216s - loss: 0.0545 - acc: 0.9860 - val_loss: 0.0604 - val_acc: 0.9839
Epoch 3/40
 - 216s - loss: 0.0509 - acc: 0.9873 - val_loss: 0.0620 - val_acc: 0.9840
Epoch 4/40
 - 216s - loss: 0.0489 - acc: 0.9879 - val_loss: 0.0649 - val_acc: 0.9838
Epoch 5/40
 - 216s - loss: 0.0476 - acc: 0.9883 - val_loss: 0.0684 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 19.47 minutes 
==================================================================================================
	PARSING TIME: 3.47 minutes 
==================================================================================================
	Identification : 0.468
	P, R  : 0.564, 0.4

==================================================================================================
	XP Ends: 2/7 (23 h:59)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,287            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.112          ,50             ,31             ,192            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,60             ,True           ,False          ,265            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 287, False, 0.112, 50, 31, 192, 8, 60, True, False, 265
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 2/7 (23h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 192)      1448640     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 31)       4712        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 60)        452700      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_280 (Concatenate)   (None, 50, 223)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 240)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 265)          518340      concatenate_280[0][0]            
__________________________________________________________________________________________________
concatenate_281 (Concatenate)   (None, 272)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_282 (Concatenate)   (None, 537)          0           phraseRnn[0][0]                  
                                                                 concatenate_281[0][0]            
__________________________________________________________________________________________________
dense_187 (Dense)               (None, 287)          154406      concatenate_282[0][0]            
__________________________________________________________________________________________________
dense_188 (Dense)               (None, 4)            1152        dense_187[0][0]                  
==================================================================================================
Total params: 2,581,166
Trainable params: 2,581,166
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 240s - loss: 12.0969 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 2/40
 - 240s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 3/40
 - 240s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 4/40
 - 240s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 5/40
 - 241s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 00005: early stopping
	TRAINING TIME: 20.87 minutes 
==================================================================================================
	PARSING TIME: 10.37 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (0 h:30)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (0h:30)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 192)      1390272     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 31)       5239        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 60)        434460      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_283 (Concatenate)   (None, 50, 223)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 240)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 265)          518340      concatenate_283[0][0]            
__________________________________________________________________________________________________
concatenate_284 (Concatenate)   (None, 272)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_285 (Concatenate)   (None, 537)          0           phraseRnn[0][0]                  
                                                                 concatenate_284[0][0]            
__________________________________________________________________________________________________
dense_189 (Dense)               (None, 287)          154406      concatenate_285[0][0]            
__________________________________________________________________________________________________
dense_190 (Dense)               (None, 4)            1152        dense_189[0][0]                  
==================================================================================================
Total params: 2,505,221
Trainable params: 2,505,221
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 161s - loss: 12.0760 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 2/40
 - 161s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 3/40
 - 161s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 4/40
 - 161s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 5/40
 - 161s - loss: 12.0806 - acc: 0.2505 - val_loss: 12.1205 - val_acc: 0.2480
Epoch 00005: early stopping
	TRAINING TIME: 13.95 minutes 
==================================================================================================
	PARSING TIME: 15.65 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (1 h:0)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (1h:0)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 192)      2648256     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 31)       3379        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 60)        827580      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_286 (Concatenate)   (None, 50, 223)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 240)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 265)          518340      concatenate_286[0][0]            
__________________________________________________________________________________________________
concatenate_287 (Concatenate)   (None, 272)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_288 (Concatenate)   (None, 537)          0           phraseRnn[0][0]                  
                                                                 concatenate_287[0][0]            
__________________________________________________________________________________________________
dense_191 (Dense)               (None, 287)          154406      concatenate_288[0][0]            
__________________________________________________________________________________________________
dense_192 (Dense)               (None, 4)            1152        dense_191[0][0]                  
==================================================================================================
Total params: 4,153,985
Trainable params: 4,153,985
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 323s - loss: 12.0865 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 2/40
 - 323s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 3/40
 - 323s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 4/40
 - 323s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 5/40
 - 323s - loss: 12.0887 - acc: 0.2500 - val_loss: 12.0882 - val_acc: 0.2500
Epoch 00005: early stopping
	TRAINING TIME: 28.32 minutes 
==================================================================================================
	PARSING TIME: 3.57 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (1 h:33)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,157            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.042          ,50             ,5              ,166            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
43             ,197            ,True           ,True           ,144            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 157, True, 0.042, 50, 5, 166, 43, 197, True, True, 144
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (1h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 166)      1252470     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 197)       1486365     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 43)        6536        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_289 (Concatenate)   (None, 50, 171)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 985)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 215)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 144)          136512      concatenate_289[0][0]            
__________________________________________________________________________________________________
concatenate_290 (Concatenate)   (None, 1200)         0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_291 (Concatenate)   (None, 1344)         0           phraseRnn[0][0]                  
                                                                 concatenate_290[0][0]            
__________________________________________________________________________________________________
dense_193 (Dense)               (None, 157)          211165      concatenate_291[0][0]            
__________________________________________________________________________________________________
dense_194 (Dense)               (None, 4)            632         dense_193[0][0]                  
==================================================================================================
Total params: 3,094,440
Trainable params: 3,094,440
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 147s - loss: 0.0786 - acc: 0.9811 - val_loss: 0.0577 - val_acc: 0.9849
Epoch 2/40
 - 148s - loss: 0.0509 - acc: 0.9873 - val_loss: 0.0561 - val_acc: 0.9857
Epoch 3/40
 - 142s - loss: 0.0476 - acc: 0.9884 - val_loss: 0.0586 - val_acc: 0.9856
Epoch 4/40
 - 142s - loss: 0.0459 - acc: 0.9889 - val_loss: 0.0622 - val_acc: 0.9855
Epoch 5/40
 - 144s - loss: 0.0449 - acc: 0.9892 - val_loss: 0.0660 - val_acc: 0.9856
Epoch 00005: early stopping
	TRAINING TIME: 12.88 minutes 
==================================================================================================
	PARSING TIME: 4.3 minutes 
==================================================================================================
	Identification : 0.584
	P, R  : 0.699, 0.501

==================================================================================================
	XP Ends: 3/7 (1 h:50)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (1h:50)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 166)      1202006     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 197)       1426477     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 43)        7267        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_292 (Concatenate)   (None, 50, 171)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 985)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 215)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 144)          136512      concatenate_292[0][0]            
__________________________________________________________________________________________________
concatenate_293 (Concatenate)   (None, 1200)         0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_294 (Concatenate)   (None, 1344)         0           phraseRnn[0][0]                  
                                                                 concatenate_293[0][0]            
__________________________________________________________________________________________________
dense_195 (Dense)               (None, 157)          211165      concatenate_294[0][0]            
__________________________________________________________________________________________________
dense_196 (Dense)               (None, 4)            632         dense_195[0][0]                  
==================================================================================================
Total params: 2,984,904
Trainable params: 2,984,904
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 100s - loss: 0.0755 - acc: 0.9797 - val_loss: 0.0596 - val_acc: 0.9839
Epoch 2/40
 - 95s - loss: 0.0518 - acc: 0.9869 - val_loss: 0.0610 - val_acc: 0.9844
Epoch 3/40
 - 94s - loss: 0.0482 - acc: 0.9882 - val_loss: 0.0644 - val_acc: 0.9841
Epoch 4/40
 - 101s - loss: 0.0468 - acc: 0.9886 - val_loss: 0.0674 - val_acc: 0.9847
Epoch 5/40
 - 99s - loss: 0.0460 - acc: 0.9887 - val_loss: 0.0739 - val_acc: 0.9845
Epoch 00005: early stopping
	TRAINING TIME: 8.68 minutes 
==================================================================================================
	PARSING TIME: 6.52 minutes 
==================================================================================================
	Identification : 0.529
	P, R  : 0.466, 0.611

==================================================================================================
	XP Ends: 3/7 (2 h:6)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (2h:6)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 166)      2289638     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 197)       2717221     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 43)        4687        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_295 (Concatenate)   (None, 50, 171)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 985)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 215)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 144)          136512      concatenate_295[0][0]            
__________________________________________________________________________________________________
concatenate_296 (Concatenate)   (None, 1200)         0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_297 (Concatenate)   (None, 1344)         0           phraseRnn[0][0]                  
                                                                 concatenate_296[0][0]            
__________________________________________________________________________________________________
dense_197 (Dense)               (None, 157)          211165      concatenate_297[0][0]            
__________________________________________________________________________________________________
dense_198 (Dense)               (None, 4)            632         dense_197[0][0]                  
==================================================================================================
Total params: 5,360,400
Trainable params: 5,360,400
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 192s - loss: 0.0672 - acc: 0.9819 - val_loss: 0.0571 - val_acc: 0.9847
Epoch 2/40
 - 195s - loss: 0.0518 - acc: 0.9867 - val_loss: 0.0591 - val_acc: 0.9846
Epoch 3/40
 - 190s - loss: 0.0486 - acc: 0.9879 - val_loss: 0.0604 - val_acc: 0.9846
Epoch 4/40
 - 212s - loss: 0.0467 - acc: 0.9885 - val_loss: 0.0676 - val_acc: 0.9842
Epoch 5/40
 - 201s - loss: 0.0452 - acc: 0.9889 - val_loss: 0.0764 - val_acc: 0.9841
Epoch 00005: early stopping
	TRAINING TIME: 18.03 minutes 
==================================================================================================
	PARSING TIME: 2.82 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.483, 0.463

==================================================================================================
	XP Ends: 3/7 (2 h:27)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,185            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.043          ,50             ,6              ,42             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
13             ,38             ,False          ,True           ,264            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 185, False, 0.043, 50, 6, 42, 13, 38, False, True, 264
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (2h:27)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 42)       480396      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 38)        434644      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 13)        1976        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_298 (Concatenate)   (None, 50, 48)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 152)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 52)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 264)          330528      concatenate_298[0][0]            
__________________________________________________________________________________________________
concatenate_299 (Concatenate)   (None, 204)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_300 (Concatenate)   (None, 468)          0           phraseRnn[0][0]                  
                                                                 concatenate_299[0][0]            
__________________________________________________________________________________________________
dense_199 (Dense)               (None, 185)          86765       concatenate_300[0][0]            
__________________________________________________________________________________________________
dense_200 (Dense)               (None, 4)            744         dense_199[0][0]                  
==================================================================================================
Total params: 1,335,965
Trainable params: 1,335,965
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 189s - loss: 12.0776 - acc: 0.2503 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 2/40
 - 187s - loss: 12.0844 - acc: 0.2503 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 3/40
 - 189s - loss: 12.0844 - acc: 0.2503 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 4/40
 - 191s - loss: 12.0844 - acc: 0.2503 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 5/40
 - 202s - loss: 12.0844 - acc: 0.2503 - val_loss: 12.1051 - val_acc: 0.2490
Epoch 00005: early stopping
	TRAINING TIME: 16.9 minutes 
==================================================================================================
	PARSING TIME: 11.2 minutes 
==================================================================================================
	Identification : 0.001
	P, R  : 0.001, 0.001

==================================================================================================
	XP Ends: 3/7 (2 h:55)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (2h:55)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 42)       394842      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 38)        357238      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 13)        2197        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_301 (Concatenate)   (None, 50, 48)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 152)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 52)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 264)          330528      concatenate_301[0][0]            
__________________________________________________________________________________________________
concatenate_302 (Concatenate)   (None, 204)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_303 (Concatenate)   (None, 468)          0           phraseRnn[0][0]                  
                                                                 concatenate_302[0][0]            
__________________________________________________________________________________________________
dense_201 (Dense)               (None, 185)          86765       concatenate_303[0][0]            
__________________________________________________________________________________________________
dense_202 (Dense)               (None, 4)            744         dense_201[0][0]                  
==================================================================================================
Total params: 1,173,328
Trainable params: 1,173,328
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 126s - loss: 12.0696 - acc: 0.2507 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 2/40
 - 126s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 3/40
 - 127s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 4/40
 - 127s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 5/40
 - 125s - loss: 12.0793 - acc: 0.2506 - val_loss: 12.1258 - val_acc: 0.2477
Epoch 00005: early stopping
	TRAINING TIME: 11.03 minutes 
==================================================================================================
	PARSING TIME: 8.17 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (3 h:15)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (3h:15)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 42)       926982      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 38)        838698      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 13)        1417        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_304 (Concatenate)   (None, 50, 48)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 152)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 52)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 264)          330528      concatenate_304[0][0]            
__________________________________________________________________________________________________
concatenate_305 (Concatenate)   (None, 204)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_306 (Concatenate)   (None, 468)          0           phraseRnn[0][0]                  
                                                                 concatenate_305[0][0]            
__________________________________________________________________________________________________
dense_203 (Dense)               (None, 185)          86765       concatenate_306[0][0]            
__________________________________________________________________________________________________
dense_204 (Dense)               (None, 4)            744         dense_203[0][0]                  
==================================================================================================
Total params: 2,185,788
Trainable params: 2,185,788
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 251s - loss: 12.0870 - acc: 0.2499 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 2/40
 - 255s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 3/40
 - 252s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 4/40
 - 255s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 5/40
 - 255s - loss: 12.0918 - acc: 0.2498 - val_loss: 12.0758 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 22.62 minutes 
==================================================================================================
	PARSING TIME: 6.47 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (3 h:44)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,26             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.023          ,50             ,17             ,71             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,55             ,True           ,True           ,155            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 26, False, 0.023, 50, 17, 71, 8, 55, True, True, 155
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (3h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 71)       535695      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2584        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 55)        414975      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_307 (Concatenate)   (None, 50, 88)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 275)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 155)          151280      concatenate_307[0][0]            
__________________________________________________________________________________________________
concatenate_308 (Concatenate)   (None, 315)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_309 (Concatenate)   (None, 470)          0           phraseRnn[0][0]                  
                                                                 concatenate_308[0][0]            
__________________________________________________________________________________________________
dense_205 (Dense)               (None, 26)           12246       concatenate_309[0][0]            
__________________________________________________________________________________________________
dense_206 (Dense)               (None, 4)            108         dense_205[0][0]                  
==================================================================================================
Total params: 1,118,104
Trainable params: 1,118,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 161s - loss: 0.0766 - acc: 0.9806 - val_loss: 0.0622 - val_acc: 0.9842
Epoch 2/40
 - 168s - loss: 0.0536 - acc: 0.9867 - val_loss: 0.0620 - val_acc: 0.9854
Epoch 3/40
 - 165s - loss: 0.0494 - acc: 0.9880 - val_loss: 0.0638 - val_acc: 0.9854
Epoch 4/40
 - 163s - loss: 0.0473 - acc: 0.9887 - val_loss: 0.0659 - val_acc: 0.9853
Epoch 5/40
 - 164s - loss: 0.0460 - acc: 0.9890 - val_loss: 0.0683 - val_acc: 0.9852
Epoch 00005: early stopping
	TRAINING TIME: 14.55 minutes 
==================================================================================================
	PARSING TIME: 5.33 minutes 
==================================================================================================
	Identification : 0.541
	P, R  : 0.537, 0.545

==================================================================================================
	XP Ends: 3/7 (4 h:5)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (4h:5)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 71)       514111      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2873        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 55)        398255      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_310 (Concatenate)   (None, 50, 88)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 275)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 155)          151280      concatenate_310[0][0]            
__________________________________________________________________________________________________
concatenate_311 (Concatenate)   (None, 315)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_312 (Concatenate)   (None, 470)          0           phraseRnn[0][0]                  
                                                                 concatenate_311[0][0]            
__________________________________________________________________________________________________
dense_207 (Dense)               (None, 26)           12246       concatenate_312[0][0]            
__________________________________________________________________________________________________
dense_208 (Dense)               (None, 4)            108         dense_207[0][0]                  
==================================================================================================
Total params: 1,080,225
Trainable params: 1,080,225
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 119s - loss: 0.0826 - acc: 0.9781 - val_loss: 0.0645 - val_acc: 0.9831
Epoch 2/40
 - 109s - loss: 0.0566 - acc: 0.9857 - val_loss: 0.0627 - val_acc: 0.9834
Epoch 3/40
 - 119s - loss: 0.0519 - acc: 0.9871 - val_loss: 0.0644 - val_acc: 0.9838
Epoch 4/40
 - 122s - loss: 0.0496 - acc: 0.9879 - val_loss: 0.0668 - val_acc: 0.9836
Epoch 5/40
 - 116s - loss: 0.0483 - acc: 0.9882 - val_loss: 0.0686 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 10.27 minutes 
==================================================================================================
	PARSING TIME: 9.13 minutes 
==================================================================================================
	Identification : 0.454
	P, R  : 0.353, 0.637

==================================================================================================
	XP Ends: 3/7 (4 h:25)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (4h:25)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 71)       979303      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       1853        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 55)        758615      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_313 (Concatenate)   (None, 50, 88)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 275)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 155)          151280      concatenate_313[0][0]            
__________________________________________________________________________________________________
concatenate_314 (Concatenate)   (None, 315)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_315 (Concatenate)   (None, 470)          0           phraseRnn[0][0]                  
                                                                 concatenate_314[0][0]            
__________________________________________________________________________________________________
dense_209 (Dense)               (None, 26)           12246       concatenate_315[0][0]            
__________________________________________________________________________________________________
dense_210 (Dense)               (None, 4)            108         dense_209[0][0]                  
==================================================================================================
Total params: 1,904,277
Trainable params: 1,904,277
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 227s - loss: 0.0728 - acc: 0.9806 - val_loss: 0.0602 - val_acc: 0.9838
Epoch 2/40
 - 231s - loss: 0.0539 - acc: 0.9862 - val_loss: 0.0595 - val_acc: 0.9840
Epoch 3/40
 - 227s - loss: 0.0505 - acc: 0.9873 - val_loss: 0.0617 - val_acc: 0.9840
Epoch 4/40
 - 224s - loss: 0.0486 - acc: 0.9880 - val_loss: 0.0672 - val_acc: 0.9838
Epoch 5/40
 - 223s - loss: 0.0473 - acc: 0.9884 - val_loss: 0.0680 - val_acc: 0.9835
Epoch 00005: early stopping
	TRAINING TIME: 20.38 minutes 
==================================================================================================
	PARSING TIME: 3.42 minutes 
==================================================================================================
	Identification : 0.507
	P, R  : 0.49, 0.525

==================================================================================================
	XP Ends: 3/7 (4 h:49)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,28             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.194          ,50             ,6              ,111            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
5              ,133            ,True           ,True           ,212            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 28, False, 0.194, 50, 6, 111, 5, 133, True, True, 212
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (4h:49)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 111)      837495      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        912         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 133)       1003485     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 5)         760         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_316 (Concatenate)   (None, 50, 117)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 665)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 25)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 212)          279840      concatenate_316[0][0]            
__________________________________________________________________________________________________
concatenate_317 (Concatenate)   (None, 690)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_318 (Concatenate)   (None, 902)          0           phraseRnn[0][0]                  
                                                                 concatenate_317[0][0]            
__________________________________________________________________________________________________
dense_211 (Dense)               (None, 28)           25284       concatenate_318[0][0]            
__________________________________________________________________________________________________
dense_212 (Dense)               (None, 4)            116         dense_211[0][0]                  
==================================================================================================
Total params: 2,147,892
Trainable params: 2,147,892
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 174s - loss: 12.0951 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 2/40
 - 175s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 3/40
 - 172s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 4/40
 - 175s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 5/40
 - 175s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 00005: early stopping
	TRAINING TIME: 15.37 minutes 
==================================================================================================
	PARSING TIME: 13.8 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.058

==================================================================================================
	XP Ends: 3/7 (5 h:18)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (5h:18)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 111)      803751      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        1014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 133)       963053      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 5)         845         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_319 (Concatenate)   (None, 50, 117)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 665)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 25)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 212)          279840      concatenate_319[0][0]            
__________________________________________________________________________________________________
concatenate_320 (Concatenate)   (None, 690)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_321 (Concatenate)   (None, 902)          0           phraseRnn[0][0]                  
                                                                 concatenate_320[0][0]            
__________________________________________________________________________________________________
dense_213 (Dense)               (None, 28)           25284       concatenate_321[0][0]            
__________________________________________________________________________________________________
dense_214 (Dense)               (None, 4)            116         dense_213[0][0]                  
==================================================================================================
Total params: 2,073,903
Trainable params: 2,073,903
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 118s - loss: 8.0797 - acc: 0.4982 - val_loss: 8.1258 - val_acc: 0.4959
Epoch 2/40
 - 118s - loss: 8.0427 - acc: 0.5010 - val_loss: 8.1258 - val_acc: 0.4959
Epoch 3/40
 - 118s - loss: 8.0427 - acc: 0.5010 - val_loss: 8.1258 - val_acc: 0.4959
Epoch 4/40
 - 119s - loss: 8.0427 - acc: 0.5010 - val_loss: 8.1258 - val_acc: 0.4959
Epoch 5/40
 - 116s - loss: 8.0427 - acc: 0.5010 - val_loss: 8.1258 - val_acc: 0.4959
Epoch 00005: early stopping
	TRAINING TIME: 10.35 minutes 
==================================================================================================
	PARSING TIME: 14.87 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (5 h:44)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (5h:44)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 111)      1531023     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 6)        654         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 133)       1834469     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 5)         545         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_322 (Concatenate)   (None, 50, 117)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 665)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 25)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 212)          279840      concatenate_322[0][0]            
__________________________________________________________________________________________________
concatenate_323 (Concatenate)   (None, 690)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_324 (Concatenate)   (None, 902)          0           phraseRnn[0][0]                  
                                                                 concatenate_323[0][0]            
__________________________________________________________________________________________________
dense_215 (Dense)               (None, 28)           25284       concatenate_324[0][0]            
__________________________________________________________________________________________________
dense_216 (Dense)               (None, 4)            116         dense_215[0][0]                  
==================================================================================================
Total params: 3,671,931
Trainable params: 3,671,931
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 238s - loss: 0.2685 - acc: 0.9680 - val_loss: 0.0643 - val_acc: 0.9828
Epoch 2/40
 - 239s - loss: 0.0549 - acc: 0.9857 - val_loss: 0.0646 - val_acc: 0.9833
Epoch 3/40
 - 237s - loss: 0.0510 - acc: 0.9872 - val_loss: 0.0638 - val_acc: 0.9835
Epoch 4/40
 - 238s - loss: 0.0489 - acc: 0.9878 - val_loss: 0.0684 - val_acc: 0.9831
Epoch 5/40
 - 238s - loss: 0.0476 - acc: 0.9882 - val_loss: 0.0721 - val_acc: 0.9831
Epoch 00005: early stopping
	TRAINING TIME: 21.28 minutes 
==================================================================================================
	PARSING TIME: 3.68 minutes 
==================================================================================================
	Identification : 0.476
	P, R  : 0.508, 0.447

==================================================================================================
	XP Ends: 3/7 (6 h:9)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,129            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.09           ,50             ,14             ,92             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,106            ,False          ,True           ,43             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 129, True, 0.09, 50, 14, 92, 8, 106, False, True, 43
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (6h:9)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 92)       694140      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2128        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 106)       799770      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_325 (Concatenate)   (None, 50, 106)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 424)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 43)           19350       concatenate_325[0][0]            
__________________________________________________________________________________________________
concatenate_326 (Concatenate)   (None, 456)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_327 (Concatenate)   (None, 499)          0           phraseRnn[0][0]                  
                                                                 concatenate_326[0][0]            
__________________________________________________________________________________________________
dense_217 (Dense)               (None, 129)          64500       concatenate_327[0][0]            
__________________________________________________________________________________________________
dense_218 (Dense)               (None, 4)            520         dense_217[0][0]                  
==================================================================================================
Total params: 1,581,624
Trainable params: 1,581,624
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 139s - loss: 0.0716 - acc: 0.9820 - val_loss: 0.0564 - val_acc: 0.9856
Epoch 2/40
 - 142s - loss: 0.0512 - acc: 0.9873 - val_loss: 0.0571 - val_acc: 0.9853
Epoch 3/40
 - 137s - loss: 0.0482 - acc: 0.9883 - val_loss: 0.0586 - val_acc: 0.9856
Epoch 4/40
 - 143s - loss: 0.0466 - acc: 0.9887 - val_loss: 0.0617 - val_acc: 0.9855
Epoch 5/40
 - 137s - loss: 0.0456 - acc: 0.9890 - val_loss: 0.0636 - val_acc: 0.9856
Epoch 00005: early stopping
	TRAINING TIME: 12.53 minutes 
==================================================================================================
	PARSING TIME: 4.15 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.683, 0.524

==================================================================================================
	XP Ends: 3/7 (6 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (6h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 92)       666172      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2366        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 106)       767546      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_328 (Concatenate)   (None, 50, 106)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 424)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 43)           19350       concatenate_328[0][0]            
__________________________________________________________________________________________________
concatenate_329 (Concatenate)   (None, 456)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_330 (Concatenate)   (None, 499)          0           phraseRnn[0][0]                  
                                                                 concatenate_329[0][0]            
__________________________________________________________________________________________________
dense_219 (Dense)               (None, 129)          64500       concatenate_330[0][0]            
__________________________________________________________________________________________________
dense_220 (Dense)               (None, 4)            520         dense_219[0][0]                  
==================================================================================================
Total params: 1,521,806
Trainable params: 1,521,806
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0839 - acc: 0.9787 - val_loss: 0.0612 - val_acc: 0.9841
Epoch 2/40
 - 93s - loss: 0.0530 - acc: 0.9866 - val_loss: 0.0602 - val_acc: 0.9848
Epoch 3/40
 - 92s - loss: 0.0491 - acc: 0.9879 - val_loss: 0.0645 - val_acc: 0.9846
Epoch 4/40
 - 92s - loss: 0.0472 - acc: 0.9885 - val_loss: 0.0680 - val_acc: 0.9846
Epoch 5/40
 - 92s - loss: 0.0463 - acc: 0.9887 - val_loss: 0.0782 - val_acc: 0.9848
Epoch 00005: early stopping
	TRAINING TIME: 8.18 minutes 
==================================================================================================
	PARSING TIME: 6.5 minutes 
==================================================================================================
	Identification : 0.562
	P, R  : 0.53, 0.599

==================================================================================================
	XP Ends: 3/7 (6 h:42)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (6h:42)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 92)       1268956     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       1526        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 106)       1462058     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_331 (Concatenate)   (None, 50, 106)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 424)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 32)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 43)           19350       concatenate_331[0][0]            
__________________________________________________________________________________________________
concatenate_332 (Concatenate)   (None, 456)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_333 (Concatenate)   (None, 499)          0           phraseRnn[0][0]                  
                                                                 concatenate_332[0][0]            
__________________________________________________________________________________________________
dense_221 (Dense)               (None, 129)          64500       concatenate_333[0][0]            
__________________________________________________________________________________________________
dense_222 (Dense)               (None, 4)            520         dense_221[0][0]                  
==================================================================================================
Total params: 2,817,782
Trainable params: 2,817,782
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 181s - loss: 0.0727 - acc: 0.9811 - val_loss: 0.0568 - val_acc: 0.9846
Epoch 2/40
 - 181s - loss: 0.0524 - acc: 0.9864 - val_loss: 0.0582 - val_acc: 0.9846
Epoch 3/40
 - 181s - loss: 0.0492 - acc: 0.9876 - val_loss: 0.0624 - val_acc: 0.9835
Epoch 4/40
 - 181s - loss: 0.0473 - acc: 0.9882 - val_loss: 0.0679 - val_acc: 0.9839
Epoch 5/40
 - 181s - loss: 0.0458 - acc: 0.9887 - val_loss: 0.0764 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 16.5 minutes 
==================================================================================================
	PARSING TIME: 2.78 minutes 
==================================================================================================
	Identification : 0.489
	P, R  : 0.449, 0.537

==================================================================================================
	XP Ends: 3/7 (7 h:1)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,81             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.168          ,50             ,17             ,155            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
16             ,38             ,False          ,True           ,243            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 81, True, 0.168, 50, 17, 155, 16, 38, False, True, 243
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (7h:1)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 155)      1169475     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2584        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 38)        286710      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 16)        2432        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_334 (Concatenate)   (None, 50, 172)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 152)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 64)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 243)          303264      concatenate_334[0][0]            
__________________________________________________________________________________________________
concatenate_335 (Concatenate)   (None, 216)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_336 (Concatenate)   (None, 459)          0           phraseRnn[0][0]                  
                                                                 concatenate_335[0][0]            
__________________________________________________________________________________________________
dense_223 (Dense)               (None, 81)           37260       concatenate_336[0][0]            
__________________________________________________________________________________________________
dense_224 (Dense)               (None, 4)            328         dense_223[0][0]                  
==================================================================================================
Total params: 1,802,053
Trainable params: 1,802,053
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 152s - loss: 1.2846 - acc: 0.9197 - val_loss: 0.4589 - val_acc: 0.9715
Epoch 2/40
 - 152s - loss: 0.4650 - acc: 0.9711 - val_loss: 0.4545 - val_acc: 0.9718
Epoch 3/40
 - 152s - loss: 0.4594 - acc: 0.9713 - val_loss: 0.4479 - val_acc: 0.9720
Epoch 4/40
 - 152s - loss: 0.3788 - acc: 0.9737 - val_loss: 0.0951 - val_acc: 0.9794
Epoch 5/40
 - 152s - loss: 0.0696 - acc: 0.9831 - val_loss: 0.0624 - val_acc: 0.9841
Epoch 6/40
 - 152s - loss: 0.0553 - acc: 0.9861 - val_loss: 0.0608 - val_acc: 0.9847
Epoch 7/40
 - 152s - loss: 0.0515 - acc: 0.9872 - val_loss: 0.0647 - val_acc: 0.9840
Epoch 8/40
 - 152s - loss: 0.0499 - acc: 0.9876 - val_loss: 0.0647 - val_acc: 0.9850
Epoch 00008: early stopping
	TRAINING TIME: 21.18 minutes 
==================================================================================================
	PARSING TIME: 4.0 minutes 
==================================================================================================
	Identification : 0.575
	P, R  : 0.66, 0.51

==================================================================================================
	XP Ends: 3/7 (7 h:27)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (7h:27)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 155)      1122355     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       2873        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 38)        275158      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 16)        2704        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_337 (Concatenate)   (None, 50, 172)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 152)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 64)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 243)          303264      concatenate_337[0][0]            
__________________________________________________________________________________________________
concatenate_338 (Concatenate)   (None, 216)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_339 (Concatenate)   (None, 459)          0           phraseRnn[0][0]                  
                                                                 concatenate_338[0][0]            
__________________________________________________________________________________________________
dense_225 (Dense)               (None, 81)           37260       concatenate_339[0][0]            
__________________________________________________________________________________________________
dense_226 (Dense)               (None, 4)            328         dense_225[0][0]                  
==================================================================================================
Total params: 1,743,942
Trainable params: 1,743,942
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 103s - loss: 4.3271 - acc: 0.7309 - val_loss: 4.0899 - val_acc: 0.7462
Epoch 2/40
 - 103s - loss: 4.0357 - acc: 0.7496 - val_loss: 4.0891 - val_acc: 0.7463
Epoch 3/40
 - 103s - loss: 4.0349 - acc: 0.7496 - val_loss: 4.0881 - val_acc: 0.7463
Epoch 4/40
 - 103s - loss: 3.7168 - acc: 0.7671 - val_loss: 0.1923 - val_acc: 0.9463
Epoch 5/40
 - 103s - loss: 0.0877 - acc: 0.9790 - val_loss: 0.0749 - val_acc: 0.9822
Epoch 6/40
 - 103s - loss: 0.0653 - acc: 0.9848 - val_loss: 0.1104 - val_acc: 0.9802
Epoch 7/40
 - 103s - loss: 0.0600 - acc: 0.9863 - val_loss: 0.1573 - val_acc: 0.9682
Epoch 8/40
 - 103s - loss: 0.0578 - acc: 0.9870 - val_loss: 0.0796 - val_acc: 0.9828
Epoch 00008: early stopping
	TRAINING TIME: 14.2 minutes 
==================================================================================================
	PARSING TIME: 6.22 minutes 
==================================================================================================
	Identification : 0.525
	P, R  : 0.466, 0.602

==================================================================================================
	XP Ends: 3/7 (7 h:48)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (7h:48)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 155)      2137915     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 17)       1853        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 38)        524134      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 16)        1744        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_340 (Concatenate)   (None, 50, 172)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 152)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 64)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 243)          303264      concatenate_340[0][0]            
__________________________________________________________________________________________________
concatenate_341 (Concatenate)   (None, 216)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_342 (Concatenate)   (None, 459)          0           phraseRnn[0][0]                  
                                                                 concatenate_341[0][0]            
__________________________________________________________________________________________________
dense_227 (Dense)               (None, 81)           37260       concatenate_342[0][0]            
__________________________________________________________________________________________________
dense_228 (Dense)               (None, 4)            328         dense_227[0][0]                  
==================================================================================================
Total params: 3,006,498
Trainable params: 3,006,498
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 204s - loss: 12.0892 - acc: 0.2498 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 2/40
 - 204s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 3/40
 - 204s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 4/40
 - 204s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 5/40
 - 204s - loss: 12.0907 - acc: 0.2499 - val_loss: 12.0800 - val_acc: 0.2505
Epoch 00005: early stopping
	TRAINING TIME: 18.43 minutes 
==================================================================================================
	PARSING TIME: 4.87 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (8 h:11)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,209            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.056          ,50             ,14             ,51             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
36             ,163            ,True           ,True           ,239            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 209, False, 0.056, 50, 14, 51, 36, 163, True, True, 239
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (8h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 51)       583338      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2128        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 163)       1864394     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 36)        5472        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_343 (Concatenate)   (None, 50, 65)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 815)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 180)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 239)          291580      concatenate_343[0][0]            
__________________________________________________________________________________________________
concatenate_344 (Concatenate)   (None, 995)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_345 (Concatenate)   (None, 1234)         0           phraseRnn[0][0]                  
                                                                 concatenate_344[0][0]            
__________________________________________________________________________________________________
dense_229 (Dense)               (None, 209)          258115      concatenate_345[0][0]            
__________________________________________________________________________________________________
dense_230 (Dense)               (None, 4)            840         dense_229[0][0]                  
==================================================================================================
Total params: 3,005,867
Trainable params: 3,005,867
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 174s - loss: 12.0850 - acc: 0.2499 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 2/40
 - 174s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 3/40
 - 174s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 4/40
 - 174s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 5/40
 - 174s - loss: 12.0917 - acc: 0.2498 - val_loss: 12.0762 - val_acc: 0.2508
Epoch 00005: early stopping
	TRAINING TIME: 15.37 minutes 
==================================================================================================
	PARSING TIME: 9.55 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (8 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (8h:37)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 51)       479451      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       2366        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 163)       1532363     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 36)        6084        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_346 (Concatenate)   (None, 50, 65)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 815)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 180)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 239)          291580      concatenate_346[0][0]            
__________________________________________________________________________________________________
concatenate_347 (Concatenate)   (None, 995)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_348 (Concatenate)   (None, 1234)         0           phraseRnn[0][0]                  
                                                                 concatenate_347[0][0]            
__________________________________________________________________________________________________
dense_231 (Dense)               (None, 209)          258115      concatenate_348[0][0]            
__________________________________________________________________________________________________
dense_232 (Dense)               (None, 4)            840         dense_231[0][0]                  
==================================================================================================
Total params: 2,570,799
Trainable params: 2,570,799
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 117s - loss: 12.0868 - acc: 0.2498 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 2/40
 - 117s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 3/40
 - 117s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 4/40
 - 117s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 5/40
 - 117s - loss: 12.0940 - acc: 0.2497 - val_loss: 12.0667 - val_acc: 0.2514
Epoch 00005: early stopping
	TRAINING TIME: 10.35 minutes 
==================================================================================================
	PARSING TIME: 14.82 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (9 h:2)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (9h:2)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 51)       1125621     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 14)       1526        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 163)       3597573     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 36)        3924        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_349 (Concatenate)   (None, 50, 65)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 815)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 180)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 239)          291580      concatenate_349[0][0]            
__________________________________________________________________________________________________
concatenate_350 (Concatenate)   (None, 995)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_351 (Concatenate)   (None, 1234)         0           phraseRnn[0][0]                  
                                                                 concatenate_350[0][0]            
__________________________________________________________________________________________________
dense_233 (Dense)               (None, 209)          258115      concatenate_351[0][0]            
__________________________________________________________________________________________________
dense_234 (Dense)               (None, 4)            840         dense_233[0][0]                  
==================================================================================================
Total params: 5,279,179
Trainable params: 5,279,179
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 237s - loss: 12.0819 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 2/40
 - 237s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 3/40
 - 237s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 4/40
 - 237s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 5/40
 - 237s - loss: 12.0854 - acc: 0.2502 - val_loss: 12.1013 - val_acc: 0.2492
Epoch 00005: early stopping
	TRAINING TIME: 21.27 minutes 
==================================================================================================
	PARSING TIME: 6.47 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (9 h:30)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,73             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.023          ,50             ,18             ,176            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
45             ,184            ,False          ,True           ,191            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 73, True, 0.023, 50, 18, 176, 45, 184, False, True, 191
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (9h:30)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 176)      2013088     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       2736        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 184)       2104592     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 45)        6840        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_352 (Concatenate)   (None, 50, 194)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 736)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 180)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 191)          221178      concatenate_352[0][0]            
__________________________________________________________________________________________________
concatenate_353 (Concatenate)   (None, 916)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_354 (Concatenate)   (None, 1107)         0           phraseRnn[0][0]                  
                                                                 concatenate_353[0][0]            
__________________________________________________________________________________________________
dense_235 (Dense)               (None, 73)           80884       concatenate_354[0][0]            
__________________________________________________________________________________________________
dense_236 (Dense)               (None, 4)            296         dense_235[0][0]                  
==================================================================================================
Total params: 4,429,614
Trainable params: 4,429,614
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 143s - loss: 0.0654 - acc: 0.9829 - val_loss: 0.0544 - val_acc: 0.9859
Epoch 2/40
 - 143s - loss: 0.0496 - acc: 0.9878 - val_loss: 0.0544 - val_acc: 0.9863
Epoch 3/40
 - 143s - loss: 0.0465 - acc: 0.9888 - val_loss: 0.0572 - val_acc: 0.9861
Epoch 4/40
 - 144s - loss: 0.0453 - acc: 0.9891 - val_loss: 0.0596 - val_acc: 0.9862
Epoch 5/40
 - 143s - loss: 0.0446 - acc: 0.9892 - val_loss: 0.0627 - val_acc: 0.9860
Epoch 00005: early stopping
	TRAINING TIME: 12.85 minutes 
==================================================================================================
	PARSING TIME: 4.1 minutes 
==================================================================================================
	Identification : 0.538
	P, R  : 0.493, 0.593

==================================================================================================
	XP Ends: 3/7 (9 h:48)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (9h:48)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 176)      1654576     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       3042        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 184)       1729784     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 45)        7605        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_355 (Concatenate)   (None, 50, 194)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 736)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 180)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 191)          221178      concatenate_355[0][0]            
__________________________________________________________________________________________________
concatenate_356 (Concatenate)   (None, 916)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_357 (Concatenate)   (None, 1107)         0           phraseRnn[0][0]                  
                                                                 concatenate_356[0][0]            
__________________________________________________________________________________________________
dense_237 (Dense)               (None, 73)           80884       concatenate_357[0][0]            
__________________________________________________________________________________________________
dense_238 (Dense)               (None, 4)            296         dense_237[0][0]                  
==================================================================================================
Total params: 3,697,365
Trainable params: 3,697,365
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 96s - loss: 0.0766 - acc: 0.9791 - val_loss: 0.0586 - val_acc: 0.9844
Epoch 2/40
 - 96s - loss: 0.0536 - acc: 0.9865 - val_loss: 0.0995 - val_acc: 0.9717
Epoch 3/40
 - 96s - loss: 0.0496 - acc: 0.9878 - val_loss: 0.0630 - val_acc: 0.9845
Epoch 4/40
 - 96s - loss: 0.0477 - acc: 0.9882 - val_loss: 0.0869 - val_acc: 0.9795
Epoch 5/40
 - 96s - loss: 0.0467 - acc: 0.9884 - val_loss: 0.0781 - val_acc: 0.9838
Epoch 00005: early stopping
	TRAINING TIME: 8.52 minutes 
==================================================================================================
	PARSING TIME: 6.22 minutes 
==================================================================================================
	Identification : 0.496
	P, R  : 0.429, 0.588

==================================================================================================
	XP Ends: 3/7 (10 h:3)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (10h:3)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 176)      3884496     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 18)       1962        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 184)       4061064     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 45)        4905        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_358 (Concatenate)   (None, 50, 194)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 736)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 180)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 191)          221178      concatenate_358[0][0]            
__________________________________________________________________________________________________
concatenate_359 (Concatenate)   (None, 916)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_360 (Concatenate)   (None, 1107)         0           phraseRnn[0][0]                  
                                                                 concatenate_359[0][0]            
__________________________________________________________________________________________________
dense_239 (Dense)               (None, 73)           80884       concatenate_360[0][0]            
__________________________________________________________________________________________________
dense_240 (Dense)               (None, 4)            296         dense_239[0][0]                  
==================================================================================================
Total params: 8,254,785
Trainable params: 8,254,785
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 197s - loss: 0.0647 - acc: 0.9828 - val_loss: 0.0583 - val_acc: 0.9845
Epoch 2/40
 - 197s - loss: 0.0498 - acc: 0.9874 - val_loss: 0.0600 - val_acc: 0.9845
Epoch 3/40
 - 197s - loss: 0.0471 - acc: 0.9884 - val_loss: 0.0643 - val_acc: 0.9844
Epoch 4/40
 - 197s - loss: 0.0453 - acc: 0.9888 - val_loss: 0.0731 - val_acc: 0.9841
Epoch 5/40
 - 197s - loss: 0.0440 - acc: 0.9891 - val_loss: 0.0848 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 17.88 minutes 
==================================================================================================
	PARSING TIME: 2.7 minutes 
==================================================================================================
	Identification : 0.495
	P, R  : 0.483, 0.508

==================================================================================================
	XP Ends: 3/7 (10 h:24)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,48             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.032          ,50             ,5              ,162            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
15             ,156            ,True           ,True           ,104            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 48, True, 0.032, 50, 5, 162, 15, 156, True, True, 104
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (10h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 162)      1852956     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 156)       1784328     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 15)        2280        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_361 (Concatenate)   (None, 50, 167)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 780)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 75)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 104)          84864       concatenate_361[0][0]            
__________________________________________________________________________________________________
concatenate_362 (Concatenate)   (None, 855)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_363 (Concatenate)   (None, 959)          0           phraseRnn[0][0]                  
                                                                 concatenate_362[0][0]            
__________________________________________________________________________________________________
dense_241 (Dense)               (None, 48)           46080       concatenate_363[0][0]            
__________________________________________________________________________________________________
dense_242 (Dense)               (None, 4)            196         dense_241[0][0]                  
==================================================================================================
Total params: 3,771,464
Trainable params: 3,771,464
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 138s - loss: 0.0640 - acc: 0.9832 - val_loss: 0.0531 - val_acc: 0.9864
Epoch 2/40
 - 138s - loss: 0.0486 - acc: 0.9882 - val_loss: 0.0539 - val_acc: 0.9864
Epoch 3/40
 - 138s - loss: 0.0460 - acc: 0.9889 - val_loss: 0.0561 - val_acc: 0.9864
Epoch 4/40
 - 138s - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0603 - val_acc: 0.9862
Epoch 5/40
 - 138s - loss: 0.0442 - acc: 0.9894 - val_loss: 0.0638 - val_acc: 0.9860
Epoch 00005: early stopping
	TRAINING TIME: 12.33 minutes 
==================================================================================================
	PARSING TIME: 4.13 minutes 
==================================================================================================
	Identification : 0.545
	P, R  : 0.575, 0.518

==================================================================================================
	XP Ends: 3/7 (10 h:41)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (10h:41)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 162)      1522962     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 156)       1466556     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 15)        2535        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_364 (Concatenate)   (None, 50, 167)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 780)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 75)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 104)          84864       concatenate_364[0][0]            
__________________________________________________________________________________________________
concatenate_365 (Concatenate)   (None, 855)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_366 (Concatenate)   (None, 959)          0           phraseRnn[0][0]                  
                                                                 concatenate_365[0][0]            
__________________________________________________________________________________________________
dense_243 (Dense)               (None, 48)           46080       concatenate_366[0][0]            
__________________________________________________________________________________________________
dense_244 (Dense)               (None, 4)            196         dense_243[0][0]                  
==================================================================================================
Total params: 3,124,038
Trainable params: 3,124,038
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0741 - acc: 0.9798 - val_loss: 0.0583 - val_acc: 0.9849
Epoch 2/40
 - 94s - loss: 0.0521 - acc: 0.9869 - val_loss: 0.0576 - val_acc: 0.9849
Epoch 3/40
 - 94s - loss: 0.0485 - acc: 0.9881 - val_loss: 0.0615 - val_acc: 0.9847
Epoch 4/40
 - 93s - loss: 0.0472 - acc: 0.9885 - val_loss: 0.0665 - val_acc: 0.9845
Epoch 5/40
 - 93s - loss: 0.0461 - acc: 0.9886 - val_loss: 0.0759 - val_acc: 0.9845
Epoch 00005: early stopping
	TRAINING TIME: 8.32 minutes 
==================================================================================================
	PARSING TIME: 6.32 minutes 
==================================================================================================
	Identification : 0.471
	P, R  : 0.382, 0.615

==================================================================================================
	XP Ends: 3/7 (10 h:56)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (10h:56)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 162)      3575502     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        545         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 156)       3443076     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 15)        1635        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_367 (Concatenate)   (None, 50, 167)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 780)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 75)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 104)          84864       concatenate_367[0][0]            
__________________________________________________________________________________________________
concatenate_368 (Concatenate)   (None, 855)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_369 (Concatenate)   (None, 959)          0           phraseRnn[0][0]                  
                                                                 concatenate_368[0][0]            
__________________________________________________________________________________________________
dense_245 (Dense)               (None, 48)           46080       concatenate_369[0][0]            
__________________________________________________________________________________________________
dense_246 (Dense)               (None, 4)            196         dense_245[0][0]                  
==================================================================================================
Total params: 7,151,898
Trainable params: 7,151,898
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 187s - loss: 0.0628 - acc: 0.9833 - val_loss: 0.0570 - val_acc: 0.9848
Epoch 2/40
 - 187s - loss: 0.0484 - acc: 0.9880 - val_loss: 0.0600 - val_acc: 0.9843
Epoch 3/40
 - 187s - loss: 0.0459 - acc: 0.9889 - val_loss: 0.0628 - val_acc: 0.9843
Epoch 4/40
 - 188s - loss: 0.0446 - acc: 0.9893 - val_loss: 0.0678 - val_acc: 0.9842
Epoch 5/40
 - 188s - loss: 0.0438 - acc: 0.9894 - val_loss: 0.0742 - val_acc: 0.9840
Epoch 00005: early stopping
	TRAINING TIME: 17.05 minutes 
==================================================================================================
	PARSING TIME: 2.8 minutes 
==================================================================================================
	Identification : 0.501
	P, R  : 0.452, 0.561

==================================================================================================
	XP Ends: 3/7 (11 h:16)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,240            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.054          ,50             ,11             ,190            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
8              ,67             ,True           ,True           ,29             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 240, False, 0.054, 50, 11, 190, 8, 67, True, True, 29
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (11h:16)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 190)      2173220     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1672        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 67)        766346      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1216        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_370 (Concatenate)   (None, 50, 201)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 335)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 29)           26796       concatenate_370[0][0]            
__________________________________________________________________________________________________
concatenate_371 (Concatenate)   (None, 375)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_372 (Concatenate)   (None, 404)          0           phraseRnn[0][0]                  
                                                                 concatenate_371[0][0]            
__________________________________________________________________________________________________
dense_247 (Dense)               (None, 240)          97200       concatenate_372[0][0]            
__________________________________________________________________________________________________
dense_248 (Dense)               (None, 4)            964         dense_247[0][0]                  
==================================================================================================
Total params: 3,067,414
Trainable params: 3,067,414
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 17893, 3: 17879, 1: 17774, 2: 17751})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 164s - loss: 0.0648 - acc: 0.9832 - val_loss: 0.0530 - val_acc: 0.9868
Epoch 2/40
 - 164s - loss: 0.0482 - acc: 0.9883 - val_loss: 0.0542 - val_acc: 0.9868
Epoch 3/40
 - 164s - loss: 0.0457 - acc: 0.9890 - val_loss: 0.0559 - val_acc: 0.9866
Epoch 4/40
 - 164s - loss: 0.0445 - acc: 0.9893 - val_loss: 0.0616 - val_acc: 0.9866
Epoch 5/40
 - 164s - loss: 0.0438 - acc: 0.9894 - val_loss: 0.0679 - val_acc: 0.9863
Epoch 00005: early stopping
	TRAINING TIME: 14.5 minutes 
==================================================================================================
	PARSING TIME: 5.28 minutes 
==================================================================================================
	Identification : 0.536
	P, R  : 0.487, 0.597

==================================================================================================
	XP Ends: 3/7 (11 h:36)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (11h:36)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12103
	After : 9401

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 9401 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 182
	MWE not in vocabulary 1082
	Dashed keys in vocabulary 2380
	One occurrence keys in vocabulary 2380 / 9401
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 190)      1786190     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1859        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 67)        629867      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         1352        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_373 (Concatenate)   (None, 50, 201)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 335)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 29)           26796       concatenate_373[0][0]            
__________________________________________________________________________________________________
concatenate_374 (Concatenate)   (None, 375)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_375 (Concatenate)   (None, 404)          0           phraseRnn[0][0]                  
                                                                 concatenate_374[0][0]            
__________________________________________________________________________________________________
dense_249 (Dense)               (None, 240)          97200       concatenate_375[0][0]            
__________________________________________________________________________________________________
dense_250 (Dense)               (None, 4)            964         dense_249[0][0]                  
==================================================================================================
Total params: 2,544,228
Trainable params: 2,544,228
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12221, 2: 12134, 3: 11962, 1: 11957})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 110s - loss: 0.0755 - acc: 0.9796 - val_loss: 0.0571 - val_acc: 0.9854
Epoch 2/40
 - 110s - loss: 0.0515 - acc: 0.9872 - val_loss: 0.0585 - val_acc: 0.9850
Epoch 3/40
 - 110s - loss: 0.0483 - acc: 0.9882 - val_loss: 0.0604 - val_acc: 0.9852
Epoch 4/40
 - 110s - loss: 0.0469 - acc: 0.9885 - val_loss: 0.0681 - val_acc: 0.9848
Epoch 5/40
 - 110s - loss: 0.0460 - acc: 0.9886 - val_loss: 0.0747 - val_acc: 0.9847
Epoch 00005: early stopping
	TRAINING TIME: 9.7 minutes 
==================================================================================================
	PARSING TIME: 7.97 minutes 
==================================================================================================
	Identification : 0.459
	P, R  : 0.366, 0.617

==================================================================================================
	XP Ends: 3/7 (11 h:54)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (11h:54)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 29784
	After : 22071

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22071 * POS : 109
__________________________________________________________________________________________________
	Important words not in vocabulary 221
	MWE not in vocabulary 1768
	Dashed keys in vocabulary 3975
	One occurrence keys in vocabulary 3975 / 22071
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 190)      4193490     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 11)       1199        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 67)        1478757     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 8)         872         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_376 (Concatenate)   (None, 50, 201)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 335)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 40)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 29)           26796       concatenate_376[0][0]            
__________________________________________________________________________________________________
concatenate_377 (Concatenate)   (None, 375)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_378 (Concatenate)   (None, 404)          0           phraseRnn[0][0]                  
                                                                 concatenate_377[0][0]            
__________________________________________________________________________________________________
dense_251 (Dense)               (None, 240)          97200       concatenate_378[0][0]            
__________________________________________________________________________________________________
dense_252 (Dense)               (None, 4)            964         dense_251[0][0]                  
==================================================================================================
Total params: 5,799,278
Trainable params: 5,799,278
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({2: 24103, 0: 24101, 3: 23949, 1: 23947})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 222s - loss: 0.0640 - acc: 0.9834 - val_loss: 0.0572 - val_acc: 0.9847
Epoch 2/40
 - 222s - loss: 0.0482 - acc: 0.9881 - val_loss: 0.0592 - val_acc: 0.9847
Epoch 3/40
 - 222s - loss: 0.0456 - acc: 0.9890 - val_loss: 0.0675 - val_acc: 0.9845
Epoch 4/40
 - 223s - loss: 0.0439 - acc: 0.9893 - val_loss: 0.0769 - val_acc: 0.9843
Epoch 5/40
 - 222s - loss: 0.0430 - acc: 0.9894 - val_loss: 0.0884 - val_acc: 0.9843
Epoch 00005: early stopping
	TRAINING TIME: 19.97 minutes 
==================================================================================================
	PARSING TIME: 3.47 minutes 
==================================================================================================
	Identification : 0.494
	P, R  : 0.436, 0.571

==================================================================================================
	XP Ends: 3/7 (12 h:18)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,97             ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.097          ,50             ,8              ,67             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
36             ,95             ,False          ,True           ,45             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 97, True, 0.097, 50, 8, 67, 36, 95, False, True, 45
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (12h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 67)       505515      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1216        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 95)        716775      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 36)        5472        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_379 (Concatenate)   (None, 50, 75)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 380)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 144)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           16335       concatenate_379[0][0]            
__________________________________________________________________________________________________
concatenate_380 (Concatenate)   (None, 524)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_381 (Concatenate)   (None, 569)          0           phraseRnn[0][0]                  
                                                                 concatenate_380[0][0]            
__________________________________________________________________________________________________
dense_253 (Dense)               (None, 97)           55290       concatenate_381[0][0]            
__________________________________________________________________________________________________
dense_254 (Dense)               (None, 4)            392         dense_253[0][0]                  
==================================================================================================
Total params: 1,300,995
Trainable params: 1,300,995
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 145s - loss: 0.0699 - acc: 0.9824 - val_loss: 0.0559 - val_acc: 0.9857
Epoch 2/40
 - 137s - loss: 0.0499 - acc: 0.9877 - val_loss: 0.0557 - val_acc: 0.9860
Epoch 3/40
 - 137s - loss: 0.0468 - acc: 0.9887 - val_loss: 0.0580 - val_acc: 0.9861
Epoch 4/40
 - 137s - loss: 0.0453 - acc: 0.9891 - val_loss: 0.0612 - val_acc: 0.9861
Epoch 5/40
 - 137s - loss: 0.0444 - acc: 0.9894 - val_loss: 0.0654 - val_acc: 0.9862
Epoch 00005: early stopping
	TRAINING TIME: 12.38 minutes 
==================================================================================================
	PARSING TIME: 4.12 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.58, 0.564

==================================================================================================
	XP Ends: 3/7 (12 h:35)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (12h:35)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 67)       485147      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        1352        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 95)        687895      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 36)        6084        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_382 (Concatenate)   (None, 50, 75)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 380)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 144)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           16335       concatenate_382[0][0]            
__________________________________________________________________________________________________
concatenate_383 (Concatenate)   (None, 524)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_384 (Concatenate)   (None, 569)          0           phraseRnn[0][0]                  
                                                                 concatenate_383[0][0]            
__________________________________________________________________________________________________
dense_255 (Dense)               (None, 97)           55290       concatenate_384[0][0]            
__________________________________________________________________________________________________
dense_256 (Dense)               (None, 4)            392         dense_255[0][0]                  
==================================================================================================
Total params: 1,252,495
Trainable params: 1,252,495
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 93s - loss: 0.0890 - acc: 0.9791 - val_loss: 0.0619 - val_acc: 0.9838
Epoch 2/40
 - 93s - loss: 0.0528 - acc: 0.9866 - val_loss: 0.0624 - val_acc: 0.9839
Epoch 3/40
 - 92s - loss: 0.0496 - acc: 0.9876 - val_loss: 0.0643 - val_acc: 0.9843
Epoch 4/40
 - 92s - loss: 0.0477 - acc: 0.9883 - val_loss: 0.0693 - val_acc: 0.9843
Epoch 5/40
 - 92s - loss: 0.0466 - acc: 0.9886 - val_loss: 0.0734 - val_acc: 0.9842
Epoch 00005: early stopping
	TRAINING TIME: 8.17 minutes 
==================================================================================================
	PARSING TIME: 6.35 minutes 
==================================================================================================
	Identification : 0.545
	P, R  : 0.479, 0.631

==================================================================================================
	XP Ends: 3/7 (12 h:50)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (12h:50)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 67)       924131      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 8)        872         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 95)        1310335     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 36)        3924        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_385 (Concatenate)   (None, 50, 75)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 380)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 144)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 45)           16335       concatenate_385[0][0]            
__________________________________________________________________________________________________
concatenate_386 (Concatenate)   (None, 524)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_387 (Concatenate)   (None, 569)          0           phraseRnn[0][0]                  
                                                                 concatenate_386[0][0]            
__________________________________________________________________________________________________
dense_257 (Dense)               (None, 97)           55290       concatenate_387[0][0]            
__________________________________________________________________________________________________
dense_258 (Dense)               (None, 4)            392         dense_257[0][0]                  
==================================================================================================
Total params: 2,311,279
Trainable params: 2,311,279
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 180s - loss: 0.1293 - acc: 0.9779 - val_loss: 0.0582 - val_acc: 0.9844
Epoch 2/40
 - 180s - loss: 0.0529 - acc: 0.9862 - val_loss: 0.0587 - val_acc: 0.9846
Epoch 3/40
 - 180s - loss: 0.0500 - acc: 0.9873 - val_loss: 0.0615 - val_acc: 0.9845
Epoch 4/40
 - 180s - loss: 0.0480 - acc: 0.9879 - val_loss: 0.0703 - val_acc: 0.9843
Epoch 5/40
 - 180s - loss: 0.0466 - acc: 0.9883 - val_loss: 0.0768 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 16.42 minutes 
==================================================================================================
	PARSING TIME: 2.77 minutes 
==================================================================================================
	Identification : 0.478
	P, R  : 0.445, 0.516

==================================================================================================
	XP Ends: 3/7 (13 h:9)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,305            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.024          ,50             ,20             ,94             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
5              ,60             ,False          ,True           ,145            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 305, True, 0.024, 50, 20, 94, 5, 60, False, True, 145
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (13h:9)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 94)       709230      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3040        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 60)        452700      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         760         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_388 (Concatenate)   (None, 50, 114)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 240)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 145)          113100      concatenate_388[0][0]            
__________________________________________________________________________________________________
concatenate_389 (Concatenate)   (None, 260)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_390 (Concatenate)   (None, 405)          0           phraseRnn[0][0]                  
                                                                 concatenate_389[0][0]            
__________________________________________________________________________________________________
dense_259 (Dense)               (None, 305)          123830      concatenate_390[0][0]            
__________________________________________________________________________________________________
dense_260 (Dense)               (None, 4)            1224        dense_259[0][0]                  
==================================================================================================
Total params: 1,403,884
Trainable params: 1,403,884
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 136s - loss: 0.0662 - acc: 0.9825 - val_loss: 0.0555 - val_acc: 0.9857
Epoch 2/40
 - 137s - loss: 0.0507 - acc: 0.9873 - val_loss: 0.0557 - val_acc: 0.9858
Epoch 3/40
 - 136s - loss: 0.0475 - acc: 0.9885 - val_loss: 0.0576 - val_acc: 0.9860
Epoch 4/40
 - 136s - loss: 0.0458 - acc: 0.9890 - val_loss: 0.0608 - val_acc: 0.9858
Epoch 5/40
 - 136s - loss: 0.0448 - acc: 0.9892 - val_loss: 0.0645 - val_acc: 0.9856
Epoch 00005: early stopping
	TRAINING TIME: 12.23 minutes 
==================================================================================================
	PARSING TIME: 4.12 minutes 
==================================================================================================
	Identification : 0.594
	P, R  : 0.745, 0.494

==================================================================================================
	XP Ends: 3/7 (13 h:26)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (13h:26)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 94)       680654      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       3380        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 60)        434460      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         845         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_391 (Concatenate)   (None, 50, 114)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 240)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 145)          113100      concatenate_391[0][0]            
__________________________________________________________________________________________________
concatenate_392 (Concatenate)   (None, 260)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_393 (Concatenate)   (None, 405)          0           phraseRnn[0][0]                  
                                                                 concatenate_392[0][0]            
__________________________________________________________________________________________________
dense_261 (Dense)               (None, 305)          123830      concatenate_393[0][0]            
__________________________________________________________________________________________________
dense_262 (Dense)               (None, 4)            1224        dense_261[0][0]                  
==================================================================================================
Total params: 1,357,493
Trainable params: 1,357,493
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 94s - loss: 0.0758 - acc: 0.9792 - val_loss: 0.0606 - val_acc: 0.9840
Epoch 2/40
 - 95s - loss: 0.0531 - acc: 0.9865 - val_loss: 0.0605 - val_acc: 0.9848
Epoch 3/40
 - 93s - loss: 0.0491 - acc: 0.9880 - val_loss: 0.0628 - val_acc: 0.9846
Epoch 4/40
 - 93s - loss: 0.0475 - acc: 0.9884 - val_loss: 0.0670 - val_acc: 0.9844
Epoch 5/40
 - 93s - loss: 0.0465 - acc: 0.9885 - val_loss: 0.0733 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 8.3 minutes 
==================================================================================================
	PARSING TIME: 6.32 minutes 
==================================================================================================
	Identification : 0.488
	P, R  : 0.403, 0.617

==================================================================================================
	XP Ends: 3/7 (13 h:41)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (13h:41)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 4)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 4)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 94)       1296542     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 20)       2180        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 4, 60)        827580      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 4, 5)         545         transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_394 (Concatenate)   (None, 50, 114)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 240)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 20)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 145)          113100      concatenate_394[0][0]            
__________________________________________________________________________________________________
concatenate_395 (Concatenate)   (None, 260)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_396 (Concatenate)   (None, 405)          0           phraseRnn[0][0]                  
                                                                 concatenate_395[0][0]            
__________________________________________________________________________________________________
dense_263 (Dense)               (None, 305)          123830      concatenate_396[0][0]            
__________________________________________________________________________________________________
dense_264 (Dense)               (None, 4)            1224        dense_263[0][0]                  
==================================================================================================
Total params: 2,365,001
Trainable params: 2,365,001
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 181s - loss: 0.0678 - acc: 0.9816 - val_loss: 0.0572 - val_acc: 0.9843
Epoch 2/40
 - 181s - loss: 0.0527 - acc: 0.9864 - val_loss: 0.0577 - val_acc: 0.9842
Epoch 3/40
 - 181s - loss: 0.0498 - acc: 0.9874 - val_loss: 0.0604 - val_acc: 0.9845
Epoch 4/40
 - 182s - loss: 0.0479 - acc: 0.9880 - val_loss: 0.0653 - val_acc: 0.9840
Epoch 5/40
 - 181s - loss: 0.0466 - acc: 0.9884 - val_loss: 0.0710 - val_acc: 0.9837
Epoch 00005: early stopping
	TRAINING TIME: 16.52 minutes 
==================================================================================================
	PARSING TIME: 2.7 minutes 
==================================================================================================
	Identification : 0.473
	P, R  : 0.554, 0.412

==================================================================================================
	XP Ends: 3/7 (14 h:1)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,291            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
True           ,0.19           ,50             ,46             ,26             ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
24             ,35             ,True           ,True           ,266            ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 291, True, 0.19, 50, 46, 26, 24, 35, True, True, 266
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (14h:1)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 26)       196170      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 46)       6992        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 35)        264075      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 24)        3648        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_397 (Concatenate)   (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 175)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 120)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 266)          270522      concatenate_397[0][0]            
__________________________________________________________________________________________________
concatenate_398 (Concatenate)   (None, 295)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_399 (Concatenate)   (None, 561)          0           phraseRnn[0][0]                  
                                                                 concatenate_398[0][0]            
__________________________________________________________________________________________________
dense_265 (Dense)               (None, 291)          163542      concatenate_399[0][0]            
__________________________________________________________________________________________________
dense_266 (Dense)               (None, 4)            1168        dense_265[0][0]                  
==================================================================================================
Total params: 906,117
Trainable params: 906,117
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 153s - loss: 12.0972 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 2/40
 - 153s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 3/40
 - 153s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 4/40
 - 153s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 5/40
 - 153s - loss: 12.1003 - acc: 0.2493 - val_loss: 12.0416 - val_acc: 0.2529
Epoch 00005: early stopping
	TRAINING TIME: 13.6 minutes 
==================================================================================================
	PARSING TIME: 7.58 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (14 h:22)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (14h:22)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 26)       188266      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 46)       7774        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 35)        253435      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 24)        4056        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_400 (Concatenate)   (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 175)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 120)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 266)          270522      concatenate_400[0][0]            
__________________________________________________________________________________________________
concatenate_401 (Concatenate)   (None, 295)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_402 (Concatenate)   (None, 561)          0           phraseRnn[0][0]                  
                                                                 concatenate_401[0][0]            
__________________________________________________________________________________________________
dense_267 (Dense)               (None, 291)          163542      concatenate_402[0][0]            
__________________________________________________________________________________________________
dense_268 (Dense)               (None, 4)            1168        dense_267[0][0]                  
==================================================================================================
Total params: 888,763
Trainable params: 888,763
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 104s - loss: 12.0905 - acc: 0.2495 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 2/40
 - 104s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 3/40
 - 104s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 4/40
 - 104s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 5/40
 - 104s - loss: 12.0984 - acc: 0.2494 - val_loss: 12.0493 - val_acc: 0.2524
Epoch 00005: early stopping
	TRAINING TIME: 9.22 minutes 
==================================================================================================
	PARSING TIME: 6.02 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (14 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (14h:38)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 13793

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13793 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 13793
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 5)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 26)       358618      phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 46)       5014        phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 5, 35)        482755      transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 5, 24)        2616        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_403 (Concatenate)   (None, 50, 72)       0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 175)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 120)          0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (GRU)                 (None, 266)          270522      concatenate_403[0][0]            
__________________________________________________________________________________________________
concatenate_404 (Concatenate)   (None, 295)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_405 (Concatenate)   (None, 561)          0           phraseRnn[0][0]                  
                                                                 concatenate_404[0][0]            
__________________________________________________________________________________________________
dense_269 (Dense)               (None, 291)          163542      concatenate_405[0][0]            
__________________________________________________________________________________________________
dense_270 (Dense)               (None, 4)            1168        dense_269[0][0]                  
==================================================================================================
Total params: 1,284,235
Trainable params: 1,284,235
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({0: 24076, 2: 24044, 1: 24027, 3: 23953})
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 206s - loss: 12.0878 - acc: 0.2499 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 2/40
 - 206s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 3/40
 - 206s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 4/40
 - 206s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 5/40
 - 206s - loss: 12.0894 - acc: 0.2500 - val_loss: 12.0854 - val_acc: 0.2502
Epoch 00005: early stopping
	TRAINING TIME: 18.6 minutes 
==================================================================================================
	PARSING TIME: 2.65 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 3/7 (14 h:59)
==================================================================================================
	Mode: MLPPHRASE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, denseUnitNumber, gru, lr, phraseMaxLength, phrasePosEmb, phraseTokenEmb, transPosEmb, transTokenEmb, useB-1, useB1, wordRnnUnitNum
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpPhrase      ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,denseUnitNumber,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,320            ,
__________________________________________________________________________________________________
gru            ,lr             ,phraseMaxLength,phrasePosEmb   ,phraseTokenEmb ,
__________________________________________________________________________________________________
False          ,0.023          ,50             ,5              ,159            ,
__________________________________________________________________________________________________
transPosEmb    ,transTokenEmb  ,useB-1         ,useB1          ,wordRnnUnitNum ,
__________________________________________________________________________________________________
9              ,161            ,False          ,False          ,90             ,
__________________________________________________________________________________________________

__________________________________________________________________________________________________

__________________________________________________________________________________________________
# Configs: mlpPhrase, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 320, False, 0.023, 50, 5, 159, 9, 161, False, False, 90
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 3/7 (14h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 159)      1199655     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        760         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 161)       1214745     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 9)         1368        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_406 (Concatenate)   (None, 50, 164)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 483)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 27)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 90)           91800       concatenate_406[0][0]            
__________________________________________________________________________________________________
concatenate_407 (Concatenate)   (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_408 (Concatenate)   (None, 600)          0           phraseRnn[0][0]                  
                                                                 concatenate_407[0][0]            
__________________________________________________________________________________________________
dense_271 (Dense)               (None, 320)          192320      concatenate_408[0][0]            
__________________________________________________________________________________________________
dense_272 (Dense)               (None, 4)            1284        dense_271[0][0]                  
==================================================================================================
Total params: 2,701,932
Trainable params: 2,701,932
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18032, 2: 17815, 1: 17792, 3: 17658})
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 167s - loss: 0.0655 - acc: 0.9828 - val_loss: 0.0576 - val_acc: 0.9850
Epoch 2/40
 - 166s - loss: 0.0509 - acc: 0.9872 - val_loss: 0.0590 - val_acc: 0.9855
Epoch 3/40
 - 166s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0594 - val_acc: 0.9855
Epoch 4/40
 - 166s - loss: 0.0462 - acc: 0.9887 - val_loss: 0.0637 - val_acc: 0.9854
Epoch 5/40
 - 166s - loss: 0.0451 - acc: 0.9891 - val_loss: 0.0676 - val_acc: 0.9853
Epoch 00005: early stopping
	TRAINING TIME: 14.78 minutes 
==================================================================================================
	PARSING TIME: 5.13 minutes 
==================================================================================================
	Identification : 0.602
	P, R  : 0.772, 0.494

==================================================================================================
	XP Ends: 3/7 (15 h:20)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 3/7 (15h:20)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 7241

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7241 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 7241
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
phraseTokens (InputLayer)       (None, 50)           0                                            
__________________________________________________________________________________________________
phrasePoss (InputLayer)         (None, 50)           0                                            
__________________________________________________________________________________________________
transTokens (InputLayer)        (None, 3)            0                                            
__________________________________________________________________________________________________
transPoss (InputLayer)          (None, 3)            0                                            
__________________________________________________________________________________________________
phraseTokenEmb (Embedding)      (None, 50, 159)      1151319     phraseTokens[0][0]               
__________________________________________________________________________________________________
phrasePosEmb (Embedding)        (None, 50, 5)        845         phrasePoss[0][0]                 
__________________________________________________________________________________________________
transTokenEmb (Embedding)       (None, 3, 161)       1165801     transTokens[0][0]                
__________________________________________________________________________________________________
transPosEmb (Embedding)         (None, 3, 9)         1521        transPoss[0][0]                  
__________________________________________________________________________________________________
concatenate_409 (Concatenate)   (None, 50, 164)      0           phraseTokenEmb[0][0]             
                                                                 phrasePosEmb[0][0]               
__________________________________________________________________________________________________
transTokenFlat (Flatten)        (None, 483)          0           transTokenEmb[0][0]              
__________________________________________________________________________________________________
transPosFlat (Flatten)          (None, 27)           0           transPosEmb[0][0]                
__________________________________________________________________________________________________
phraseRnn (LSTM)                (None, 90)           91800       concatenate_409[0][0]            
__________________________________________________________________________________________________
concatenate_410 (Concatenate)   (None, 510)          0           transTokenFlat[0][0]             
                                                                 transPosFlat[0][0]               
__________________________________________________________________________________________________
concatenate_411 (Concatenate)   (None, 600)          0           phraseRnn[0][0]                  
                                                                 concatenate_410[0][0]            
__________________________________________________________________________________________________
dense_273 (Dense)               (None, 320)          192320      concatenate_411[0][0]            
__________________________________________________________________________________________________
dense_274 (Dense)               (None, 4)            1284        dense_273[0][0]                  
==================================================================================================
Total params: 2,604,890
Trainable params: 2,604,890
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({1: 12186, 3: 12150, 0: 11973, 2: 11965})
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 112s - loss: 0.0744 - acc: 0.9794 - val_loss: 0.0615 - val_acc: 0.9838
Epoch 2/40
 - 111s - loss: 0.0550 - acc: 0.9857 - val_loss: 0.0614 - val_acc: 0.9843
Epoch 3/40
 - 111s - loss: 0.0510 - acc: 0.9873 - val_loss: 0.0652 - val_acc: 0.9839
Epoch 4/40
 - 111s - loss: 0.0487 - acc: 0.9879 - val_loss: 0.0700 - val_acc: 0.9836
Epoch 5/40
 - 111s - loss: 0.0472 - acc: 0.9883 - val_loss: 0.0761 - val_acc: 0.9836
Epoch 00005: early stopping
	TRAINING TIME: 9.85 minutes 
==================================================================================================
## OAR [2019-07-03 15:35:43] Job 1988942 KILLED ##
