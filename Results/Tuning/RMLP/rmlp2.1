Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_acgcfm.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 10869/11441 Mb (0.950000) on cuda
Mapped name None to device cuda: Tesla K40m (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: RNN
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, bTokenNum, batchSize, denseDropout, denseUnitNum, earlyStop, focusedElements, gru, lr, posDim, posRnnUnitNum, rnnDropout, rnnSequence, s0TokenNum, s1TokenNum, shuffle, useB-1, useDense, wordDim, wordRnnUnitNum, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
rnn            ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,bTokenNum      ,
__________________________________________________________________________________________________
True           ,True           ,1              ,1              ,1              ,
__________________________________________________________________________________________________
batchSize      ,denseDropout   ,denseUnitNum   ,earlyStop      ,focusedElements,
__________________________________________________________________________________________________
64             ,0.3            ,28             ,True           ,7              ,
__________________________________________________________________________________________________
gru            ,lr             ,posDim         ,posRnnUnitNum  ,rnnDropout     ,
__________________________________________________________________________________________________
True           ,0.104          ,54             ,35             ,0.1            ,
__________________________________________________________________________________________________
rnnSequence    ,s0TokenNum     ,s1TokenNum     ,shuffle        ,useB-1         ,
__________________________________________________________________________________________________
False          ,4              ,2              ,False          ,0              ,
__________________________________________________________________________________________________
useDense       ,wordDim        ,wordRnnUnitNum ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
True           ,300            ,28             ,96             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,32             ,0.02           ,False          ,15             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.02           ,32             ,1              ,50             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.001          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
32             ,0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: rnn, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, True, 1, 1, 1, 64, 0.3, 28, True, 7, True, 0.104, 54, 35, 0.1, False, 4, 2, False, 0, True, 300, 28, 96, False, relu, 32, 0.02, False, 15, 0.02, 32, 1, 50, categorical_crossentropy, 0.001, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 6/8 (11h:13)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 7, 300)       1819500     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 7, 54)        1026        input_2[0][0]                    
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, 28)           27636       embedding_1[0][0]                
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, 35)           9450        embedding_2[0][0]                
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 28)           0           gru_1[0][0]                      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 35)           0           gru_2[0][0]                      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 63)           0           dropout_1[0][0]                  
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 28)           1792        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 28)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            116         dropout_3[0][0]                  
==================================================================================================
Total params: 1,859,520
Trainable params: 1,859,520
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
Train on 285187 samples, validate on 71297 samples
Epoch 1/15
 - 68s - loss: 0.1001 - acc: 0.9651 - val_loss: 0.2156 - val_acc: 0.9967
Epoch 2/15
 - 68s - loss: 0.0585 - acc: 0.9798 - val_loss: 0.2405 - val_acc: 0.9973
Epoch 3/15
 - 68s - loss: 0.0528 - acc: 0.9814 - val_loss: 0.2176 - val_acc: 0.9958
Epoch 4/15
 - 68s - loss: 0.0504 - acc: 0.9822 - val_loss: 0.2111 - val_acc: 0.9981
Epoch 5/15
 - 69s - loss: 0.0485 - acc: 0.9825 - val_loss: 0.2176 - val_acc: 0.9980
Epoch 00005: early stopping
	TRAINING TIME: 6.68 minutes 
==================================================================================================
	PARSING TIME: 3.63 minutes 
==================================================================================================
	Identification : 0.536
	P, R  : 0.497, 0.582

==================================================================================================
	XP Ends: 6/8 (11 h:24)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 6/8 (11h:24)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 7, 300)       1743000     input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 7, 54)        1026        input_4[0][0]                    
__________________________________________________________________________________________________
gru_3 (GRU)                     (None, 28)           27636       embedding_3[0][0]                
__________________________________________________________________________________________________
gru_4 (GRU)                     (None, 35)           9450        embedding_4[0][0]                
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 28)           0           gru_3[0][0]                      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 35)           0           gru_4[0][0]                      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 63)           0           dropout_4[0][0]                  
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 28)           1792        concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 28)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            116         dropout_6[0][0]                  
==================================================================================================
Total params: 1,783,020
Trainable params: 1,783,020
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
Train on 193094 samples, validate on 48274 samples
Epoch 1/15
 - 46s - loss: 0.1272 - acc: 0.9545 - val_loss: 0.2494 - val_acc: 0.9970
Epoch 2/15
 - 47s - loss: 0.0745 - acc: 0.9749 - val_loss: 0.2246 - val_acc: 0.9978
Epoch 3/15
 - 47s - loss: 0.0637 - acc: 0.9778 - val_loss: 0.2285 - val_acc: 0.9979
Epoch 4/15
 - 47s - loss: 0.0591 - acc: 0.9792 - val_loss: 0.1972 - val_acc: 0.9976
Epoch 5/15
 - 47s - loss: 0.0568 - acc: 0.9796 - val_loss: 0.1932 - val_acc: 0.9993
Epoch 00005: early stopping
	TRAINING TIME: 4.4 minutes 
==================================================================================================
	PARSING TIME: 5.5 minutes 
==================================================================================================
	Identification : 0.474
	P, R  : 0.369, 0.662

==================================================================================================
	XP Ends: 6/8 (11 h:34)
==================================================================================================
/home/halsaied/miniconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.py:399: UserWarning: The graph doesn't contain a node that depends on the root element.
  "The graph doesn't contain a node " "that depends on the root element."
# Seed: 0
==================================================================================================
XP Starts: 6/8 (11h:34)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 7, 300)       3263400     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 7, 54)        756         input_6[0][0]                    
__________________________________________________________________________________________________
gru_5 (GRU)                     (None, 28)           27636       embedding_5[0][0]                
__________________________________________________________________________________________________
gru_6 (GRU)                     (None, 35)           9450        embedding_6[0][0]                
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 28)           0           gru_5[0][0]                      
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 35)           0           gru_6[0][0]                      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 63)           0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 28)           1792        concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 28)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            116         dropout_9[0][0]                  
==================================================================================================
Total params: 3,303,150
Trainable params: 3,303,150
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
Train on 384396 samples, validate on 96100 samples
Epoch 1/15
 - 91s - loss: 0.1058 - acc: 0.9626 - val_loss: 0.2208 - val_acc: 0.9998
Epoch 2/15
 - 92s - loss: 0.0626 - acc: 0.9770 - val_loss: 0.1872 - val_acc: 0.9996
Epoch 3/15
 - 91s - loss: 0.0563 - acc: 0.9792 - val_loss: 0.1734 - val_acc: 0.9999
Epoch 4/15
 - 86s - loss: 0.0532 - acc: 0.9800 - val_loss: 0.2341 - val_acc: 0.9997
Epoch 5/15
 - 86s - loss: 0.0512 - acc: 0.9806 - val_loss: 0.1955 - val_acc: 1.0000
Epoch 00005: early stopping
	TRAINING TIME: 7.92 minutes 
==================================================================================================
	PARSING TIME: 2.35 minutes 
==================================================================================================
	Identification : 0.5
	P, R  : 0.46, 0.547

==================================================================================================
	XP Ends: 6/8 (11 h:45)
==================================================================================================
ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR:theano.gof.opt:Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: Elemwise{Cast{float32}}(TensorConstant{(1, 1) of ..8682955233})
ERROR:theano.gof.opt:node: Elemwise{Cast{float32}}(TensorConstant{(1, 1) of ..8682955233})
ERROR (theano.gof.opt): TRACEBACK:
ERROR:theano.gof.opt:TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpbgYdLX/key.pkl'

ERROR:theano.gof.opt:Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpbgYdLX/key.pkl'

ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR:theano.gof.opt:Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: Elemwise{Cast{float32}}(TensorConstant{(1, 1) of ..8682955233})
ERROR:theano.gof.opt:node: Elemwise{Cast{float32}}(TensorConstant{(1, 1) of ..8682955233})
ERROR (theano.gof.opt): TRACEBACK:
ERROR:theano.gof.opt:TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpbgYdLX/key.pkl'

ERROR:theano.gof.opt:Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpbgYdLX/key.pkl'

ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR:theano.gof.opt:Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: Elemwise{Cast{float32}}(TensorConstant{(1, 1) of ..8682955233})
ERROR:theano.gof.opt:node: Elemwise{Cast{float32}}(TensorConstant{(1, 1) of ..8682955233})
ERROR (theano.gof.opt): TRACEBACK:
ERROR:theano.gof.opt:TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 501, in add_key
    assert key not in self.keys
AssertionError

ERROR:theano.gof.opt:Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 501, in add_key
    assert key not in self.keys
AssertionError

	Mode: RNN
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, bTokenNum, batchSize, denseDropout, denseUnitNum, earlyStop, focusedElements, gru, lr, posDim, posRnnUnitNum, rnnDropout, rnnSequence, s0TokenNum, s1TokenNum, shuffle, useB-1, useDense, wordDim, wordRnnUnitNum, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
rnn            ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,bTokenNum      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,2              ,
__________________________________________________________________________________________________
batchSize      ,denseDropout   ,denseUnitNum   ,earlyStop      ,focusedElements,
__________________________________________________________________________________________________
64             ,0.2            ,16             ,True           ,7              ,
__________________________________________________________________________________________________
gru            ,lr             ,posDim         ,posRnnUnitNum  ,rnnDropout     ,
__________________________________________________________________________________________________
True           ,0.084          ,40             ,73             ,0.1            ,
__________________________________________________________________________________________________
rnnSequence    ,s0TokenNum     ,s1TokenNum     ,shuffle        ,useB-1         ,
__________________________________________________________________________________________________
False          ,4              ,2              ,False          ,0              ,
__________________________________________________________________________________________________
useDense       ,wordDim        ,wordRnnUnitNum ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
True           ,68             ,134            ,128            ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,32             ,0.02           ,False          ,15             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.02           ,32             ,1              ,50             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.01           ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
32             ,0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: rnn, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, True, False, True, True, False, 1, 1, 2, 64, 0.2, 16, True, 7, True, 0.084, 40, 73, 0.1, False, 4, 2, False, 0, True, 68, 134, 128, False, relu, 32, 0.02, False, 15, 0.02, 32, 1, 50, categorical_crossentropy, 0.01, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 6/8 (11h:45)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
Traceback (most recent call last):
  File "src/xpNonCompo.py", line 260, in <module>
    # configuration['tmp']['trainJointly'] = True
  File "/home/halsaied/NNIdenSys/src/rsg.py", line 27, in runRSGSpontaneously
    complentary=complentary, outputCupt=False)
  File "/home/halsaied/NNIdenSys/src/xpTools.py", line 26, in xp
    runXp(lang, mlpInLinear, linearInMlp, complentary, s, cuptTitle=title)
  File "/home/halsaied/NNIdenSys/src/xpTools.py", line 47, in runXp
    corpus = identify(lang)
  File "/home/halsaied/NNIdenSys/src/identification.py", line 29, in identify
    network, vectorizer = parseAndTrain(corpus)
  File "/home/halsaied/NNIdenSys/src/identification.py", line 257, in parseAndTrain
    network = modelRMLP.Network(corpus)
  File "/home/halsaied/NNIdenSys/src/modelRMLP.py", line 33, in __init__
    self.model = Network.build()
  File "/home/halsaied/NNIdenSys/src/modelRMLP.py", line 45, in build
    posRnn = GRU(rnnConf['posRnnUnitNum'], return_sequences=rnnConf['rnnSequence'])(posEmb)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/layers/recurrent.py", line 500, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/engine/topology.py", line 592, in __call__
    self.build(input_shapes[0])
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/layers/recurrent.py", line 461, in build
    self.cell.build(step_input_shape)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/layers/recurrent.py", line 1224, in build
    constraint=self.kernel_constraint)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/engine/topology.py", line 416, in add_weight
    constraint=constraint)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 150, in variable
    value = value.eval()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/graph.py", line 522, in eval
    self._fn_cache[inputs] = theano.function(inputs, self)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function.py", line 317, in function
    output_keys=output_keys)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 1839, in orig_function
    name=name)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 99, in __call__
    return self.optimize(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 88, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 242, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 88, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2525, in apply
    sub_prof = gopt.apply(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2128, in apply
    nb += self.process_node(fgraph, node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2024, in process_node
    lopt, node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 1918, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 1904, in warn
    raise exc
AssertionError
