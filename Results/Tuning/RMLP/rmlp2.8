Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_ztw2W6.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 3841/4043 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX 980 (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: RNN
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, bTokenNum, batchSize, denseDropout, denseUnitNum, earlyStop, focusedElements, gru, lr, posDim, posRnnUnitNum, rnnDropout, rnnSequence, s0TokenNum, s1TokenNum, shuffle, useB-1, useDense, wordDim, wordRnnUnitNum, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
rnn            ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,True           ,True           ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,bTokenNum      ,
__________________________________________________________________________________________________
True           ,True           ,1              ,1              ,1              ,
__________________________________________________________________________________________________
batchSize      ,denseDropout   ,denseUnitNum   ,earlyStop      ,focusedElements,
__________________________________________________________________________________________________
64             ,0.1            ,22             ,True           ,7              ,
__________________________________________________________________________________________________
gru            ,lr             ,posDim         ,posRnnUnitNum  ,rnnDropout     ,
__________________________________________________________________________________________________
True           ,0.106          ,61             ,56             ,0.2            ,
__________________________________________________________________________________________________
rnnSequence    ,s0TokenNum     ,s1TokenNum     ,shuffle        ,useB-1         ,
__________________________________________________________________________________________________
False          ,4              ,2              ,False          ,0              ,
__________________________________________________________________________________________________
useDense       ,wordDim        ,wordRnnUnitNum ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
True           ,300            ,57             ,256            ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,32             ,0.02           ,False          ,15             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.02           ,32             ,1              ,50             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.018          ,val_acc        ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
32             ,0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: rnn, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, True, True, False, False, True, True, 1, 1, 1, 64, 0.1, 22, True, 7, True, 0.106, 61, 56, 0.2, False, 4, 2, False, 0, True, 300, 57, 256, False, relu, 32, 0.02, False, 15, 0.02, 32, 1, 50, categorical_crossentropy, 0.018, val_acc, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 6/8 (11h:16)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 7, 300)       150900      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 7, 61)        1159        input_2[0][0]                    
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, 57)           61218       embedding_1[0][0]                
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, 56)           19824       embedding_2[0][0]                
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 57)           0           gru_1[0][0]                      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 56)           0           gru_2[0][0]                      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 113)          0           dropout_1[0][0]                  
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 22)           2508        concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 22)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            92          dropout_3[0][0]                  
==================================================================================================
Total params: 235,701
Trainable params: 235,701
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
Train on 285187 samples, validate on 71297 samples
Epoch 1/15
 - 24s - loss: 0.1144 - acc: 0.9639 - val_loss: 0.1329 - val_acc: 0.9951
Epoch 2/15
 - 24s - loss: 0.0767 - acc: 0.9742 - val_loss: 0.1639 - val_acc: 0.9945
Epoch 3/15
 - 24s - loss: 0.0734 - acc: 0.9750 - val_loss: 0.1626 - val_acc: 0.9931
Epoch 4/15
 - 24s - loss: 0.0711 - acc: 0.9757 - val_loss: 0.1651 - val_acc: 0.9967
Epoch 5/15
 - 24s - loss: 0.0699 - acc: 0.9759 - val_loss: 0.2376 - val_acc: 0.9965
Epoch 6/15
 - 24s - loss: 0.0686 - acc: 0.9762 - val_loss: 0.2075 - val_acc: 0.9973
Epoch 7/15
 - 24s - loss: 0.0684 - acc: 0.9762 - val_loss: 0.2038 - val_acc: 0.9983
Epoch 8/15
 - 24s - loss: 0.0673 - acc: 0.9765 - val_loss: 0.2165 - val_acc: 0.9970
Epoch 9/15
 - 24s - loss: 0.0668 - acc: 0.9767 - val_loss: 0.2244 - val_acc: 0.9966
Epoch 10/15
 - 24s - loss: 0.0665 - acc: 0.9767 - val_loss: 0.2072 - val_acc: 0.9983
Epoch 11/15
 - 25s - loss: 0.0662 - acc: 0.9768 - val_loss: 0.1946 - val_acc: 0.9983
Epoch 12/15
 - 24s - loss: 0.0658 - acc: 0.9770 - val_loss: 0.3925 - val_acc: 0.9949
Epoch 13/15
 - 24s - loss: 0.0655 - acc: 0.9770 - val_loss: 0.4292 - val_acc: 0.9980
Epoch 14/15
 - 24s - loss: 0.0655 - acc: 0.9768 - val_loss: 0.2131 - val_acc: 0.9980
Epoch 15/15
 - 24s - loss: 0.0650 - acc: 0.9771 - val_loss: 0.2044 - val_acc: 0.9964
	TRAINING TIME: 7.07 minutes 
==================================================================================================
	PARSING TIME: 1.8 minutes 
==================================================================================================
	Identification : 0.452
	P, R  : 0.442, 0.463

==================================================================================================
	XP Ends: 6/8 (11 h:25)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 6/8 (11h:25)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 7, 300)       285900      input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 7, 61)        1159        input_4[0][0]                    
__________________________________________________________________________________________________
gru_3 (GRU)                     (None, 57)           61218       embedding_3[0][0]                
__________________________________________________________________________________________________
gru_4 (GRU)                     (None, 56)           19824       embedding_4[0][0]                
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 57)           0           gru_3[0][0]                      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 56)           0           gru_4[0][0]                      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 113)          0           dropout_4[0][0]                  
                                                                 dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 22)           2508        concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 22)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            92          dropout_6[0][0]                  
==================================================================================================
Total params: 370,701
Trainable params: 370,701
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
Train on 193094 samples, validate on 48274 samples
Epoch 1/15
 - 16s - loss: 0.1757 - acc: 0.9377 - val_loss: 0.2288 - val_acc: 0.9952
Epoch 2/15
 - 16s - loss: 0.0942 - acc: 0.9663 - val_loss: 0.2123 - val_acc: 0.9919
Epoch 3/15
 - 16s - loss: 0.0843 - acc: 0.9698 - val_loss: 0.2365 - val_acc: 0.9978
Epoch 4/15
 - 17s - loss: 0.0793 - acc: 0.9716 - val_loss: 0.2165 - val_acc: 0.9952
Epoch 5/15
 - 17s - loss: 0.0768 - acc: 0.9719 - val_loss: 0.2003 - val_acc: 0.9978
Epoch 6/15
 - 17s - loss: 0.0745 - acc: 0.9725 - val_loss: 0.1764 - val_acc: 0.9974
Epoch 7/15
 - 17s - loss: 0.0729 - acc: 0.9727 - val_loss: 0.2012 - val_acc: 0.9978
Epoch 8/15
 - 17s - loss: 0.0717 - acc: 0.9731 - val_loss: 0.2045 - val_acc: 0.9988
Epoch 9/15
 - 16s - loss: 0.0707 - acc: 0.9732 - val_loss: 0.2093 - val_acc: 0.9976
Epoch 10/15
 - 17s - loss: 0.0698 - acc: 0.9736 - val_loss: 0.2358 - val_acc: 0.9985
Epoch 11/15
 - 17s - loss: 0.0694 - acc: 0.9737 - val_loss: 0.2062 - val_acc: 0.9993
Epoch 12/15
 - 17s - loss: 0.0689 - acc: 0.9738 - val_loss: 0.2335 - val_acc: 0.9988
Epoch 13/15
 - 17s - loss: 0.0681 - acc: 0.9740 - val_loss: 0.2050 - val_acc: 0.9985
Epoch 14/15
 - 17s - loss: 0.0675 - acc: 0.9741 - val_loss: 0.1820 - val_acc: 0.9985
Epoch 15/15
 - 17s - loss: 0.0670 - acc: 0.9742 - val_loss: 0.2323 - val_acc: 0.9988
	TRAINING TIME: 4.38 minutes 
==================================================================================================
	PARSING TIME: 2.73 minutes 
==================================================================================================
	Identification : 0.336
	P, R  : 0.242, 0.548

==================================================================================================
	XP Ends: 6/8 (11 h:32)
==================================================================================================
/home/halsaied/miniconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.py:399: UserWarning: The graph doesn't contain a node that depends on the root element.
  "The graph doesn't contain a node " "that depends on the root element."
# Seed: 0
==================================================================================================
XP Starts: 6/8 (11h:32)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 7)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 7, 300)       583500      input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 7, 61)        854         input_6[0][0]                    
__________________________________________________________________________________________________
gru_5 (GRU)                     (None, 57)           61218       embedding_5[0][0]                
__________________________________________________________________________________________________
gru_6 (GRU)                     (None, 56)           19824       embedding_6[0][0]                
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 57)           0           gru_5[0][0]                      
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 56)           0           gru_6[0][0]                      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 113)          0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 22)           2508        concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 22)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            92          dropout_9[0][0]                  
==================================================================================================
Total params: 667,996
Trainable params: 667,996
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
Train on 384396 samples, validate on 96100 samples
Epoch 1/15
 - 33s - loss: 0.1297 - acc: 0.9540 - val_loss: 0.1554 - val_acc: 1.0000
Epoch 2/15
 - 33s - loss: 0.0771 - acc: 0.9735 - val_loss: 0.2739 - val_acc: 0.9985
Epoch 3/15
 - 33s - loss: 0.0692 - acc: 0.9763 - val_loss: 0.1910 - val_acc: 0.9993
Epoch 4/15
 - 33s - loss: 0.0657 - acc: 0.9774 - val_loss: 0.1745 - val_acc: 0.9996
Epoch 5/15
 - 33s - loss: 0.0636 - acc: 0.9780 - val_loss: 0.2596 - val_acc: 0.9990
Epoch 6/15
 - 33s - loss: 0.0621 - acc: 0.9785 - val_loss: 0.2964 - val_acc: 0.9988
Epoch 7/15
 - 33s - loss: 0.0614 - acc: 0.9787 - val_loss: 0.2426 - val_acc: 0.9994
Epoch 8/15
 - 33s - loss: 0.0608 - acc: 0.9789 - val_loss: 0.2203 - val_acc: 0.9993
Epoch 9/15
 - 33s - loss: 0.0603 - acc: 0.9790 - val_loss: 0.1750 - val_acc: 0.9994
Epoch 10/15
 - 33s - loss: 0.0599 - acc: 0.9791 - val_loss: 0.2121 - val_acc: 0.9993
Epoch 11/15
 - 33s - loss: 0.0595 - acc: 0.9792 - val_loss: 0.2633 - val_acc: 0.9996
Epoch 12/15
 - 33s - loss: 0.0593 - acc: 0.9792 - val_loss: 0.1991 - val_acc: 0.9994
Epoch 13/15
 - 33s - loss: 0.0594 - acc: 0.9792 - val_loss: 0.2201 - val_acc: 0.9998
Epoch 14/15
 - 33s - loss: 0.0588 - acc: 0.9793 - val_loss: 0.2227 - val_acc: 0.9995
Epoch 15/15
 - 33s - loss: 0.0588 - acc: 0.9793 - val_loss: 0.2141 - val_acc: 0.9994
	TRAINING TIME: 8.55 minutes 
==================================================================================================
	PARSING TIME: 1.13 minutes 
==================================================================================================
	Identification : 0.42
	P, R  : 0.423, 0.418

==================================================================================================
	XP Ends: 6/8 (11 h:42)
==================================================================================================
	Mode: RNN
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, bTokenNum, batchSize, denseDropout, denseUnitNum, earlyStop, focusedElements, gru, lr, posDim, posRnnUnitNum, rnnDropout, rnnSequence, s0TokenNum, s1TokenNum, shuffle, useB-1, useDense, wordDim, wordRnnUnitNum, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
rnn            ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,bTokenNum      ,
__________________________________________________________________________________________________
True           ,True           ,1              ,1              ,2              ,
__________________________________________________________________________________________________
batchSize      ,denseDropout   ,denseUnitNum   ,earlyStop      ,focusedElements,
__________________________________________________________________________________________________
64             ,0.1            ,114            ,True           ,7              ,
__________________________________________________________________________________________________
gru            ,lr             ,posDim         ,posRnnUnitNum  ,rnnDropout     ,
__________________________________________________________________________________________________
True           ,0.154          ,25             ,48             ,0.1            ,
__________________________________________________________________________________________________
rnnSequence    ,s0TokenNum     ,s1TokenNum     ,shuffle        ,useB-1         ,
__________________________________________________________________________________________________
True           ,4              ,2              ,False          ,1              ,
__________________________________________________________________________________________________
useDense       ,wordDim        ,wordRnnUnitNum ,batchSize      ,checkPoint     ,
__________________________________________________________________________________________________
True           ,300            ,28             ,96             ,False          ,
__________________________________________________________________________________________________
dense1Activatio,depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,
__________________________________________________________________________________________________
relu           ,32             ,0.02           ,True           ,15             ,
__________________________________________________________________________________________________
idenLR         ,identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,
__________________________________________________________________________________________________
0.02           ,32             ,1              ,50             ,categorical_crossentropy,
__________________________________________________________________________________________________
minDelta       ,monitor        ,optimizer      ,patience       ,predictVerbose ,
__________________________________________________________________________________________________
0.021          ,val_loss       ,adagrad        ,4              ,False          ,
__________________________________________________________________________________________________
taggingBatchSiz,taggingLR      ,validationSplit,
__________________________________________________________________________________________________
32             ,0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: rnn, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, True, True, False, True, True, True, 1, 1, 2, 64, 0.1, 114, True, 7, True, 0.154, 25, 48, 0.1, True, 4, 2, False, 1, True, 300, 28, 96, False, relu, 32, 0.02, True, 15, 0.02, 32, 1, 50, categorical_crossentropy, 0.021, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 6/8 (11h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
Traceback (most recent call last):
  File "src/xpNonCompo.py", line 260, in <module>
    # configuration['tmp']['trainJointly'] = True
  File "/home/halsaied/NNIdenSys/src/rsg.py", line 27, in runRSGSpontaneously
    complentary=complentary, outputCupt=False)
  File "/home/halsaied/NNIdenSys/src/xpTools.py", line 26, in xp
    runXp(lang, mlpInLinear, linearInMlp, complentary, s, cuptTitle=title)
  File "/home/halsaied/NNIdenSys/src/xpTools.py", line 47, in runXp
    corpus = identify(lang)
  File "/home/halsaied/NNIdenSys/src/identification.py", line 29, in identify
    network, vectorizer = parseAndTrain(corpus)
  File "/home/halsaied/NNIdenSys/src/identification.py", line 257, in parseAndTrain
    network = modelRMLP.Network(corpus)
  File "/home/halsaied/NNIdenSys/src/modelRMLP.py", line 33, in __init__
    self.model = Network.build()
  File "/home/halsaied/NNIdenSys/src/modelRMLP.py", line 45, in build
    posRnn = GRU(rnnConf['posRnnUnitNum'], return_sequences=rnnConf['rnnSequence'])(posEmb)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/layers/recurrent.py", line 500, in __call__
    return super(RNN, self).__call__(inputs, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/engine/topology.py", line 592, in __call__
    self.build(input_shapes[0])
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/layers/recurrent.py", line 461, in build
    self.cell.build(step_input_shape)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/layers/recurrent.py", line 1224, in build
    constraint=self.kernel_constraint)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/engine/topology.py", line 416, in add_weight
    constraint=constraint)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 150, in variable
    value = value.eval()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/graph.py", line 522, in eval
    self._fn_cache[inputs] = theano.function(inputs, self)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function.py", line 317, in function
    output_keys=output_keys)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 1841, in orig_function
    fn = m.create(defaults)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 1715, in create
    input_storage=input_storage_lists, storage_map=storage_map)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/link.py", line 699, in make_thunk
    storage_map=storage_map)[:3]
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/vm.py", line 1084, in make_all
    impl=impl))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpHo6qkO/key.pkl'
