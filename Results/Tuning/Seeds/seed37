Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_5FHWnp.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 10619/11178 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: NON.COMPO
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, lemma, compactVocab, favorisationCoeff, focused, importantSentences, importantTransitions, overSampling, sampleWeight, bPadding, batchSize, checkPoint, compactVocab, dense1, dense1Activation, dense1Dropout, dense1UnitNumber, dense2, dense2Activation, dense2Dropout, dense2UnitNumber, earlyStop, epochs, features, initialize, inputItems, lemma, loss, lr, lrPatience, minDelta, optimizer, posEmb, predictVerbose, s0Padding, s1Padding, tokenEmb, trainable, validationSplit, verbose
==================================================================================================
# Configs: NonCompo, sharedtask2, fixedSize, True, False, 4, True, True, False, True, True, 2, 48, False, False, True, relu, 0.3, 217, False, relu, 0, 0, True, 40, False, False, 4, True, categorical_crossentropy, 0.124, 4, 0.2, adagrad, 62, False, 5, 5, 202, True, 0.1, 0
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 20/1 (6 h:12)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545
# Parameters = 1763755
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 202)       1524090     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 62)        9424        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 808)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 248)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1056)         0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 217)          229369      concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 217)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            872         dropout_1[0][0]                  
==================================================================================================
Total params: 1,763,755
Trainable params: 1,763,755
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 197745
	data size after focused sampling = 197745
	data size before sampling = 197745
	data size after sampling = 379340
	4 Labels in train : Counter({0: 94835, 1: 94835, 2: 94835, 3: 94835})
	4 Labels in valid : Counter({0: 9529, 2: 9512, 1: 9459, 3: 9434})
	Favorisation Coeff : 4

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.124
__________________________________________________________________________________________________
Train on 341406 samples, validate on 37934 samples
Epoch 1/40
 - 11s - loss: 6.2461 - acc: 0.7908 - val_loss: 0.0852 - val_acc: 0.9838
Epoch 2/40
 - 11s - loss: 0.0784 - acc: 0.9846 - val_loss: 0.0728 - val_acc: 0.9858
Epoch 3/40
 - 11s - loss: 0.0691 - acc: 0.9863 - val_loss: 0.0721 - val_acc: 0.9862
Epoch 4/40
 - 11s - loss: 0.0659 - acc: 0.9870 - val_loss: 0.0728 - val_acc: 0.9863
Epoch 5/40
 - 11s - loss: 0.0644 - acc: 0.9874 - val_loss: 0.0732 - val_acc: 0.9859

==================================================================================================
	Training time : 0:01:27.803355
==================================================================================================

==================================================================================================
	Parsing time : 0:00:30.695522
==================================================================================================
	Identification : 0.597
	P, R  : 0.675, 0.534

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Cupt files starting with : 20.01.fixedsize.BG were created!XP Ends: 20/1 (6 h:14)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 20/1 (6 h:14)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7541
# Parameters = 1762947
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 202)       1523282     input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 62)        9424        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 808)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 248)          0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 1056)         0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 217)          229369      concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 217)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            872         dropout_2[0][0]                  
==================================================================================================
Total params: 1,762,947
Trainable params: 1,762,947
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 197745
	data size after focused sampling = 197745
	data size before sampling = 197745
	data size after sampling = 379340
	4 Labels in train : Counter({0: 94835, 1: 94835, 2: 94835, 3: 94835})
	4 Labels in valid : Counter({3: 9580, 1: 9544, 0: 9532, 2: 9278})
	Favorisation Coeff : 4

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.124
__________________________________________________________________________________________________
Train on 341406 samples, validate on 37934 samples
Epoch 1/40
 - 11s - loss: 5.0719 - acc: 0.6890 - val_loss: 4.3640 - val_acc: 0.7331
Epoch 2/40
 - 11s - loss: 4.3349 - acc: 0.7349 - val_loss: 4.3624 - val_acc: 0.7332
Epoch 3/40
 - 11s - loss: 4.3330 - acc: 0.7349 - val_loss: 4.3617 - val_acc: 0.7332
Epoch 4/40
 - 11s - loss: 4.3331 - acc: 0.7349 - val_loss: 4.3612 - val_acc: 0.7333
Epoch 5/40
 - 11s - loss: 4.3328 - acc: 0.7350 - val_loss: 4.3578 - val_acc: 0.7335

==================================================================================================
	Training time : 0:01:11.257990
==================================================================================================

==================================================================================================
	Parsing time : 0:00:26.690320
==================================================================================================
	Identification : 0

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Cupt files starting with : 20.01.fixedsize.BG were created!INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '6045')
XP Ends: 20/1 (6 h:16)
==================================================================================================
# Seed: 2
==================================================================================================
XP Starts: 20/1 (6 h:16)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7537
# Parameters = 1762139
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 202)       1522474     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 62)        9424        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 808)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 248)          0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 1056)         0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 217)          229369      concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 217)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            872         dropout_3[0][0]                  
==================================================================================================
Total params: 1,762,139
Trainable params: 1,762,139
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 197745
	data size after focused sampling = 197745
	data size before sampling = 197745
	data size after sampling = 379340
	4 Labels in train : Counter({0: 94835, 1: 94835, 2: 94835, 3: 94835})
	4 Labels in valid : Counter({3: 9510, 1: 9477, 2: 9476, 0: 9471})
	Favorisation Coeff : 4

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.124
__________________________________________________________________________________________________
Train on 341406 samples, validate on 37934 samples
Epoch 1/40
 - 11s - loss: 0.1848 - acc: 0.9752 - val_loss: 0.1052 - val_acc: 0.9831
Epoch 2/40
 - 11s - loss: 0.0879 - acc: 0.9842 - val_loss: 0.0723 - val_acc: 0.9861
Epoch 3/40
 - 11s - loss: 0.0690 - acc: 0.9865 - val_loss: 0.0724 - val_acc: 0.9862
Epoch 4/40
 - 11s - loss: 0.0658 - acc: 0.9871 - val_loss: 0.0718 - val_acc: 0.9867
Epoch 5/40
 - 11s - loss: 0.0639 - acc: 0.9875 - val_loss: 0.0746 - val_acc: 0.9862

==================================================================================================
	Training time : 0:01:28.758980
==================================================================================================

==================================================================================================
	Parsing time : 0:00:27.730054
==================================================================================================
	Identification : 0.607
	P, R  : 0.672, 0.554

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Cupt files starting with : 20.01.fixedsize.BG were created!XP Ends: 20/1 (6 h:19)
==================================================================================================
# Seed: 3
==================================================================================================
XP Starts: 20/1 (6 h:19)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7492
# Parameters = 1753049
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 202)       1513384     input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 62)        9424        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 808)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 248)          0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 1056)         0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 217)          229369      concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 217)          0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4)            872         dropout_4[0][0]                  
==================================================================================================
Total params: 1,753,049
Trainable params: 1,753,049
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 197745
	data size after focused sampling = 197745
	data size before sampling = 197745
	data size after sampling = 379340
	4 Labels in train : Counter({0: 94835, 1: 94835, 2: 94835, 3: 94835})
	4 Labels in valid : Counter({3: 9616, 0: 9500, 2: 9410, 1: 9408})
	Favorisation Coeff : 4

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.124
__________________________________________________________________________________________________
Train on 341406 samples, validate on 37934 samples
Epoch 1/40
 - 11s - loss: 0.2218 - acc: 0.9740 - val_loss: 0.0835 - val_acc: 0.9834
Epoch 2/40
 - 11s - loss: 0.0762 - acc: 0.9851 - val_loss: 0.0743 - val_acc: 0.9849
Epoch 3/40
 - 11s - loss: 0.0674 - acc: 0.9865 - val_loss: 0.0737 - val_acc: 0.9854
Epoch 4/40
 - 11s - loss: 0.0647 - acc: 0.9872 - val_loss: 0.0794 - val_acc: 0.9858
Epoch 5/40
 - 11s - loss: 0.0632 - acc: 0.9876 - val_loss: 0.0767 - val_acc: 0.9859

==================================================================================================
	Training time : 0:01:08.884652
==================================================================================================

==================================================================================================
	Parsing time : 0:00:28.746697
==================================================================================================
	Identification : 0.618
	P, R  : 0.735, 0.533

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Cupt files starting with : 20.01.fixedsize.BG were created!XP Ends: 20/1 (6 h:21)
==================================================================================================
# Seed: 4
==================================================================================================
XP Starts: 20/1 (6 h:21)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7517
# Parameters = 1758099
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 202)       1518434     input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 62)        9424        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 808)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 248)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 1056)         0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 217)          229369      concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 217)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 4)            872         dropout_5[0][0]                  
==================================================================================================
Total params: 1,758,099
Trainable params: 1,758,099
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 197745
	data size after focused sampling = 197745
	data size before sampling = 197745
	data size after sampling = 379340
	4 Labels in train : Counter({0: 94835, 1: 94835, 2: 94835, 3: 94835})
	4 Labels in valid : Counter({0: 9732, 3: 9526, 1: 9355, 2: 9321})
	Favorisation Coeff : 4

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.124
__________________________________________________________________________________________________
Train on 341406 samples, validate on 37934 samples
Epoch 1/40
 - 11s - loss: 19.8959 - acc: 0.5150 - val_loss: 16.7272 - val_acc: 0.7156
Epoch 2/40
 - 11s - loss: 10.7371 - acc: 0.8096 - val_loss: 0.1551 - val_acc: 0.9766
Epoch 3/40
 - 10s - loss: 0.1371 - acc: 0.9801 - val_loss: 0.1370 - val_acc: 0.9807
Epoch 4/40
 - 10s - loss: 0.1264 - acc: 0.9826 - val_loss: 0.1357 - val_acc: 0.9819
Epoch 5/40
 - 10s - loss: 0.1236 - acc: 0.9833 - val_loss: 0.1372 - val_acc: 0.9822
Epoch 6/40
 - 10s - loss: 0.1221 - acc: 0.9838 - val_loss: 0.1382 - val_acc: 0.9823

==================================================================================================
	Training time : 0:01:19.518992
==================================================================================================

==================================================================================================
	Parsing time : 0:00:26.270242
==================================================================================================
	Identification : 0.488
	P, R  : 0.493, 0.482

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Cupt files starting with : 20.01.fixedsize.BG were created!XP Ends: 20/1 (6 h:23)
==================================================================================================
# Seed: 5
==================================================================================================
XP Starts: 20/1 (6 h:23)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7494
# Parameters = 1753453
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 202)       1513788     input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 62)        9424        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 808)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 248)          0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 1056)         0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 217)          229369      concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 217)          0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 4)            872         dropout_6[0][0]                  
==================================================================================================
Total params: 1,753,453
Trainable params: 1,753,453
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 197745
	data size after focused sampling = 197745
	data size before sampling = 197745
	data size after sampling = 379340
	4 Labels in train : Counter({0: 94835, 1: 94835, 2: 94835, 3: 94835})
	4 Labels in valid : Counter({3: 9502, 2: 9494, 1: 9493, 0: 9445})
	Favorisation Coeff : 4

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.124
__________________________________________________________________________________________________
Train on 341406 samples, validate on 37934 samples
Epoch 1/40
 - 11s - loss: 1.4285 - acc: 0.9398 - val_loss: 0.2379 - val_acc: 0.9806
Epoch 2/40
 - 11s - loss: 0.1407 - acc: 0.9820 - val_loss: 0.0940 - val_acc: 0.9845
Epoch 3/40
 - 11s - loss: 0.0868 - acc: 0.9854 - val_loss: 0.0767 - val_acc: 0.9861
Epoch 4/40
 - 11s - loss: 0.0687 - acc: 0.9867 - val_loss: 0.0734 - val_acc: 0.9858
Epoch 5/40
 - 11s - loss: 0.0648 - acc: 0.9872 - val_loss: 0.0729 - val_acc: 0.9863

==================================================================================================
	Training time : 0:01:08.629287
==================================================================================================

==================================================================================================
	Parsing time : 0:00:28.597225
==================================================================================================
	Identification : 0.591
	P, R  : 0.635, 0.552

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Cupt files starting with : 20.01.fixedsize.BG were created!XP Ends: 20/1 (6 h:25)
==================================================================================================
# Seed: 6
==================================================================================================
XP Starts: 20/1 (6 h:25)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7528
# Parameters = 1760321
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 202)       1520656     input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 62)        9424        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 808)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 248)          0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 1056)         0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 217)          229369      concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 217)          0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 4)            872         dropout_7[0][0]                  
==================================================================================================
Total params: 1,760,321
Trainable params: 1,760,321
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 197745
	data size after focused sampling = 197745
	data size before sampling = 197745
	data size after sampling = 379340
	4 Labels in train : Counter({0: 94835, 1: 94835, 2: 94835, 3: 94835})
	4 Labels in valid : Counter({1: 9598, 2: 9479, 0: 9464, 3: 9393})
	Favorisation Coeff : 4

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.124
__________________________________________________________________________________________________
Train on 341406 samples, validate on 37934 samples
Epoch 1/40
 - 11s - loss: 1.5575 - acc: 0.9334 - val_loss: 0.1170 - val_acc: 0.9814
Epoch 2/40
 - 11s - loss: 0.0957 - acc: 0.9837 - val_loss: 0.0808 - val_acc: 0.9847
Epoch 3/40
 - 11s - loss: 0.0727 - acc: 0.9860 - val_loss: 0.0742 - val_acc: 0.9851
Epoch 4/40
 - 11s - loss: 0.0674 - acc: 0.9869 - val_loss: 0.0760 - val_acc: 0.9855
Epoch 5/40
 - 11s - loss: 0.0654 - acc: 0.9872 - val_loss: 0.0737 - val_acc: 0.9859

==================================================================================================
	Training time : 0:01:08.872242
==================================================================================================

==================================================================================================
	Parsing time : 0:00:28.557800
==================================================================================================
	Identification : 0.596
	P, R  : 0.677, 0.533

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Cupt files starting with : 20.01.fixedsize.BG were created!XP Ends: 20/1 (6 h:26)
==================================================================================================
# Seed: 7
==================================================================================================
XP Starts: 20/1 (6 h:26)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7467
# Parameters = 1747999
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 202)       1508334     input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 62)        9424        input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 808)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 248)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 1056)         0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 217)          229369      concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 217)          0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 4)            872         dropout_8[0][0]                  
==================================================================================================
Total params: 1,747,999
Trainable params: 1,747,999
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 197745
	data size after focused sampling = 197745
	data size before sampling = 197745
	data size after sampling = 379340
	4 Labels in train : Counter({0: 94835, 1: 94835, 2: 94835, 3: 94835})
	4 Labels in valid : Counter({0: 9576, 2: 9560, 1: 9421, 3: 9377})
	Favorisation Coeff : 4

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.124
__________________________________________________________________________________________________
Train on 341406 samples, validate on 37934 samples
Epoch 1/40
 - 11s - loss: 8.0705 - acc: 0.4998 - val_loss: 8.0752 - val_acc: 0.4992
Epoch 2/40
 - 11s - loss: 8.0663 - acc: 0.5000 - val_loss: 8.0752 - val_acc: 0.4992
Epoch 3/40
 - 11s - loss: 8.0663 - acc: 0.5000 - val_loss: 8.0752 - val_acc: 0.4992
Epoch 4/40
 - 11s - loss: 8.0663 - acc: 0.5000 - val_loss: 8.0752 - val_acc: 0.4992
Epoch 5/40
 - 11s - loss: 8.0663 - acc: 0.5000 - val_loss: 8.0752 - val_acc: 0.4992

==================================================================================================
	Training time : 0:01:10.225350
==================================================================================================
NNIdenSys/Scripts/nonCompo.sh: line 4:  6045 Killed                  env MKL_THREADING_LAYER=GNU python src/xpNonCompo.py
