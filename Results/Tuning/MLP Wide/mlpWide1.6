Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_47ghiK.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 10869/11441 Mb (0.950000) on cuda
Mapped name None to device cuda: Tesla K40m (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: MLPWIDE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpWide        ,sharedtask2    ,fixedSize      ,11             ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,20             ,True           ,True           ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
False          ,True           ,1              ,1              ,128            ,
__________________________________________________________________________________________________
dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,posWindow      ,
__________________________________________________________________________________________________
0.5            ,141            ,0.095          ,38             ,1              ,
__________________________________________________________________________________________________
tokenEmb       ,trainable      ,
__________________________________________________________________________________________________
300            ,True           ,
__________________________________________________________________________________________________
# Configs: mlpWide, sharedtask2, fixedSize, 11, False, True, False, 20, True, True, True, False, False, False, True, False, True, 1, 1, 128, 0.5, 141, 0.095, 38, 1, 300, True
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 5/7 (10h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 9312
# Parameters = 3199115
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 35)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 5, 300)       2793600     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 35, 38)       5776        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1500)         0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 1330)         0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 2830)         0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 141)          399171      concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 141)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            568         dropout_1[0][0]                  
==================================================================================================
Total params: 3,199,115
Trainable params: 3,199,115
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18089, 2: 17772, 3: 17743, 1: 17693})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.095
__________________________________________________________________________________________________
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 7s - loss: 0.4696 - acc: 0.9562 - val_loss: 0.0630 - val_acc: 0.9839
Epoch 2/40
 - 8s - loss: 0.0609 - acc: 0.9847 - val_loss: 0.0578 - val_acc: 0.9853
Epoch 3/40
 - 8s - loss: 0.0539 - acc: 0.9865 - val_loss: 0.0601 - val_acc: 0.9855
Epoch 4/40
 - 8s - loss: 0.0512 - acc: 0.9872 - val_loss: 0.0606 - val_acc: 0.9856
Epoch 5/40
 - 8s - loss: 0.0498 - acc: 0.9877 - val_loss: 0.0611 - val_acc: 0.9856
Epoch 00005: early stopping
	TRAINING TIME: 1.9 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.707, 0.51

==================================================================================================
	XP Ends: 5/7 (11 h:2)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 5/7 (11h:2)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9194
	After : 9194
# Parameters = 3164361
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 35)           0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 5, 300)       2758200     input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 35, 38)       6422        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 1500)         0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 1330)         0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 2830)         0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 141)          399171      concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 141)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            568         dropout_2[0][0]                  
==================================================================================================
Total params: 3,164,361
Trainable params: 3,164,361
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12122, 3: 12071, 1: 12046, 2: 12035})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.095
__________________________________________________________________________________________________
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 5s - loss: 0.4170 - acc: 0.9534 - val_loss: 0.0695 - val_acc: 0.9818
Epoch 2/40
 - 5s - loss: 0.0649 - acc: 0.9834 - val_loss: 0.0668 - val_acc: 0.9831
Epoch 3/40
 - 5s - loss: 0.0564 - acc: 0.9857 - val_loss: 0.0672 - val_acc: 0.9832
Epoch 4/40
 - 5s - loss: 0.0531 - acc: 0.9867 - val_loss: 0.0693 - val_acc: 0.9835
Epoch 5/40
 - 5s - loss: 0.0511 - acc: 0.9871 - val_loss: 0.0742 - val_acc: 0.9839
Epoch 00005: early stopping
	TRAINING TIME: 0.77 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.532
	P, R  : 0.462, 0.626

==================================================================================================
	XP Ends: 5/7 (11 h:4)
==================================================================================================
/home/halsaied/miniconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.py:399: UserWarning: The graph doesn't contain a node that depends on the root element.
  "The graph doesn't contain a node " "that depends on the root element."
# Seed: 0
==================================================================================================
XP Starts: 5/7 (11h:4)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 17288
	After : 17288
# Parameters = 5590281
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 35)           0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 5, 300)       5186400     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 35, 38)       4142        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 1500)         0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 1330)         0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 2830)         0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 141)          399171      concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 141)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            568         dropout_3[0][0]                  
==================================================================================================
Total params: 5,590,281
Trainable params: 5,590,281
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({1: 24187, 2: 24000, 0: 23959, 3: 23954})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.095
__________________________________________________________________________________________________
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 11s - loss: 0.1610 - acc: 0.9729 - val_loss: 0.0783 - val_acc: 0.9828
Epoch 2/40
 - 11s - loss: 0.0583 - acc: 0.9847 - val_loss: 0.0618 - val_acc: 0.9840
Epoch 3/40
 - 11s - loss: 0.0532 - acc: 0.9862 - val_loss: 0.0644 - val_acc: 0.9834
Epoch 4/40
 - 11s - loss: 0.0511 - acc: 0.9869 - val_loss: 0.0669 - val_acc: 0.9834
Epoch 5/40
 - 11s - loss: 0.0499 - acc: 0.9874 - val_loss: 0.0695 - val_acc: 0.9834
Epoch 00005: early stopping
	TRAINING TIME: 1.63 minutes 
==================================================================================================
	PARSING TIME: 0.43 minutes 
==================================================================================================
	Identification : 0.52
	P, R  : 0.511, 0.529

==================================================================================================
	XP Ends: 5/7 (11 h:7)
==================================================================================================
ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR:theano.gof.opt:Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-0.0385519..1163203145})
ERROR:theano.gof.opt:node: InplaceDimShuffle{x,x}(TensorConstant{-0.0385519..1163203145})
ERROR (theano.gof.opt): TRACEBACK:
ERROR:theano.gof.opt:TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpE8xmpi/key.pkl'

ERROR:theano.gof.opt:Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpE8xmpi/key.pkl'

ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR:theano.gof.opt:Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{0.038551941163203145})
ERROR:theano.gof.opt:node: InplaceDimShuffle{x,x}(TensorConstant{0.038551941163203145})
ERROR (theano.gof.opt): TRACEBACK:
ERROR:theano.gof.opt:TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpE8xmpi/key.pkl'

ERROR:theano.gof.opt:Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpE8xmpi/key.pkl'

ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR:theano.gof.opt:Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-0.0385519..1163203145})
ERROR:theano.gof.opt:node: InplaceDimShuffle{x,x}(TensorConstant{-0.0385519..1163203145})
ERROR (theano.gof.opt): TRACEBACK:
ERROR:theano.gof.opt:TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 501, in add_key
    assert key not in self.keys
AssertionError

ERROR:theano.gof.opt:Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 501, in add_key
    assert key not in self.keys
AssertionError

	Mode: MLPWIDE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpWide        ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,5              ,True           ,True           ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
False          ,True           ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,0              ,16             ,
__________________________________________________________________________________________________
dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,posWindow      ,
__________________________________________________________________________________________________
0.4            ,389            ,0.037          ,57             ,4              ,
__________________________________________________________________________________________________
tokenEmb       ,trainable      ,
__________________________________________________________________________________________________
513            ,True           ,
__________________________________________________________________________________________________
# Configs: mlpWide, sharedtask2, fixedSize, 1, False, True, False, 5, True, True, False, True, False, False, False, True, False, 1, 0, 16, 0.4, 389, 0.037, 57, 4, 513, True
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 5/7 (11h:7)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 14798
	After : 2685
Traceback (most recent call last):
  File "src/xpNonCompo.py", line 228, in <module>
    xpNumByThread=250)
  File "/home/halsaied/NNIdenSys/src/rsg.py", line 27, in runRSGSpontaneously
    complentary=complentary, outputCupt=False)
  File "/home/halsaied/NNIdenSys/src/xpTools.py", line 27, in xp
    runXp(lang, mlpInLinear, linearInMlp, complentary, s, cuptTitle=title)
  File "/home/halsaied/NNIdenSys/src/xpTools.py", line 48, in runXp
    corpus = identify(lang)
  File "/home/halsaied/NNIdenSys/src/identification.py", line 29, in identify
    network, vectorizer = parseAndTrain(corpus)
  File "/home/halsaied/NNIdenSys/src/identification.py", line 261, in parseAndTrain
    network = modelMlpWide.Network(corpus)
  File "/home/halsaied/NNIdenSys/src/modelMlpWide.py", line 27, in __init__
    inputs, output = createTheModel(self.vocabulary)
  File "/home/halsaied/NNIdenSys/src/modelMlpWide.py", line 261, in createTheModel
    activation=configuration['nn']['dense1Activation'])(interLayers)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/engine/topology.py", line 592, in __call__
    self.build(input_shapes[0])
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/layers/core.py", line 864, in build
    constraint=self.kernel_constraint)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/engine/topology.py", line 416, in add_weight
    constraint=constraint)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 150, in variable
    value = value.eval()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/graph.py", line 522, in eval
    self._fn_cache[inputs] = theano.function(inputs, self)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function.py", line 317, in function
    output_keys=output_keys)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 1839, in orig_function
    name=name)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 99, in __call__
    return self.optimize(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 88, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 242, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 88, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2525, in apply
    sub_prof = gopt.apply(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2128, in apply
    nb += self.process_node(fgraph, node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2024, in process_node
    lopt, node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 1918, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 1904, in warn
    raise exc
AssertionError
