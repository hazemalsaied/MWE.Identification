Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_MZJLW6.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 10869/11441 Mb (0.950000) on cuda
Mapped name None to device cuda: Tesla K40m (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: MLPWIDE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpWide        ,sharedtask2    ,fixedSize      ,3              ,True           ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,15             ,True           ,True           ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
False          ,True           ,1              ,1              ,16             ,
__________________________________________________________________________________________________
dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,posWindow      ,
__________________________________________________________________________________________________
0.4            ,70             ,0.044          ,47             ,4              ,
__________________________________________________________________________________________________
tokenEmb       ,trainable      ,
__________________________________________________________________________________________________
300            ,True           ,
__________________________________________________________________________________________________
# Configs: mlpWide, sharedtask2, fixedSize, 3, True, True, False, 15, True, True, True, True, True, False, True, False, True, 1, 1, 16, 0.4, 70, 0.044, 47, 4, 300, True
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 5/7 (10h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 9312
	After : 2800
# Parameters = 1067648
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 35)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 5, 300)       840000      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 35, 47)       7144        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1500)         0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 1645)         0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 3145)         0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 70)           220220      concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 70)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            284         dropout_1[0][0]                  
==================================================================================================
Total params: 1,067,648
Trainable params: 1,067,648
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18089, 2: 17772, 3: 17743, 1: 17693})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 42s - loss: 0.0698 - acc: 0.9826 - val_loss: 0.0538 - val_acc: 0.9864
Epoch 2/40
 - 42s - loss: 0.0550 - acc: 0.9863 - val_loss: 0.0543 - val_acc: 0.9864
Epoch 3/40
 - 42s - loss: 0.0522 - acc: 0.9870 - val_loss: 0.0551 - val_acc: 0.9866
Epoch 4/40
 - 42s - loss: 0.0505 - acc: 0.9874 - val_loss: 0.0549 - val_acc: 0.9867
Epoch 5/40
 - 42s - loss: 0.0496 - acc: 0.9876 - val_loss: 0.0570 - val_acc: 0.9865
Epoch 00005: early stopping
	TRAINING TIME: 5.57 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.606
	P, R  : 0.754, 0.507

==================================================================================================
	XP Ends: 5/7 (11 h:6)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 5/7 (11h:6)
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 9194
	After : 2807
# Parameters = 1070547
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 35)           0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 5, 300)       842100      input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 35, 47)       7943        input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 1500)         0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 1645)         0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 3145)         0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 70)           220220      concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 70)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            284         dropout_2[0][0]                  
==================================================================================================
Total params: 1,070,547
Trainable params: 1,070,547
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12122, 3: 12071, 1: 12046, 2: 12035})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 28s - loss: 0.0767 - acc: 0.9804 - val_loss: 0.0615 - val_acc: 0.9841
Epoch 2/40
 - 28s - loss: 0.0574 - acc: 0.9855 - val_loss: 0.0615 - val_acc: 0.9846
Epoch 3/40
 - 28s - loss: 0.0536 - acc: 0.9865 - val_loss: 0.0614 - val_acc: 0.9848
Epoch 4/40
 - 28s - loss: 0.0519 - acc: 0.9869 - val_loss: 0.0630 - val_acc: 0.9847
Epoch 5/40
 - 28s - loss: 0.0506 - acc: 0.9873 - val_loss: 0.0652 - val_acc: 0.9849
Epoch 00005: early stopping
	TRAINING TIME: 3.08 minutes 
==================================================================================================
	PARSING TIME: 1.03 minutes 
==================================================================================================
	Identification : 0.655
	P, R  : 0.79, 0.559

==================================================================================================
	XP Ends: 5/7 (11 h:11)
==================================================================================================
/home/halsaied/miniconda2/lib/python2.7/site-packages/nltk/parse/dependencygraph.py:399: UserWarning: The graph doesn't contain a node that depends on the root element.
  "The graph doesn't contain a node " "that depends on the root element."
# Seed: 0
==================================================================================================
XP Starts: 5/7 (11h:11)
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 17288
	After : 5327
# Parameters = 1823727
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 35)           0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 5, 300)       1598100     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 35, 47)       5123        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 1500)         0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 1645)         0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 3145)         0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 70)           220220      concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 70)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            284         dropout_3[0][0]                  
==================================================================================================
Total params: 1,823,727
Trainable params: 1,823,727
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({1: 24187, 2: 24000, 0: 23959, 3: 23954})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 62s - loss: 0.0673 - acc: 0.9823 - val_loss: 0.0568 - val_acc: 0.9844
Epoch 2/40
 - 60s - loss: 0.0560 - acc: 0.9853 - val_loss: 0.0570 - val_acc: 0.9851
Epoch 3/40
 - 60s - loss: 0.0533 - acc: 0.9860 - val_loss: 0.0587 - val_acc: 0.9850
Epoch 4/40
 - 60s - loss: 0.0518 - acc: 0.9865 - val_loss: 0.0601 - val_acc: 0.9848
Epoch 5/40
 - 60s - loss: 0.0507 - acc: 0.9868 - val_loss: 0.0627 - val_acc: 0.9850
Epoch 00005: early stopping
	TRAINING TIME: 6.62 minutes 
==================================================================================================
	PARSING TIME: 0.42 minutes 
==================================================================================================
	Identification : 0.491
	P, R  : 0.603, 0.414

==================================================================================================
	XP Ends: 5/7 (11 h:19)
==================================================================================================
ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR:theano.gof.opt:Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-0.0465410..3233164825})
ERROR:theano.gof.opt:node: InplaceDimShuffle{x,x}(TensorConstant{-0.0465410..3233164825})
ERROR (theano.gof.opt): TRACEBACK:
ERROR:theano.gof.opt:TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpE8xmpi/key.pkl'

ERROR:theano.gof.opt:Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpE8xmpi/key.pkl'

ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR:theano.gof.opt:Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{0.046541003233164825})
ERROR:theano.gof.opt:node: InplaceDimShuffle{x,x}(TensorConstant{0.046541003233164825})
ERROR (theano.gof.opt): TRACEBACK:
ERROR:theano.gof.opt:TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpE8xmpi/key.pkl'

ERROR:theano.gof.opt:Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 504, in add_key
    self.save_pkl()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 525, in save_pkl
    with open(self.key_pkl, 'wb') as f:
IOError: [Errno 2] No such file or directory: '/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.9--2.7.14-64/tmpE8xmpi/key.pkl'

ERROR (theano.gof.opt): Optimization failure due to: constant_folding
ERROR:theano.gof.opt:Optimization failure due to: constant_folding
ERROR (theano.gof.opt): node: InplaceDimShuffle{x,x}(TensorConstant{-0.0465410..3233164825})
ERROR:theano.gof.opt:node: InplaceDimShuffle{x,x}(TensorConstant{-0.0465410..3233164825})
ERROR (theano.gof.opt): TRACEBACK:
ERROR:theano.gof.opt:TRACEBACK:
ERROR (theano.gof.opt): Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 501, in add_key
    assert key not in self.keys
AssertionError

ERROR:theano.gof.opt:Traceback (most recent call last):
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2019, in process_node
    replacements = lopt.transform(node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/tensor/opt.py", line 6507, in constant_folding
    no_recycling=[], impl=impl)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 955, in make_thunk
    no_recycling)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/op.py", line 858, in make_c_thunk
    output_storage=node_output_storage)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1217, in make_thunk
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1157, in __compile__
    keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cc.py", line 1620, in cthunk_factory
    key=key, lnk=self, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1140, in module_from_key
    module = self._get_from_hash(module_hash, key, keep_lock=keep_lock)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 1040, in _get_from_hash
    key_data.add_key(key, save_pkl=bool(key[0]))
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/cmodule.py", line 501, in add_key
    assert key not in self.keys
AssertionError

	Mode: MLPWIDE
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
mlpWide        ,sharedtask2    ,fixedSize      ,14             ,True           ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,30             ,True           ,True           ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
False          ,True           ,0              ,1              ,32             ,
__________________________________________________________________________________________________
dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,posWindow      ,
__________________________________________________________________________________________________
0.3            ,58             ,0.025          ,54             ,3              ,
__________________________________________________________________________________________________
tokenEmb       ,trainable      ,
__________________________________________________________________________________________________
300            ,True           ,
__________________________________________________________________________________________________
# Configs: mlpWide, sharedtask2, fixedSize, 14, True, True, False, 30, True, True, True, False, False, False, False, False, True, 0, 1, 32, 0.3, 58, 0.025, 54, 3, 300, True
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 5/7 (11h:19)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 14798
Traceback (most recent call last):
  File "src/xpNonCompo.py", line 228, in <module>
    xpNumByThread=250)
  File "/home/halsaied/NNIdenSys/src/rsg.py", line 27, in runRSGSpontaneously
    complentary=complentary, outputCupt=False)
  File "/home/halsaied/NNIdenSys/src/xpTools.py", line 27, in xp
    runXp(lang, mlpInLinear, linearInMlp, complentary, s, cuptTitle=title)
  File "/home/halsaied/NNIdenSys/src/xpTools.py", line 48, in runXp
    corpus = identify(lang)
  File "/home/halsaied/NNIdenSys/src/identification.py", line 29, in identify
    network, vectorizer = parseAndTrain(corpus)
  File "/home/halsaied/NNIdenSys/src/identification.py", line 261, in parseAndTrain
    network = modelMlpWide.Network(corpus)
  File "/home/halsaied/NNIdenSys/src/modelMlpWide.py", line 27, in __init__
    inputs, output = createTheModel(self.vocabulary)
  File "/home/halsaied/NNIdenSys/src/modelMlpWide.py", line 261, in createTheModel
    activation=configuration['nn']['dense1Activation'])(interLayers)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/engine/topology.py", line 592, in __call__
    self.build(input_shapes[0])
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/layers/core.py", line 864, in build
    constraint=self.kernel_constraint)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/engine/topology.py", line 416, in add_weight
    constraint=constraint)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py", line 150, in variable
    value = value.eval()
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/graph.py", line 522, in eval
    self._fn_cache[inputs] = theano.function(inputs, self)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function.py", line 317, in function
    output_keys=output_keys)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/pfunc.py", line 486, in pfunc
    output_keys=output_keys)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 1839, in orig_function
    name=name)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/compile/function_module.py", line 1519, in __init__
    optimizer_profile = optimizer(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 99, in __call__
    return self.optimize(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 88, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 242, in apply
    sub_prof = optimizer.optimize(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 88, in optimize
    ret = self.apply(fgraph, *args, **kwargs)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2525, in apply
    sub_prof = gopt.apply(fgraph)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2128, in apply
    nb += self.process_node(fgraph, node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 2024, in process_node
    lopt, node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 1918, in warn_inplace
    return NavigatorOptimizer.warn(exc, nav, repl_pairs, local_opt, node)
  File "/home/halsaied/miniconda2/lib/python2.7/site-packages/theano/gof/opt.py", line 1904, in warn
    raise exc
AssertionError
