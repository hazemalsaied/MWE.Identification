Corpus Test
********************
# XP = FR: 
********************
********************
# Language = FR
train.cupt 23658
Sent num = 14759
Tokens: 443113
Total VMWEs: 23658
Total MWTs: 102
Ireflv: 0
lvc: 0
id: 0
vpc: 0
dev.cupt 2120
Sent num = 1235
Tokens: 38820
Total VMWEs: 2120
Total MWTs: 1
Ireflv: 0
lvc: 0
id: 0
vpc: 0
test.cupt 4049
Sent num = 2541
Tokens: 75216
Total VMWEs: 4049
Total MWTs: 6
Ireflv: 0
lvc: 0
id: 0
vpc: 0
# Train = 15994, Test = 2541
Training started
# Tokens vocabulary = 20746
# POSs vocabulary = 979
# embedding: frWac_non_lem_no_postag_no_phrase_200_cbow_cut100.bin
# token vocabulary = 20746
# POS vocabulary = 979
# Padding = {'active': True, 's0Padding': 5, 'bPadding': 2, 's1Padding': 5}
# Embedding = True
# Initialisation = False
# Concatenation = False
# Lemma  = True
# Token/Lemma emb = 200
# POS = True
# POS emb = 15
# Features = False
Deep model(Non compositional)
# Parameters = 4185618
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 200)       4149200     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 15)        14685       input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 800)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 60)           0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 860)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 25)           21525       concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 25)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 8)            208         dropout_1[0][0]                  
==================================================================================================
Total params: 4,185,618
Trainable params: 4,185,618
Non-trainable params: 0
__________________________________________________________________________________________________
None
data size before sampling = 829729
data size after sampling = 1607992
class_weight{0.0: 1.0, 1.0: 1.0, 2.0: 10.0, 7.0: 10.0}
# Network optimizer = adagrad, learning rate = 0.02
Training over validation data# Training time = 0:30:19.508147
# F-Score(Ordinary) = 0.216, Recall: 0.169, Precision: 0.3
# F-Score(Categorization) = 0.216, Recall: 0.169, Precision: 0.3
# F-Score(oth) = 0.216, Recall: 0.169, Precision: 0.3
********************
