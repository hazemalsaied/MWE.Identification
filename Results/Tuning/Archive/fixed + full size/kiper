Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_DsJly_.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 10869/11441 Mb (0.950000) on cuda
Mapped name None to device cuda: Tesla K40m (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Network TransitionClassifier(
  (p_embeddings): Embedding(228, 15)
  (w_embeddings): Embedding(10073, 200)
  (lstm): LSTM(215, 32, num_layers=2, dropout=0.5, bidirectional=True)
  (linear1): Linear(in_features=512, out_features=128, bias=True)
  (dropout1): Dropout(p=0.3)
  (linear2): Linear(in_features=128, out_features=8, bias=True)
)

==================================================================================================
	Optimizer Adagrad (
Parameter Group 0
    initial_accumulator_value: 0
    lr: 0.02
    lr_decay: 0
    weight_decay: 0
)

==================================================================================================
	Epoch 0....
	GPU Enabled
==================================================================================================
	Dev Mode
==================================================================================================
	Language : FR
==================================================================================================
	Dataset : Sharedtask 1.0
	Training (Important) : 3474, Test : 1788
	MWEs in tain : 1418, occurrences : 3953
	Impotant words in tain : 1076
	MWE length mean : 2.29
	Seen MWEs : 357 (75 %)
	New MWEs : 114 (24 %)
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 13334
	After : 10073

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 10073 * POS : 228
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1787
	One occurrence keys in vocabulary 1787 / 10073
	Embedding
==================================================================================================
	Initialisation = None
	Concatenation = False
	Lemma : 200
	POS = 15 
# Network optimizer = adagrad, learning rate = 0.02
Number of used sentences in train = 3126
Total loss for epoch 0: 63204.014742
validation loss after epoch 0 : 6890.308813
	Epoch 1....
Epoch has taken 0:06:57.407702
Total loss for epoch 1: 61063.011791
validation loss after epoch 1 : 6854.100085
	Epoch 2....
Epoch has taken 0:06:58.494260
Total loss for epoch 2: 60490.499341
validation loss after epoch 2 : 6858.416784
	Epoch 3....
Epoch has taken 0:06:58.962196
Total loss for epoch 3: 59975.363927
validation loss after epoch 3 : 6832.576666
	Epoch 4....
Epoch has taken 0:06:58.793600
Total loss for epoch 4: 59377.097481
validation loss after epoch 4 : 6772.002172
	Epoch 5....
Epoch has taken 0:06:58.976634
Total loss for epoch 5: 58646.197038
validation loss after epoch 5 : 6755.504485
	Epoch 6....
Epoch has taken 0:06:58.678022
Total loss for epoch 6: 58128.642387
validation loss after epoch 6 : 6708.448509
	Epoch 7....
Epoch has taken 0:06:58.496658
Total loss for epoch 7: 57711.301080
validation loss after epoch 7 : 6673.636288
	Epoch 8....
Epoch has taken 0:07:08.400970
Total loss for epoch 8: 57472.094589
validation loss after epoch 8 : 6675.695303
	Epoch 9....
Epoch has taken 0:07:07.642674
Total loss for epoch 9: 57204.172288
validation loss after epoch 9 : 6671.563505
	Epoch 10....
Epoch has taken 0:07:08.472423
Total loss for epoch 10: 56927.383500
validation loss after epoch 10 : 6676.270479
	Epoch 11....
Epoch has taken 0:07:47.688665
Total loss for epoch 11: 56805.690356
validation loss after epoch 11 : 6694.854453
	Epoch 12....
Epoch has taken 0:06:58.927203
Total loss for epoch 12: 56569.819684
validation loss after epoch 12 : 6647.016486
	Epoch 13....
Epoch has taken 0:06:58.971258
Total loss for epoch 13: 56386.301997
validation loss after epoch 13 : 6661.765800
	Epoch 14....
Epoch has taken 0:06:59.038256
Total loss for epoch 14: 56203.908267
validation loss after epoch 14 : 6699.250817
	Epoch 15....
Epoch has taken 0:06:59.352186
Total loss for epoch 15: 56054.804395
validation loss after epoch 15 : 6693.520543
	Epoch 16....
Epoch has taken 0:06:59.255017
Total loss for epoch 16: 55915.565759
validation loss after epoch 16 : 6782.200169
	Epoch 17....
Epoch has taken 0:06:59.384745
Total loss for epoch 17: 55824.667882
validation loss after epoch 17 : 6680.213741
	Epoch 18....
Epoch has taken 0:06:59.066429
Total loss for epoch 18: 55727.902092
validation loss after epoch 18 : 6725.573338
	Epoch 19....
Epoch has taken 0:06:58.950875
Total loss for epoch 19: 55615.300078
validation loss after epoch 19 : 6690.163713
Epoch has taken 0:06:59.288729
	Identification : 0
	Test analysis
==================================================================================================
	Correctly identified MWEs
==================================================================================================

__________________________________________________________________________________________________
	Non Identified MWEs
==================================================================================================
	0 : 232
	25 : 6
	50 : 4
	100 : 2
	5 : 77

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Language : FR
==================================================================================================
	Dataset : Sharedtask 1.0
	Training (Important) : 3474, Test : 1788
	MWEs in tain : 1418, occurrences : 3953
	Impotant words in tain : 1076
	MWE length mean : 2.29
	Seen MWEs : 357 (75 %)
	New MWEs : 114 (24 %)
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 13334
	After : 10063

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 10063 * POS : 228
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1787
	One occurrence keys in vocabulary 1787 / 10063
	Embedding
==================================================================================================
	Initialisation = None
	Concatenation = False
	Lemma : 200
	POS = 15 
	Network TransitionClassifier(
  (p_embeddings): Embedding(228, 15)
  (w_embeddings): Embedding(10063, 200)
  (lstm): LSTM(215, 32, num_layers=2, dropout=0.5, bidirectional=True)
  (linear1): Linear(in_features=512, out_features=128, bias=True)
  (dropout1): Dropout(p=0.3)
  (linear2): Linear(in_features=128, out_features=8, bias=True)
)

==================================================================================================
	Optimizer Adagrad (
Parameter Group 0
    initial_accumulator_value: 0
    lr: 0.02
    lr_decay: 0
    weight_decay: 0
)

==================================================================================================
	Epoch 0....
# Network optimizer = adagrad, learning rate = 0.02
Number of used sentences in train = 3126
Total loss for epoch 0: 63657.938824
validation loss after epoch 0 : 7010.728754
	Epoch 1....
Epoch has taken 0:07:05.377126
Total loss for epoch 1: 61084.426624
validation loss after epoch 1 : 6898.569271
	Epoch 2....
Epoch has taken 0:07:05.839937
Total loss for epoch 2: 60383.608751
validation loss after epoch 2 : 6881.869327
	Epoch 3....
Epoch has taken 0:07:05.701659
Total loss for epoch 3: 59906.464479
validation loss after epoch 3 : 6830.727782
	Epoch 4....
Epoch has taken 0:07:05.915242
Total loss for epoch 4: 59571.155713
validation loss after epoch 4 : 6832.448713
	Epoch 5....
Epoch has taken 0:07:05.825106
## OAR [2018-07-24 13:20:54] Job 1621064 KILLED ##
