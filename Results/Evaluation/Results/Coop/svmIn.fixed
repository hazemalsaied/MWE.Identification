Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_YdWSNq.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 3841/4043 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX 980 (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: NON.COMPO
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, tokenEmb, trainable
==================================================================================================
# Configs: NonCompo, sharedtask2, fixedSize, 1, False, False, False, 35, False, False, True, False, False, False, True, True, False, 1, 1, 64, 0.4, 60, 0.059, 42, 480, True
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (16h:31)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 9312
	After : 2800

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2800 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 2800
# Parameters = 766626
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 5, 168)       470400      input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 5, 25)        3800        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 840)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 125)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 973)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
                                                                 input_3[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 299)          291226      concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 299)          0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            1200        dropout_1[0][0]                  
==================================================================================================
Total params: 766,626
Trainable params: 766,626
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({0: 18089, 2: 17772, 3: 17743, 1: 17693})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 22s - loss: 0.0239 - acc: 0.9941 - val_loss: 0.0120 - val_acc: 0.9968
Epoch 2/40
 - 22s - loss: 0.0094 - acc: 0.9973 - val_loss: 0.0116 - val_acc: 0.9966
Epoch 3/40
 - 22s - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0117 - val_acc: 0.9967
Epoch 4/40
 - 22s - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0125 - val_acc: 0.9967
Epoch 5/40
 - 22s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0129 - val_acc: 0.9967
Epoch 00005: early stopping
	TRAINING TIME: 10.7 minutes 
==================================================================================================
	PARSING TIME: 0.67 minutes 
==================================================================================================
	Identification : 0.62
	P, R  : 0.72, 0.545

==================================================================================================
	XP Ends: 7/2 (16 h:53)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (16h:53)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 9312
	After : 2800

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2800 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 2800
# Parameters = 766626
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 5, 168)       470400      input_4[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 5, 25)        3800        input_5[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 840)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 125)          0           embedding_4[0][0]                
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 973)          0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
                                                                 input_6[0][0]                    
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 299)          291226      concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 299)          0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            1200        dropout_2[0][0]                  
==================================================================================================
Total params: 766,626
Trainable params: 766,626
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 181825
	data size after sampling = 356484
	4 Labels in train : Counter({0: 89121, 1: 89121, 2: 89121, 3: 89121})
	4 Labels in valid : Counter({3: 18100, 0: 17808, 1: 17748, 2: 17641})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 285187 samples, validate on 71297 samples
Epoch 1/40
 - 23s - loss: 0.0230 - acc: 0.9944 - val_loss: 0.0123 - val_acc: 0.9962
Epoch 2/40
 - 22s - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0115 - val_acc: 0.9966
Epoch 3/40
 - 22s - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0119 - val_acc: 0.9965
Epoch 4/40
 - 22s - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0125 - val_acc: 0.9967
Epoch 5/40
 - 22s - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0134 - val_acc: 0.9966
Epoch 00005: early stopping
	TRAINING TIME: 10.65 minutes 
==================================================================================================
	PARSING TIME: 0.68 minutes 
==================================================================================================
	Identification : 0.615
	P, R  : 0.73, 0.531

==================================================================================================
	XP Ends: 7/2 (17 h:15)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (17h:15)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	DE Train (2374)
==================================================================================================
	Important sentence: 2364
	Token occurrences: 53040
	MWE number: 1699
	MWE occurrences: 2746
	Continuous occurrences: 26.0 %
	Frequent MWE occurences: 18.0 %
	MWE length: 1.94
	Recognizable MWEs: 100.0 %
	MWT occurrences: 885
	Embedded occurrences: 39

==================================================================================================
	 Test (1184)
==================================================================================================
	Important sentence: 425
	Token occurrences: 22092
	MWE number: 415
	MWE occurrences: 503
	Continuous occurrences: 28.0 %
	MWE length: 1.99
	Seen occurrences : 55% 
	Recognizable MWEs: 97.0 %
	MWT occurrences: 146
	Embedded occurrences: 19

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 13554
	After : 3230

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 3230 * POS : 261
__________________________________________________________________________________________________
	Important words not in vocabulary 2
	MWE not in vocabulary 2
	Dashed keys in vocabulary 1721
	One occurrence keys in vocabulary 1721 / 3230
# Parameters = 841591
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 5, 168)       542640      input_7[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 5, 25)        6525        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 840)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 125)          0           embedding_6[0][0]                
__________________________________________________________________________________________________
input_9 (InputLayer)            (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 973)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
                                                                 input_9[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 299)          291226      concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 299)          0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            1200        dropout_3[0][0]                  
==================================================================================================
Total params: 841,591
Trainable params: 841,591
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 108826
	data size after sampling = 212160
	4 Labels in train : Counter({0: 53040, 1: 53040, 2: 53040, 3: 53040})
	4 Labels in valid : Counter({3: 10721, 1: 10669, 0: 10551, 2: 10491})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 169728 samples, validate on 42432 samples
Epoch 1/40
 - 13s - loss: 0.0648 - acc: 0.9848 - val_loss: 0.0286 - val_acc: 0.9918
Epoch 2/40
 - 13s - loss: 0.0233 - acc: 0.9940 - val_loss: 0.0245 - val_acc: 0.9932
Epoch 3/40
 - 13s - loss: 0.0173 - acc: 0.9954 - val_loss: 0.0242 - val_acc: 0.9934
Epoch 4/40
 - 13s - loss: 0.0143 - acc: 0.9963 - val_loss: 0.0234 - val_acc: 0.9940
Epoch 5/40
 - 13s - loss: 0.0124 - acc: 0.9967 - val_loss: 0.0244 - val_acc: 0.9938
Epoch 00005: early stopping
	TRAINING TIME: 5.35 minutes 
==================================================================================================
	PARSING TIME: 0.38 minutes 
==================================================================================================
	Identification : 0.564
	P, R  : 0.789, 0.439

==================================================================================================
	XP Ends: 7/2 (17 h:27)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (17h:27)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	DE Train (2374)
==================================================================================================
	Important sentence: 2364
	Token occurrences: 53040
	MWE number: 1699
	MWE occurrences: 2746
	Continuous occurrences: 26.0 %
	Frequent MWE occurences: 18.0 %
	MWE length: 1.94
	Recognizable MWEs: 100.0 %
	MWT occurrences: 885
	Embedded occurrences: 39

==================================================================================================
	 Test (1184)
==================================================================================================
	Important sentence: 425
	Token occurrences: 22092
	MWE number: 415
	MWE occurrences: 503
	Continuous occurrences: 28.0 %
	MWE length: 1.99
	Seen occurrences : 55% 
	Recognizable MWEs: 97.0 %
	MWT occurrences: 146
	Embedded occurrences: 19

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 13554
	After : 3230

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 3230 * POS : 261
__________________________________________________________________________________________________
	Important words not in vocabulary 2
	MWE not in vocabulary 2
	Dashed keys in vocabulary 1721
	One occurrence keys in vocabulary 1721 / 3230
# Parameters = 841591
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_11 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 5, 168)       542640      input_10[0][0]                   
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 5, 25)        6525        input_11[0][0]                   
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 840)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 125)          0           embedding_8[0][0]                
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 973)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
                                                                 input_12[0][0]                   
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 299)          291226      concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 299)          0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4)            1200        dropout_4[0][0]                  
==================================================================================================
Total params: 841,591
Trainable params: 841,591
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 108826
	data size after sampling = 212160
	4 Labels in train : Counter({0: 53040, 1: 53040, 2: 53040, 3: 53040})
	4 Labels in valid : Counter({3: 10767, 1: 10649, 0: 10572, 2: 10444})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 169728 samples, validate on 42432 samples
Epoch 1/40
 - 14s - loss: 0.0675 - acc: 0.9843 - val_loss: 0.0255 - val_acc: 0.9929
Epoch 2/40
 - 14s - loss: 0.0237 - acc: 0.9940 - val_loss: 0.0237 - val_acc: 0.9930
Epoch 3/40
 - 14s - loss: 0.0174 - acc: 0.9954 - val_loss: 0.0228 - val_acc: 0.9938
Epoch 4/40
 - 14s - loss: 0.0143 - acc: 0.9961 - val_loss: 0.0226 - val_acc: 0.9937
Epoch 5/40
 - 14s - loss: 0.0123 - acc: 0.9967 - val_loss: 0.0231 - val_acc: 0.9940
Epoch 00005: early stopping
	TRAINING TIME: 5.42 minutes 
==================================================================================================
	PARSING TIME: 0.38 minutes 
==================================================================================================
	Identification : 0.553
	P, R  : 0.747, 0.439

==================================================================================================
	XP Ends: 7/2 (17 h:38)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (17h:38)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	EL Train (1217)
==================================================================================================
	Important sentence: 1217
	Token occurrences: 40030
	MWE number: 901
	MWE occurrences: 1362
	Continuous occurrences: 53.0 %
	Frequent MWE occurences: 17.0 %
	MWE length: 2.38
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 4

==================================================================================================
	 Test (2562)
==================================================================================================
	Important sentence: 440
	Token occurrences: 64776
	MWE number: 337
	MWE occurrences: 500
	Continuous occurrences: 43.0 %
	MWE length: 2.33
	Seen occurrences : 45% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 4

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 8215
	After : 2048

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2048 * POS : 186
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1197
	One occurrence keys in vocabulary 1197 / 2048
# Parameters = 641140
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 5, 168)       344064      input_13[0][0]                   
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 5, 25)        4650        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 840)          0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 125)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
input_15 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 973)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
                                                                 input_15[0][0]                   
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 299)          291226      concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 299)          0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 4)            1200        dropout_5[0][0]                  
==================================================================================================
Total params: 641,140
Trainable params: 641,140
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 81422
	data size after sampling = 160120
	4 Labels in train : Counter({0: 40030, 1: 40030, 2: 40030, 3: 40030})
	4 Labels in valid : Counter({1: 8024, 2: 8014, 0: 7997, 3: 7989})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 128096 samples, validate on 32024 samples
Epoch 1/40
 - 10s - loss: 0.0386 - acc: 0.9912 - val_loss: 0.0132 - val_acc: 0.9960
Epoch 2/40
 - 10s - loss: 0.0100 - acc: 0.9972 - val_loss: 0.0127 - val_acc: 0.9958
Epoch 3/40
 - 10s - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0135 - val_acc: 0.9960
Epoch 4/40
 - 10s - loss: 0.0055 - acc: 0.9983 - val_loss: 0.0130 - val_acc: 0.9961
Epoch 5/40
 - 10s - loss: 0.0045 - acc: 0.9986 - val_loss: 0.0134 - val_acc: 0.9960
Epoch 00005: early stopping
	TRAINING TIME: 2.73 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.533
	P, R  : 0.824, 0.394

==================================================================================================
	XP Ends: 7/2 (17 h:46)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (17h:46)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	EL Train (1217)
==================================================================================================
	Important sentence: 1217
	Token occurrences: 40030
	MWE number: 901
	MWE occurrences: 1362
	Continuous occurrences: 53.0 %
	Frequent MWE occurences: 17.0 %
	MWE length: 2.38
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 4

==================================================================================================
	 Test (2562)
==================================================================================================
	Important sentence: 440
	Token occurrences: 64776
	MWE number: 337
	MWE occurrences: 500
	Continuous occurrences: 43.0 %
	MWE length: 2.33
	Seen occurrences : 45% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 4

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 8215
	After : 2048

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2048 * POS : 186
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1197
	One occurrence keys in vocabulary 1197 / 2048
# Parameters = 641140
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_16 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_17 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 5, 168)       344064      input_16[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 5, 25)        4650        input_17[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 840)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 125)          0           embedding_12[0][0]               
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 973)          0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
                                                                 input_18[0][0]                   
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 299)          291226      concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 299)          0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 4)            1200        dropout_6[0][0]                  
==================================================================================================
Total params: 641,140
Trainable params: 641,140
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 81422
	data size after sampling = 160120
	4 Labels in train : Counter({0: 40030, 1: 40030, 2: 40030, 3: 40030})
	4 Labels in valid : Counter({3: 8023, 2: 8004, 1: 8002, 0: 7995})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 128096 samples, validate on 32024 samples
Epoch 1/40
 - 10s - loss: 0.0411 - acc: 0.9910 - val_loss: 0.0125 - val_acc: 0.9964
Epoch 2/40
 - 10s - loss: 0.0099 - acc: 0.9972 - val_loss: 0.0123 - val_acc: 0.9960
Epoch 3/40
 - 10s - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0125 - val_acc: 0.9964
Epoch 4/40
 - 10s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0133 - val_acc: 0.9963
Epoch 5/40
 - 10s - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0124 - val_acc: 0.9966
Epoch 00005: early stopping
	TRAINING TIME: 2.75 minutes 
==================================================================================================
	PARSING TIME: 1.0 minutes 
==================================================================================================
	Identification : 0.518
	P, R  : 0.812, 0.38

==================================================================================================
	XP Ends: 7/2 (17 h:54)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (17h:54)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	EN Train (300)
==================================================================================================
	Important sentence: 300
	Token occurrences: 7066
	MWE number: 233
	MWE occurrences: 331
	Continuous occurrences: 68.0 %
	Frequent MWE occurences: 6.0 %
	MWE length: 2.14
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	 Test (2818)
==================================================================================================
	Important sentence: 255
	Token occurrences: 43012
	MWE number: 205
	MWE occurrences: 280
	Continuous occurrences: 69.0 %
	MWE length: 2.14
	Seen occurrences : 100% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 1967
	After : 519

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 519 * POS : 62
__________________________________________________________________________________________________
	Dashed keys in vocabulary 275
	One occurrence keys in vocabulary 275 / 519
# Parameters = 381168
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 5, 168)       87192       input_19[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 5, 25)        1550        input_20[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 840)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 125)          0           embedding_14[0][0]               
__________________________________________________________________________________________________
input_21 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 973)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
                                                                 input_21[0][0]                   
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 299)          291226      concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 299)          0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 4)            1200        dropout_7[0][0]                  
==================================================================================================
Total params: 381,168
Trainable params: 381,168
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 14463
	data size after sampling = 28264
	4 Labels in train : Counter({0: 7066, 1: 7066, 2: 7066, 3: 7066})
	4 Labels in valid : Counter({2: 1443, 3: 1415, 0: 1413, 1: 1382})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 22611 samples, validate on 5653 samples
Epoch 1/40
 - 2s - loss: 0.1077 - acc: 0.9769 - val_loss: 0.0210 - val_acc: 0.9931
Epoch 2/40
 - 2s - loss: 0.0153 - acc: 0.9948 - val_loss: 0.0158 - val_acc: 0.9943
Epoch 3/40
 - 2s - loss: 0.0097 - acc: 0.9964 - val_loss: 0.0167 - val_acc: 0.9945
Epoch 4/40
 - 2s - loss: 0.0072 - acc: 0.9976 - val_loss: 0.0154 - val_acc: 0.9949
Epoch 5/40
 - 2s - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0164 - val_acc: 0.9947
Epoch 00005: early stopping
	TRAINING TIME: 0.32 minutes 
==================================================================================================
	PARSING TIME: 0.62 minutes 
==================================================================================================
	Identification : 0.847
	P, R  : 0.739, 0.993

==================================================================================================
	XP Ends: 7/2 (17 h:56)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (17h:56)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	EN Train (300)
==================================================================================================
	Important sentence: 300
	Token occurrences: 7066
	MWE number: 233
	MWE occurrences: 331
	Continuous occurrences: 68.0 %
	Frequent MWE occurences: 6.0 %
	MWE length: 2.14
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	 Test (2818)
==================================================================================================
	Important sentence: 255
	Token occurrences: 43012
	MWE number: 205
	MWE occurrences: 280
	Continuous occurrences: 69.0 %
	MWE length: 2.14
	Seen occurrences : 100% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 1967
	After : 519

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 519 * POS : 62
__________________________________________________________________________________________________
	Dashed keys in vocabulary 275
	One occurrence keys in vocabulary 275 / 519
# Parameters = 381168
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_22 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_23 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 5, 168)       87192       input_22[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 5, 25)        1550        input_23[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 840)          0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 125)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
input_24 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 973)          0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
                                                                 input_24[0][0]                   
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 299)          291226      concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 299)          0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 4)            1200        dropout_8[0][0]                  
==================================================================================================
Total params: 381,168
Trainable params: 381,168
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 14463
	data size after sampling = 28264
	4 Labels in train : Counter({0: 7066, 1: 7066, 2: 7066, 3: 7066})
	4 Labels in valid : Counter({3: 1437, 0: 1419, 2: 1405, 1: 1392})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 22611 samples, validate on 5653 samples
Epoch 1/40
 - 2s - loss: 0.1138 - acc: 0.9768 - val_loss: 0.0234 - val_acc: 0.9899
Epoch 2/40
 - 2s - loss: 0.0152 - acc: 0.9955 - val_loss: 0.0204 - val_acc: 0.9922
Epoch 3/40
 - 2s - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0179 - val_acc: 0.9940
Epoch 4/40
 - 2s - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0187 - val_acc: 0.9943
Epoch 5/40
 - 2s - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0185 - val_acc: 0.9945
Epoch 00005: early stopping
	TRAINING TIME: 0.33 minutes 
==================================================================================================
	PARSING TIME: 0.62 minutes 
==================================================================================================
	Identification : 0.817
	P, R  : 0.709, 0.964

==================================================================================================
	XP Ends: 7/2 (17 h:59)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 4 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 4 sentences!
ERROR:root:ATTENTION: Oracle problems with 4 sentences!
# Seed: 0
==================================================================================================
XP Starts: 7/2 (17h:59)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	ES Train (1118)
==================================================================================================
	Important sentence: 1118
	Token occurrences: 45809
	MWE number: 917
	MWE occurrences: 1633
	Continuous occurrences: 75.0 %
	Frequent MWE occurences: 25.0 %
	MWE length: 2.27
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2
	Embedded occurrences: 131

==================================================================================================
	 Test (698)
==================================================================================================
	Important sentence: 332
	Token occurrences: 26220
	MWE number: 378
	MWE occurrences: 500
	Continuous occurrences: 72.0 %
	MWE length: 2.26
	Seen occurrences : 51% 
	Recognizable MWEs: 95.0 %
	Embedded occurrences: 22
	Interleaving occurrences: 21

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 7203
	After : 1732

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1732 * POS : 114
__________________________________________________________________________________________________
	MWE not in vocabulary 1
	Dashed keys in vocabulary 1034
	One occurrence keys in vocabulary 1034 / 1732
# Parameters = 586252
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_26 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 5, 168)       290976      input_25[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 5, 25)        2850        input_26[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 840)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 125)          0           embedding_18[0][0]               
__________________________________________________________________________________________________
input_27 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 973)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
                                                                 input_27[0][0]                   
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 299)          291226      concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 299)          0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 4)            1200        dropout_9[0][0]                  
==================================================================================================
Total params: 586,252
Trainable params: 586,252
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 93247
	data size after sampling = 183236
	4 Labels in train : Counter({0: 45809, 1: 45809, 2: 45809, 3: 45809})
	4 Labels in valid : Counter({0: 9280, 1: 9172, 2: 9104, 3: 9092})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 146588 samples, validate on 36648 samples
Epoch 1/40
 - 11s - loss: 0.0455 - acc: 0.9898 - val_loss: 0.0157 - val_acc: 0.9953
Epoch 2/40
 - 11s - loss: 0.0140 - acc: 0.9957 - val_loss: 0.0141 - val_acc: 0.9956
Epoch 3/40
 - 11s - loss: 0.0101 - acc: 0.9970 - val_loss: 0.0138 - val_acc: 0.9959
Epoch 4/40
 - 11s - loss: 0.0078 - acc: 0.9976 - val_loss: 0.0143 - val_acc: 0.9957
Epoch 5/40
 - 11s - loss: 0.0062 - acc: 0.9981 - val_loss: 0.0146 - val_acc: 0.9957
Epoch 00005: early stopping
	TRAINING TIME: 2.97 minutes 
==================================================================================================
	PARSING TIME: 0.38 minutes 
==================================================================================================
	Identification : 0.562
	P, R  : 0.811, 0.43

==================================================================================================
	XP Ends: 7/2 (18 h:5)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 4 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 4 sentences!
ERROR:root:ATTENTION: Oracle problems with 4 sentences!
# Seed: 1
==================================================================================================
XP Starts: 7/2 (18h:5)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	ES Train (1118)
==================================================================================================
	Important sentence: 1118
	Token occurrences: 45809
	MWE number: 917
	MWE occurrences: 1633
	Continuous occurrences: 75.0 %
	Frequent MWE occurences: 25.0 %
	MWE length: 2.27
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2
	Embedded occurrences: 131

==================================================================================================
	 Test (698)
==================================================================================================
	Important sentence: 332
	Token occurrences: 26220
	MWE number: 378
	MWE occurrences: 500
	Continuous occurrences: 72.0 %
	MWE length: 2.26
	Seen occurrences : 51% 
	Recognizable MWEs: 95.0 %
	Embedded occurrences: 22
	Interleaving occurrences: 21

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 7203
	After : 1732

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1732 * POS : 114
__________________________________________________________________________________________________
	MWE not in vocabulary 1
	Dashed keys in vocabulary 1034
	One occurrence keys in vocabulary 1034 / 1732
# Parameters = 586252
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_28 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_29 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 5, 168)       290976      input_28[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 5, 25)        2850        input_29[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 840)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 125)          0           embedding_20[0][0]               
__________________________________________________________________________________________________
input_30 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 973)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
                                                                 input_30[0][0]                   
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 299)          291226      concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 299)          0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 4)            1200        dropout_10[0][0]                 
==================================================================================================
Total params: 586,252
Trainable params: 586,252
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 93247
	data size after sampling = 183236
	4 Labels in train : Counter({0: 45809, 1: 45809, 2: 45809, 3: 45809})
	4 Labels in valid : Counter({3: 9290, 1: 9136, 2: 9115, 0: 9107})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 146588 samples, validate on 36648 samples
Epoch 1/40
 - 11s - loss: 0.0530 - acc: 0.9896 - val_loss: 0.0190 - val_acc: 0.9945
Epoch 2/40
 - 11s - loss: 0.0139 - acc: 0.9958 - val_loss: 0.0166 - val_acc: 0.9949
Epoch 3/40
 - 11s - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0166 - val_acc: 0.9949
Epoch 4/40
 - 11s - loss: 0.0078 - acc: 0.9976 - val_loss: 0.0174 - val_acc: 0.9948
Epoch 5/40
 - 11s - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0169 - val_acc: 0.9951
Epoch 00005: early stopping
	TRAINING TIME: 2.98 minutes 
==================================================================================================
	PARSING TIME: 0.4 minutes 
==================================================================================================
	Identification : 0.57
	P, R  : 0.817, 0.438

==================================================================================================
	XP Ends: 7/2 (18 h:12)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (18h:12)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	EU Train (2306)
==================================================================================================
	Important sentence: 2306
	Token occurrences: 39413
	MWE number: 834
	MWE occurrences: 2798
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 56.0 %
	MWE length: 2.02
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 4

==================================================================================================
	 Test (1500)
==================================================================================================
	Important sentence: 397
	Token occurrences: 21604
	MWE number: 264
	MWE occurrences: 500
	Continuous occurrences: 81.0 %
	MWE length: 2.02
	Seen occurrences : 78% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 3
	Interleaving occurrences: 3

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 6198
	After : 1458

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1458 * POS : 120
__________________________________________________________________________________________________
	Dashed keys in vocabulary 879
	One occurrence keys in vocabulary 879 / 1458
# Parameters = 540370
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_31 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_32 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_21 (Embedding)        (None, 5, 168)       244944      input_31[0][0]                   
__________________________________________________________________________________________________
embedding_22 (Embedding)        (None, 5, 25)        3000        input_32[0][0]                   
__________________________________________________________________________________________________
flatten_21 (Flatten)            (None, 840)          0           embedding_21[0][0]               
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 125)          0           embedding_22[0][0]               
__________________________________________________________________________________________________
input_33 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 973)          0           flatten_21[0][0]                 
                                                                 flatten_22[0][0]                 
                                                                 input_33[0][0]                   
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 299)          291226      concatenate_11[0][0]             
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 299)          0           dense_21[0][0]                   
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 4)            1200        dropout_11[0][0]                 
==================================================================================================
Total params: 540,370
Trainable params: 540,370
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 81624
	data size after sampling = 157652
	4 Labels in train : Counter({0: 39413, 1: 39413, 2: 39413, 3: 39413})
	4 Labels in valid : Counter({1: 7900, 2: 7899, 3: 7894, 0: 7838})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 126121 samples, validate on 31531 samples
Epoch 1/40
 - 10s - loss: 0.0385 - acc: 0.9905 - val_loss: 0.0152 - val_acc: 0.9958
Epoch 2/40
 - 10s - loss: 0.0127 - acc: 0.9961 - val_loss: 0.0146 - val_acc: 0.9957
Epoch 3/40
 - 10s - loss: 0.0098 - acc: 0.9968 - val_loss: 0.0146 - val_acc: 0.9959
Epoch 4/40
 - 10s - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0157 - val_acc: 0.9958
Epoch 5/40
 - 10s - loss: 0.0067 - acc: 0.9977 - val_loss: 0.0155 - val_acc: 0.9958
Epoch 00005: early stopping
	TRAINING TIME: 3.77 minutes 
==================================================================================================
	PARSING TIME: 0.32 minutes 
==================================================================================================
	Identification : 0.772
	P, R  : 0.811, 0.736

==================================================================================================
	XP Ends: 7/2 (18 h:20)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (18h:20)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	EU Train (2306)
==================================================================================================
	Important sentence: 2306
	Token occurrences: 39413
	MWE number: 834
	MWE occurrences: 2798
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 56.0 %
	MWE length: 2.02
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 4

==================================================================================================
	 Test (1500)
==================================================================================================
	Important sentence: 397
	Token occurrences: 21604
	MWE number: 264
	MWE occurrences: 500
	Continuous occurrences: 81.0 %
	MWE length: 2.02
	Seen occurrences : 78% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 3
	Interleaving occurrences: 3

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 6198
	After : 1458

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1458 * POS : 120
__________________________________________________________________________________________________
	Dashed keys in vocabulary 879
	One occurrence keys in vocabulary 879 / 1458
# Parameters = 540370
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_34 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_35 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_23 (Embedding)        (None, 5, 168)       244944      input_34[0][0]                   
__________________________________________________________________________________________________
embedding_24 (Embedding)        (None, 5, 25)        3000        input_35[0][0]                   
__________________________________________________________________________________________________
flatten_23 (Flatten)            (None, 840)          0           embedding_23[0][0]               
__________________________________________________________________________________________________
flatten_24 (Flatten)            (None, 125)          0           embedding_24[0][0]               
__________________________________________________________________________________________________
input_36 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 973)          0           flatten_23[0][0]                 
                                                                 flatten_24[0][0]                 
                                                                 input_36[0][0]                   
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 299)          291226      concatenate_12[0][0]             
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 299)          0           dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 4)            1200        dropout_12[0][0]                 
==================================================================================================
Total params: 540,370
Trainable params: 540,370
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 81624
	data size after sampling = 157652
	4 Labels in train : Counter({0: 39413, 1: 39413, 2: 39413, 3: 39413})
	4 Labels in valid : Counter({3: 8027, 0: 7899, 2: 7865, 1: 7740})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 126121 samples, validate on 31531 samples
Epoch 1/40
 - 10s - loss: 0.0408 - acc: 0.9902 - val_loss: 0.0146 - val_acc: 0.9954
Epoch 2/40
 - 10s - loss: 0.0127 - acc: 0.9961 - val_loss: 0.0144 - val_acc: 0.9956
Epoch 3/40
 - 10s - loss: 0.0102 - acc: 0.9966 - val_loss: 0.0145 - val_acc: 0.9957
Epoch 4/40
 - 10s - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0150 - val_acc: 0.9956
Epoch 5/40
 - 10s - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0151 - val_acc: 0.9958
Epoch 00005: early stopping
	TRAINING TIME: 3.78 minutes 
==================================================================================================
	PARSING TIME: 0.32 minutes 
==================================================================================================
	Identification : 0.762
	P, R  : 0.806, 0.722

==================================================================================================
	XP Ends: 7/2 (18 h:28)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (18h:28)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	FA Train (1645)
==================================================================================================
	Important sentence: 1645
	Token occurrences: 31982
	MWE number: 1116
	MWE occurrences: 2447
	Continuous occurrences: 85.0 %
	Frequent MWE occurences: 36.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 6

==================================================================================================
	 Test (474)
==================================================================================================
	Important sentence: 320
	Token occurrences: 8923
	MWE number: 353
	MWE occurrences: 501
	Continuous occurrences: 86.0 %
	MWE length: 2.18
	Seen occurrences : 61% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 4801
	After : 1972

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1972 * POS : 64
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1243
	One occurrence keys in vocabulary 1243 / 1972
# Parameters = 625322
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_37 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_38 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_25 (Embedding)        (None, 5, 168)       331296      input_37[0][0]                   
__________________________________________________________________________________________________
embedding_26 (Embedding)        (None, 5, 25)        1600        input_38[0][0]                   
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 840)          0           embedding_25[0][0]               
__________________________________________________________________________________________________
flatten_26 (Flatten)            (None, 125)          0           embedding_26[0][0]               
__________________________________________________________________________________________________
input_39 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 973)          0           flatten_25[0][0]                 
                                                                 flatten_26[0][0]                 
                                                                 input_39[0][0]                   
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 299)          291226      concatenate_13[0][0]             
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 299)          0           dense_25[0][0]                   
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 4)            1200        dropout_13[0][0]                 
==================================================================================================
Total params: 625,322
Trainable params: 625,322
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 66411
	data size after sampling = 127928
	4 Labels in train : Counter({0: 31982, 1: 31982, 2: 31982, 3: 31982})
	4 Labels in valid : Counter({0: 6490, 2: 6440, 3: 6353, 1: 6303})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 102342 samples, validate on 25586 samples
Epoch 1/40
 - 8s - loss: 0.0409 - acc: 0.9911 - val_loss: 0.0135 - val_acc: 0.9959
Epoch 2/40
 - 8s - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0133 - val_acc: 0.9962
Epoch 3/40
 - 8s - loss: 0.0080 - acc: 0.9975 - val_loss: 0.0136 - val_acc: 0.9957
Epoch 4/40
 - 8s - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0152 - val_acc: 0.9961
Epoch 5/40
 - 8s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0145 - val_acc: 0.9960
Epoch 00005: early stopping
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 0.15 minutes 
==================================================================================================
	Identification : 0.813
	P, R  : 0.881, 0.754

==================================================================================================
	XP Ends: 7/2 (18 h:32)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (18h:32)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	FA Train (1645)
==================================================================================================
	Important sentence: 1645
	Token occurrences: 31982
	MWE number: 1116
	MWE occurrences: 2447
	Continuous occurrences: 85.0 %
	Frequent MWE occurences: 36.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 6

==================================================================================================
	 Test (474)
==================================================================================================
	Important sentence: 320
	Token occurrences: 8923
	MWE number: 353
	MWE occurrences: 501
	Continuous occurrences: 86.0 %
	MWE length: 2.18
	Seen occurrences : 61% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 4801
	After : 1972

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1972 * POS : 64
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1243
	One occurrence keys in vocabulary 1243 / 1972
# Parameters = 625322
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_40 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_41 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_27 (Embedding)        (None, 5, 168)       331296      input_40[0][0]                   
__________________________________________________________________________________________________
embedding_28 (Embedding)        (None, 5, 25)        1600        input_41[0][0]                   
__________________________________________________________________________________________________
flatten_27 (Flatten)            (None, 840)          0           embedding_27[0][0]               
__________________________________________________________________________________________________
flatten_28 (Flatten)            (None, 125)          0           embedding_28[0][0]               
__________________________________________________________________________________________________
input_42 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 973)          0           flatten_27[0][0]                 
                                                                 flatten_28[0][0]                 
                                                                 input_42[0][0]                   
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 299)          291226      concatenate_14[0][0]             
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 299)          0           dense_27[0][0]                   
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 4)            1200        dropout_14[0][0]                 
==================================================================================================
Total params: 625,322
Trainable params: 625,322
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 66411
	data size after sampling = 127928
	4 Labels in train : Counter({0: 31982, 1: 31982, 2: 31982, 3: 31982})
	4 Labels in valid : Counter({3: 6489, 0: 6399, 1: 6378, 2: 6320})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 102342 samples, validate on 25586 samples
Epoch 1/40
 - 8s - loss: 0.0384 - acc: 0.9911 - val_loss: 0.0131 - val_acc: 0.9960
Epoch 2/40
 - 8s - loss: 0.0105 - acc: 0.9968 - val_loss: 0.0134 - val_acc: 0.9955
Epoch 3/40
 - 8s - loss: 0.0079 - acc: 0.9977 - val_loss: 0.0138 - val_acc: 0.9957
Epoch 4/40
 - 8s - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0143 - val_acc: 0.9959
Epoch 5/40
 - 8s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0148 - val_acc: 0.9959
Epoch 00005: early stopping
	TRAINING TIME: 2.57 minutes 
==================================================================================================
	PARSING TIME: 0.15 minutes 
==================================================================================================
	Identification : 0.799
	P, R  : 0.884, 0.729

==================================================================================================
	XP Ends: 7/2 (18 h:37)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 7/2 (18h:37)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	FR Train (2495)
==================================================================================================
	Important sentence: 2495
	Token occurrences: 74558
	MWE number: 1209
	MWE occurrences: 2896
	Continuous occurrences: 60.0 %
	Frequent MWE occurences: 41.0 %
	MWE length: 2.3
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 19

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 70% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 10723
	After : 2513

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2513 * POS : 174
__________________________________________________________________________________________________
	MWE not in vocabulary 2
	Dashed keys in vocabulary 1510
	One occurrence keys in vocabulary 1510 / 2513
# Parameters = 718960
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_43 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_44 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_29 (Embedding)        (None, 5, 168)       422184      input_43[0][0]                   
__________________________________________________________________________________________________
embedding_30 (Embedding)        (None, 5, 25)        4350        input_44[0][0]                   
__________________________________________________________________________________________________
flatten_29 (Flatten)            (None, 840)          0           embedding_29[0][0]               
__________________________________________________________________________________________________
flatten_30 (Flatten)            (None, 125)          0           embedding_30[0][0]               
__________________________________________________________________________________________________
input_45 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 973)          0           flatten_29[0][0]                 
                                                                 flatten_30[0][0]                 
                                                                 input_45[0][0]                   
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 299)          291226      concatenate_15[0][0]             
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 299)          0           dense_29[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 4)            1200        dropout_15[0][0]                 
==================================================================================================
Total params: 718,960
Trainable params: 718,960
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 152010
	data size after sampling = 298232
	4 Labels in train : Counter({0: 74558, 1: 74558, 2: 74558, 3: 74558})
	4 Labels in valid : Counter({0: 14994, 3: 14930, 1: 14878, 2: 14845})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 238585 samples, validate on 59647 samples
Epoch 1/40
 - 19s - loss: 0.0271 - acc: 0.9935 - val_loss: 0.0113 - val_acc: 0.9969
Epoch 2/40
 - 19s - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0106 - val_acc: 0.9972
Epoch 3/40
 - 19s - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0106 - val_acc: 0.9973
Epoch 4/40
 - 19s - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0111 - val_acc: 0.9972
Epoch 5/40
 - 19s - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0113 - val_acc: 0.9973
Epoch 00005: early stopping
	TRAINING TIME: 7.4 minutes 
==================================================================================================
	PARSING TIME: 0.82 minutes 
==================================================================================================
	Identification : 0.755
	P, R  : 0.863, 0.671

==================================================================================================
	XP Ends: 7/2 (18 h:54)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 1
==================================================================================================
XP Starts: 7/2 (18h:54)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	FR Train (2495)
==================================================================================================
	Important sentence: 2495
	Token occurrences: 74558
	MWE number: 1209
	MWE occurrences: 2896
	Continuous occurrences: 60.0 %
	Frequent MWE occurences: 41.0 %
	MWE length: 2.3
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 19

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 70% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 10723
	After : 2513

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2513 * POS : 174
__________________________________________________________________________________________________
	MWE not in vocabulary 2
	Dashed keys in vocabulary 1510
	One occurrence keys in vocabulary 1510 / 2513
# Parameters = 718960
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_46 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_47 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_31 (Embedding)        (None, 5, 168)       422184      input_46[0][0]                   
__________________________________________________________________________________________________
embedding_32 (Embedding)        (None, 5, 25)        4350        input_47[0][0]                   
__________________________________________________________________________________________________
flatten_31 (Flatten)            (None, 840)          0           embedding_31[0][0]               
__________________________________________________________________________________________________
flatten_32 (Flatten)            (None, 125)          0           embedding_32[0][0]               
__________________________________________________________________________________________________
input_48 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 973)          0           flatten_31[0][0]                 
                                                                 flatten_32[0][0]                 
                                                                 input_48[0][0]                   
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 299)          291226      concatenate_16[0][0]             
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 299)          0           dense_31[0][0]                   
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 4)            1200        dropout_16[0][0]                 
==================================================================================================
Total params: 718,960
Trainable params: 718,960
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 152010
	data size after sampling = 298232
	4 Labels in train : Counter({0: 74558, 1: 74558, 2: 74558, 3: 74558})
	4 Labels in valid : Counter({3: 15050, 0: 15047, 1: 14835, 2: 14715})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 238585 samples, validate on 59647 samples
Epoch 1/40
 - 19s - loss: 0.0280 - acc: 0.9936 - val_loss: 0.0118 - val_acc: 0.9967
Epoch 2/40
 - 19s - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0113 - val_acc: 0.9967
Epoch 3/40
 - 19s - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0116 - val_acc: 0.9968
Epoch 4/40
 - 19s - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0122 - val_acc: 0.9968
Epoch 5/40
 - 19s - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0120 - val_acc: 0.9969
Epoch 00005: early stopping
	TRAINING TIME: 7.43 minutes 
==================================================================================================
	PARSING TIME: 0.83 minutes 
==================================================================================================
	Identification : 0.764
	P, R  : 0.878, 0.676

==================================================================================================
	XP Ends: 7/2 (19 h:12)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (19h:12)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	HE Train (1139)
==================================================================================================
	Important sentence: 1139
	Token occurrences: 27447
	MWE number: 907
	MWE occurrences: 1223
	Continuous occurrences: 76.0 %
	Frequent MWE occurences: 10.0 %
	MWE length: 2.39
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 3

==================================================================================================
	 Test (3385)
==================================================================================================
	Important sentence: 454
	Token occurrences: 65843
	MWE number: 406
	MWE occurrences: 501
	Continuous occurrences: 76.0 %
	MWE length: 2.49
	Seen occurrences : 26% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 3

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 9966
	After : 2568

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2568 * POS : 241
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1243
	One occurrence keys in vocabulary 1243 / 2568
# Parameters = 729875
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_49 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_50 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_33 (Embedding)        (None, 5, 168)       431424      input_49[0][0]                   
__________________________________________________________________________________________________
embedding_34 (Embedding)        (None, 5, 25)        6025        input_50[0][0]                   
__________________________________________________________________________________________________
flatten_33 (Flatten)            (None, 840)          0           embedding_33[0][0]               
__________________________________________________________________________________________________
flatten_34 (Flatten)            (None, 125)          0           embedding_34[0][0]               
__________________________________________________________________________________________________
input_51 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 973)          0           flatten_33[0][0]                 
                                                                 flatten_34[0][0]                 
                                                                 input_51[0][0]                   
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 299)          291226      concatenate_17[0][0]             
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 299)          0           dense_33[0][0]                   
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 4)            1200        dropout_17[0][0]                 
==================================================================================================
Total params: 729,875
Trainable params: 729,875
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 56117
	data size after sampling = 109788
	4 Labels in train : Counter({0: 27447, 1: 27447, 2: 27447, 3: 27447})
	4 Labels in valid : Counter({0: 5534, 1: 5517, 2: 5489, 3: 5418})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 87830 samples, validate on 21958 samples
Epoch 1/40
 - 7s - loss: 0.0499 - acc: 0.9894 - val_loss: 0.0137 - val_acc: 0.9956
Epoch 2/40
 - 7s - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0142 - val_acc: 0.9957
Epoch 3/40
 - 7s - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0153 - val_acc: 0.9956
Epoch 4/40
 - 7s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0157 - val_acc: 0.9956
Epoch 5/40
 - 7s - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0170 - val_acc: 0.9957
Epoch 00005: early stopping
	TRAINING TIME: 1.83 minutes 
==================================================================================================
	PARSING TIME: 1.0 minutes 
==================================================================================================
	Identification : 0.345
	P, R  : 0.771, 0.222

==================================================================================================
	XP Ends: 7/2 (19 h:23)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (19h:23)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	HE Train (1139)
==================================================================================================
	Important sentence: 1139
	Token occurrences: 27447
	MWE number: 907
	MWE occurrences: 1223
	Continuous occurrences: 76.0 %
	Frequent MWE occurences: 10.0 %
	MWE length: 2.39
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 3

==================================================================================================
	 Test (3385)
==================================================================================================
	Important sentence: 454
	Token occurrences: 65843
	MWE number: 406
	MWE occurrences: 501
	Continuous occurrences: 76.0 %
	MWE length: 2.49
	Seen occurrences : 26% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 3

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 9966
	After : 2568

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2568 * POS : 241
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1243
	One occurrence keys in vocabulary 1243 / 2568
# Parameters = 729875
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_52 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_53 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_35 (Embedding)        (None, 5, 168)       431424      input_52[0][0]                   
__________________________________________________________________________________________________
embedding_36 (Embedding)        (None, 5, 25)        6025        input_53[0][0]                   
__________________________________________________________________________________________________
flatten_35 (Flatten)            (None, 840)          0           embedding_35[0][0]               
__________________________________________________________________________________________________
flatten_36 (Flatten)            (None, 125)          0           embedding_36[0][0]               
__________________________________________________________________________________________________
input_54 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 973)          0           flatten_35[0][0]                 
                                                                 flatten_36[0][0]                 
                                                                 input_54[0][0]                   
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 299)          291226      concatenate_18[0][0]             
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 299)          0           dense_35[0][0]                   
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 4)            1200        dropout_18[0][0]                 
==================================================================================================
Total params: 729,875
Trainable params: 729,875
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 56117
	data size after sampling = 109788
	4 Labels in train : Counter({0: 27447, 1: 27447, 2: 27447, 3: 27447})
	4 Labels in valid : Counter({3: 5601, 1: 5489, 0: 5466, 2: 5402})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 87830 samples, validate on 21958 samples
Epoch 1/40
 - 7s - loss: 0.0561 - acc: 0.9889 - val_loss: 0.0135 - val_acc: 0.9957
Epoch 2/40
 - 7s - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0112 - val_acc: 0.9966
Epoch 3/40
 - 7s - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0123 - val_acc: 0.9964
Epoch 4/40
 - 7s - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0121 - val_acc: 0.9964
Epoch 5/40
 - 7s - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0121 - val_acc: 0.9964
Epoch 00005: early stopping
	TRAINING TIME: 1.83 minutes 
==================================================================================================
	PARSING TIME: 1.0 minutes 
==================================================================================================
	Identification : 0.353
	P, R  : 0.786, 0.228

==================================================================================================
	XP Ends: 7/2 (19 h:33)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (19h:33)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	HI Train (418)
==================================================================================================
	Important sentence: 418
	Token occurrences: 9756
	MWE number: 250
	MWE occurrences: 499
	Continuous occurrences: 92.0 %
	Frequent MWE occurences: 30.0 %
	MWE length: 2.09
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (856)
==================================================================================================
	Important sentence: 418
	Token occurrences: 17850
	MWE number: 250
	MWE occurrences: 499
	Continuous occurrences: 92.0 %
	MWE length: 2.09
	Seen occurrences : 100% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 2272
	After : 526

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 526 * POS : 46
__________________________________________________________________________________________________
	Dashed keys in vocabulary 276
	One occurrence keys in vocabulary 276 / 526
# Parameters = 381944
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_55 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_56 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_37 (Embedding)        (None, 5, 168)       88368       input_55[0][0]                   
__________________________________________________________________________________________________
embedding_38 (Embedding)        (None, 5, 25)        1150        input_56[0][0]                   
__________________________________________________________________________________________________
flatten_37 (Flatten)            (None, 840)          0           embedding_37[0][0]               
__________________________________________________________________________________________________
flatten_38 (Flatten)            (None, 125)          0           embedding_38[0][0]               
__________________________________________________________________________________________________
input_57 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 973)          0           flatten_37[0][0]                 
                                                                 flatten_38[0][0]                 
                                                                 input_57[0][0]                   
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 299)          291226      concatenate_19[0][0]             
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 299)          0           dense_37[0][0]                   
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 4)            1200        dropout_19[0][0]                 
==================================================================================================
Total params: 381,944
Trainable params: 381,944
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 20011
	data size after sampling = 39024
	4 Labels in train : Counter({0: 9756, 1: 9756, 2: 9756, 3: 9756})
	4 Labels in valid : Counter({2: 1971, 0: 1953, 3: 1951, 1: 1930})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 31219 samples, validate on 7805 samples
Epoch 1/40
 - 2s - loss: 0.0720 - acc: 0.9872 - val_loss: 0.0104 - val_acc: 0.9969
Epoch 2/40
 - 2s - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0105 - val_acc: 0.9971
Epoch 3/40
 - 2s - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0101 - val_acc: 0.9972
Epoch 4/40
 - 2s - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0113 - val_acc: 0.9973
Epoch 5/40
 - 2s - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0131 - val_acc: 0.9972
Epoch 00005: early stopping
	TRAINING TIME: 0.47 minutes 
==================================================================================================
	PARSING TIME: 0.27 minutes 
==================================================================================================
	Identification : 0.977
	P, R  : 0.956, 0.998

==================================================================================================
	XP Ends: 7/2 (19 h:35)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (19h:35)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	HI Train (418)
==================================================================================================
	Important sentence: 418
	Token occurrences: 9756
	MWE number: 250
	MWE occurrences: 499
	Continuous occurrences: 92.0 %
	Frequent MWE occurences: 30.0 %
	MWE length: 2.09
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (856)
==================================================================================================
	Important sentence: 418
	Token occurrences: 17850
	MWE number: 250
	MWE occurrences: 499
	Continuous occurrences: 92.0 %
	MWE length: 2.09
	Seen occurrences : 100% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 2272
	After : 526

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 526 * POS : 46
__________________________________________________________________________________________________
	Dashed keys in vocabulary 276
	One occurrence keys in vocabulary 276 / 526
# Parameters = 381944
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_58 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_59 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_39 (Embedding)        (None, 5, 168)       88368       input_58[0][0]                   
__________________________________________________________________________________________________
embedding_40 (Embedding)        (None, 5, 25)        1150        input_59[0][0]                   
__________________________________________________________________________________________________
flatten_39 (Flatten)            (None, 840)          0           embedding_39[0][0]               
__________________________________________________________________________________________________
flatten_40 (Flatten)            (None, 125)          0           embedding_40[0][0]               
__________________________________________________________________________________________________
input_60 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 973)          0           flatten_39[0][0]                 
                                                                 flatten_40[0][0]                 
                                                                 input_60[0][0]                   
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 299)          291226      concatenate_20[0][0]             
__________________________________________________________________________________________________
dropout_20 (Dropout)            (None, 299)          0           dense_39[0][0]                   
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 4)            1200        dropout_20[0][0]                 
==================================================================================================
Total params: 381,944
Trainable params: 381,944
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 20011
	data size after sampling = 39024
	4 Labels in train : Counter({0: 9756, 1: 9756, 2: 9756, 3: 9756})
	4 Labels in valid : Counter({1: 2007, 3: 1974, 0: 1913, 2: 1911})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 31219 samples, validate on 7805 samples
Epoch 1/40
 - 2s - loss: 0.0692 - acc: 0.9875 - val_loss: 0.0051 - val_acc: 0.9985
Epoch 2/40
 - 2s - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0041 - val_acc: 0.9988
Epoch 3/40
 - 2s - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0035 - val_acc: 0.9988
Epoch 4/40
 - 2s - loss: 0.0022 - acc: 0.9991 - val_loss: 0.0036 - val_acc: 0.9987
Epoch 5/40
 - 2s - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0033 - val_acc: 0.9988
Epoch 00005: early stopping
	TRAINING TIME: 0.47 minutes 
==================================================================================================
	PARSING TIME: 0.27 minutes 
==================================================================================================
	Identification : 0.988
	P, R  : 0.978, 0.998

==================================================================================================
	XP Ends: 7/2 (19 h:36)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
# Seed: 0
==================================================================================================
XP Starts: 7/2 (19h:36)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	HR Train (995)
==================================================================================================
	Important sentence: 994
	Token occurrences: 25714
	MWE number: 902
	MWE occurrences: 1377
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 15.0 %
	MWE length: 2.21
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 161

==================================================================================================
	 Test (834)
==================================================================================================
	Important sentence: 368
	Token occurrences: 19621
	MWE number: 338
	MWE occurrences: 500
	Continuous occurrences: 56.0 %
	MWE length: 2.19
	Seen occurrences : 53% 
	Recognizable MWEs: 97.0 %
	Embedded occurrences: 56
	Interleaving occurrences: 9

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 6649
	After : 1781

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1781 * POS : 113
__________________________________________________________________________________________________
	MWE not in vocabulary 1
	Dashed keys in vocabulary 1006
	One occurrence keys in vocabulary 1006 / 1781
# Parameters = 594459
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_61 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_62 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_41 (Embedding)        (None, 5, 168)       299208      input_61[0][0]                   
__________________________________________________________________________________________________
embedding_42 (Embedding)        (None, 5, 25)        2825        input_62[0][0]                   
__________________________________________________________________________________________________
flatten_41 (Flatten)            (None, 840)          0           embedding_41[0][0]               
__________________________________________________________________________________________________
flatten_42 (Flatten)            (None, 125)          0           embedding_42[0][0]               
__________________________________________________________________________________________________
input_63 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 973)          0           flatten_41[0][0]                 
                                                                 flatten_42[0][0]                 
                                                                 input_63[0][0]                   
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 299)          291226      concatenate_21[0][0]             
__________________________________________________________________________________________________
dropout_21 (Dropout)            (None, 299)          0           dense_41[0][0]                   
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 4)            1200        dropout_21[0][0]                 
==================================================================================================
Total params: 594,459
Trainable params: 594,459
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 52804
	data size after sampling = 102856
	4 Labels in train : Counter({0: 25714, 1: 25714, 2: 25714, 3: 25714})
	4 Labels in valid : Counter({3: 5200, 1: 5146, 0: 5126, 2: 5100})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 82284 samples, validate on 20572 samples
Epoch 1/40
 - 6s - loss: 0.0679 - acc: 0.9856 - val_loss: 0.0237 - val_acc: 0.9937
Epoch 2/40
 - 6s - loss: 0.0180 - acc: 0.9947 - val_loss: 0.0227 - val_acc: 0.9938
Epoch 3/40
 - 6s - loss: 0.0131 - acc: 0.9957 - val_loss: 0.0242 - val_acc: 0.9933
Epoch 4/40
 - 6s - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0252 - val_acc: 0.9932
Epoch 5/40
 - 6s - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0251 - val_acc: 0.9936
Epoch 00005: early stopping
	TRAINING TIME: 1.63 minutes 
==================================================================================================
	PARSING TIME: 0.3 minutes 
==================================================================================================
	Identification : 0.595
	P, R  : 0.777, 0.482

==================================================================================================
	XP Ends: 7/2 (19 h:40)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
# Seed: 1
==================================================================================================
XP Starts: 7/2 (19h:40)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	HR Train (995)
==================================================================================================
	Important sentence: 994
	Token occurrences: 25714
	MWE number: 902
	MWE occurrences: 1377
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 15.0 %
	MWE length: 2.21
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 161

==================================================================================================
	 Test (834)
==================================================================================================
	Important sentence: 368
	Token occurrences: 19621
	MWE number: 338
	MWE occurrences: 500
	Continuous occurrences: 56.0 %
	MWE length: 2.19
	Seen occurrences : 53% 
	Recognizable MWEs: 97.0 %
	Embedded occurrences: 56
	Interleaving occurrences: 9

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 6649
	After : 1781

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1781 * POS : 113
__________________________________________________________________________________________________
	MWE not in vocabulary 1
	Dashed keys in vocabulary 1006
	One occurrence keys in vocabulary 1006 / 1781
# Parameters = 594459
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_64 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_65 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_43 (Embedding)        (None, 5, 168)       299208      input_64[0][0]                   
__________________________________________________________________________________________________
embedding_44 (Embedding)        (None, 5, 25)        2825        input_65[0][0]                   
__________________________________________________________________________________________________
flatten_43 (Flatten)            (None, 840)          0           embedding_43[0][0]               
__________________________________________________________________________________________________
flatten_44 (Flatten)            (None, 125)          0           embedding_44[0][0]               
__________________________________________________________________________________________________
input_66 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 973)          0           flatten_43[0][0]                 
                                                                 flatten_44[0][0]                 
                                                                 input_66[0][0]                   
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 299)          291226      concatenate_22[0][0]             
__________________________________________________________________________________________________
dropout_22 (Dropout)            (None, 299)          0           dense_43[0][0]                   
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 4)            1200        dropout_22[0][0]                 
==================================================================================================
Total params: 594,459
Trainable params: 594,459
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 52804
	data size after sampling = 102856
	4 Labels in train : Counter({0: 25714, 1: 25714, 2: 25714, 3: 25714})
	4 Labels in valid : Counter({3: 5181, 0: 5149, 1: 5143, 2: 5099})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 82284 samples, validate on 20572 samples
Epoch 1/40
 - 6s - loss: 0.0683 - acc: 0.9857 - val_loss: 0.0235 - val_acc: 0.9934
Epoch 2/40
 - 6s - loss: 0.0176 - acc: 0.9945 - val_loss: 0.0218 - val_acc: 0.9938
Epoch 3/40
 - 6s - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0218 - val_acc: 0.9938
Epoch 4/40
 - 6s - loss: 0.0100 - acc: 0.9968 - val_loss: 0.0227 - val_acc: 0.9939
Epoch 5/40
 - 6s - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0241 - val_acc: 0.9933
Epoch 00005: early stopping
	TRAINING TIME: 1.62 minutes 
==================================================================================================
	PARSING TIME: 0.3 minutes 
==================================================================================================
	Identification : 0.588
	P, R  : 0.69, 0.512

==================================================================================================
	XP Ends: 7/2 (19 h:43)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
# Seed: 0
==================================================================================================
XP Starts: 7/2 (19h:43)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	HU Train (3165)
==================================================================================================
	Important sentence: 3165
	Token occurrences: 89543
	MWE number: 696
	MWE occurrences: 6138
	Continuous occurrences: 19.0 %
	Frequent MWE occurences: 85.0 %
	MWE length: 1.26
	Recognizable MWEs: 100.0 %
	MWT occurrences: 4564
	Embedded occurrences: 161

==================================================================================================
	 Test (601)
==================================================================================================
	Important sentence: 430
	Token occurrences: 15564
	MWE number: 192
	MWE occurrences: 779
	Continuous occurrences: 14.0 %
	MWE length: 1.22
	Seen occurrences : 92% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 608
	Embedded occurrences: 14
	Interleaving occurrences: 2

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 5941
	After : 1036

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1036 * POS : 50
__________________________________________________________________________________________________
	Dashed keys in vocabulary 459
	One occurrence keys in vocabulary 459 / 1036
# Parameters = 467724
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_67 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_68 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_45 (Embedding)        (None, 5, 168)       174048      input_67[0][0]                   
__________________________________________________________________________________________________
embedding_46 (Embedding)        (None, 5, 25)        1250        input_68[0][0]                   
__________________________________________________________________________________________________
flatten_45 (Flatten)            (None, 840)          0           embedding_45[0][0]               
__________________________________________________________________________________________________
flatten_46 (Flatten)            (None, 125)          0           embedding_46[0][0]               
__________________________________________________________________________________________________
input_69 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 973)          0           flatten_45[0][0]                 
                                                                 flatten_46[0][0]                 
                                                                 input_69[0][0]                   
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 299)          291226      concatenate_23[0][0]             
__________________________________________________________________________________________________
dropout_23 (Dropout)            (None, 299)          0           dense_45[0][0]                   
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 4)            1200        dropout_23[0][0]                 
==================================================================================================
Total params: 467,724
Trainable params: 467,724
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 185218
	data size after sampling = 358172
	4 Labels in train : Counter({0: 89543, 1: 89543, 2: 89543, 3: 89543})
	4 Labels in valid : Counter({0: 18033, 1: 17927, 3: 17844, 2: 17831})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 286537 samples, validate on 71635 samples
Epoch 1/40
 - 21s - loss: 0.0807 - acc: 0.9943 - val_loss: 0.0054 - val_acc: 0.9985
Epoch 2/40
 - 21s - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0048 - val_acc: 0.9987
Epoch 3/40
 - 21s - loss: 0.0039 - acc: 0.9992 - val_loss: 0.0051 - val_acc: 0.9987
Epoch 4/40
 - 21s - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0050 - val_acc: 0.9987
Epoch 5/40
 - 21s - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0050 - val_acc: 0.9988
Epoch 00005: early stopping
	TRAINING TIME: 10.45 minutes 
==================================================================================================
	PARSING TIME: 0.23 minutes 
==================================================================================================
	Identification : 0.947
	P, R  : 0.983, 0.914

==================================================================================================
	XP Ends: 7/2 (19 h:58)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
# Seed: 1
==================================================================================================
XP Starts: 7/2 (19h:58)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	HU Train (3165)
==================================================================================================
	Important sentence: 3165
	Token occurrences: 89543
	MWE number: 696
	MWE occurrences: 6138
	Continuous occurrences: 19.0 %
	Frequent MWE occurences: 85.0 %
	MWE length: 1.26
	Recognizable MWEs: 100.0 %
	MWT occurrences: 4564
	Embedded occurrences: 161

==================================================================================================
	 Test (601)
==================================================================================================
	Important sentence: 430
	Token occurrences: 15564
	MWE number: 192
	MWE occurrences: 779
	Continuous occurrences: 14.0 %
	MWE length: 1.22
	Seen occurrences : 92% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 608
	Embedded occurrences: 14
	Interleaving occurrences: 2

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 5941
	After : 1036

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 1036 * POS : 50
__________________________________________________________________________________________________
	Dashed keys in vocabulary 459
	One occurrence keys in vocabulary 459 / 1036
# Parameters = 467724
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_70 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_71 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_47 (Embedding)        (None, 5, 168)       174048      input_70[0][0]                   
__________________________________________________________________________________________________
embedding_48 (Embedding)        (None, 5, 25)        1250        input_71[0][0]                   
__________________________________________________________________________________________________
flatten_47 (Flatten)            (None, 840)          0           embedding_47[0][0]               
__________________________________________________________________________________________________
flatten_48 (Flatten)            (None, 125)          0           embedding_48[0][0]               
__________________________________________________________________________________________________
input_72 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 973)          0           flatten_47[0][0]                 
                                                                 flatten_48[0][0]                 
                                                                 input_72[0][0]                   
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 299)          291226      concatenate_24[0][0]             
__________________________________________________________________________________________________
dropout_24 (Dropout)            (None, 299)          0           dense_47[0][0]                   
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 4)            1200        dropout_24[0][0]                 
==================================================================================================
Total params: 467,724
Trainable params: 467,724
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 185218
	data size after sampling = 358172
	4 Labels in train : Counter({0: 89543, 1: 89543, 2: 89543, 3: 89543})
	4 Labels in valid : Counter({0: 18031, 2: 17897, 3: 17855, 1: 17852})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 286537 samples, validate on 71635 samples
Epoch 1/40
 - 21s - loss: 0.0234 - acc: 0.9963 - val_loss: 0.0071 - val_acc: 0.9983
Epoch 2/40
 - 22s - loss: 0.0048 - acc: 0.9989 - val_loss: 0.0062 - val_acc: 0.9987
Epoch 3/40
 - 22s - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0062 - val_acc: 0.9987
Epoch 4/40
 - 21s - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0063 - val_acc: 0.9987
Epoch 5/40
 - 22s - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0061 - val_acc: 0.9988
Epoch 00005: early stopping
	TRAINING TIME: 10.47 minutes 
==================================================================================================
	PARSING TIME: 0.25 minutes 
==================================================================================================
	Identification : 0.948
	P, R  : 0.989, 0.911

==================================================================================================
	XP Ends: 7/2 (20 h:13)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
# Seed: 0
==================================================================================================
XP Starts: 7/2 (20h:13)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	IT Train (1980)
==================================================================================================
	Important sentence: 1964
	Token occurrences: 79800
	MWE number: 1162
	MWE occurrences: 2426
	Continuous occurrences: 72.0 %
	Frequent MWE occurences: 31.0 %
	MWE length: 2.46
	Recognizable MWEs: 100.0 %
	MWT occurrences: 4
	Embedded occurrences: 77

==================================================================================================
	 Test (917)
==================================================================================================
	Important sentence: 303
	Token occurrences: 31220
	MWE number: 387
	MWE occurrences: 500
	Continuous occurrences: 67.0 %
	MWE length: 2.49
	Seen occurrences : 49% 
	Recognizable MWEs: 96.0 %
	MWT occurrences: 3
	Embedded occurrences: 18
	Interleaving occurrences: 13

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 11129
	After : 2611

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2611 * POS : 211
__________________________________________________________________________________________________
	Important words not in vocabulary 2
	MWE not in vocabulary 4
	Dashed keys in vocabulary 1647
	One occurrence keys in vocabulary 1647 / 2611
# Parameters = 736349
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_73 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_74 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_49 (Embedding)        (None, 5, 168)       438648      input_73[0][0]                   
__________________________________________________________________________________________________
embedding_50 (Embedding)        (None, 5, 25)        5275        input_74[0][0]                   
__________________________________________________________________________________________________
flatten_49 (Flatten)            (None, 840)          0           embedding_49[0][0]               
__________________________________________________________________________________________________
flatten_50 (Flatten)            (None, 125)          0           embedding_50[0][0]               
__________________________________________________________________________________________________
input_75 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 973)          0           flatten_49[0][0]                 
                                                                 flatten_50[0][0]                 
                                                                 input_75[0][0]                   
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 299)          291226      concatenate_25[0][0]             
__________________________________________________________________________________________________
dropout_25 (Dropout)            (None, 299)          0           dense_49[0][0]                   
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 4)            1200        dropout_25[0][0]                 
==================================================================================================
Total params: 736,349
Trainable params: 736,349
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 162024
	data size after sampling = 319200
	4 Labels in train : Counter({0: 79800, 1: 79800, 2: 79800, 3: 79800})
	4 Labels in valid : Counter({3: 16000, 0: 15995, 1: 15958, 2: 15887})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 255360 samples, validate on 63840 samples
Epoch 1/40
 - 20s - loss: 0.0319 - acc: 0.9927 - val_loss: 0.0166 - val_acc: 0.9953
Epoch 2/40
 - 20s - loss: 0.0120 - acc: 0.9966 - val_loss: 0.0147 - val_acc: 0.9958
Epoch 3/40
 - 20s - loss: 0.0090 - acc: 0.9973 - val_loss: 0.0147 - val_acc: 0.9959
Epoch 4/40
 - 20s - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0154 - val_acc: 0.9960
Epoch 5/40
 - 20s - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0161 - val_acc: 0.9959
Epoch 00005: early stopping
	TRAINING TIME: 6.92 minutes 
==================================================================================================
	PARSING TIME: 0.48 minutes 
==================================================================================================
	Identification : 0.521
	P, R  : 0.795, 0.388

==================================================================================================
	XP Ends: 7/2 (20 h:29)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
# Seed: 1
==================================================================================================
XP Starts: 7/2 (20h:29)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	IT Train (1980)
==================================================================================================
	Important sentence: 1964
	Token occurrences: 79800
	MWE number: 1162
	MWE occurrences: 2426
	Continuous occurrences: 72.0 %
	Frequent MWE occurences: 31.0 %
	MWE length: 2.46
	Recognizable MWEs: 100.0 %
	MWT occurrences: 4
	Embedded occurrences: 77

==================================================================================================
	 Test (917)
==================================================================================================
	Important sentence: 303
	Token occurrences: 31220
	MWE number: 387
	MWE occurrences: 500
	Continuous occurrences: 67.0 %
	MWE length: 2.49
	Seen occurrences : 49% 
	Recognizable MWEs: 96.0 %
	MWT occurrences: 3
	Embedded occurrences: 18
	Interleaving occurrences: 13

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 11129
	After : 2611

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2611 * POS : 211
__________________________________________________________________________________________________
	Important words not in vocabulary 2
	MWE not in vocabulary 4
	Dashed keys in vocabulary 1647
	One occurrence keys in vocabulary 1647 / 2611
# Parameters = 736349
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_76 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_77 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_51 (Embedding)        (None, 5, 168)       438648      input_76[0][0]                   
__________________________________________________________________________________________________
embedding_52 (Embedding)        (None, 5, 25)        5275        input_77[0][0]                   
__________________________________________________________________________________________________
flatten_51 (Flatten)            (None, 840)          0           embedding_51[0][0]               
__________________________________________________________________________________________________
flatten_52 (Flatten)            (None, 125)          0           embedding_52[0][0]               
__________________________________________________________________________________________________
input_78 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 973)          0           flatten_51[0][0]                 
                                                                 flatten_52[0][0]                 
                                                                 input_78[0][0]                   
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 299)          291226      concatenate_26[0][0]             
__________________________________________________________________________________________________
dropout_26 (Dropout)            (None, 299)          0           dense_51[0][0]                   
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 4)            1200        dropout_26[0][0]                 
==================================================================================================
Total params: 736,349
Trainable params: 736,349
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 162024
	data size after sampling = 319200
	4 Labels in train : Counter({0: 79800, 1: 79800, 2: 79800, 3: 79800})
	4 Labels in valid : Counter({3: 16088, 1: 15971, 0: 15955, 2: 15826})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 255360 samples, validate on 63840 samples
Epoch 1/40
 - 20s - loss: 0.0402 - acc: 0.9920 - val_loss: 0.0142 - val_acc: 0.9958
Epoch 2/40
 - 20s - loss: 0.0121 - acc: 0.9964 - val_loss: 0.0134 - val_acc: 0.9961
Epoch 3/40
 - 20s - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0133 - val_acc: 0.9963
Epoch 4/40
 - 20s - loss: 0.0073 - acc: 0.9978 - val_loss: 0.0136 - val_acc: 0.9961
Epoch 5/40
 - 20s - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0142 - val_acc: 0.9962
Epoch 00005: early stopping
	TRAINING TIME: 6.92 minutes 
==================================================================================================
	PARSING TIME: 0.48 minutes 
==================================================================================================
	Identification : 0.517
	P, R  : 0.828, 0.376

==================================================================================================
	XP Ends: 7/2 (20 h:46)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (20h:46)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	LT Train (297)
==================================================================================================
	Important sentence: 297
	Token occurrences: 6834
	MWE number: 192
	MWE occurrences: 312
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 14.0 %
	MWE length: 2.16
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2337)
==================================================================================================
	Important sentence: 148
	Token occurrences: 43009
	MWE number: 109
	MWE occurrences: 152
	Continuous occurrences: 55.0 %
	MWE length: 2.14
	Seen occurrences : 100% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 2353
	After : 504

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 504 * POS : 56
__________________________________________________________________________________________________
	Dashed keys in vocabulary 238
	One occurrence keys in vocabulary 238 / 504
# Parameters = 378498
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_79 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_80 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_53 (Embedding)        (None, 5, 168)       84672       input_79[0][0]                   
__________________________________________________________________________________________________
embedding_54 (Embedding)        (None, 5, 25)        1400        input_80[0][0]                   
__________________________________________________________________________________________________
flatten_53 (Flatten)            (None, 840)          0           embedding_53[0][0]               
__________________________________________________________________________________________________
flatten_54 (Flatten)            (None, 125)          0           embedding_54[0][0]               
__________________________________________________________________________________________________
input_81 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 973)          0           flatten_53[0][0]                 
                                                                 flatten_54[0][0]                 
                                                                 input_81[0][0]                   
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 299)          291226      concatenate_27[0][0]             
__________________________________________________________________________________________________
dropout_27 (Dropout)            (None, 299)          0           dense_53[0][0]                   
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 4)            1200        dropout_27[0][0]                 
==================================================================================================
Total params: 378,498
Trainable params: 378,498
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 13980
	data size after sampling = 27336
	4 Labels in train : Counter({0: 6834, 1: 6834, 2: 6834, 3: 6834})
	4 Labels in valid : Counter({2: 1394, 1: 1367, 0: 1361, 3: 1346})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 21868 samples, validate on 5468 samples
Epoch 1/40
 - 2s - loss: 0.1801 - acc: 0.9789 - val_loss: 0.0160 - val_acc: 0.9934
Epoch 2/40
 - 2s - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0162 - val_acc: 0.9947
Epoch 3/40
 - 2s - loss: 0.0062 - acc: 0.9985 - val_loss: 0.0168 - val_acc: 0.9943
Epoch 4/40
 - 2s - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0172 - val_acc: 0.9936
Epoch 5/40
 - 2s - loss: 0.0041 - acc: 0.9984 - val_loss: 0.0163 - val_acc: 0.9951
Epoch 00005: early stopping
	TRAINING TIME: 0.32 minutes 
==================================================================================================
	PARSING TIME: 0.62 minutes 
==================================================================================================
	Identification : 0.874
	P, R  : 0.776, 1.0

==================================================================================================
	XP Ends: 7/2 (20 h:49)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (20h:49)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	LT Train (297)
==================================================================================================
	Important sentence: 297
	Token occurrences: 6834
	MWE number: 192
	MWE occurrences: 312
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 14.0 %
	MWE length: 2.16
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2337)
==================================================================================================
	Important sentence: 148
	Token occurrences: 43009
	MWE number: 109
	MWE occurrences: 152
	Continuous occurrences: 55.0 %
	MWE length: 2.14
	Seen occurrences : 100% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 2353
	After : 504

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 504 * POS : 56
__________________________________________________________________________________________________
	Dashed keys in vocabulary 238
	One occurrence keys in vocabulary 238 / 504
# Parameters = 378498
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_82 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_83 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_55 (Embedding)        (None, 5, 168)       84672       input_82[0][0]                   
__________________________________________________________________________________________________
embedding_56 (Embedding)        (None, 5, 25)        1400        input_83[0][0]                   
__________________________________________________________________________________________________
flatten_55 (Flatten)            (None, 840)          0           embedding_55[0][0]               
__________________________________________________________________________________________________
flatten_56 (Flatten)            (None, 125)          0           embedding_56[0][0]               
__________________________________________________________________________________________________
input_84 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 973)          0           flatten_55[0][0]                 
                                                                 flatten_56[0][0]                 
                                                                 input_84[0][0]                   
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 299)          291226      concatenate_28[0][0]             
__________________________________________________________________________________________________
dropout_28 (Dropout)            (None, 299)          0           dense_55[0][0]                   
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 4)            1200        dropout_28[0][0]                 
==================================================================================================
Total params: 378,498
Trainable params: 378,498
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 13980
	data size after sampling = 27336
	4 Labels in train : Counter({0: 6834, 1: 6834, 2: 6834, 3: 6834})
	4 Labels in valid : Counter({3: 1399, 1: 1369, 0: 1366, 2: 1334})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 21868 samples, validate on 5468 samples
Epoch 1/40
 - 2s - loss: 0.1081 - acc: 0.9799 - val_loss: 0.0147 - val_acc: 0.9960
Epoch 2/40
 - 2s - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0116 - val_acc: 0.9963
Epoch 3/40
 - 2s - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0130 - val_acc: 0.9952
Epoch 4/40
 - 2s - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0111 - val_acc: 0.9963
Epoch 5/40
 - 2s - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0121 - val_acc: 0.9960
Epoch 00005: early stopping
	TRAINING TIME: 0.33 minutes 
==================================================================================================
	PARSING TIME: 0.62 minutes 
==================================================================================================
	Identification : 0.953
	P, R  : 0.91, 1.0

==================================================================================================
	XP Ends: 7/2 (20 h:53)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
# Seed: 0
==================================================================================================
XP Starts: 7/2 (20h:53)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	PL Train (3456)
==================================================================================================
	Important sentence: 3456
	Token occurrences: 71272
	MWE number: 1645
	MWE occurrences: 4059
	Continuous occurrences: 71.0 %
	Frequent MWE occurences: 46.0 %
	MWE length: 2.13
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 94

==================================================================================================
	 Test (1763)
==================================================================================================
	Important sentence: 462
	Token occurrences: 26014
	MWE number: 360
	MWE occurrences: 515
	Continuous occurrences: 72.0 %
	MWE length: 2.15
	Seen occurrences : 70% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 7
	Interleaving occurrences: 6

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 12413
	After : 3160

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 3160 * POS : 138
__________________________________________________________________________________________________
	MWE not in vocabulary 5
	Dashed keys in vocabulary 1865
	One occurrence keys in vocabulary 1865 / 3160
# Parameters = 826756
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_85 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_86 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_57 (Embedding)        (None, 5, 168)       530880      input_85[0][0]                   
__________________________________________________________________________________________________
embedding_58 (Embedding)        (None, 5, 25)        3450        input_86[0][0]                   
__________________________________________________________________________________________________
flatten_57 (Flatten)            (None, 840)          0           embedding_57[0][0]               
__________________________________________________________________________________________________
flatten_58 (Flatten)            (None, 125)          0           embedding_58[0][0]               
__________________________________________________________________________________________________
input_87 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 973)          0           flatten_57[0][0]                 
                                                                 flatten_58[0][0]                 
                                                                 input_87[0][0]                   
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 299)          291226      concatenate_29[0][0]             
__________________________________________________________________________________________________
dropout_29 (Dropout)            (None, 299)          0           dense_57[0][0]                   
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 4)            1200        dropout_29[0][0]                 
==================================================================================================
Total params: 826,756
Trainable params: 826,756
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 146598
	data size after sampling = 285088
	4 Labels in train : Counter({0: 71272, 1: 71272, 2: 71272, 3: 71272})
	4 Labels in valid : Counter({0: 14340, 1: 14290, 2: 14241, 3: 14147})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 228070 samples, validate on 57018 samples
Epoch 1/40
 - 18s - loss: 0.0340 - acc: 0.9923 - val_loss: 0.0148 - val_acc: 0.9954
Epoch 2/40
 - 18s - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0152 - val_acc: 0.9953
Epoch 3/40
 - 18s - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0143 - val_acc: 0.9956
Epoch 4/40
 - 18s - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0150 - val_acc: 0.9953
Epoch 5/40
 - 18s - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0156 - val_acc: 0.9954
Epoch 00005: early stopping
	TRAINING TIME: 9.13 minutes 
==================================================================================================
	PARSING TIME: 0.43 minutes 
==================================================================================================
	Identification : 0.744
	P, R  : 0.864, 0.654

==================================================================================================
	XP Ends: 7/2 (21 h:11)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
# Seed: 1
==================================================================================================
XP Starts: 7/2 (21h:11)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	PL Train (3456)
==================================================================================================
	Important sentence: 3456
	Token occurrences: 71272
	MWE number: 1645
	MWE occurrences: 4059
	Continuous occurrences: 71.0 %
	Frequent MWE occurences: 46.0 %
	MWE length: 2.13
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 94

==================================================================================================
	 Test (1763)
==================================================================================================
	Important sentence: 462
	Token occurrences: 26014
	MWE number: 360
	MWE occurrences: 515
	Continuous occurrences: 72.0 %
	MWE length: 2.15
	Seen occurrences : 70% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 7
	Interleaving occurrences: 6

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 12413
	After : 3160

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 3160 * POS : 138
__________________________________________________________________________________________________
	MWE not in vocabulary 5
	Dashed keys in vocabulary 1865
	One occurrence keys in vocabulary 1865 / 3160
# Parameters = 826756
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_88 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_89 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_59 (Embedding)        (None, 5, 168)       530880      input_88[0][0]                   
__________________________________________________________________________________________________
embedding_60 (Embedding)        (None, 5, 25)        3450        input_89[0][0]                   
__________________________________________________________________________________________________
flatten_59 (Flatten)            (None, 840)          0           embedding_59[0][0]               
__________________________________________________________________________________________________
flatten_60 (Flatten)            (None, 125)          0           embedding_60[0][0]               
__________________________________________________________________________________________________
input_90 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 973)          0           flatten_59[0][0]                 
                                                                 flatten_60[0][0]                 
                                                                 input_90[0][0]                   
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 299)          291226      concatenate_30[0][0]             
__________________________________________________________________________________________________
dropout_30 (Dropout)            (None, 299)          0           dense_59[0][0]                   
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 4)            1200        dropout_30[0][0]                 
==================================================================================================
Total params: 826,756
Trainable params: 826,756
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 146598
	data size after sampling = 285088
	4 Labels in train : Counter({0: 71272, 1: 71272, 2: 71272, 3: 71272})
	4 Labels in valid : Counter({3: 14512, 1: 14246, 0: 14220, 2: 14040})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 228070 samples, validate on 57018 samples
Epoch 1/40
 - 18s - loss: 0.0302 - acc: 0.9928 - val_loss: 0.0139 - val_acc: 0.9958
Epoch 2/40
 - 18s - loss: 0.0107 - acc: 0.9968 - val_loss: 0.0125 - val_acc: 0.9962
Epoch 3/40
 - 18s - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0121 - val_acc: 0.9963
Epoch 4/40
 - 18s - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0126 - val_acc: 0.9964
Epoch 5/40
 - 18s - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0132 - val_acc: 0.9965
Epoch 00005: early stopping
	TRAINING TIME: 9.12 minutes 
==================================================================================================
	PARSING TIME: 0.4 minutes 
==================================================================================================
	Identification : 0.739
	P, R  : 0.855, 0.65

==================================================================================================
	XP Ends: 7/2 (21 h:29)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 0
==================================================================================================
XP Starts: 7/2 (21h:29)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 9194
	After : 2807

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2807 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 2807
# Parameters = 768227
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_91 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_92 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_61 (Embedding)        (None, 5, 168)       471576      input_91[0][0]                   
__________________________________________________________________________________________________
embedding_62 (Embedding)        (None, 5, 25)        4225        input_92[0][0]                   
__________________________________________________________________________________________________
flatten_61 (Flatten)            (None, 840)          0           embedding_61[0][0]               
__________________________________________________________________________________________________
flatten_62 (Flatten)            (None, 125)          0           embedding_62[0][0]               
__________________________________________________________________________________________________
input_93 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 973)          0           flatten_61[0][0]                 
                                                                 flatten_62[0][0]                 
                                                                 input_93[0][0]                   
__________________________________________________________________________________________________
dense_61 (Dense)                (None, 299)          291226      concatenate_31[0][0]             
__________________________________________________________________________________________________
dropout_31 (Dropout)            (None, 299)          0           dense_61[0][0]                   
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 4)            1200        dropout_31[0][0]                 
==================================================================================================
Total params: 768,227
Trainable params: 768,227
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({0: 12122, 3: 12071, 1: 12046, 2: 12035})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 15s - loss: 0.0282 - acc: 0.9929 - val_loss: 0.0122 - val_acc: 0.9966
Epoch 2/40
 - 15s - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0126 - val_acc: 0.9965
Epoch 3/40
 - 15s - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0120 - val_acc: 0.9966
Epoch 4/40
 - 15s - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0128 - val_acc: 0.9968
Epoch 5/40
 - 15s - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0136 - val_acc: 0.9966
Epoch 00005: early stopping
	TRAINING TIME: 6.07 minutes 
==================================================================================================
	PARSING TIME: 1.02 minutes 
==================================================================================================
	Identification : 0.637
	P, R  : 0.722, 0.57

==================================================================================================
	XP Ends: 7/2 (21 h:46)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
# Seed: 1
==================================================================================================
XP Starts: 7/2 (21h:46)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	PT Train (2305)
==================================================================================================
	Important sentence: 2305
	Token occurrences: 60342
	MWE number: 1412
	MWE occurrences: 2542
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 5

==================================================================================================
	 Test (3117)
==================================================================================================
	Important sentence: 494
	Token occurrences: 64078
	MWE number: 429
	MWE occurrences: 553
	Continuous occurrences: 59.0 %
	MWE length: 2.25
	Seen occurrences : 62% 
	Recognizable MWEs: 98.0 %
	Embedded occurrences: 4
	Interleaving occurrences: 8

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 9194
	After : 2807

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2807 * POS : 169
__________________________________________________________________________________________________
	Important words not in vocabulary 1
	MWE not in vocabulary 3
	Dashed keys in vocabulary 1674
	One occurrence keys in vocabulary 1674 / 2807
# Parameters = 768227
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_94 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_95 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_63 (Embedding)        (None, 5, 168)       471576      input_94[0][0]                   
__________________________________________________________________________________________________
embedding_64 (Embedding)        (None, 5, 25)        4225        input_95[0][0]                   
__________________________________________________________________________________________________
flatten_63 (Flatten)            (None, 840)          0           embedding_63[0][0]               
__________________________________________________________________________________________________
flatten_64 (Flatten)            (None, 125)          0           embedding_64[0][0]               
__________________________________________________________________________________________________
input_96 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 973)          0           flatten_63[0][0]                 
                                                                 flatten_64[0][0]                 
                                                                 input_96[0][0]                   
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 299)          291226      concatenate_32[0][0]             
__________________________________________________________________________________________________
dropout_32 (Dropout)            (None, 299)          0           dense_63[0][0]                   
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 4)            1200        dropout_32[0][0]                 
==================================================================================================
Total params: 768,227
Trainable params: 768,227
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 123224
	data size after sampling = 241368
	4 Labels in train : Counter({0: 60342, 1: 60342, 2: 60342, 3: 60342})
	4 Labels in valid : Counter({3: 12233, 1: 12068, 0: 12003, 2: 11970})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 193094 samples, validate on 48274 samples
Epoch 1/40
 - 15s - loss: 0.0294 - acc: 0.9928 - val_loss: 0.0093 - val_acc: 0.9971
Epoch 2/40
 - 15s - loss: 0.0093 - acc: 0.9971 - val_loss: 0.0086 - val_acc: 0.9972
Epoch 3/40
 - 15s - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0089 - val_acc: 0.9972
Epoch 4/40
 - 15s - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0088 - val_acc: 0.9972
Epoch 5/40
 - 15s - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0091 - val_acc: 0.9973
Epoch 00005: early stopping
	TRAINING TIME: 6.02 minutes 
==================================================================================================
	PARSING TIME: 1.03 minutes 
==================================================================================================
	Identification : 0.623
	P, R  : 0.686, 0.57

==================================================================================================
	XP Ends: 7/2 (22 h:3)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (22h:3)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	RO Train (1478)
==================================================================================================
	Important sentence: 1478
	Token occurrences: 52656
	MWE number: 371
	MWE occurrences: 1645
	Continuous occurrences: 68.0 %
	Frequent MWE occurences: 65.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 2

==================================================================================================
	 Test (7065)
==================================================================================================
	Important sentence: 529
	Token occurrences: 118658
	MWE number: 197
	MWE occurrences: 589
	Continuous occurrences: 70.0 %
	MWE length: 2.15
	Seen occurrences : 89% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 6679
	After : 877

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 877 * POS : 67
__________________________________________________________________________________________________
	Dashed keys in vocabulary 528
	One occurrence keys in vocabulary 528 / 877
# Parameters = 441437
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_97 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_98 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_65 (Embedding)        (None, 5, 168)       147336      input_97[0][0]                   
__________________________________________________________________________________________________
embedding_66 (Embedding)        (None, 5, 25)        1675        input_98[0][0]                   
__________________________________________________________________________________________________
flatten_65 (Flatten)            (None, 840)          0           embedding_65[0][0]               
__________________________________________________________________________________________________
flatten_66 (Flatten)            (None, 125)          0           embedding_66[0][0]               
__________________________________________________________________________________________________
input_99 (InputLayer)           (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 973)          0           flatten_65[0][0]                 
                                                                 flatten_66[0][0]                 
                                                                 input_99[0][0]                   
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 299)          291226      concatenate_33[0][0]             
__________________________________________________________________________________________________
dropout_33 (Dropout)            (None, 299)          0           dense_65[0][0]                   
__________________________________________________________________________________________________
dense_66 (Dense)                (None, 4)            1200        dropout_33[0][0]                 
==================================================================================================
Total params: 441,437
Trainable params: 441,437
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 106957
	data size after sampling = 210624
	4 Labels in train : Counter({0: 52656, 1: 52656, 2: 52656, 3: 52656})
	4 Labels in valid : Counter({1: 10605, 3: 10570, 0: 10494, 2: 10456})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 168499 samples, validate on 42125 samples
Epoch 1/40
 - 13s - loss: 10.1725 - acc: 0.5774 - val_loss: 0.0101 - val_acc: 0.9967
Epoch 2/40
 - 13s - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0035 - val_acc: 0.9989
Epoch 3/40
 - 13s - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0029 - val_acc: 0.9992
Epoch 4/40
 - 13s - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0029 - val_acc: 0.9991
Epoch 5/40
 - 13s - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0030 - val_acc: 0.9992
Epoch 00005: early stopping
	TRAINING TIME: 3.88 minutes 
==================================================================================================
	PARSING TIME: 1.77 minutes 
==================================================================================================
	Identification : 0.847
	P, R  : 0.827, 0.868

==================================================================================================
	XP Ends: 7/2 (22 h:18)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (22h:18)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	RO Train (1478)
==================================================================================================
	Important sentence: 1478
	Token occurrences: 52656
	MWE number: 371
	MWE occurrences: 1645
	Continuous occurrences: 68.0 %
	Frequent MWE occurences: 65.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 2

==================================================================================================
	 Test (7065)
==================================================================================================
	Important sentence: 529
	Token occurrences: 118658
	MWE number: 197
	MWE occurrences: 589
	Continuous occurrences: 70.0 %
	MWE length: 2.15
	Seen occurrences : 89% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 6679
	After : 877

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 877 * POS : 67
__________________________________________________________________________________________________
	Dashed keys in vocabulary 528
	One occurrence keys in vocabulary 528 / 877
# Parameters = 441437
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_100 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
input_101 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_67 (Embedding)        (None, 5, 168)       147336      input_100[0][0]                  
__________________________________________________________________________________________________
embedding_68 (Embedding)        (None, 5, 25)        1675        input_101[0][0]                  
__________________________________________________________________________________________________
flatten_67 (Flatten)            (None, 840)          0           embedding_67[0][0]               
__________________________________________________________________________________________________
flatten_68 (Flatten)            (None, 125)          0           embedding_68[0][0]               
__________________________________________________________________________________________________
input_102 (InputLayer)          (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 973)          0           flatten_67[0][0]                 
                                                                 flatten_68[0][0]                 
                                                                 input_102[0][0]                  
__________________________________________________________________________________________________
dense_67 (Dense)                (None, 299)          291226      concatenate_34[0][0]             
__________________________________________________________________________________________________
dropout_34 (Dropout)            (None, 299)          0           dense_67[0][0]                   
__________________________________________________________________________________________________
dense_68 (Dense)                (None, 4)            1200        dropout_34[0][0]                 
==================================================================================================
Total params: 441,437
Trainable params: 441,437
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 106957
	data size after sampling = 210624
	4 Labels in train : Counter({0: 52656, 1: 52656, 2: 52656, 3: 52656})
	4 Labels in valid : Counter({3: 10696, 0: 10571, 1: 10448, 2: 10410})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 168499 samples, validate on 42125 samples
Epoch 1/40
 - 13s - loss: 0.0177 - acc: 0.9964 - val_loss: 0.0036 - val_acc: 0.9989
Epoch 2/40
 - 13s - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0035 - val_acc: 0.9990
Epoch 3/40
 - 13s - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0035 - val_acc: 0.9989
Epoch 4/40
 - 13s - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0037 - val_acc: 0.9990
Epoch 5/40
 - 13s - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0036 - val_acc: 0.9990
Epoch 00005: early stopping
	TRAINING TIME: 3.93 minutes 
==================================================================================================
	PARSING TIME: 1.72 minutes 
==================================================================================================
	Identification : 0.855
	P, R  : 0.837, 0.873

==================================================================================================
	XP Ends: 7/2 (22 h:33)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
# Seed: 0
==================================================================================================
XP Starts: 7/2 (22h:33)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	SL Train (2080)
==================================================================================================
	Important sentence: 2080
	Token occurrences: 54472
	MWE number: 949
	MWE occurrences: 2364
	Continuous occurrences: 44.0 %
	Frequent MWE occurences: 46.0 %
	MWE length: 2.23
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2
	Embedded occurrences: 5

==================================================================================================
	 Test (1950)
==================================================================================================
	Important sentence: 436
	Token occurrences: 38146
	MWE number: 309
	MWE occurrences: 500
	Continuous occurrences: 48.0 %
	MWE length: 2.22
	Seen occurrences : 64% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 1

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 10287
	After : 2100

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2100 * POS : 10
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1256
	One occurrence keys in vocabulary 1256 / 2100
# Parameters = 645476
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_103 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
input_104 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_69 (Embedding)        (None, 5, 168)       352800      input_103[0][0]                  
__________________________________________________________________________________________________
embedding_70 (Embedding)        (None, 5, 25)        250         input_104[0][0]                  
__________________________________________________________________________________________________
flatten_69 (Flatten)            (None, 840)          0           embedding_69[0][0]               
__________________________________________________________________________________________________
flatten_70 (Flatten)            (None, 125)          0           embedding_70[0][0]               
__________________________________________________________________________________________________
input_105 (InputLayer)          (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 973)          0           flatten_69[0][0]                 
                                                                 flatten_70[0][0]                 
                                                                 input_105[0][0]                  
__________________________________________________________________________________________________
dense_69 (Dense)                (None, 299)          291226      concatenate_35[0][0]             
__________________________________________________________________________________________________
dropout_35 (Dropout)            (None, 299)          0           dense_69[0][0]                   
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 4)            1200        dropout_35[0][0]                 
==================================================================================================
Total params: 645,476
Trainable params: 645,476
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 111306
	data size after sampling = 217888
	4 Labels in train : Counter({0: 54472, 1: 54472, 2: 54472, 3: 54472})
	4 Labels in valid : Counter({1: 11061, 0: 10880, 3: 10854, 2: 10783})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 174310 samples, validate on 43578 samples
Epoch 1/40
 - 14s - loss: 0.0459 - acc: 0.9893 - val_loss: 0.0216 - val_acc: 0.9939
Epoch 2/40
 - 14s - loss: 0.0182 - acc: 0.9947 - val_loss: 0.0208 - val_acc: 0.9945
Epoch 3/40
 - 14s - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0202 - val_acc: 0.9945
Epoch 4/40
 - 14s - loss: 0.0131 - acc: 0.9959 - val_loss: 0.0200 - val_acc: 0.9946
Epoch 5/40
 - 14s - loss: 0.0113 - acc: 0.9963 - val_loss: 0.0203 - val_acc: 0.9945
Epoch 00005: early stopping
	TRAINING TIME: 4.93 minutes 
==================================================================================================
	PARSING TIME: 0.65 minutes 
==================================================================================================
	Identification : 0.579
	P, R  : 0.687, 0.5

==================================================================================================
	XP Ends: 7/2 (22 h:45)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
# Seed: 1
==================================================================================================
XP Starts: 7/2 (22h:45)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	SL Train (2080)
==================================================================================================
	Important sentence: 2080
	Token occurrences: 54472
	MWE number: 949
	MWE occurrences: 2364
	Continuous occurrences: 44.0 %
	Frequent MWE occurences: 46.0 %
	MWE length: 2.23
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2
	Embedded occurrences: 5

==================================================================================================
	 Test (1950)
==================================================================================================
	Important sentence: 436
	Token occurrences: 38146
	MWE number: 309
	MWE occurrences: 500
	Continuous occurrences: 48.0 %
	MWE length: 2.22
	Seen occurrences : 64% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 1

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 10287
	After : 2100

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 2100 * POS : 10
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1256
	One occurrence keys in vocabulary 1256 / 2100
# Parameters = 645476
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_106 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
input_107 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_71 (Embedding)        (None, 5, 168)       352800      input_106[0][0]                  
__________________________________________________________________________________________________
embedding_72 (Embedding)        (None, 5, 25)        250         input_107[0][0]                  
__________________________________________________________________________________________________
flatten_71 (Flatten)            (None, 840)          0           embedding_71[0][0]               
__________________________________________________________________________________________________
flatten_72 (Flatten)            (None, 125)          0           embedding_72[0][0]               
__________________________________________________________________________________________________
input_108 (InputLayer)          (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 973)          0           flatten_71[0][0]                 
                                                                 flatten_72[0][0]                 
                                                                 input_108[0][0]                  
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 299)          291226      concatenate_36[0][0]             
__________________________________________________________________________________________________
dropout_36 (Dropout)            (None, 299)          0           dense_71[0][0]                   
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 4)            1200        dropout_36[0][0]                 
==================================================================================================
Total params: 645,476
Trainable params: 645,476
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 111306
	data size after sampling = 217888
	4 Labels in train : Counter({0: 54472, 1: 54472, 2: 54472, 3: 54472})
	4 Labels in valid : Counter({0: 10989, 3: 10962, 2: 10839, 1: 10788})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 174310 samples, validate on 43578 samples
Epoch 1/40
 - 14s - loss: 0.0451 - acc: 0.9895 - val_loss: 0.0214 - val_acc: 0.9933
Epoch 2/40
 - 14s - loss: 0.0178 - acc: 0.9949 - val_loss: 0.0209 - val_acc: 0.9939
Epoch 3/40
 - 14s - loss: 0.0145 - acc: 0.9958 - val_loss: 0.0196 - val_acc: 0.9940
Epoch 4/40
 - 14s - loss: 0.0127 - acc: 0.9962 - val_loss: 0.0210 - val_acc: 0.9939
Epoch 5/40
 - 14s - loss: 0.0111 - acc: 0.9965 - val_loss: 0.0213 - val_acc: 0.9941
Epoch 00005: early stopping
	TRAINING TIME: 4.93 minutes 
==================================================================================================
	PARSING TIME: 0.62 minutes 
==================================================================================================
	Identification : 0.56
	P, R  : 0.632, 0.502

==================================================================================================
	XP Ends: 7/2 (22 h:57)
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 7/2 (22h:57)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 17288
	After : 5327

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 5327 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 5327
# Parameters = 1190087
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_109 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
input_110 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_73 (Embedding)        (None, 5, 168)       894936      input_109[0][0]                  
__________________________________________________________________________________________________
embedding_74 (Embedding)        (None, 5, 25)        2725        input_110[0][0]                  
__________________________________________________________________________________________________
flatten_73 (Flatten)            (None, 840)          0           embedding_73[0][0]               
__________________________________________________________________________________________________
flatten_74 (Flatten)            (None, 125)          0           embedding_74[0][0]               
__________________________________________________________________________________________________
input_111 (InputLayer)          (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 973)          0           flatten_73[0][0]                 
                                                                 flatten_74[0][0]                 
                                                                 input_111[0][0]                  
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 299)          291226      concatenate_37[0][0]             
__________________________________________________________________________________________________
dropout_37 (Dropout)            (None, 299)          0           dense_73[0][0]                   
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 4)            1200        dropout_37[0][0]                 
==================================================================================================
Total params: 1,190,087
Trainable params: 1,190,087
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({1: 24187, 2: 24000, 0: 23959, 3: 23954})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 32s - loss: 0.0213 - acc: 0.9940 - val_loss: 0.0120 - val_acc: 0.9957
Epoch 2/40
 - 32s - loss: 0.0096 - acc: 0.9963 - val_loss: 0.0117 - val_acc: 0.9958
Epoch 3/40
 - 32s - loss: 0.0078 - acc: 0.9969 - val_loss: 0.0126 - val_acc: 0.9958
Epoch 4/40
 - 32s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0139 - val_acc: 0.9957
Epoch 5/40
 - 32s - loss: 0.0057 - acc: 0.9977 - val_loss: 0.0145 - val_acc: 0.9955
Epoch 00005: early stopping
	TRAINING TIME: 15.92 minutes 
==================================================================================================
	PARSING TIME: 0.48 minutes 
==================================================================================================
	Identification : 0.483
	P, R  : 0.575, 0.416

==================================================================================================
	XP Ends: 7/2 (23 h:27)
==================================================================================================
# Seed: 1
==================================================================================================
XP Starts: 7/2 (23h:27)
==================================================================================================
Jacknfing:
==================================================================================================
Finished training the fold 0
Finished training the fold 1
Finished training the fold 2
Finished training the fold 3
Finished training the fold 4
Jacknfing Finshed
==================================================================================================

==================================================================================================
	TR Train (3585)
==================================================================================================
	Important sentence: 3585
	Token occurrences: 120124
	MWE number: 2979
	MWE occurrences: 4870
	Continuous occurrences: 49.0 %
	Frequent MWE occurences: 24.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2

==================================================================================================
	 Test (1320)
==================================================================================================
	Important sentence: 385
	Token occurrences: 27196
	MWE number: 418
	MWE occurrences: 510
	Continuous occurrences: 50.0 %
	MWE length: 2.07
	Seen occurrences : 43% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 17288
	After : 5327

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 5327 * POS : 109
__________________________________________________________________________________________________
	Dashed keys in vocabulary 3161
	One occurrence keys in vocabulary 3161 / 5327
# Parameters = 1190087
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_112 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
input_113 (InputLayer)          (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_75 (Embedding)        (None, 5, 168)       894936      input_112[0][0]                  
__________________________________________________________________________________________________
embedding_76 (Embedding)        (None, 5, 25)        2725        input_113[0][0]                  
__________________________________________________________________________________________________
flatten_75 (Flatten)            (None, 840)          0           embedding_75[0][0]               
__________________________________________________________________________________________________
flatten_76 (Flatten)            (None, 125)          0           embedding_76[0][0]               
__________________________________________________________________________________________________
input_114 (InputLayer)          (None, 8)            0                                            
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 973)          0           flatten_75[0][0]                 
                                                                 flatten_76[0][0]                 
                                                                 input_114[0][0]                  
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 299)          291226      concatenate_38[0][0]             
__________________________________________________________________________________________________
dropout_38 (Dropout)            (None, 299)          0           dense_75[0][0]                   
__________________________________________________________________________________________________
dense_76 (Dense)                (None, 4)            1200        dropout_38[0][0]                 
==================================================================================================
Total params: 1,190,087
Trainable params: 1,190,087
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 245118
	data size after sampling = 480496
	4 Labels in train : Counter({0: 120124, 1: 120124, 2: 120124, 3: 120124})
	4 Labels in valid : Counter({3: 24153, 0: 24100, 1: 23986, 2: 23861})
	Favorisation Coeff : 2

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.036
__________________________________________________________________________________________________
Train on 384396 samples, validate on 96100 samples
Epoch 1/40
 - 32s - loss: 0.0213 - acc: 0.9940 - val_loss: 0.0116 - val_acc: 0.9957
Epoch 2/40
 - 32s - loss: 0.0095 - acc: 0.9964 - val_loss: 0.0117 - val_acc: 0.9958
Epoch 3/40
 - 32s - loss: 0.0077 - acc: 0.9970 - val_loss: 0.0122 - val_acc: 0.9956
Epoch 4/40
 - 32s - loss: 0.0067 - acc: 0.9974 - val_loss: 0.0129 - val_acc: 0.9956
Epoch 5/40
 - 32s - loss: 0.0057 - acc: 0.9977 - val_loss: 0.0138 - val_acc: 0.9955
Epoch 00005: early stopping
	TRAINING TIME: 16.27 minutes 
==================================================================================================
	PARSING TIME: 0.45 minutes 
==================================================================================================
	Identification : 0.483
	P, R  : 0.556, 0.427

==================================================================================================
	XP Ends: 7/2 (23 h:57)
==================================================================================================
