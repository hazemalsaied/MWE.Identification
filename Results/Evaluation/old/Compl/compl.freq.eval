INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_jkc1Q4.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 5779/6083 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX TITAN Black (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
	Mode: NON.COMPO
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, lemma, compactVocab, favorisationCoeff, focused, importantSentences, importantTransitions, overSampling, sampleWeight, bPadding, batchSize, chickPoint, compactVocab, dense1, dense1Activation, dense1Dropout, dense1UnitNumber, dense2, dense2Activation, dense2Dropout, dense2UnitNumber, earlyStop, epochs, features, inputItems, lemma, loss, lr, minDelta, optimizer, posEmb, predictVerbose, s0Padding, s1Padding, tokenEmb, trainable, validationSplit, verbose
==================================================================================================
# Configs: NonCompo, sharedtask2, corpus, True, False, 1, False, False, False, False, False, 2, 64, False, False, True, relu, 0.43, 60, False, relu, 0, 0, True, 40, False, 4, True, categorical_crossentropy, 0.059, 0.2, adagrad, 42, False, 5, 5, 480, True, 0.1, 0
==================================================================================================
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================
	Train deformed lemmas: 41 

==================================================================================================
	BG Train (19767)
==================================================================================================
	Important sentence: 5248
	Token occurrences: 441193
	MWE number: 2021
	MWE occurrences: 6034
	Continuous occurrences: 80.0 %
	Frequent MWE occurences: 56.0 %
	MWE length: 2.13
	Recognizable MWEs: 100.0 %
	MWT occurrences: 11

==================================================================================================
	 Test (1832)
==================================================================================================
	Important sentence: 554
	Token occurrences: 39220
	MWE number: 432
	MWE occurrences: 670
	Continuous occurrences: 71.0 %
	MWE length: 2.11
	Seen occurrences : 65% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 1525592
==================================================================================================

==================================================================================================
	Training time : 0:03:33.589018
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 19814
	After : 16015
# Parameters = 7820260
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 4, 480)       7687200     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 4, 42)        7476        input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 1920)         0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 168)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 2088)         0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 60)           125340      concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 60)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            244         dropout_1[0][0]                  
==================================================================================================
Total params: 7,820,260
Trainable params: 7,820,260
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 1120225
	data size after focused sampling = 1120225
	data size before sampling = 1120225
	data size after sampling = 2097472
	4 Labels in train : Counter({0: 524368, 1: 524368, 2: 524368, 3: 524368})
	4 Labels in valid : Counter({1: 53041, 0: 52510, 3: 52329, 2: 51868})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 1887724 samples, validate on 209748 samples
Epoch 1/40
 - 78s - loss: 0.0491 - acc: 0.9905 - val_loss: 0.0332 - val_acc: 0.9933
Epoch 2/40
 - 78s - loss: 0.0324 - acc: 0.9938 - val_loss: 0.0333 - val_acc: 0.9937
Epoch 3/40
 - 78s - loss: 0.0299 - acc: 0.9943 - val_loss: 0.0324 - val_acc: 0.9939

==================================================================================================
	Training time : 0:05:15.713775
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:46.940912
==================================================================================================
	Identification : 0.639
	P, R  : 0.855, 0.51

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	DE Train (2799)
==================================================================================================
	Important sentence: 2788
	Token occurrences: 61973
	MWE number: 1914
	MWE occurrences: 3234
	Continuous occurrences: 26.0 %
	Frequent MWE occurences: 21.0 %
	MWE length: 1.94
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1030
	Embedded occurrences: 48

==================================================================================================
	 Test (1078)
==================================================================================================
	Important sentence: 410
	Token occurrences: 20524
	MWE number: 423
	MWE occurrences: 500
	Continuous occurrences: 24.0 %
	MWE length: 1.96
	Seen occurrences : 48% 
	Recognizable MWEs: 97.0 %
	MWT occurrences: 149
	Embedded occurrences: 13
	Interleaving occurrences: 2

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 638021
==================================================================================================
Train data = 127180, Train data = 433811, 
==================================================================================================
	Training time : 0:04:57.565520
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 15152
	After : 10820
# Parameters = 5331364
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 4, 480)       5193600     input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 4, 42)        12180       input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 1920)         0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 168)          0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 2088)         0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 60)           125340      concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 60)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            244         dropout_2[0][0]                  
==================================================================================================
Total params: 5,331,364
Trainable params: 5,331,364
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 333665
	data size after focused sampling = 333665
	data size before sampling = 333665
	data size after sampling = 528164
	4 Labels in train : Counter({0: 132041, 1: 132041, 2: 132041, 3: 132041})
	4 Labels in valid : Counter({1: 13267, 0: 13214, 2: 13178, 3: 13158})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 475347 samples, validate on 52817 samples
Epoch 1/40
 - 17s - loss: 0.2132 - acc: 0.9630 - val_loss: 0.1401 - val_acc: 0.9768
Epoch 2/40
 - 17s - loss: 0.1393 - acc: 0.9774 - val_loss: 0.1361 - val_acc: 0.9778
Epoch 3/40
 - 17s - loss: 0.1315 - acc: 0.9789 - val_loss: 0.1357 - val_acc: 0.9780

==================================================================================================
	Training time : 0:01:07.395420
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:26.722605
==================================================================================================
	Identification : 0.497
	P, R  : 0.824, 0.356

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	EL Train (1657)
==================================================================================================
	Important sentence: 1657
	Token occurrences: 53762
	MWE number: 1121
	MWE occurrences: 1856
	Continuous occurrences: 50.0 %
	Frequent MWE occurences: 22.0 %
	MWE length: 2.37
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 6

==================================================================================================
	 Test (1261)
==================================================================================================
	Important sentence: 436
	Token occurrences: 35860
	MWE number: 335
	MWE occurrences: 501
	Continuous occurrences: 55.0 %
	MWE length: 2.39
	Seen occurrences : 57% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 7
	Interleaving occurrences: 3

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 444874
==================================================================================================
Train data = 109380, Train data = 322572, 
==================================================================================================
	Training time : 0:02:54.979963
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9410
	After : 7122
# Parameters = 3552502
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 480)       3418560     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 42)        8358        input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 1920)         0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 168)          0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 2088)         0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 60)           125340      concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 60)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            244         dropout_3[0][0]                  
==================================================================================================
Total params: 3,552,502
Trainable params: 3,552,502
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 253999
	data size after focused sampling = 253999
	data size before sampling = 253999
	data size after sampling = 428920
	4 Labels in train : Counter({0: 107230, 1: 107230, 2: 107230, 3: 107230})
	4 Labels in valid : Counter({0: 10891, 2: 10742, 1: 10693, 3: 10566})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 386028 samples, validate on 42892 samples
Epoch 1/40
 - 12s - loss: 0.1172 - acc: 0.9792 - val_loss: 0.0680 - val_acc: 0.9876
Epoch 2/40
 - 12s - loss: 0.0702 - acc: 0.9879 - val_loss: 0.0660 - val_acc: 0.9881
Epoch 3/40
 - 12s - loss: 0.0650 - acc: 0.9888 - val_loss: 0.0648 - val_acc: 0.9889

==================================================================================================
	Training time : 0:00:50.688968
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:44.059058
==================================================================================================
	Identification : 0.627
	P, R  : 0.866, 0.491

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	EN Train (300)
==================================================================================================
	Important sentence: 300
	Token occurrences: 7066
	MWE number: 233
	MWE occurrences: 331
	Continuous occurrences: 68.0 %
	Frequent MWE occurences: 6.0 %
	MWE length: 2.14
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	 Test (3965)
==================================================================================================
	Important sentence: 447
	Token occurrences: 70998
	MWE number: 353
	MWE occurrences: 501
	Continuous occurrences: 58.0 %
	MWE length: 2.17
	Seen occurrences : 27% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 3
	Embedded occurrences: 8
	Interleaving occurrences: 5

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 72706
==================================================================================================
Train data = 14463, Train data = 42396, 
==================================================================================================
	Training time : 0:00:10.357792
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 1967
	After : 1473
# Parameters = 835228
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 4, 480)       707040      input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 4, 42)        2604        input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 1920)         0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 168)          0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 2088)         0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 60)           125340      concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 60)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4)            244         dropout_4[0][0]                  
==================================================================================================
Total params: 835,228
Trainable params: 835,228
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 41063
	data size after focused sampling = 41063
	data size before sampling = 41063
	data size after sampling = 65816
	4 Labels in train : Counter({0: 16454, 1: 16454, 2: 16454, 3: 16454})
	4 Labels in valid : Counter({2: 1691, 3: 1666, 1: 1641, 0: 1584})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 59234 samples, validate on 6582 samples
Epoch 1/40
 - 1s - loss: 0.1894 - acc: 0.9658 - val_loss: 0.1053 - val_acc: 0.9809
Epoch 2/40
 - 1s - loss: 0.0926 - acc: 0.9844 - val_loss: 0.1010 - val_acc: 0.9816
Epoch 3/40
 - 1s - loss: 0.0837 - acc: 0.9853 - val_loss: 0.1025 - val_acc: 0.9819

==================================================================================================
	Training time : 0:00:07.899671
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:01:19.035878
==================================================================================================
	Identification : 0.338
	P, R  : 0.483, 0.259

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
ERROR:root:ATTENTION: Oracle problems with 5 sentences!
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	ES Train (1450)
==================================================================================================
	Important sentence: 1450
	Token occurrences: 60202
	MWE number: 1130
	MWE occurrences: 2110
	Continuous occurrences: 75.0 %
	Frequent MWE occurences: 28.0 %
	MWE length: 2.27
	Recognizable MWEs: 100.0 %
	MWT occurrences: 2
	Embedded occurrences: 150

==================================================================================================
	 Test (2046)
==================================================================================================
	Important sentence: 359
	Token occurrences: 58861
	MWE number: 380
	MWE occurrences: 500
	Continuous occurrences: 72.0 %
	MWE length: 2.3
	Seen occurrences : 55% 
	Recognizable MWEs: 96.0 %
	Embedded occurrences: 28
	Interleaving occurrences: 18

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 411774
==================================================================================================
Train data = 122509, Train data = 421414, 
==================================================================================================
	Training time : 0:03:18.649982
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 8446
	After : 6669
# Parameters = 3331996
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 4, 480)       3201120     input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 4, 42)        5292        input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 1920)         0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 168)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 2088)         0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 60)           125340      concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 60)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 4)            244         dropout_5[0][0]                  
==================================================================================================
Total params: 3,331,996
Trainable params: 3,331,996
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 262193
	data size after focused sampling = 262193
	data size before sampling = 262193
	data size after sampling = 435520
	4 Labels in train : Counter({0: 108880, 1: 108880, 2: 108880, 3: 108880})
	4 Labels in valid : Counter({3: 11003, 2: 10920, 1: 10826, 0: 10803})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 391968 samples, validate on 43552 samples
Epoch 1/40
 - 12s - loss: 0.1931 - acc: 0.9683 - val_loss: 0.1269 - val_acc: 0.9795
Epoch 2/40
 - 12s - loss: 0.1321 - acc: 0.9785 - val_loss: 0.1214 - val_acc: 0.9811
Epoch 3/40
 - 12s - loss: 0.1251 - acc: 0.9797 - val_loss: 0.1227 - val_acc: 0.9810

==================================================================================================
	Training time : 0:00:51.175471
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:01:14.714730
==================================================================================================
	Identification : 0.403
	P, R  : 0.378, 0.432

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================
	Train deformed lemmas: 14 

==================================================================================================
	EU Train (2703)
==================================================================================================
	Important sentence: 2703
	Token occurrences: 46060
	MWE number: 938
	MWE occurrences: 3295
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 57.0 %
	MWE length: 2.02
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 7

==================================================================================================
	 Test (1404)
==================================================================================================
	Important sentence: 424
	Token occurrences: 19038
	MWE number: 200
	MWE occurrences: 500
	Continuous occurrences: 81.0 %
	MWE length: 2.01
	Seen occurrences : 86% 
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 2
	Interleaving occurrences: 1

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 388743
==================================================================================================
Train data = 95415, Train data = 230300, 
==================================================================================================
	Training time : 0:01:13.222846
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 6774
	After : 5305
# Parameters = 2677108
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 4, 480)       2546400     input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 4, 42)        5124        input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 1920)         0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 168)          0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 2088)         0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 60)           125340      concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 60)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 4)            244         dropout_6[0][0]                  
==================================================================================================
Total params: 2,677,108
Trainable params: 2,677,108
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 189234
	data size after focused sampling = 189234
	data size before sampling = 189234
	data size after sampling = 310988
	4 Labels in train : Counter({0: 77747, 1: 77747, 2: 77747, 3: 77747})
	4 Labels in valid : Counter({1: 7810, 2: 7786, 3: 7756, 0: 7747})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 279889 samples, validate on 31099 samples
Epoch 1/40
 - 8s - loss: 0.1799 - acc: 0.9615 - val_loss: 0.1188 - val_acc: 0.9724
Epoch 2/40
 - 8s - loss: 0.1208 - acc: 0.9736 - val_loss: 0.1147 - val_acc: 0.9750
Epoch 3/40
 - 8s - loss: 0.1118 - acc: 0.9756 - val_loss: 0.1134 - val_acc: 0.9756

==================================================================================================
	Training time : 0:00:34.920223
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:22.902507
==================================================================================================
	Identification : 0.806
	P, R  : 0.887, 0.738

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	FA Train (1965)
==================================================================================================
	Important sentence: 1965
	Token occurrences: 38999
	MWE number: 1294
	MWE occurrences: 2948
	Continuous occurrences: 85.0 %
	Frequent MWE occurences: 39.0 %
	MWE length: 2.13
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 6

==================================================================================================
	 Test (359)
==================================================================================================
	Important sentence: 291
	Token occurrences: 7492
	MWE number: 382
	MWE occurrences: 501
	Continuous occurrences: 79.0 %
	MWE length: 2.22
	Seen occurrences : 65% 
	Recognizable MWEs: 100.0 %

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 298672
==================================================================================================
Train data = 80946, Train data = 233994, 
==================================================================================================
	Training time : 0:01:11.570028
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 5495
	After : 4639
# Parameters = 2355496
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 4, 480)       2226720     input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 4, 42)        3192        input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 1920)         0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 168)          0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 2088)         0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 60)           125340      concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 60)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 4)            244         dropout_7[0][0]                  
==================================================================================================
Total params: 2,355,496
Trainable params: 2,355,496
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 222876
	data size after focused sampling = 222876
	data size before sampling = 222876
	data size after sampling = 354492
	4 Labels in train : Counter({0: 88623, 1: 88623, 2: 88623, 3: 88623})
	4 Labels in valid : Counter({3: 8933, 2: 8919, 1: 8848, 0: 8750})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 319042 samples, validate on 35450 samples
Epoch 1/40
 - 9s - loss: 0.1690 - acc: 0.9688 - val_loss: 0.1190 - val_acc: 0.9764
Epoch 2/40
 - 9s - loss: 0.1196 - acc: 0.9760 - val_loss: 0.1178 - val_acc: 0.9771
Epoch 3/40
 - 9s - loss: 0.1138 - acc: 0.9770 - val_loss: 0.1140 - val_acc: 0.9776

==================================================================================================
	Training time : 0:00:38.574945
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:09.716925
==================================================================================================
	Identification : 0.768
	P, R  : 0.922, 0.659

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	FR Train (4426)
==================================================================================================
	Important sentence: 4426
	Token occurrences: 133116
	MWE number: 1752
	MWE occurrences: 5145
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 52.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 5
	Embedded occurrences: 40

==================================================================================================
	 Test (1606)
==================================================================================================
	Important sentence: 400
	Token occurrences: 38402
	MWE number: 377
	MWE occurrences: 498
	Continuous occurrences: 56.0 %
	MWE length: 2.35
	Seen occurrences : 52% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 6
	Interleaving occurrences: 6

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 816915
==================================================================================================
Train data = 271374, Train data = 798696, 
==================================================================================================
	Training time : 0:05:23.758844
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 15282
	After : 11615
# Parameters = 5710150
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 480)       5575200     input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 42)        9366        input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 1920)         0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 168)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 2088)         0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 60)           125340      concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 60)           0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 4)            244         dropout_8[0][0]                  
==================================================================================================
Total params: 5,710,150
Trainable params: 5,710,150
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 487572
	data size after focused sampling = 487572
	data size before sampling = 487572
	data size after sampling = 850112
	4 Labels in train : Counter({0: 212528, 1: 212528, 2: 212528, 3: 212528})
	4 Labels in valid : Counter({1: 21431, 2: 21374, 0: 21307, 3: 20900})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 765100 samples, validate on 85012 samples
Epoch 1/40
 - 28s - loss: 0.1092 - acc: 0.9781 - val_loss: 0.0763 - val_acc: 0.9839
Epoch 2/40
 - 28s - loss: 0.0740 - acc: 0.9849 - val_loss: 0.0746 - val_acc: 0.9851
Epoch 3/40
 - 28s - loss: 0.0696 - acc: 0.9858 - val_loss: 0.0740 - val_acc: 0.9851

==================================================================================================
	Training time : 0:01:48.033702
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:47.172184
==================================================================================================
	Identification : 0.57
	P, R  : 0.816, 0.438

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================
	Train deformed lemmas: 7618 
	Train important deformed Lemmas: 89 

==================================================================================================
	HE Train (1593)
==================================================================================================
	Important sentence: 1593
	Token occurrences: 37903
	MWE number: 1229
	MWE occurrences: 1719
	Continuous occurrences: 76.0 %
	Frequent MWE occurences: 12.0 %
	MWE length: 2.41
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 5

==================================================================================================
	 Test (3209)
==================================================================================================
	Important sentence: 450
	Token occurrences: 65698
	MWE number: 391
	MWE occurrences: 502
	Continuous occurrences: 76.0 %
	MWE length: 2.3
	Seen occurrences : 37% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 7
	Interleaving occurrences: 2

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 423385
==================================================================================================
Train data = 77525, Train data = 227418, 
==================================================================================================
	Training time : 0:01:31.962008
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12066
	After : 9282
# Parameters = 4594384
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 480)       4455360     input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 42)        13440       input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 1920)         0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 168)          0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 2088)         0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 60)           125340      concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 60)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 4)            244         dropout_9[0][0]                  
==================================================================================================
Total params: 4,594,384
Trainable params: 4,594,384
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 240132
	data size after focused sampling = 240132
	data size before sampling = 240132
	data size after sampling = 393760
	4 Labels in train : Counter({0: 98440, 1: 98440, 2: 98440, 3: 98440})
	4 Labels in valid : Counter({1: 9888, 0: 9883, 3: 9828, 2: 9777})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 354384 samples, validate on 39376 samples
Epoch 1/40
 - 12s - loss: 0.1348 - acc: 0.9757 - val_loss: 0.0822 - val_acc: 0.9854
Epoch 2/40
 - 12s - loss: 0.0818 - acc: 0.9858 - val_loss: 0.0788 - val_acc: 0.9862
Epoch 3/40
 - 12s - loss: 0.0772 - acc: 0.9865 - val_loss: 0.0791 - val_acc: 0.9864

==================================================================================================
	Training time : 0:00:47.038044
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:01:18.944679
==================================================================================================
	Identification : 0.459
	P, R  : 0.794, 0.323

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	HI Train (418)
==================================================================================================
	Important sentence: 418
	Token occurrences: 9756
	MWE number: 250
	MWE occurrences: 499
	Continuous occurrences: 92.0 %
	Frequent MWE occurences: 30.0 %
	MWE length: 2.09
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (828)
==================================================================================================
	Important sentence: 382
	Token occurrences: 17580
	MWE number: 285
	MWE occurrences: 500
	Continuous occurrences: 93.0 %
	MWE length: 2.21
	Seen occurrences : 55% 
	Recognizable MWEs: 94.0 %
	Embedded occurrences: 5
	Interleaving occurrences: 28

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 86247
==================================================================================================
Train data = 20011, Train data = 48780, 
==================================================================================================
	Training time : 0:00:08.900699
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 2272
	After : 1762
# Parameters = 973276
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 480)       845760      input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 42)        1932        input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 1920)         0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 168)          0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 2088)         0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 60)           125340      concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 60)           0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 4)            244         dropout_10[0][0]                 
==================================================================================================
Total params: 973,276
Trainable params: 973,276
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 46576
	data size after focused sampling = 46576
	data size before sampling = 46576
	data size after sampling = 75644
	4 Labels in train : Counter({0: 18911, 1: 18911, 2: 18911, 3: 18911})
	4 Labels in valid : Counter({2: 1965, 1: 1902, 0: 1851, 3: 1847})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 68079 samples, validate on 7565 samples
Epoch 1/40
 - 2s - loss: 0.1457 - acc: 0.9734 - val_loss: 0.0905 - val_acc: 0.9831
Epoch 2/40
 - 2s - loss: 0.0872 - acc: 0.9846 - val_loss: 0.0901 - val_acc: 0.9836
Epoch 3/40
 - 2s - loss: 0.0809 - acc: 0.9852 - val_loss: 0.0898 - val_acc: 0.9835

==================================================================================================
	Training time : 0:00:09.097977
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:21.862722
==================================================================================================
	Identification : 0.644
	P, R  : 0.89, 0.504

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	HR Train (1363)
==================================================================================================
	Important sentence: 1362
	Token occurrences: 35120
	MWE number: 1095
	MWE occurrences: 1861
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 22.0 %
	MWE length: 2.21
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 211

==================================================================================================
	 Test (708)
==================================================================================================
	Important sentence: 350
	Token occurrences: 16429
	MWE number: 347
	MWE occurrences: 501
	Continuous occurrences: 58.0 %
	MWE length: 2.2
	Seen occurrences : 56% 
	Recognizable MWEs: 96.0 %
	Embedded occurrences: 59
	Interleaving occurrences: 10

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 366350
==================================================================================================
Train data = 72100, Train data = 245840, 
==================================================================================================
	Training time : 0:02:23.254257
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 7771
	After : 6052
# Parameters = 3035584
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_21 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_22 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_21 (Embedding)        (None, 4, 480)       2904960     input_21[0][0]                   
__________________________________________________________________________________________________
embedding_22 (Embedding)        (None, 4, 42)        5040        input_22[0][0]                   
__________________________________________________________________________________________________
flatten_21 (Flatten)            (None, 1920)         0           embedding_21[0][0]               
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 168)          0           embedding_22[0][0]               
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 2088)         0           flatten_21[0][0]                 
                                                                 flatten_22[0][0]                 
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 60)           125340      concatenate_11[0][0]             
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 60)           0           dense_21[0][0]                   
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 4)            244         dropout_11[0][0]                 
==================================================================================================
Total params: 3,035,584
Trainable params: 3,035,584
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 201456
	data size after focused sampling = 201456
	data size before sampling = 201456
	data size after sampling = 308440
	4 Labels in train : Counter({0: 77110, 1: 77110, 2: 77110, 3: 77110})
	4 Labels in valid : Counter({2: 7824, 3: 7733, 1: 7656, 0: 7631})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 277596 samples, validate on 30844 samples
Epoch 1/40
 - 9s - loss: 0.2660 - acc: 0.9523 - val_loss: 0.1854 - val_acc: 0.9667
Epoch 2/40
 - 9s - loss: 0.1919 - acc: 0.9651 - val_loss: 0.1795 - val_acc: 0.9681
Epoch 3/40
 - 9s - loss: 0.1841 - acc: 0.9665 - val_loss: 0.1799 - val_acc: 0.9684

==================================================================================================
	Training time : 0:00:35.277181
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:21.310864
==================================================================================================
	Identification : 0.595
	P, R  : 0.851, 0.457

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	HU Train (3595)
==================================================================================================
	Important sentence: 3595
	Token occurrences: 101601
	MWE number: 738
	MWE occurrences: 6907
	Continuous occurrences: 18.0 %
	Frequent MWE occurences: 86.0 %
	MWE length: 1.25
	Recognizable MWEs: 100.0 %
	MWT occurrences: 5164
	Embedded occurrences: 175

==================================================================================================
	 Test (755)
==================================================================================================
	Important sentence: 431
	Token occurrences: 20759
	MWE number: 258
	MWE occurrences: 776
	Continuous occurrences: 24.0 %
	MWE length: 1.33
	Seen occurrences : 91% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 523
	Embedded occurrences: 18
	Interleaving occurrences: 4

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 504499
==================================================================================================
Train data = 210103, Train data = 609606, 
==================================================================================================
	Training time : 0:03:20.993437
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 6181
	After : 5033
# Parameters = 2543524
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_23 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_24 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_23 (Embedding)        (None, 4, 480)       2415840     input_23[0][0]                   
__________________________________________________________________________________________________
embedding_24 (Embedding)        (None, 4, 42)        2100        input_24[0][0]                   
__________________________________________________________________________________________________
flatten_23 (Flatten)            (None, 1920)         0           embedding_23[0][0]               
__________________________________________________________________________________________________
flatten_24 (Flatten)            (None, 168)          0           embedding_24[0][0]               
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 2088)         0           flatten_23[0][0]                 
                                                                 flatten_24[0][0]                 
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 60)           125340      concatenate_12[0][0]             
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 60)           0           dense_23[0][0]                   
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 4)            244         dropout_12[0][0]                 
==================================================================================================
Total params: 2,543,524
Trainable params: 2,543,524
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 262793
	data size after focused sampling = 262793
	data size before sampling = 262793
	data size after sampling = 465176
	4 Labels in train : Counter({0: 116294, 1: 116294, 2: 116294, 3: 116294})
	4 Labels in valid : Counter({3: 11676, 2: 11674, 1: 11651, 0: 11517})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 418658 samples, validate on 46518 samples
Epoch 1/40
 - 12s - loss: 0.2324 - acc: 0.9617 - val_loss: 0.1831 - val_acc: 0.9708
Epoch 2/40
 - 12s - loss: 0.1832 - acc: 0.9706 - val_loss: 0.1827 - val_acc: 0.9711
Epoch 3/40
 - 12s - loss: 0.1778 - acc: 0.9715 - val_loss: 0.1822 - val_acc: 0.9712

==================================================================================================
	Training time : 0:00:51.642127
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:24.182233
==================================================================================================
	Identification : 0.923
	P, R  : 0.997, 0.86

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	IT Train (2824)
==================================================================================================
	Important sentence: 2799
	Token occurrences: 115960
	MWE number: 1595
	MWE occurrences: 3563
	Continuous occurrences: 72.0 %
	Frequent MWE occurences: 36.0 %
	MWE length: 2.47
	Recognizable MWEs: 100.0 %
	MWT occurrences: 9
	Embedded occurrences: 117

==================================================================================================
	 Test (1256)
==================================================================================================
	Important sentence: 380
	Token occurrences: 35558
	MWE number: 382
	MWE occurrences: 503
	Continuous occurrences: 67.0 %
	MWE length: 2.6
	Seen occurrences : 59% 
	Recognizable MWEs: 95.0 %
	Embedded occurrences: 25
	Interleaving occurrences: 7

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 755783
==================================================================================================
Train data = 235480, Train data = 811720, 
==================================================================================================
	Training time : 0:10:09.837976
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 13991
	After : 10965
# Parameters = 5399578
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_26 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_25 (Embedding)        (None, 4, 480)       5263200     input_25[0][0]                   
__________________________________________________________________________________________________
embedding_26 (Embedding)        (None, 4, 42)        10794       input_26[0][0]                   
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 1920)         0           embedding_25[0][0]               
__________________________________________________________________________________________________
flatten_26 (Flatten)            (None, 168)          0           embedding_26[0][0]               
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 2088)         0           flatten_25[0][0]                 
                                                                 flatten_26[0][0]                 
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 60)           125340      concatenate_13[0][0]             
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 60)           0           dense_25[0][0]                   
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 4)            244         dropout_13[0][0]                 
==================================================================================================
Total params: 5,399,578
Trainable params: 5,399,578
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 465188
	data size after focused sampling = 465188
	data size before sampling = 465188
	data size after sampling = 812720
	4 Labels in train : Counter({0: 203180, 1: 203180, 2: 203180, 3: 203180})
	4 Labels in valid : Counter({1: 20484, 2: 20359, 3: 20344, 0: 20085})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 731448 samples, validate on 81272 samples
Epoch 1/40
 - 26s - loss: 0.1355 - acc: 0.9752 - val_loss: 0.0892 - val_acc: 0.9838
Epoch 2/40
 - 26s - loss: 0.0901 - acc: 0.9839 - val_loss: 0.0854 - val_acc: 0.9857
Epoch 3/40
 - 26s - loss: 0.0846 - acc: 0.9851 - val_loss: 0.0858 - val_acc: 0.9852

==================================================================================================
	Training time : 0:01:41.992415
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:45.818083
==================================================================================================
	Identification : 0.568
	P, R  : 0.817, 0.435

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	LT Train (297)
==================================================================================================
	Important sentence: 297
	Token occurrences: 6834
	MWE number: 192
	MWE occurrences: 312
	Continuous occurrences: 58.0 %
	Frequent MWE occurences: 14.0 %
	MWE length: 2.16
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (6209)
==================================================================================================
	Important sentence: 474
	Token occurrences: 118402
	MWE number: 328
	MWE occurrences: 500
	Continuous occurrences: 60.0 %
	MWE length: 2.25
	Seen occurrences : 38% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 1
	Interleaving occurrences: 2

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 83373
==================================================================================================
Train data = 13980, Train data = 34170, 
==================================================================================================
	Training time : 0:00:06.840571
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 2353
	After : 1757
# Parameters = 971296
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_27 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_28 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_27 (Embedding)        (None, 4, 480)       843360      input_27[0][0]                   
__________________________________________________________________________________________________
embedding_28 (Embedding)        (None, 4, 42)        2352        input_28[0][0]                   
__________________________________________________________________________________________________
flatten_27 (Flatten)            (None, 1920)         0           embedding_27[0][0]               
__________________________________________________________________________________________________
flatten_28 (Flatten)            (None, 168)          0           embedding_28[0][0]               
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 2088)         0           flatten_27[0][0]                 
                                                                 flatten_28[0][0]                 
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 60)           125340      concatenate_14[0][0]             
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 60)           0           dense_27[0][0]                   
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 4)            244         dropout_14[0][0]                 
==================================================================================================
Total params: 971,296
Trainable params: 971,296
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 36326
	data size after focused sampling = 36326
	data size before sampling = 36326
	data size after sampling = 59212
	4 Labels in train : Counter({0: 14803, 1: 14803, 2: 14803, 3: 14803})
	4 Labels in valid : Counter({2: 1533, 1: 1490, 0: 1455, 3: 1444})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 53290 samples, validate on 5922 samples
Epoch 1/40
 - 1s - loss: 0.2196 - acc: 0.9545 - val_loss: 0.0748 - val_acc: 0.9858
Epoch 2/40
 - 1s - loss: 0.0831 - acc: 0.9859 - val_loss: 0.0718 - val_acc: 0.9865
Epoch 3/40
 - 1s - loss: 0.0754 - acc: 0.9871 - val_loss: 0.0749 - val_acc: 0.9865

==================================================================================================
	Training time : 0:00:07.935124
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:02:09.916198
==================================================================================================
	Identification : 0.411
	P, R  : 0.84, 0.272

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
ERROR:root:ATTENTION: Oracle problems with 3 sentences!
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	PL Train (3918)
==================================================================================================
	Important sentence: 3918
	Token occurrences: 79518
	MWE number: 1791
	MWE occurrences: 4567
	Continuous occurrences: 71.0 %
	Frequent MWE occurences: 48.0 %
	MWE length: 2.13
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 100

==================================================================================================
	 Test (1300)
==================================================================================================
	Important sentence: 425
	Token occurrences: 27661
	MWE number: 356
	MWE occurrences: 515
	Continuous occurrences: 70.0 %
	MWE length: 2.15
	Seen occurrences : 68% 
	Recognizable MWEs: 99.0 %
	Embedded occurrences: 12
	Interleaving occurrences: 4

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 701834
==================================================================================================
Train data = 163598, Train data = 556626, 
==================================================================================================
	Training time : 0:04:21.604981
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 13223
	After : 10326
# Parameters = 5088658
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_29 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_30 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_29 (Embedding)        (None, 4, 480)       4956480     input_29[0][0]                   
__________________________________________________________________________________________________
embedding_30 (Embedding)        (None, 4, 42)        6594        input_30[0][0]                   
__________________________________________________________________________________________________
flatten_29 (Flatten)            (None, 1920)         0           embedding_29[0][0]               
__________________________________________________________________________________________________
flatten_30 (Flatten)            (None, 168)          0           embedding_30[0][0]               
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 2088)         0           flatten_29[0][0]                 
                                                                 flatten_30[0][0]                 
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 60)           125340      concatenate_15[0][0]             
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 60)           0           dense_29[0][0]                   
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 4)            244         dropout_15[0][0]                 
==================================================================================================
Total params: 5,088,658
Trainable params: 5,088,658
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 360963
	data size after focused sampling = 360963
	data size before sampling = 360963
	data size after sampling = 594172
	4 Labels in train : Counter({0: 148543, 1: 148543, 2: 148543, 3: 148543})
	4 Labels in valid : Counter({1: 14900, 3: 14876, 2: 14846, 0: 14796})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 534754 samples, validate on 59418 samples
Epoch 1/40
 - 18s - loss: 0.1523 - acc: 0.9704 - val_loss: 0.1035 - val_acc: 0.9790
Epoch 2/40
 - 18s - loss: 0.0997 - acc: 0.9801 - val_loss: 0.1015 - val_acc: 0.9800
Epoch 3/40
 - 18s - loss: 0.0931 - acc: 0.9812 - val_loss: 0.1025 - val_acc: 0.9805

==================================================================================================
	Training time : 0:01:13.106234
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:34.123915
==================================================================================================
	Identification : 0.719
	P, R  : 0.916, 0.592

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
ERROR:root:ATTENTION: Oracle problems with 4 sentences!
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================
	Train deformed lemmas: 23 

==================================================================================================
	PT Train (4474)
==================================================================================================
	Important sentence: 4474
	Token occurrences: 117645
	MWE number: 2202
	MWE occurrences: 4923
	Continuous occurrences: 57.0 %
	Frequent MWE occurences: 35.0 %
	MWE length: 2.22
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 8

==================================================================================================
	 Test (2770)
==================================================================================================
	Important sentence: 483
	Token occurrences: 58604
	MWE number: 448
	MWE occurrences: 553
	Continuous occurrences: 57.0 %
	MWE length: 2.25
	Seen occurrences : 69% 
	Recognizable MWEs: 97.0 %
	Embedded occurrences: 3
	Interleaving occurrences: 13

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 713723
==================================================================================================
Train data = 240208, Train data = 705870, 
==================================================================================================
	Training time : 0:04:38.074990
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 13649
	After : 10790
# Parameters = 5315032
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_31 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_32 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_31 (Embedding)        (None, 4, 480)       5179200     input_31[0][0]                   
__________________________________________________________________________________________________
embedding_32 (Embedding)        (None, 4, 42)        10248       input_32[0][0]                   
__________________________________________________________________________________________________
flatten_31 (Flatten)            (None, 1920)         0           embedding_31[0][0]               
__________________________________________________________________________________________________
flatten_32 (Flatten)            (None, 168)          0           embedding_32[0][0]               
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 2088)         0           flatten_31[0][0]                 
                                                                 flatten_32[0][0]                 
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 60)           125340      concatenate_16[0][0]             
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 60)           0           dense_31[0][0]                   
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 4)            244         dropout_16[0][0]                 
==================================================================================================
Total params: 5,315,032
Trainable params: 5,315,032
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 495291
	data size after focused sampling = 495291
	data size before sampling = 495291
	data size after sampling = 835920
	4 Labels in train : Counter({0: 208980, 1: 208980, 2: 208980, 3: 208980})
	4 Labels in valid : Counter({0: 21034, 1: 20970, 2: 20835, 3: 20753})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 752328 samples, validate on 83592 samples
Epoch 1/40
 - 26s - loss: 0.1192 - acc: 0.9774 - val_loss: 0.0760 - val_acc: 0.9856
Epoch 2/40
 - 26s - loss: 0.0790 - acc: 0.9850 - val_loss: 0.0737 - val_acc: 0.9861
Epoch 3/40
 - 26s - loss: 0.0742 - acc: 0.9858 - val_loss: 0.0730 - val_acc: 0.9867

==================================================================================================
	Training time : 0:01:43.158154
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:01:12.110397
==================================================================================================
	Identification : 0.703
	P, R  : 0.825, 0.613

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	RO Train (4797)
==================================================================================================
	Important sentence: 4797
	Token occurrences: 172618
	MWE number: 591
	MWE occurrences: 5301
	Continuous occurrences: 69.0 %
	Frequent MWE occurences: 84.0 %
	MWE length: 2.13
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1
	Embedded occurrences: 11

==================================================================================================
	 Test (6934)
==================================================================================================
	Important sentence: 533
	Token occurrences: 114997
	MWE number: 202
	MWE occurrences: 589
	Continuous occurrences: 67.0 %
	MWE length: 2.15
	Seen occurrences : 94% 
	Recognizable MWEs: 100.0 %
	Embedded occurrences: 1

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 724948
==================================================================================================
Train data = 350537, Train data = 1035708, 
==================================================================================================
	Training time : 0:05:55.703921
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 11692
	After : 9645
# Parameters = 4759678
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_33 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_34 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_33 (Embedding)        (None, 4, 480)       4629600     input_33[0][0]                   
__________________________________________________________________________________________________
embedding_34 (Embedding)        (None, 4, 42)        4494        input_34[0][0]                   
__________________________________________________________________________________________________
flatten_33 (Flatten)            (None, 1920)         0           embedding_33[0][0]               
__________________________________________________________________________________________________
flatten_34 (Flatten)            (None, 168)          0           embedding_34[0][0]               
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 2088)         0           flatten_33[0][0]                 
                                                                 flatten_34[0][0]                 
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 60)           125340      concatenate_17[0][0]             
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 60)           0           dense_33[0][0]                   
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 4)            244         dropout_17[0][0]                 
==================================================================================================
Total params: 4,759,678
Trainable params: 4,759,678
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 414338
	data size after focused sampling = 414338
	data size before sampling = 414338
	data size after sampling = 782112
	4 Labels in train : Counter({0: 195528, 1: 195528, 2: 195528, 3: 195528})
	4 Labels in valid : Counter({2: 19644, 3: 19621, 0: 19513, 1: 19434})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 703900 samples, validate on 78212 samples
Epoch 1/40
 - 24s - loss: 0.0971 - acc: 0.9845 - val_loss: 0.0648 - val_acc: 0.9895
Epoch 2/40
 - 24s - loss: 0.0709 - acc: 0.9887 - val_loss: 0.0649 - val_acc: 0.9895
Epoch 3/40
 - 24s - loss: 0.0683 - acc: 0.9890 - val_loss: 0.0647 - val_acc: 0.9898

==================================================================================================
	Training time : 0:01:36.392903
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:02:06.124074
==================================================================================================
	Identification : 0.819
	P, R  : 0.752, 0.9

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
ERROR:root:ATTENTION: Oracle problems with 1 sentences!
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================

==================================================================================================
	SL Train (2516)
==================================================================================================
	Important sentence: 2516
	Token occurrences: 65338
	MWE number: 1101
	MWE occurrences: 2864
	Continuous occurrences: 45.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.23
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 6

==================================================================================================
	 Test (1994)
==================================================================================================
	Important sentence: 428
	Token occurrences: 40523
	MWE number: 313
	MWE occurrences: 500
	Continuous occurrences: 49.0 %
	MWE length: 2.23
	Seen occurrences : 72% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 1
	Interleaving occurrences: 3

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 486888
==================================================================================================
Train data = 133538, Train data = 457366, 
==================================================================================================
	Training time : 0:03:59.854846
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 11519
	After : 8702
# Parameters = 4302964
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_35 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_36 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_35 (Embedding)        (None, 4, 480)       4176960     input_35[0][0]                   
__________________________________________________________________________________________________
embedding_36 (Embedding)        (None, 4, 42)        420         input_36[0][0]                   
__________________________________________________________________________________________________
flatten_35 (Flatten)            (None, 1920)         0           embedding_35[0][0]               
__________________________________________________________________________________________________
flatten_36 (Flatten)            (None, 168)          0           embedding_36[0][0]               
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 2088)         0           flatten_35[0][0]                 
                                                                 flatten_36[0][0]                 
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 60)           125340      concatenate_18[0][0]             
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 60)           0           dense_35[0][0]                   
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 4)            244         dropout_18[0][0]                 
==================================================================================================
Total params: 4,302,964
Trainable params: 4,302,964
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 274461
	data size after focused sampling = 274461
	data size before sampling = 274461
	data size after sampling = 470980
	4 Labels in train : Counter({0: 117745, 1: 117745, 2: 117745, 3: 117745})
	4 Labels in valid : Counter({1: 11898, 3: 11832, 2: 11720, 0: 11648})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 423882 samples, validate on 47098 samples
Epoch 1/40
 - 14s - loss: 0.1448 - acc: 0.9700 - val_loss: 0.0819 - val_acc: 0.9817
Epoch 2/40
 - 14s - loss: 0.0858 - acc: 0.9825 - val_loss: 0.0783 - val_acc: 0.9838
Epoch 3/40
 - 14s - loss: 0.0782 - acc: 0.9840 - val_loss: 0.0782 - val_acc: 0.9843

==================================================================================================
	Training time : 0:00:56.948787
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:50.287022
==================================================================================================
	Identification : 0.627
	P, R  : 0.705, 0.564

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
	Mode: LINEAR
==================================================================================================
	 Annotation issues
==================================================================================================
	Train deformed lemmas: 31277 
	Train important deformed Lemmas: 3223 

==================================================================================================
	TR Train (4843)
==================================================================================================
	Important sentence: 4843
	Token occurrences: 161269
	MWE number: 3813
	MWE occurrences: 6618
	Continuous occurrences: 50.0 %
	Frequent MWE occurences: 52.0 %
	MWE length: 2.06
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3

==================================================================================================
	 Test (589)
==================================================================================================
	Important sentence: 297
	Token occurrences: 14388
	MWE number: 439
	MWE occurrences: 506
	Continuous occurrences: 40.0 %
	MWE length: 2.07
	Seen occurrences : 25% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 4
	Interleaving occurrences: 3

==================================================================================================
	Linear classifier:
==================================================================================================
LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
     intercept_scaling=1, loss='squared_hinge', max_iter=1000,
     multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,
     verbose=0)
==================================================================================================
	Feature number = 955264
==================================================================================================
Train data = 329156, Train data = 806345, 
==================================================================================================
	Training time : 0:06:47.570519
==================================================================================================
	Mode: NON.COMPO
==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 12382
	After : 10351
# Parameters = 5099230
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_37 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_38 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_37 (Embedding)        (None, 4, 480)       4968480     input_37[0][0]                   
__________________________________________________________________________________________________
embedding_38 (Embedding)        (None, 4, 42)        5166        input_38[0][0]                   
__________________________________________________________________________________________________
flatten_37 (Flatten)            (None, 1920)         0           embedding_37[0][0]               
__________________________________________________________________________________________________
flatten_38 (Flatten)            (None, 168)          0           embedding_38[0][0]               
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 2088)         0           flatten_37[0][0]                 
                                                                 flatten_38[0][0]                 
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 60)           125340      concatenate_19[0][0]             
__________________________________________________________________________________________________
dropout_19 (Dropout)            (None, 60)           0           dense_37[0][0]                   
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 4)            244         dropout_19[0][0]                 
==================================================================================================
Total params: 5,099,230
Trainable params: 5,099,230
Non-trainable params: 0
__________________________________________________________________________________________________
None

__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 564975
	data size after focused sampling = 564975
	data size before sampling = 564975
	data size after sampling = 972548
	4 Labels in train : Counter({0: 243137, 1: 243137, 2: 243137, 3: 243137})
	4 Labels in valid : Counter({3: 24435, 2: 24365, 0: 24355, 1: 24100})
	Favorisation Coeff : 6

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 875293 samples, validate on 97255 samples
Epoch 1/40
 - 30s - loss: 0.1113 - acc: 0.9762 - val_loss: 0.0761 - val_acc: 0.9833
Epoch 2/40
 - 30s - loss: 0.0783 - acc: 0.9829 - val_loss: 0.0752 - val_acc: 0.9841
Epoch 3/40
 - 30s - loss: 0.0734 - acc: 0.9839 - val_loss: 0.0748 - val_acc: 0.9841

==================================================================================================
	Training time : 0:02:00.255393
==================================================================================================
	Mode: LINEAR
==================================================================================================
	Mode: NON.COMPO
==================================================================================================

==================================================================================================
	Parsing time : 0:00:18.826027
==================================================================================================
	Identification : 0.56
	P, R  : 0.888, 0.409

*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|*|
