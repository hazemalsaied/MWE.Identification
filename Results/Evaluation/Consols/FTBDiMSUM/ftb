INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_L9TIyn.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 5779/6083 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX TITAN Black (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmpXYMTUG and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/tmppGvunp). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
ERROR:root:ATTENTION: Oracle problems with 28 sentences!
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '9236')
INFO:theano.gof.compilelock:Waiting for existing lock by unknown process (I am process '9236')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO:theano.gof.compilelock:To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '9395' (I am process '9236')
INFO:theano.gof.compilelock:Waiting for existing lock by process '9395' (I am process '9236')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO:theano.gof.compilelock:To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '9236')
INFO:theano.gof.compilelock:Waiting for existing lock by unknown process (I am process '9236')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
INFO:theano.gof.compilelock:To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.11--2.7.14-64/lock_dir
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
64             ,0.4            ,60             ,0.059          ,42             ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,480            ,True           ,True           ,False          ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,True           ,False          ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
1              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 1, False, False, False, 35, False, False, 64, 0.4, 60, 0.059, 42, 3, 480, True, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (12h:57)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (15994)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 481933
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Non frequent word cleaning:
==================================================================================================
	Before : 25582
	After : 22742

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 22742 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9127
	One occurrence keys in vocabulary 9127 / 22742
# Parameters = 11114266
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 5, 480)       10916160    input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 5, 42)        41202       input_2[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 2400)         0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 210)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 2610)         0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 60)           156660      concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 60)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 4)            244         dropout_1[0][0]                  
==================================================================================================
Total params: 11,114,266
Trainable params: 11,114,266
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================
	4 Labels in train : Counter({0: 481933, 1: 439308, 2: 42625, 3: 25644})
	4 Labels in valid : Counter({0: 96161, 1: 88041, 2: 8565, 3: 5135})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.059
__________________________________________________________________________________________________
Train on 791608 samples, validate on 197902 samples
Epoch 1/10
 - 35s - loss: 0.0951 - acc: 0.9554 - val_loss: 0.0733 - val_acc: 0.9604
Epoch 2/10
 - 35s - loss: 0.0677 - acc: 0.9620 - val_loss: 0.0720 - val_acc: 0.9619
Epoch 3/10
 - 35s - loss: 0.0617 - acc: 0.9637 - val_loss: 0.0737 - val_acc: 0.9612
Epoch 4/10
 - 35s - loss: 0.0581 - acc: 0.9649 - val_loss: 0.0750 - val_acc: 0.9618
Epoch 5/10
 - 35s - loss: 0.0558 - acc: 0.9658 - val_loss: 0.0769 - val_acc: 0.9609
Epoch 00005: early stopping
	TRAINING TIME: 5.15 minutes 
==================================================================================================
	PARSING TIME: 0.63 minutes 
==================================================================================================
	Identification : 0.054
	P, R  : 0.638, 0.028

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 80.5
	F : 0.061
	P, R  : 0.786, 0.032

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 58.0
	F : 0.062
	P, R  : 0.832, 0.032

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 22.4
	F : 0.059
	P, R  : 0.667, 0.031

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 19.5
	F : 0.004
	P, R  : 0.029, 0.002

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.1
	Predicted: 12.6
	F : 0.004
	P, R  : 0.045, 0.002

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 19.5
	F : 0.004
	P, R  : 0.029, 0.002

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 99.4
	F : 0.054
	P, R  : 0.642, 0.028

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.6
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 75.9 / (all:seen + non seen)
	F : 0.062
	P, R  : 0.811, 0.032

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 4.6 / (all:seen + non seen)
	F : 0.054
	P, R  : 0.375, 0.029

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.054
	P, R  : 0.638, 0.028

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 54.0
	F : 0.059
	P, R  : 0.617, 0.031

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 33.9
	F : 0.041
	P, R  : 0.661, 0.021

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 12.1
	F : 0.083
	P, R  : 0.667, 0.044

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 32.5
	Seens: 47.6
	Non Seens: 52.4
	Frequently Seen: 27.0
	Barely Seen: 20.6
	Partially Seen: 52.4
	Partially Seen (Without stop words): 33.3
	Three Token MWEs: 31.7
	Two Token MWEs: 57.1
	MWTs: 0.0

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 28.2
	Seens: 85.3
	Non Seens: 14.7
	Frequently Seen: 64.5
	Barely Seen: 20.8
	Partially Seen: 14.0
	Partially Seen (Without stop words): 10.4
	Three Token MWEs: 46.2
	Two Token MWEs: 46.1
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (13 h:8)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 18 sentences!
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,2              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
128            ,0.3            ,85             ,0.017          ,147            ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,157            ,True           ,False          ,True           ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,True           ,False          ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
1              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 2, False, True, False, 35, True, False, 128, 0.3, 85, 0.017, 147, 3, 157, True, False, True, False, False, True, True, False, 1, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (13h:8)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (11492)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 401491
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 24177
	After : 13303

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13303 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9126
	One occurrence keys in vocabulary 9126 / 13303
# Parameters = 2362407
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_4 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 5, 157)       2088571     input_3[0][0]                    
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 5, 147)       144207      input_4[0][0]                    
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 785)          0           embedding_3[0][0]                
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 735)          0           embedding_4[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 1520)         0           flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 85)           129285      concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 85)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 4)            344         dropout_2[0][0]                  
==================================================================================================
Total params: 2,362,407
Trainable params: 2,362,407
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 828614
	data size after sampling = 1605964
	4 Labels in train : Counter({0: 401491, 1: 401491, 2: 401491, 3: 401491})
	4 Labels in valid : Counter({3: 80379, 1: 80373, 2: 80307, 0: 80134})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
Train on 1284771 samples, validate on 321193 samples
Epoch 1/10
 - 16s - loss: 0.0986 - acc: 0.9711 - val_loss: 0.0867 - val_acc: 0.9747
Epoch 2/10
 - 16s - loss: 0.0852 - acc: 0.9752 - val_loss: 0.0847 - val_acc: 0.9754
Epoch 3/10
 - 16s - loss: 0.0821 - acc: 0.9762 - val_loss: 0.0840 - val_acc: 0.9758
Epoch 4/10
 - 16s - loss: 0.0804 - acc: 0.9768 - val_loss: 0.0844 - val_acc: 0.9759
Epoch 5/10
 - 16s - loss: 0.0791 - acc: 0.9772 - val_loss: 0.0845 - val_acc: 0.9761
Epoch 00005: early stopping
	TRAINING TIME: 2.32 minutes 
==================================================================================================
	PARSING TIME: 0.65 minutes 
==================================================================================================
	Identification : 0.755
	P, R  : 0.777, 0.734

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 88.3
	F : 0.839
	P, R  : 0.851, 0.827

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 68.7
	F : 0.881
	P, R  : 0.881, 0.881

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 19.6
	F : 0.697
	P, R  : 0.742, 0.658

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 11.7
	F : 0.205
	P, R  : 0.228, 0.186

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.6
	Predicted: 8.9
	F : 0.237
	P, R  : 0.268, 0.213

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 11.7
	F : 0.199
	P, R  : 0.228, 0.177

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.755
	P, R  : 0.777, 0.734

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 85.4 / (all:seen + non seen)
	F : 0.847
	P, R  : 0.861, 0.834

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 2.9 / (all:seen + non seen)
	F : 0.547
	P, R  : 0.527, 0.569

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 1.9
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.755
	P, R  : 0.778, 0.734

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 48.5
	F : 0.722
	P, R  : 0.726, 0.719

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 46.2
	F : 0.816
	P, R  : 0.838, 0.796

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 5.3
	F : 0.558
	P, R  : 0.72, 0.456

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 6.7
	Seens: 59.3
	Non Seens: 40.7
	Frequently Seen: 36.6
	Barely Seen: 22.7
	Partially Seen: 40.7
	Partially Seen (Without stop words): 29.4
	Three Token MWEs: 33.6
	Two Token MWEs: 59.6
	MWTs: 0.1

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 7.7
	Seens: 55.8
	Non Seens: 44.2
	Frequently Seen: 29.0
	Barely Seen: 26.8
	Partially Seen: 41.6
	Partially Seen (Without stop words): 31.4
	Three Token MWEs: 35.1
	Two Token MWEs: 48.8
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (13 h:19)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 18 sentences!
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,2              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
16             ,0.1            ,56             ,0.095          ,132            ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,300            ,True           ,True           ,False          ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
0              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 2, False, True, False, 35, True, False, 16, 0.1, 56, 0.095, 132, 3, 300, True, True, False, False, False, True, False, True, 0, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (13h:19)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (11492)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 401491
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Non frequent word cleaning:
==================================================================================================
	Before : 24177
	After : 21567

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 21567 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9126
	One occurrence keys in vocabulary 9126 / 21567
# Parameters = 6696644
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_5 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 4, 300)       6470100     input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 4, 132)       129492      input_6[0][0]                    
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 1200)         0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 528)          0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 1728)         0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 56)           96824       concatenate_3[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 56)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 4)            228         dropout_3[0][0]                  
==================================================================================================
Total params: 6,696,644
Trainable params: 6,696,644
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 828614
	data size after sampling = 1605964
	4 Labels in train : Counter({0: 401491, 1: 401491, 2: 401491, 3: 401491})
	4 Labels in valid : Counter({3: 80456, 0: 80388, 1: 80253, 2: 80096})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.095
__________________________________________________________________________________________________
Train on 1284771 samples, validate on 321193 samples
Epoch 1/10
 - 168s - loss: 0.0996 - acc: 0.9710 - val_loss: 0.0893 - val_acc: 0.9739
Epoch 2/10
 - 168s - loss: 0.0841 - acc: 0.9754 - val_loss: 0.0880 - val_acc: 0.9748
Epoch 3/10
 - 167s - loss: 0.0807 - acc: 0.9766 - val_loss: 0.0879 - val_acc: 0.9753
Epoch 4/10
 - 167s - loss: 0.0788 - acc: 0.9771 - val_loss: 0.0880 - val_acc: 0.9755
Epoch 5/10
 - 167s - loss: 0.0775 - acc: 0.9775 - val_loss: 0.0892 - val_acc: 0.9756
Epoch 00005: early stopping
	TRAINING TIME: 17.92 minutes 
==================================================================================================
	PARSING TIME: 0.65 minutes 
==================================================================================================
	Identification : 0.766
	P, R  : 0.769, 0.764

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 92.2
	F : 0.841
	P, R  : 0.814, 0.869

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 69.8
	F : 0.881
	P, R  : 0.852, 0.911

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 22.4
	F : 0.717
	P, R  : 0.695, 0.741

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 7.7
	F : 0.173
	P, R  : 0.239, 0.135

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.6
	Predicted: 5.8
	F : 0.199
	P, R  : 0.283, 0.154

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 7.8
	F : 0.166
	P, R  : 0.238, 0.128

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.767
	P, R  : 0.77, 0.764

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 88.3 / (all:seen + non seen)
	F : 0.851
	P, R  : 0.83, 0.874

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 3.9 / (all:seen + non seen)
	F : 0.562
	P, R  : 0.462, 0.716

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 2.2
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.1
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 99.9
	F : 0.767
	P, R  : 0.77, 0.764

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 47.3
	F : 0.74
	P, R  : 0.734, 0.746

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 46.0
	F : 0.821
	P, R  : 0.824, 0.819

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 6.5
	F : 0.595
	P, R  : 0.656, 0.544

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 6.6
	Seens: 74.3
	Non Seens: 25.7
	Frequently Seen: 44.7
	Barely Seen: 29.6
	Partially Seen: 25.5
	Partially Seen (Without stop words): 18.1
	Three Token MWEs: 35.1
	Two Token MWEs: 54.6
	MWTs: 0.5

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 6.9
	Seens: 47.3
	Non Seens: 52.7
	Frequently Seen: 24.4
	Barely Seen: 22.9
	Partially Seen: 49.7
	Partially Seen (Without stop words): 38.0
	Three Token MWEs: 35.2
	Two Token MWEs: 49.7
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (13 h:45)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 18 sentences!
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,15             ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
48             ,0.4            ,75             ,0.03           ,35             ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,300            ,True           ,True           ,True           ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
1              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 15, False, True, False, 35, True, False, 48, 0.4, 75, 0.03, 35, 3, 300, True, True, True, False, False, True, False, True, 1, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (13h:45)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (11492)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 401491
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 24177
	After : 13303

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13303 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9126
	One occurrence keys in vocabulary 9126 / 13303
# Parameters = 4151239
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 5, 300)       3990900     input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 5, 35)        34335       input_8[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 1500)         0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 175)          0           embedding_8[0][0]                
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 1675)         0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 75)           125700      concatenate_4[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 75)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 4)            304         dropout_4[0][0]                  
==================================================================================================
Total params: 4,151,239
Trainable params: 4,151,239
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 828614
	data size after sampling = 1605964
	4 Labels in train : Counter({0: 401491, 1: 401491, 2: 401491, 3: 401491})
	4 Labels in valid : Counter({3: 80379, 1: 80373, 2: 80307, 0: 80134})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Train on 1284771 samples, validate on 321193 samples
Epoch 1/10
 - 47s - loss: 0.0978 - acc: 0.9715 - val_loss: 0.0852 - val_acc: 0.9751
Epoch 2/10
 - 47s - loss: 0.0836 - acc: 0.9756 - val_loss: 0.0840 - val_acc: 0.9757
Epoch 3/10
 - 47s - loss: 0.0805 - acc: 0.9766 - val_loss: 0.0840 - val_acc: 0.9760
Epoch 4/10
 - 47s - loss: 0.0786 - acc: 0.9772 - val_loss: 0.0841 - val_acc: 0.9764
Epoch 5/10
 - 47s - loss: 0.0774 - acc: 0.9776 - val_loss: 0.0843 - val_acc: 0.9763
Epoch 00005: early stopping
	TRAINING TIME: 5.55 minutes 
==================================================================================================
	PARSING TIME: 0.65 minutes 
==================================================================================================
	Identification : 0.777
	P, R  : 0.827, 0.732

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 98.9
	F : 0.843
	P, R  : 0.834, 0.852

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 75.6
	F : 0.884
	P, R  : 0.87, 0.899

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 23.3
	F : 0.711
	P, R  : 0.716, 0.707

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 1.0
	F : 0.028
	P, R  : 0.216, 0.015

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.6
	Predicted: 0.9
	F : 0.035
	P, R  : 0.258, 0.019

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 1.1
	F : 0.026
	P, R  : 0.205, 0.014

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.777
	P, R  : 0.827, 0.732

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 95.4 / (all:seen + non seen)
	F : 0.851
	P, R  : 0.845, 0.858

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 3.5 / (all:seen + non seen)
	F : 0.579
	P, R  : 0.524, 0.647

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 1.6
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.1
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 99.9
	F : 0.777
	P, R  : 0.828, 0.732

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 47.0
	F : 0.754
	P, R  : 0.796, 0.716

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 46.8
	F : 0.831
	P, R  : 0.876, 0.791

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 6.0
	F : 0.577
	P, R  : 0.715, 0.484

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 5.2
	Seens: 95.0
	Non Seens: 5.0
	Frequently Seen: 56.7
	Barely Seen: 38.2
	Partially Seen: 4.7
	Partially Seen (Without stop words): 3.7
	Three Token MWEs: 33.7
	Two Token MWEs: 55.6
	MWTs: 0.8

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 7.8
	Seens: 47.4
	Non Seens: 52.6
	Frequently Seen: 24.6
	Barely Seen: 22.8
	Partially Seen: 50.0
	Partially Seen (Without stop words): 38.9
	Three Token MWEs: 35.9
	Two Token MWEs: 49.0
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (13 h:58)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 18 sentences!
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,15             ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
48             ,0.4            ,75             ,0.03           ,35             ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,300            ,True           ,True           ,True           ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,False          ,False          ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
1              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 15, False, True, False, 35, True, False, 48, 0.4, 75, 0.03, 35, 3, 300, True, True, True, False, False, True, False, False, 1, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (13h:58)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (11492)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 401491
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 24177
	After : 13303

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13303 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9126
	One occurrence keys in vocabulary 9126 / 13303
# Parameters = 4151239
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_9 (InputLayer)            (None, 5)            0                                            
__________________________________________________________________________________________________
input_10 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 5, 300)       3990900     input_9[0][0]                    
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 5, 35)        34335       input_10[0][0]                   
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 1500)         0           embedding_9[0][0]                
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 175)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 1675)         0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 75)           125700      concatenate_5[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 75)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 4)            304         dropout_5[0][0]                  
==================================================================================================
Total params: 4,151,239
Trainable params: 4,151,239
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 828614
	data size after sampling = 1605964
	4 Labels in train : Counter({0: 401491, 1: 401491, 2: 401491, 3: 401491})
	4 Labels in valid : Counter({3: 80379, 1: 80373, 2: 80307, 0: 80134})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Train on 1284771 samples, validate on 321193 samples
Epoch 1/10
 - 47s - loss: 0.0944 - acc: 0.9726 - val_loss: 0.0846 - val_acc: 0.9754
Epoch 2/10
 - 47s - loss: 0.0826 - acc: 0.9761 - val_loss: 0.0831 - val_acc: 0.9760
Epoch 3/10
 - 47s - loss: 0.0796 - acc: 0.9770 - val_loss: 0.0834 - val_acc: 0.9762
Epoch 4/10
 - 47s - loss: 0.0778 - acc: 0.9775 - val_loss: 0.0843 - val_acc: 0.9763
Epoch 5/10
 - 47s - loss: 0.0766 - acc: 0.9779 - val_loss: 0.0849 - val_acc: 0.9765
Epoch 00005: early stopping
	TRAINING TIME: 5.52 minutes 
==================================================================================================
	PARSING TIME: 0.67 minutes 
==================================================================================================
	Identification : 0.783
	P, R  : 0.815, 0.754

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 97.6
	F : 0.851
	P, R  : 0.83, 0.873

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 73.5
	F : 0.891
	P, R  : 0.87, 0.912

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 24.1
	F : 0.729
	P, R  : 0.706, 0.754

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 2.4
	F : 0.066
	P, R  : 0.239, 0.038

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.6
	Predicted: 1.9
	F : 0.084
	P, R  : 0.304, 0.049

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 2.4
	F : 0.062
	P, R  : 0.233, 0.036

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.783
	P, R  : 0.815, 0.754

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 93.8 / (all:seen + non seen)
	F : 0.86
	P, R  : 0.842, 0.878

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 3.8 / (all:seen + non seen)
	F : 0.603
	P, R  : 0.521, 0.716

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 1.3
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.1
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 99.9
	F : 0.784
	P, R  : 0.816, 0.754

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 48.0
	F : 0.766
	P, R  : 0.782, 0.751

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 46.1
	F : 0.831
	P, R  : 0.863, 0.801

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 5.8
	F : 0.587
	P, R  : 0.722, 0.494

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 5.5
	Seens: 90.0
	Non Seens: 10.0
	Frequently Seen: 51.6
	Barely Seen: 38.4
	Partially Seen: 9.7
	Partially Seen (Without stop words): 7.0
	Three Token MWEs: 34.3
	Two Token MWEs: 56.5
	MWTs: 0.4

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 7.1
	Seens: 44.1
	Non Seens: 55.9
	Frequently Seen: 23.3
	Barely Seen: 20.8
	Partially Seen: 53.1
	Partially Seen (Without stop words): 41.0
	Three Token MWEs: 37.1
	Two Token MWEs: 46.8
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (14 h:12)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 18 sentences!
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,15             ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
48             ,0.4            ,75             ,0.03           ,35             ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,300            ,True           ,True           ,True           ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,False          ,False          ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
1              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 15, False, True, False, 35, True, False, 48, 0.4, 75, 0.03, 35, 3, 300, True, True, True, False, False, True, False, False, 1, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (14h:12)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (11492)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 401491
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 24177
	After : 13303

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13303 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9126
	One occurrence keys in vocabulary 9126 / 13303
# Parameters = 4151239
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_11 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 5, 300)       3990900     input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 5, 35)        34335       input_12[0][0]                   
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 1500)         0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 175)          0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 1675)         0           flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 75)           125700      concatenate_6[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 75)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 4)            304         dropout_6[0][0]                  
==================================================================================================
Total params: 4,151,239
Trainable params: 4,151,239
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 828614
	data size after sampling = 1605964
	4 Labels in train : Counter({0: 401491, 1: 401491, 2: 401491, 3: 401491})
	4 Labels in valid : Counter({3: 80379, 1: 80373, 2: 80307, 0: 80134})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
Train on 1284771 samples, validate on 321193 samples
Epoch 1/10
 - 47s - loss: 0.0944 - acc: 0.9726 - val_loss: 0.0846 - val_acc: 0.9754
Epoch 2/10
 - 47s - loss: 0.0826 - acc: 0.9761 - val_loss: 0.0831 - val_acc: 0.9760
Epoch 3/10
 - 47s - loss: 0.0796 - acc: 0.9770 - val_loss: 0.0834 - val_acc: 0.9762
Epoch 4/10
 - 47s - loss: 0.0778 - acc: 0.9775 - val_loss: 0.0842 - val_acc: 0.9763
Epoch 5/10
 - 47s - loss: 0.0766 - acc: 0.9780 - val_loss: 0.0849 - val_acc: 0.9765
Epoch 00005: early stopping
	TRAINING TIME: 5.5 minutes 
==================================================================================================
	PARSING TIME: 0.67 minutes 
==================================================================================================
	Identification : 0.783
	P, R  : 0.819, 0.75

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 98.1
	F : 0.851
	P, R  : 0.831, 0.871

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 74.0
	F : 0.89
	P, R  : 0.871, 0.91

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 24.1
	F : 0.728
	P, R  : 0.709, 0.749

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 1.8
	F : 0.046
	P, R  : 0.206, 0.026

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.6
	Predicted: 1.4
	F : 0.059
	P, R  : 0.264, 0.033

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 1.9
	F : 0.043
	P, R  : 0.2, 0.024

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.783
	P, R  : 0.819, 0.75

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 94.3 / (all:seen + non seen)
	F : 0.86
	P, R  : 0.844, 0.876

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 3.8 / (all:seen + non seen)
	F : 0.598
	P, R  : 0.518, 0.706

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 1.3
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.1
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 99.9
	F : 0.783
	P, R  : 0.82, 0.75

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 47.8
	F : 0.766
	P, R  : 0.788, 0.746

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 46.3
	F : 0.83
	P, R  : 0.865, 0.798

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 5.8
	F : 0.581
	P, R  : 0.72, 0.487

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 5.4
	Seens: 91.6
	Non Seens: 8.4
	Frequently Seen: 52.8
	Barely Seen: 38.8
	Partially Seen: 8.1
	Partially Seen (Without stop words): 5.8
	Three Token MWEs: 34.5
	Two Token MWEs: 56.1
	MWTs: 0.4

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 7.3
	Seens: 44.3
	Non Seens: 55.7
	Frequently Seen: 23.4
	Barely Seen: 20.9
	Partially Seen: 52.9
	Partially Seen (Without stop words): 41.0
	Three Token MWEs: 37.0
	Two Token MWEs: 47.0
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (14 h:25)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 18 sentences!
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,2              ,True           ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,10             ,True           ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
64             ,0.3            ,174            ,0.015          ,15             ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,383            ,True           ,True           ,True           ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,True           ,False          ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
1              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 2, True, True, False, 10, True, False, 64, 0.3, 174, 0.015, 15, 3, 383, True, True, True, False, False, True, True, False, 1, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (14h:25)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (11492)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 401491
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 24177
	After : 13303

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13303 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9126
	One occurrence keys in vocabulary 9126 / 13303
# Parameters = 5456898
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 5)            0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 5, 383)       5095049     input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 5, 15)        14715       input_14[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 1915)         0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 75)           0           embedding_14[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 1990)         0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 174)          346434      concatenate_7[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 174)          0           dense_13[0][0]                   
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 4)            700         dropout_7[0][0]                  
==================================================================================================
Total params: 5,456,898
Trainable params: 5,456,898
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 828614
10 10
	data size after focused sampling = 1038429

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 1038429
	data size after sampling = 1937116
	4 Labels in train : Counter({0: 484279, 1: 484279, 2: 484279, 3: 484279})
	4 Labels in valid : Counter({0: 97073, 1: 96921, 3: 96849, 2: 96581})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
Train on 1549692 samples, validate on 387424 samples
Epoch 1/10
 - 52s - loss: 0.1050 - acc: 0.9660 - val_loss: 0.0845 - val_acc: 0.9727
Epoch 2/10
 - 52s - loss: 0.0804 - acc: 0.9742 - val_loss: 0.0794 - val_acc: 0.9757
Epoch 3/10
 - 52s - loss: 0.0746 - acc: 0.9764 - val_loss: 0.0772 - val_acc: 0.9770
Epoch 4/10
 - 52s - loss: 0.0715 - acc: 0.9774 - val_loss: 0.0765 - val_acc: 0.9777
Epoch 5/10
 - 52s - loss: 0.0695 - acc: 0.9781 - val_loss: 0.0758 - val_acc: 0.9780
Epoch 00005: early stopping
	TRAINING TIME: 6.03 minutes 
==================================================================================================
	PARSING TIME: 0.62 minutes 
==================================================================================================
	Identification : 0.782
	P, R  : 0.819, 0.749

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 99.3
	F : 0.848
	P, R  : 0.824, 0.873

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 72.1
	F : 0.888
	P, R  : 0.881, 0.895

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 27.3
	F : 0.734
	P, R  : 0.674, 0.806

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 0.7
	F : 0.01
	P, R  : 0.125, 0.005

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.6
	Predicted: 0.4
	F : 0.013
	P, R  : 0.188, 0.007

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 0.7
	F : 0.01
	P, R  : 0.125, 0.005

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.782
	P, R  : 0.819, 0.749

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 95.2 / (all:seen + non seen)
	F : 0.858
	P, R  : 0.839, 0.878

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 4.2 / (all:seen + non seen)
	F : 0.57
	P, R  : 0.474, 0.716

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 1.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.1
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 99.9
	F : 0.783
	P, R  : 0.82, 0.749

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 46.2
	F : 0.77
	P, R  : 0.806, 0.737

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 47.2
	F : 0.827
	P, R  : 0.853, 0.802

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 6.5
	F : 0.586
	P, R  : 0.679, 0.516

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 5.4
	Seens: 96.8
	Non Seens: 3.2
	Frequently Seen: 47.6
	Barely Seen: 49.2
	Partially Seen: 3.2
	Partially Seen (Without stop words): 2.0
	Three Token MWEs: 38.3
	Two Token MWEs: 49.7
	MWTs: 0.5

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 7.3
	Seens: 43.3
	Non Seens: 56.7
	Frequently Seen: 27.2
	Barely Seen: 16.1
	Partially Seen: 53.9
	Partially Seen (Without stop words): 42.0
	Three Token MWEs: 36.3
	Two Token MWEs: 48.6
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (14 h:39)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 18 sentences!
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,2              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,10             ,True           ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
128            ,0.1            ,105            ,0.067          ,125            ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,300            ,True           ,True           ,False          ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
0              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 2, False, True, False, 10, True, False, 128, 0.1, 105, 0.067, 125, 3, 300, True, True, False, False, False, True, False, True, 0, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (14h:39)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (11492)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 401491
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Non frequent word cleaning:
==================================================================================================
	Before : 24177
	After : 21567

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 21567 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9126
	One occurrence keys in vocabulary 9126 / 21567
# Parameters = 6771754
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_15 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_16 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 4, 300)       6470100     input_15[0][0]                   
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 4, 125)       122625      input_16[0][0]                   
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 1200)         0           embedding_15[0][0]               
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 500)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 1700)         0           flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 105)          178605      concatenate_8[0][0]              
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 105)          0           dense_15[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 4)            424         dropout_8[0][0]                  
==================================================================================================
Total params: 6,771,754
Trainable params: 6,771,754
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 828614
	data size after sampling = 1605964
	4 Labels in train : Counter({0: 401491, 1: 401491, 2: 401491, 3: 401491})
	4 Labels in valid : Counter({3: 80456, 0: 80388, 1: 80253, 2: 80096})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.067
__________________________________________________________________________________________________
Train on 1284771 samples, validate on 321193 samples
Epoch 1/10
 - 23s - loss: 0.0967 - acc: 0.9728 - val_loss: 0.0857 - val_acc: 0.9751
Epoch 2/10
 - 23s - loss: 0.0793 - acc: 0.9771 - val_loss: 0.0855 - val_acc: 0.9756
Epoch 3/10
 - 23s - loss: 0.0759 - acc: 0.9782 - val_loss: 0.0853 - val_acc: 0.9761
Epoch 4/10
 - 23s - loss: 0.0741 - acc: 0.9789 - val_loss: 0.0865 - val_acc: 0.9762
Epoch 5/10
 - 23s - loss: 0.0730 - acc: 0.9792 - val_loss: 0.0889 - val_acc: 0.9763
Epoch 00005: early stopping
	TRAINING TIME: 3.0 minutes 
==================================================================================================
	PARSING TIME: 0.67 minutes 
==================================================================================================
	Identification : 0.792
	P, R  : 0.799, 0.785

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 93.8
	F : 0.861
	P, R  : 0.831, 0.894

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 71.0
	F : 0.895
	P, R  : 0.864, 0.929

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 22.9
	F : 0.756
	P, R  : 0.729, 0.785

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 6.1
	F : 0.195
	P, R  : 0.318, 0.141

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.6
	Predicted: 4.9
	F : 0.228
	P, R  : 0.362, 0.166

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 6.2
	F : 0.188
	P, R  : 0.314, 0.134

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.792
	P, R  : 0.799, 0.785

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 89.9 / (all:seen + non seen)
	F : 0.87
	P, R  : 0.845, 0.897

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 3.9 / (all:seen + non seen)
	F : 0.627
	P, R  : 0.523, 0.784

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 1.3
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.1
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 99.9
	F : 0.792
	P, R  : 0.8, 0.785

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 47.9
	F : 0.77
	P, R  : 0.764, 0.777

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 45.7
	F : 0.841
	P, R  : 0.851, 0.831

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 6.4
	F : 0.626
	P, R  : 0.704, 0.563

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 5.9
	Seens: 78.8
	Non Seens: 21.2
	Frequently Seen: 48.0
	Barely Seen: 30.9
	Partially Seen: 20.8
	Partially Seen (Without stop words): 15.7
	Three Token MWEs: 33.9
	Two Token MWEs: 56.3
	MWTs: 0.4

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 6.2
	Seens: 42.3
	Non Seens: 57.7
	Frequently Seen: 21.4
	Barely Seen: 20.9
	Partially Seen: 54.5
	Partially Seen (Without stop words): 41.3
	Three Token MWEs: 36.1
	Two Token MWEs: 48.0
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (14 h:50)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 18 sentences!
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,8              ,True           ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,16             ,True           ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
64             ,0.3            ,200            ,0.04           ,60             ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,300            ,True           ,True           ,True           ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
0              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 8, True, True, False, 16, True, False, 64, 0.3, 200, 0.04, 60, 3, 300, True, True, True, False, False, True, False, True, 0, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (14h:50)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (11492)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 401491
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 24177
	After : 13303

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13303 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9126
	One occurrence keys in vocabulary 9126 / 13303
# Parameters = 4338764
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_17 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 4, 300)       3990900     input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 4, 60)        58860       input_18[0][0]                   
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 1200)         0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 240)          0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 1440)         0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 200)          288200      concatenate_9[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 200)          0           dense_17[0][0]                   
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 4)            804         dropout_9[0][0]                  
==================================================================================================
Total params: 4,338,764
Trainable params: 4,338,764
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 828614
8 8
	data size after focused sampling = 1196231

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 1196231
	data size after sampling = 2185540
	4 Labels in train : Counter({0: 546385, 1: 546385, 2: 546385, 3: 546385})
	4 Labels in valid : Counter({0: 109596, 1: 109397, 3: 109079, 2: 109036})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________
Train on 1748432 samples, validate on 437108 samples
Epoch 1/10
 - 50s - loss: 0.0977 - acc: 0.9684 - val_loss: 0.0760 - val_acc: 0.9751
Epoch 2/10
 - 50s - loss: 0.0724 - acc: 0.9761 - val_loss: 0.0720 - val_acc: 0.9771
Epoch 3/10
 - 50s - loss: 0.0679 - acc: 0.9775 - val_loss: 0.0708 - val_acc: 0.9777
Epoch 4/10
 - 50s - loss: 0.0658 - acc: 0.9781 - val_loss: 0.0707 - val_acc: 0.9779
Epoch 5/10
 - 50s - loss: 0.0644 - acc: 0.9784 - val_loss: 0.0707 - val_acc: 0.9781
Epoch 00005: early stopping
	TRAINING TIME: 5.87 minutes 
==================================================================================================
	PARSING TIME: 0.67 minutes 
==================================================================================================
	Identification : 0.782
	P, R  : 0.784, 0.78

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 94.9
	F : 0.853
	P, R  : 0.814, 0.896

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 67.4
	F : 0.894
	P, R  : 0.879, 0.909

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 27.5
	F : 0.741
	P, R  : 0.654, 0.856

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 5.0
	F : 0.126
	P, R  : 0.234, 0.086

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.6
	Predicted: 4.0
	F : 0.145
	P, R  : 0.265, 0.1

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 5.1
	F : 0.121
	P, R  : 0.23, 0.082

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.782
	P, R  : 0.784, 0.78

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 90.2 / (all:seen + non seen)
	F : 0.864
	P, R  : 0.832, 0.898

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 4.7 / (all:seen + non seen)
	F : 0.593
	P, R  : 0.457, 0.843

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 0.6
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.1
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 99.9
	F : 0.782
	P, R  : 0.785, 0.78

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 45.1
	F : 0.768
	P, R  : 0.78, 0.756

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 47.5
	F : 0.828
	P, R  : 0.817, 0.84

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 7.4
	F : 0.591
	P, R  : 0.611, 0.573

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 6.3
	Seens: 81.8
	Non Seens: 18.2
	Frequently Seen: 37.8
	Barely Seen: 44.0
	Partially Seen: 17.8
	Partially Seen (Without stop words): 13.8
	Three Token MWEs: 40.3
	Two Token MWEs: 46.0
	MWTs: 0.3

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 6.4
	Seens: 40.4
	Non Seens: 59.6
	Frequently Seen: 26.7
	Barely Seen: 13.6
	Partially Seen: 56.5
	Partially Seen (Without stop words): 43.4
	Three Token MWEs: 33.5
	Two Token MWEs: 51.3
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (15 h:4)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 18 sentences!
	Mode: NON.COMPO
==================================================================================================
	Dataset: FTB
==================================================================================================
	Division: CORPUS
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, batchSize, dense1Dropout, dense1UnitNumber, lr, posEmb, posWindow, tokenEmb, trainable, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, checkPoint, dense1Activation, depParserBatchSize, depParsingLR, earlyStop, epochs, idenLR, identBatchSize, initialEpochs, jointLearningEpochs, loss, minDelta, monitor, optimizer, patience, predictVerbose, taggingBatchSize, taggingLR, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
MLP            ,ftb            ,corpus         ,8              ,True           ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,16             ,True           ,False          ,
__________________________________________________________________________________________________
batchSize      ,dense1Dropout  ,dense1UnitNumbe,lr             ,posEmb         ,
__________________________________________________________________________________________________
64             ,0.3            ,200            ,0.04           ,60             ,
__________________________________________________________________________________________________
posWindow      ,tokenEmb       ,trainable      ,average        ,compactVocab   ,
__________________________________________________________________________________________________
3              ,300            ,True           ,True           ,True           ,
__________________________________________________________________________________________________
dynamicVocab   ,keras          ,lemma          ,manual         ,pretrained     ,
__________________________________________________________________________________________________
False          ,False          ,True           ,False          ,False          ,
__________________________________________________________________________________________________
useB-1         ,useB1          ,batchSize      ,checkPoint     ,dense1Activatio,
__________________________________________________________________________________________________
0              ,1              ,32             ,False          ,relu           ,
__________________________________________________________________________________________________
depParserBatchS,depParsingLR   ,earlyStop      ,epochs         ,idenLR         ,
__________________________________________________________________________________________________
32             ,0.03           ,True           ,10             ,0.01           ,
__________________________________________________________________________________________________
identBatchSize ,initialEpochs  ,jointLearningEp,loss           ,minDelta       ,
__________________________________________________________________________________________________
32             ,1              ,20             ,categorical_crossentropy,0.2            ,
__________________________________________________________________________________________________
monitor        ,optimizer      ,patience       ,predictVerbose ,taggingBatchSiz,
__________________________________________________________________________________________________
val_loss       ,adagrad        ,4              ,False          ,32             ,
__________________________________________________________________________________________________
taggingLR      ,validationSplit,
__________________________________________________________________________________________________
0.02           ,0.2            ,
__________________________________________________________________________________________________
# Configs: MLP, ftb, corpus, 8, True, True, False, 16, True, False, 64, 0.3, 200, 0.04, 60, 3, 300, True, True, True, False, False, True, False, False, 0, 1, 32, False, relu, 32, 0.03, True, 10, 0.01, 32, 1, 20, categorical_crossentropy, 0.2, val_loss, adagrad, 4, False, 32, 0.02, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 19/9 (15h:4)
==================================================================================================
FTB MWTs are cleaned!

==================================================================================================
	FR Train (11492)
==================================================================================================
	Important sentence: 11492
	Token occurrences: 401491
	MWE number: 5914
	MWE occurrences: 25612
	Continuous occurrences: 100.0 %
	Frequent MWE occurences: 67.0 %
	MWE length: 2.66
	Recognizable MWEs: 100.0 %

==================================================================================================
	 Test (2541)
==================================================================================================
	Important sentence: 1800
	Token occurrences: 75216
	MWE number: 1490
	MWE occurrences: 4031
	Continuous occurrences: 100.0 %
	MWE length: 2.66
	Seen occurrences : 85% 
	Recognizable MWEs: 100.0 %

==================================================================================================
== FR,14759,23499,1.59218104208,0,2.66747521171,0,0,0,0,0,0,0
	Compact Vocabulary cleaning:
==================================================================================================
	Before : 24177
	After : 13303

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 13303 * POS : 981
__________________________________________________________________________________________________
	Dashed keys in vocabulary 9126
	One occurrence keys in vocabulary 9126 / 13303
# Parameters = 4338764
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 4)            0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 4, 300)       3990900     input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 4, 60)        58860       input_20[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 1200)         0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 240)          0           embedding_20[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 1440)         0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 200)          288200      concatenate_10[0][0]             
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 200)          0           dense_19[0][0]                   
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 4)            804         dropout_10[0][0]                 
==================================================================================================
Total params: 4,338,764
Trainable params: 4,338,764
Non-trainable params: 0
__________________________________________________________________________________________________
None
__________________________________________________________________________________________________
	Sampling
==================================================================================================
	data size before focused sampling = 828614
8 8
	data size after focused sampling = 1196231

==================================================================================================
	Resampling:
==================================================================================================
	data size before sampling = 1196231
	data size after sampling = 2185540
	4 Labels in train : Counter({0: 546385, 1: 546385, 2: 546385, 3: 546385})
	4 Labels in valid : Counter({0: 109596, 1: 109397, 3: 109079, 2: 109036})

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.04
__________________________________________________________________________________________________
Train on 1748432 samples, validate on 437108 samples
Epoch 1/10
 - 50s - loss: 0.0924 - acc: 0.9695 - val_loss: 0.0750 - val_acc: 0.9753
Epoch 2/10
 - 50s - loss: 0.0720 - acc: 0.9762 - val_loss: 0.0715 - val_acc: 0.9768
Epoch 3/10
 - 50s - loss: 0.0677 - acc: 0.9775 - val_loss: 0.0706 - val_acc: 0.9775
Epoch 4/10
 - 50s - loss: 0.0655 - acc: 0.9780 - val_loss: 0.0702 - val_acc: 0.9778
Epoch 5/10
 - 49s - loss: 0.0642 - acc: 0.9784 - val_loss: 0.0699 - val_acc: 0.9781
Epoch 00005: early stopping
	TRAINING TIME: 5.78 minutes 
==================================================================================================
	PARSING TIME: 0.67 minutes 
==================================================================================================
	Identification : 0.774
	P, R  : 0.763, 0.785

==================================================================================================
	VID : 0.0
	VID: 0.0
	VID: -
	LVC.FULL : 0.0
	LVC.FULL: 0.0
	LVC.FULL: -
	LVC.CAUSE : 0.0
	LVC.CAUSE: 0.0
	LVC.CAUSE: -
	IRV : 0.0
	IRV: 0.0
	IRV: -
	VPC.FULL : 0.0
	VPC.FULL: 0.0
	VPC.FULL: -
	VPC.SEMI : 0.0
	VPC.SEMI: 0.0
	VPC.SEMI: -
	IAV : 0.0
	IAV: 0.0
	IAV: -
	MVC : 0.0
	MVC: 0.0
	MVC: -
	LC : 0.0
	LC: 0.0
	LC: -

==================================================================================================
Seen MWEs
==================================================================================================
	Gold: 85.7
	Predicted: 91.8
	F : 0.853
	P, R  : 0.814, 0.896

==================================================================================================
Seen MWEs(Frequently)
==================================================================================================
	Gold: 64.8
	Predicted: 65.0
	F : 0.893
	P, R  : 0.88, 0.907

==================================================================================================
Seen MWEs(Barely)
==================================================================================================
	Gold: 20.9
	Predicted: 26.8
	F : 0.743
	P, R  : 0.653, 0.862

==================================================================================================
Partially-seen MWEs
==================================================================================================
	Gold: 13.6
	Predicted: 8.2
	F : 0.153
	P, R  : 0.199, 0.124

==================================================================================================
Partially-seen MWEs (Without Noise)
==================================================================================================
	Gold: 10.6
	Predicted: 6.4
	F : 0.181
	P, R  : 0.237, 0.147

==================================================================================================
Non-seen MWEs
==================================================================================================
	Gold: 14.3
	Predicted: 8.2
	F : 0.148
	P, R  : 0.199, 0.118

==================================================================================================
Continuous MWEs
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.774
	P, R  : 0.763, 0.785

==================================================================================================
Discontinuous MWEs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Identic
==================================================================================================
	Gold: 83.2 / (all:seen + non seen)
	Predicted: 87.2 / (all:seen + non seen)
	F : 0.864
	P, R  : 0.833, 0.897

==================================================================================================
Variant
==================================================================================================
	Gold: 2.5 / (all:seen + non seen)
	Predicted: 4.6 / (all:seen + non seen)
	F : 0.589
	P, R  : 0.453, 0.843

==================================================================================================
Embeddeds
==================================================================================================
	Gold: 0.0
	Predicted: 0.8
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
MWTs
==================================================================================================
	Gold: 0.0
	Predicted: 0.0
	F : 0
	P, R  : 0.0, 0.0

==================================================================================================
Multitokens
==================================================================================================
	Gold: 100.0
	Predicted: 100.0
	F : 0.774
	P, R  : 0.763, 0.785

==================================================================================================
Length(2)
==================================================================================================
	Gold: 46.2
	Predicted: 45.4
	F : 0.753
	P, R  : 0.75, 0.757

==================================================================================================
Length(3)
==================================================================================================
	Gold: 45.9
	Predicted: 47.3
	F : 0.828
	P, R  : 0.805, 0.852

==================================================================================================
4 < Length < 100
==================================================================================================
	Gold: 7.8
	Predicted: 7.3
	F : 0.566
	P, R  : 0.579, 0.554

==================================================================================================
Misidentified:
==================================================================================================
	Misidentified / identified: 6.8
	Seens: 72.2
	Non Seens: 27.8
	Frequently Seen: 32.9
	Barely Seen: 39.2
	Partially Seen: 27.8
	Partially Seen (Without stop words): 20.7
	Three Token MWEs: 39.0
	Two Token MWEs: 48.0
	MWTs: 0.0

==================================================================================================
Non-identified:
==================================================================================================
	Non-identified / Gold: 6.2
	Seens: 41.5
	Non Seens: 58.5
	Frequently Seen: 28.1
	Barely Seen: 13.4
	Partially Seen: 55.3
	Partially Seen (Without stop words): 42.1
	Three Token MWEs: 31.6
	Two Token MWEs: 52.2
	MWTs: 0.0

==================================================================================================
	Cupt files: corpus.MLP.FTB.0.Sep.19.FR

==================================================================================================
	XP Ends: 19/9 (15 h:19)
==================================================================================================
