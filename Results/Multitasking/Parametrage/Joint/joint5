INFO: activate-binutils_linux-64.sh made the following environmental changes:
+ADDR2LINE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-addr2line
+AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ar
+AS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-as
+CXXFILT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++filt
+ELFEDIT=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-elfedit
+GPROF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gprof
+HOST=x86_64-conda_cos6-linux-gnu
+LD_GOLD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld.gold
+LD=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ld
+NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-nm
+OBJCOPY=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objcopy
+OBJDUMP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-objdump
+RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-ranlib
+READELF=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-readelf
+SIZE=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-size
+STRINGS=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strings
+STRIP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-strip
INFO: activate-gcc_linux-64.sh made the following environmental changes:
+CC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cc
+CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+_CONDA_PYTHON_SYSCONFIGDATA_NAME=_sysconfigdata_x86_64_conda_cos6_linux_gnu
+CPPFLAGS=-DNDEBUG -D_FORTIFY_SOURCE=2 -O2
+CPP=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-cpp
+DEBUG_CFLAGS=-march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+DEBUG_CPPFLAGS=-D_DEBUG -D_FORTIFY_SOURCE=2 -Og
+GCC_AR=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ar
+GCC=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc
+GCC_NM=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-nm
+GCC_RANLIB=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-gcc-ranlib
+LDFLAGS=-Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now
INFO: activate-gxx_linux-64.sh made the following environmental changes:
+CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -pipe
+CXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-c++
+DEBUG_CXXFLAGS=-fvisibility-inlines-hidden -std=c++17 -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-all -fno-plt -Og -g -Wall -Wextra -fvar-tracking-assignments -pipe
+GXX=/home/halsaied/miniconda2/bin/x86_64-conda_cos6-linux-gnu-g++
Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_RDLIG5.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 3841/4043 Mb (0.950000) on cuda
Mapped name None to device cuda: GeForce GTX 980 (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmp1crdYn and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmprZlnyD). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,104            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
22             ,1              ,10             ,2              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.01           ,8              ,8              ,61             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
62             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 104, 22, 1, 10, 2, 17, 0.01, 8, 8, 61, True, 62, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (15h:26)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 62)        467790      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 22)       26092       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 434)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 264)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 709)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
                                                                 flatten_3[0][0]                  
                                                                 flatten_4[0][0]                  
__________________________________________________________________________________________________
posDense (Dense)                (None, 61)           43310       concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 152)          9424        posDense[0][0]                   
==================================================================================================
Total params: 546,780
Trainable params: 546,780
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 62)        467790      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 22)       26092       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 434)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 264)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 434)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 264)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 434)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 264)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 434)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 264)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 709)          0           flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
                                                                 flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 709)          0           flatten_9[0][0]                  
                                                                 flatten_10[0][0]                 
                                                                 flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 709)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
                                                                 flatten_15[0][0]                 
                                                                 flatten_16[0][0]                 
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 709)          0           flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
                                                                 flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 61)           43310       concatenate_2[0][0]              
                                                                 concatenate_3[0][0]              
                                                                 concatenate_4[0][0]              
                                                                 concatenate_5[0][0]              
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 244)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 104)          25480       concatenate_6[0][0]              
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            420         idenDense[0][0]                  
==================================================================================================
Total params: 563,256
Trainable params: 563,256
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 14s - loss: 0.3262 - acc: 0.9248
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1420 - acc: 0.9684
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1100 - acc: 0.9745
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
MWE identification:
Epoch 1/1
 - 88s - loss: 0.0715 - acc: 0.9819
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1061 - acc: 0.9745
MWE identification:
Epoch 1/1
 - 96s - loss: 0.0559 - acc: 0.9862
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0884 - acc: 0.9778
MWE identification:
Epoch 1/1
 - 88s - loss: 0.0520 - acc: 0.9874
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0774 - acc: 0.9803
MWE identification:
Epoch 1/1
 - 88s - loss: 0.0499 - acc: 0.9880
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0694 - acc: 0.9822
MWE identification:
Epoch 1/1
 - 95s - loss: 0.0484 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0628 - acc: 0.9845
MWE identification:
Epoch 1/1
 - 88s - loss: 0.0475 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0573 - acc: 0.9861
MWE identification:
Epoch 1/1
 - 88s - loss: 0.0468 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0527 - acc: 0.9875
MWE identification:
Epoch 1/1
 - 92s - loss: 0.0463 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0486 - acc: 0.9888
POS tagging accuracy = 94.9
Loss = 0.196, 
POS tagging accuracy = 94.9
Loss = 0.196, 
	TRAINING TIME: 16.3 minutes 
==================================================================================================
	PARSING TIME: 1.18 minutes 
==================================================================================================
	Identification : 0.596
	P, R  : 0.789, 0.479

==================================================================================================
	XP Ends: 23/4 (15 h:44)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by process '13222' (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '13222' (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,124            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
23             ,1              ,17             ,1              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.086          ,5              ,74             ,84             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
106            ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 124, 23, 1, 17, 1, 11, 0.086, 5, 74, 84, True, 106, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (15h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.086
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 106)       1212428     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 23)       27278       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_21 (Flatten)            (None, 742)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 276)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_23 (Flatten)            (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 1023)         0           flatten_21[0][0]                 
                                                                 flatten_22[0][0]                 
                                                                 flatten_23[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 84)           86016       concatenate_7[0][0]              
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 152)          12920       posDense[0][0]                   
==================================================================================================
Total params: 1,338,742
Trainable params: 1,338,742
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.086
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 106)       1212428     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 23)       27278       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_24 (Flatten)            (None, 742)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 276)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_26 (Flatten)            (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_27 (Flatten)            (None, 742)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_28 (Flatten)            (None, 276)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_29 (Flatten)            (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_30 (Flatten)            (None, 742)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_31 (Flatten)            (None, 276)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_32 (Flatten)            (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_33 (Flatten)            (None, 742)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_34 (Flatten)            (None, 276)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_35 (Flatten)            (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_36 (Flatten)            (None, 742)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_37 (Flatten)            (None, 276)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_38 (Flatten)            (None, 5)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 1023)         0           flatten_24[0][0]                 
                                                                 flatten_25[0][0]                 
                                                                 flatten_26[0][0]                 
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 1023)         0           flatten_27[0][0]                 
                                                                 flatten_28[0][0]                 
                                                                 flatten_29[0][0]                 
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 1023)         0           flatten_30[0][0]                 
                                                                 flatten_31[0][0]                 
                                                                 flatten_32[0][0]                 
__________________________________________________________________________________________________
concatenate_11 (Concatenate)    (None, 1023)         0           flatten_33[0][0]                 
                                                                 flatten_34[0][0]                 
                                                                 flatten_35[0][0]                 
__________________________________________________________________________________________________
concatenate_12 (Concatenate)    (None, 1023)         0           flatten_36[0][0]                 
                                                                 flatten_37[0][0]                 
                                                                 flatten_38[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 84)           86016       concatenate_8[0][0]              
                                                                 concatenate_9[0][0]              
                                                                 concatenate_10[0][0]             
                                                                 concatenate_11[0][0]             
                                                                 concatenate_12[0][0]             
__________________________________________________________________________________________________
concatenate_13 (Concatenate)    (None, 420)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 124)          52204       concatenate_13[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            500         idenDense[0][0]                  
==================================================================================================
Total params: 1,378,526
Trainable params: 1,378,526
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2536 - acc: 0.9393
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0839 - acc: 0.9782
MWE identification:
Epoch 1/1
 - 57s - loss: 8.1331 - acc: 0.4954
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0794 - acc: 0.9798
MWE identification:
Epoch 1/1
 - 55s - loss: 8.1105 - acc: 0.4968
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0381 - acc: 0.9907
MWE identification:
Epoch 1/1
 - 55s - loss: 8.1105 - acc: 0.4968
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0284 - acc: 0.9935
MWE identification:
Epoch 1/1
 - 55s - loss: 8.1105 - acc: 0.4968
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0216 - acc: 0.9952
MWE identification:
Epoch 1/1
 - 56s - loss: 8.1105 - acc: 0.4968
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0184 - acc: 0.9964
POS tagging accuracy = 94.1
Loss = 0.299, 
POS tagging accuracy = 94.1
Loss = 0.299, 
	TRAINING TIME: 6.95 minutes 
==================================================================================================
	PARSING TIME: 1.05 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (15 h:52)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,175            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
24             ,2              ,20             ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.196          ,6              ,23             ,129            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
70             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 175, 24, 2, 20, 1, 8, 0.196, 6, 23, 129, True, 70, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (15h:52)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.196
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 70)        528150      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 24)       28464       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_39 (Flatten)            (None, 490)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_40 (Flatten)            (None, 288)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_41 (Flatten)            (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_42 (Flatten)            (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_14 (Concatenate)    (None, 790)          0           flatten_39[0][0]                 
                                                                 flatten_40[0][0]                 
                                                                 flatten_41[0][0]                 
                                                                 flatten_42[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 129)          102039      concatenate_14[0][0]             
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 152)          19760       posDense[0][0]                   
==================================================================================================
Total params: 678,541
Trainable params: 678,541
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.196
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 70)        528150      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 24)       28464       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_43 (Flatten)            (None, 490)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_44 (Flatten)            (None, 288)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_45 (Flatten)            (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_46 (Flatten)            (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_47 (Flatten)            (None, 490)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_48 (Flatten)            (None, 288)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_49 (Flatten)            (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_50 (Flatten)            (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_51 (Flatten)            (None, 490)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_52 (Flatten)            (None, 288)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_53 (Flatten)            (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_54 (Flatten)            (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_55 (Flatten)            (None, 490)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_56 (Flatten)            (None, 288)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_57 (Flatten)            (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_58 (Flatten)            (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_59 (Flatten)            (None, 490)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_60 (Flatten)            (None, 288)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_61 (Flatten)            (None, 6)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_62 (Flatten)            (None, 6)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_15 (Concatenate)    (None, 790)          0           flatten_43[0][0]                 
                                                                 flatten_44[0][0]                 
                                                                 flatten_45[0][0]                 
                                                                 flatten_46[0][0]                 
__________________________________________________________________________________________________
concatenate_16 (Concatenate)    (None, 790)          0           flatten_47[0][0]                 
                                                                 flatten_48[0][0]                 
                                                                 flatten_49[0][0]                 
                                                                 flatten_50[0][0]                 
__________________________________________________________________________________________________
concatenate_17 (Concatenate)    (None, 790)          0           flatten_51[0][0]                 
                                                                 flatten_52[0][0]                 
                                                                 flatten_53[0][0]                 
                                                                 flatten_54[0][0]                 
__________________________________________________________________________________________________
concatenate_18 (Concatenate)    (None, 790)          0           flatten_55[0][0]                 
                                                                 flatten_56[0][0]                 
                                                                 flatten_57[0][0]                 
                                                                 flatten_58[0][0]                 
__________________________________________________________________________________________________
concatenate_19 (Concatenate)    (None, 790)          0           flatten_59[0][0]                 
                                                                 flatten_60[0][0]                 
                                                                 flatten_61[0][0]                 
                                                                 flatten_62[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 129)          102039      concatenate_15[0][0]             
                                                                 concatenate_16[0][0]             
                                                                 concatenate_17[0][0]             
                                                                 concatenate_18[0][0]             
                                                                 concatenate_19[0][0]             
__________________________________________________________________________________________________
concatenate_20 (Concatenate)    (None, 645)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 175)          113050      concatenate_20[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            704         idenDense[0][0]                  
==================================================================================================
Total params: 772,535
Trainable params: 772,535
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.4490 - acc: 0.8958
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1933 - acc: 0.9562
MWE identification:
Epoch 1/1
 - 52s - loss: 8.1412 - acc: 0.4949
POS tagging:
Epoch 1/1
 - 5s - loss: 0.2254 - acc: 0.9528
MWE identification:
Epoch 1/1
 - 52s - loss: 8.0647 - acc: 0.4996
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1325 - acc: 0.9713
MWE identification:
Epoch 1/1
 - 54s - loss: 8.0592 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1026 - acc: 0.9784
MWE identification:
Epoch 1/1
 - 52s - loss: 8.0591 - acc: 0.5000
POS tagging accuracy = 93.9
Loss = 0.298, 
POS tagging accuracy = 93.9
Loss = 0.298, 
	TRAINING TIME: 5.28 minutes 
==================================================================================================
	PARSING TIME: 2.32 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (16 h:0)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,180            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,1              ,17             ,2              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.013          ,11             ,12             ,147            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
145            ,True           ,True           ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 180, 5, 1, 17, 2, 11, 0.013, 11, 12, 147, True, 145, True, True, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (16h:0)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 145)       1094025     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
flatten_63 (Flatten)            (None, 1015)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_64 (Flatten)            (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_21 (Concatenate)    (None, 1075)         0           flatten_63[0][0]                 
                                                                 flatten_64[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 147)          158172      concatenate_21[0][0]             
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 152)          22496       posDense[0][0]                   
==================================================================================================
Total params: 1,280,623
Trainable params: 1,280,623
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 145)       1094025     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_65 (Flatten)            (None, 1015)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_66 (Flatten)            (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_67 (Flatten)            (None, 1015)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_68 (Flatten)            (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_69 (Flatten)            (None, 1015)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_70 (Flatten)            (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_71 (Flatten)            (None, 1015)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_72 (Flatten)            (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_73 (Flatten)            (None, 1015)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_74 (Flatten)            (None, 60)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
concatenate_22 (Concatenate)    (None, 1075)         0           flatten_65[0][0]                 
                                                                 flatten_66[0][0]                 
__________________________________________________________________________________________________
concatenate_23 (Concatenate)    (None, 1075)         0           flatten_67[0][0]                 
                                                                 flatten_68[0][0]                 
__________________________________________________________________________________________________
concatenate_24 (Concatenate)    (None, 1075)         0           flatten_69[0][0]                 
                                                                 flatten_70[0][0]                 
__________________________________________________________________________________________________
concatenate_25 (Concatenate)    (None, 1075)         0           flatten_71[0][0]                 
                                                                 flatten_72[0][0]                 
__________________________________________________________________________________________________
concatenate_26 (Concatenate)    (None, 1075)         0           flatten_73[0][0]                 
                                                                 flatten_74[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 147)          158172      concatenate_22[0][0]             
                                                                 concatenate_23[0][0]             
                                                                 concatenate_24[0][0]             
                                                                 concatenate_25[0][0]             
                                                                 concatenate_26[0][0]             
__________________________________________________________________________________________________
concatenate_27 (Concatenate)    (None, 735)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 180)          132480      concatenate_27[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            724         idenDense[0][0]                  
==================================================================================================
Total params: 1,391,331
Trainable params: 1,391,331
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.2431 - acc: 0.9424
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0902 - acc: 0.9778
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0613 - acc: 0.9847
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0657 - acc: 0.9839
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0727 - acc: 0.9818
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0499 - acc: 0.9878
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0480 - acc: 0.9890
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0470 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0368 - acc: 0.9918
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0457 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0301 - acc: 0.9936
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0450 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0251 - acc: 0.9948
POS tagging accuracy = 94.8
Loss = 0.219, 
POS tagging accuracy = 94.8
Loss = 0.219, 
	TRAINING TIME: 5.93 minutes 
==================================================================================================
	PARSING TIME: 0.83 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.725, 0.479

==================================================================================================
	XP Ends: 23/4 (16 h:7)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,30             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,2              ,47             ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.123          ,11             ,27             ,25             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
26             ,True           ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 30, 6, 2, 47, 1, 8, 0.123, 11, 27, 25, True, 26, True, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (16h:7)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.123
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 26)        196170      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_75 (Flatten)            (None, 182)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_76 (Flatten)            (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_77 (Flatten)            (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_28 (Concatenate)    (None, 260)          0           flatten_75[0][0]                 
                                                                 flatten_76[0][0]                 
                                                                 flatten_77[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 25)           6525        concatenate_28[0][0]             
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 152)          3952        posDense[0][0]                   
==================================================================================================
Total params: 213,771
Trainable params: 213,771
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.123
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 26)        196170      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_78 (Flatten)            (None, 182)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_79 (Flatten)            (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_80 (Flatten)            (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_81 (Flatten)            (None, 182)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_82 (Flatten)            (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_83 (Flatten)            (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_84 (Flatten)            (None, 182)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_85 (Flatten)            (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_86 (Flatten)            (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_87 (Flatten)            (None, 182)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_88 (Flatten)            (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_89 (Flatten)            (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_29 (Concatenate)    (None, 260)          0           flatten_78[0][0]                 
                                                                 flatten_79[0][0]                 
                                                                 flatten_80[0][0]                 
__________________________________________________________________________________________________
concatenate_30 (Concatenate)    (None, 260)          0           flatten_81[0][0]                 
                                                                 flatten_82[0][0]                 
                                                                 flatten_83[0][0]                 
__________________________________________________________________________________________________
concatenate_31 (Concatenate)    (None, 260)          0           flatten_84[0][0]                 
                                                                 flatten_85[0][0]                 
                                                                 flatten_86[0][0]                 
__________________________________________________________________________________________________
concatenate_32 (Concatenate)    (None, 260)          0           flatten_87[0][0]                 
                                                                 flatten_88[0][0]                 
                                                                 flatten_89[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 25)           6525        concatenate_29[0][0]             
                                                                 concatenate_30[0][0]             
                                                                 concatenate_31[0][0]             
                                                                 concatenate_32[0][0]             
__________________________________________________________________________________________________
concatenate_33 (Concatenate)    (None, 100)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 30)           3030        concatenate_33[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            124         idenDense[0][0]                  
==================================================================================================
Total params: 212,973
Trainable params: 212,973
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2259 - acc: 0.9447
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0804 - acc: 0.9790
MWE identification:
Epoch 1/1
 - 17s - loss: 0.0747 - acc: 0.9812
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1201 - acc: 0.9702
MWE identification:
Epoch 1/1
 - 17s - loss: 0.0534 - acc: 0.9866
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0672 - acc: 0.9831
MWE identification:
Epoch 1/1
 - 17s - loss: 0.0488 - acc: 0.9881
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0458 - acc: 0.9887
MWE identification:
Epoch 1/1
 - 17s - loss: 0.0466 - acc: 0.9888
POS tagging accuracy = 93.6
Loss = 0.299, 
POS tagging accuracy = 93.6
Loss = 0.299, 
	TRAINING TIME: 2.38 minutes 
==================================================================================================
	PARSING TIME: 0.88 minutes 
==================================================================================================
	Identification : 0.585
	P, R  : 0.745, 0.481

==================================================================================================
	XP Ends: 23/4 (16 h:11)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,27             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
12             ,4              ,33             ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.022          ,6              ,33             ,182            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
28             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 27, 12, 4, 33, 1, 8, 0.022, 6, 33, 182, True, 28, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (16h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_90 (Flatten)            (None, 196)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_91 (Flatten)            (None, 144)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_92 (Flatten)            (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_34 (Concatenate)    (None, 352)          0           flatten_90[0][0]                 
                                                                 flatten_91[0][0]                 
                                                                 flatten_92[0][0]                 
__________________________________________________________________________________________________
posDense (Dense)                (None, 182)          64246       concatenate_34[0][0]             
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 152)          27816       posDense[0][0]                   
==================================================================================================
Total params: 317,570
Trainable params: 317,570
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_93 (Flatten)            (None, 196)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_94 (Flatten)            (None, 144)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_95 (Flatten)            (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_96 (Flatten)            (None, 196)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_97 (Flatten)            (None, 144)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_98 (Flatten)            (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_99 (Flatten)            (None, 196)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_100 (Flatten)           (None, 144)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_101 (Flatten)           (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_102 (Flatten)           (None, 196)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_103 (Flatten)           (None, 144)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_104 (Flatten)           (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_105 (Flatten)           (None, 196)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_106 (Flatten)           (None, 144)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_107 (Flatten)           (None, 12)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_35 (Concatenate)    (None, 352)          0           flatten_93[0][0]                 
                                                                 flatten_94[0][0]                 
                                                                 flatten_95[0][0]                 
__________________________________________________________________________________________________
concatenate_36 (Concatenate)    (None, 352)          0           flatten_96[0][0]                 
                                                                 flatten_97[0][0]                 
                                                                 flatten_98[0][0]                 
__________________________________________________________________________________________________
concatenate_37 (Concatenate)    (None, 352)          0           flatten_99[0][0]                 
                                                                 flatten_100[0][0]                
                                                                 flatten_101[0][0]                
__________________________________________________________________________________________________
concatenate_38 (Concatenate)    (None, 352)          0           flatten_102[0][0]                
                                                                 flatten_103[0][0]                
                                                                 flatten_104[0][0]                
__________________________________________________________________________________________________
concatenate_39 (Concatenate)    (None, 352)          0           flatten_105[0][0]                
                                                                 flatten_106[0][0]                
                                                                 flatten_107[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 182)          64246       concatenate_35[0][0]             
                                                                 concatenate_36[0][0]             
                                                                 concatenate_37[0][0]             
                                                                 concatenate_38[0][0]             
                                                                 concatenate_39[0][0]             
__________________________________________________________________________________________________
concatenate_40 (Concatenate)    (None, 910)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 27)           24597       concatenate_40[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            112         idenDense[0][0]                  
==================================================================================================
Total params: 314,463
Trainable params: 314,463
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2280 - acc: 0.9437
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0898 - acc: 0.9768
MWE identification:
Epoch 1/1
 - 27s - loss: 0.0674 - acc: 0.9830
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0878 - acc: 0.9768
MWE identification:
Epoch 1/1
 - 27s - loss: 0.0521 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0603 - acc: 0.9844
MWE identification:
Epoch 1/1
 - 27s - loss: 0.0488 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0462 - acc: 0.9881
MWE identification:
Epoch 1/1
 - 27s - loss: 0.0471 - acc: 0.9888
POS tagging accuracy = 94.6
Loss = 0.193, 
POS tagging accuracy = 94.6
Loss = 0.193, 
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 1.05 minutes 
==================================================================================================
	Identification : 0.58
	P, R  : 0.708, 0.491

==================================================================================================
	XP Ends: 23/4 (16 h:15)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,66             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
20             ,2              ,30             ,1              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.037          ,8              ,58             ,38             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
151            ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 66, 20, 2, 30, 1, 14, 0.037, 8, 58, 38, True, 151, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (16h:15)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.037
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 151)       1727138     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_108 (Flatten)           (None, 1057)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_109 (Flatten)           (None, 240)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_110 (Flatten)           (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_111 (Flatten)           (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_41 (Concatenate)    (None, 1311)         0           flatten_108[0][0]                
                                                                 flatten_109[0][0]                
                                                                 flatten_110[0][0]                
                                                                 flatten_111[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 38)           49856       concatenate_41[0][0]             
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 152)          5928        posDense[0][0]                   
==================================================================================================
Total params: 1,806,810
Trainable params: 1,806,810
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.037
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 151)       1727138     bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_112 (Flatten)           (None, 1057)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_113 (Flatten)           (None, 240)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_114 (Flatten)           (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_115 (Flatten)           (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_116 (Flatten)           (None, 1057)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_117 (Flatten)           (None, 240)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_118 (Flatten)           (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_119 (Flatten)           (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_120 (Flatten)           (None, 1057)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_121 (Flatten)           (None, 240)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_122 (Flatten)           (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_123 (Flatten)           (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_124 (Flatten)           (None, 1057)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_125 (Flatten)           (None, 240)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_126 (Flatten)           (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_127 (Flatten)           (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_42 (Concatenate)    (None, 1311)         0           flatten_112[0][0]                
                                                                 flatten_113[0][0]                
                                                                 flatten_114[0][0]                
                                                                 flatten_115[0][0]                
__________________________________________________________________________________________________
concatenate_43 (Concatenate)    (None, 1311)         0           flatten_116[0][0]                
                                                                 flatten_117[0][0]                
                                                                 flatten_118[0][0]                
                                                                 flatten_119[0][0]                
__________________________________________________________________________________________________
concatenate_44 (Concatenate)    (None, 1311)         0           flatten_120[0][0]                
                                                                 flatten_121[0][0]                
                                                                 flatten_122[0][0]                
                                                                 flatten_123[0][0]                
__________________________________________________________________________________________________
concatenate_45 (Concatenate)    (None, 1311)         0           flatten_124[0][0]                
                                                                 flatten_125[0][0]                
                                                                 flatten_126[0][0]                
                                                                 flatten_127[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 38)           49856       concatenate_42[0][0]             
                                                                 concatenate_43[0][0]             
                                                                 concatenate_44[0][0]             
                                                                 concatenate_45[0][0]             
__________________________________________________________________________________________________
concatenate_46 (Concatenate)    (None, 152)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 66)           10098       concatenate_46[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            268         idenDense[0][0]                  
==================================================================================================
Total params: 1,811,248
Trainable params: 1,811,248
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2412 - acc: 0.9391
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0948 - acc: 0.9754
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0660 - acc: 0.9831
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0916 - acc: 0.9756
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0488 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0497 - acc: 0.9876
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0457 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0343 - acc: 0.9920
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0258 - acc: 0.9939
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0204 - acc: 0.9952
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0166 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0443 - acc: 0.9895
POS tagging accuracy = 93.8
Loss = 0.269, 
POS tagging accuracy = 93.8
Loss = 0.269, 
	TRAINING TIME: 5.35 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.527
	P, R  : 0.497, 0.56

==================================================================================================
	XP Ends: 23/4 (16 h:22)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,45             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
24             ,1              ,31             ,4              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.168          ,7              ,10             ,93             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
123            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 45, 24, 1, 31, 4, 11, 0.168, 7, 10, 93, True, 123, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (16h:22)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.168
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 123)       1406874     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 24)       28464       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_128 (Flatten)           (None, 861)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_129 (Flatten)           (None, 288)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_130 (Flatten)           (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_131 (Flatten)           (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_47 (Concatenate)    (None, 1159)         0           flatten_128[0][0]                
                                                                 flatten_129[0][0]                
                                                                 flatten_130[0][0]                
                                                                 flatten_131[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 93)           107880      concatenate_47[0][0]             
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 152)          14288       posDense[0][0]                   
==================================================================================================
Total params: 1,557,650
Trainable params: 1,557,650
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.168
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 123)       1406874     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 24)       28464       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_132 (Flatten)           (None, 861)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_133 (Flatten)           (None, 288)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_134 (Flatten)           (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_135 (Flatten)           (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_136 (Flatten)           (None, 861)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_137 (Flatten)           (None, 288)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_138 (Flatten)           (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_139 (Flatten)           (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_140 (Flatten)           (None, 861)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_141 (Flatten)           (None, 288)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_142 (Flatten)           (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_143 (Flatten)           (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_144 (Flatten)           (None, 861)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_145 (Flatten)           (None, 288)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_146 (Flatten)           (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_147 (Flatten)           (None, 7)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_148 (Flatten)           (None, 861)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_149 (Flatten)           (None, 288)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_150 (Flatten)           (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_151 (Flatten)           (None, 7)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_48 (Concatenate)    (None, 1159)         0           flatten_132[0][0]                
                                                                 flatten_133[0][0]                
                                                                 flatten_134[0][0]                
                                                                 flatten_135[0][0]                
__________________________________________________________________________________________________
concatenate_49 (Concatenate)    (None, 1159)         0           flatten_136[0][0]                
                                                                 flatten_137[0][0]                
                                                                 flatten_138[0][0]                
                                                                 flatten_139[0][0]                
__________________________________________________________________________________________________
concatenate_50 (Concatenate)    (None, 1159)         0           flatten_140[0][0]                
                                                                 flatten_141[0][0]                
                                                                 flatten_142[0][0]                
                                                                 flatten_143[0][0]                
__________________________________________________________________________________________________
concatenate_51 (Concatenate)    (None, 1159)         0           flatten_144[0][0]                
                                                                 flatten_145[0][0]                
                                                                 flatten_146[0][0]                
                                                                 flatten_147[0][0]                
__________________________________________________________________________________________________
concatenate_52 (Concatenate)    (None, 1159)         0           flatten_148[0][0]                
                                                                 flatten_149[0][0]                
                                                                 flatten_150[0][0]                
                                                                 flatten_151[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 93)           107880      concatenate_48[0][0]             
                                                                 concatenate_49[0][0]             
                                                                 concatenate_50[0][0]             
                                                                 concatenate_51[0][0]             
                                                                 concatenate_52[0][0]             
__________________________________________________________________________________________________
concatenate_53 (Concatenate)    (None, 465)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 45)           20970       concatenate_53[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            184         idenDense[0][0]                  
==================================================================================================
Total params: 1,564,516
Trainable params: 1,564,516
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 14s - loss: 0.4424 - acc: 0.8952
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1819 - acc: 0.9595
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1254 - acc: 0.9730
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1013 - acc: 0.9787
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0884 - acc: 0.9818
MWE identification:
Epoch 1/1
 - 37s - loss: 12.0876 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1311 - acc: 0.9717
MWE identification:
Epoch 1/1
 - 37s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0832 - acc: 0.9827
MWE identification:
Epoch 1/1
 - 37s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0727 - acc: 0.9853
MWE identification:
Epoch 1/1
 - 37s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0681 - acc: 0.9865
MWE identification:
Epoch 1/1
 - 37s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0653 - acc: 0.9873
POS tagging accuracy = 93.3
Loss = 0.373, 
POS tagging accuracy = 93.3
Loss = 0.373, 
	TRAINING TIME: 6.67 minutes 
==================================================================================================
	PARSING TIME: 2.28 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (16 h:31)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,98             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
14             ,8              ,10             ,4              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.07           ,6              ,27             ,159            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
42             ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 98, 14, 8, 10, 4, 11, 0.07, 6, 27, 159, True, 42, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (16h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.07
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 42)        316890      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_152 (Flatten)           (None, 294)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_153 (Flatten)           (None, 168)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_154 (Flatten)           (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_54 (Concatenate)    (None, 468)          0           flatten_152[0][0]                
                                                                 flatten_153[0][0]                
                                                                 flatten_154[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 159)          74571       concatenate_54[0][0]             
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 152)          24320       posDense[0][0]                   
==================================================================================================
Total params: 432,505
Trainable params: 432,505
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.07
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 42)        316890      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_155 (Flatten)           (None, 294)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_156 (Flatten)           (None, 168)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_157 (Flatten)           (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_158 (Flatten)           (None, 294)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_159 (Flatten)           (None, 168)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_160 (Flatten)           (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_161 (Flatten)           (None, 294)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_162 (Flatten)           (None, 168)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_163 (Flatten)           (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_164 (Flatten)           (None, 294)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_165 (Flatten)           (None, 168)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_166 (Flatten)           (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_167 (Flatten)           (None, 294)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_168 (Flatten)           (None, 168)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_169 (Flatten)           (None, 6)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_55 (Concatenate)    (None, 468)          0           flatten_155[0][0]                
                                                                 flatten_156[0][0]                
                                                                 flatten_157[0][0]                
__________________________________________________________________________________________________
concatenate_56 (Concatenate)    (None, 468)          0           flatten_158[0][0]                
                                                                 flatten_159[0][0]                
                                                                 flatten_160[0][0]                
__________________________________________________________________________________________________
concatenate_57 (Concatenate)    (None, 468)          0           flatten_161[0][0]                
                                                                 flatten_162[0][0]                
                                                                 flatten_163[0][0]                
__________________________________________________________________________________________________
concatenate_58 (Concatenate)    (None, 468)          0           flatten_164[0][0]                
                                                                 flatten_165[0][0]                
                                                                 flatten_166[0][0]                
__________________________________________________________________________________________________
concatenate_59 (Concatenate)    (None, 468)          0           flatten_167[0][0]                
                                                                 flatten_168[0][0]                
                                                                 flatten_169[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 159)          74571       concatenate_55[0][0]             
                                                                 concatenate_56[0][0]             
                                                                 concatenate_57[0][0]             
                                                                 concatenate_58[0][0]             
                                                                 concatenate_59[0][0]             
__________________________________________________________________________________________________
concatenate_60 (Concatenate)    (None, 795)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 98)           78008       concatenate_60[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            396         idenDense[0][0]                  
==================================================================================================
Total params: 486,589
Trainable params: 486,589
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2029 - acc: 0.9504
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0609 - acc: 0.9830
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0322 - acc: 0.9914
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0199 - acc: 0.9952
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0139 - acc: 0.9970
MWE identification:
Epoch 1/1
 - 86s - loss: 8.1126 - acc: 0.4966
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0356 - acc: 0.9906
MWE identification:
Epoch 1/1
 - 87s - loss: 8.1105 - acc: 0.4968
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0117 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 86s - loss: 8.1105 - acc: 0.4968
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0085 - acc: 0.9981
MWE identification:
Epoch 1/1
 - 88s - loss: 8.1105 - acc: 0.4968
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0071 - acc: 0.9985
MWE identification:
Epoch 1/1
 - 85s - loss: 8.1105 - acc: 0.4968
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0061 - acc: 0.9988
POS tagging accuracy = 95.1
Loss = 0.269, 
POS tagging accuracy = 95.1
Loss = 0.269, 
	TRAINING TIME: 9.22 minutes 
==================================================================================================
	PARSING TIME: 1.02 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (16 h:42)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,165            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
18             ,7              ,32             ,2              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.038          ,7              ,81             ,36             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
150            ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 165, 18, 7, 32, 2, 15, 0.038, 7, 81, 36, True, 150, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (16h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 150)       1715700     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_170 (Flatten)           (None, 1050)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_171 (Flatten)           (None, 216)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_172 (Flatten)           (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_61 (Concatenate)    (None, 1273)         0           flatten_170[0][0]                
                                                                 flatten_171[0][0]                
                                                                 flatten_172[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           45864       concatenate_61[0][0]             
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 152)          5624        posDense[0][0]                   
==================================================================================================
Total params: 1,788,676
Trainable params: 1,788,676
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 150)       1715700     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_173 (Flatten)           (None, 1050)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_174 (Flatten)           (None, 216)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_175 (Flatten)           (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_176 (Flatten)           (None, 1050)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_177 (Flatten)           (None, 216)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_178 (Flatten)           (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_179 (Flatten)           (None, 1050)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_180 (Flatten)           (None, 216)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_181 (Flatten)           (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_182 (Flatten)           (None, 1050)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_183 (Flatten)           (None, 216)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_184 (Flatten)           (None, 7)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_185 (Flatten)           (None, 1050)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_186 (Flatten)           (None, 216)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_187 (Flatten)           (None, 7)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_62 (Concatenate)    (None, 1273)         0           flatten_173[0][0]                
                                                                 flatten_174[0][0]                
                                                                 flatten_175[0][0]                
__________________________________________________________________________________________________
concatenate_63 (Concatenate)    (None, 1273)         0           flatten_176[0][0]                
                                                                 flatten_177[0][0]                
                                                                 flatten_178[0][0]                
__________________________________________________________________________________________________
concatenate_64 (Concatenate)    (None, 1273)         0           flatten_179[0][0]                
                                                                 flatten_180[0][0]                
                                                                 flatten_181[0][0]                
__________________________________________________________________________________________________
concatenate_65 (Concatenate)    (None, 1273)         0           flatten_182[0][0]                
                                                                 flatten_183[0][0]                
                                                                 flatten_184[0][0]                
__________________________________________________________________________________________________
concatenate_66 (Concatenate)    (None, 1273)         0           flatten_185[0][0]                
                                                                 flatten_186[0][0]                
                                                                 flatten_187[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           45864       concatenate_62[0][0]             
                                                                 concatenate_63[0][0]             
                                                                 concatenate_64[0][0]             
                                                                 concatenate_65[0][0]             
                                                                 concatenate_66[0][0]             
__________________________________________________________________________________________________
concatenate_67 (Concatenate)    (None, 180)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 165)          29865       concatenate_67[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            664         idenDense[0][0]                  
==================================================================================================
Total params: 1,813,581
Trainable params: 1,813,581
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2498 - acc: 0.9375
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0953 - acc: 0.9757
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0569 - acc: 0.9856
MWE identification:
Epoch 1/1
 - 31s - loss: 8.0592 - acc: 0.4999
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0558 - acc: 0.9868
MWE identification:
Epoch 1/1
 - 31s - loss: 8.0590 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0304 - acc: 0.9929
MWE identification:
Epoch 1/1
 - 31s - loss: 8.0590 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0219 - acc: 0.9950
MWE identification:
Epoch 1/1
 - 31s - loss: 8.0590 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0171 - acc: 0.9961
MWE identification:
Epoch 1/1
 - 31s - loss: 8.0590 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0136 - acc: 0.9969
MWE identification:
Epoch 1/1
 - 31s - loss: 8.0590 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0113 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 31s - loss: 8.0590 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0095 - acc: 0.9978
POS tagging accuracy = 93.9
Loss = 0.27, 
POS tagging accuracy = 93.9
Loss = 0.27, 
	TRAINING TIME: 5.05 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (16 h:49)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,117            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
11             ,4              ,20             ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.018          ,6              ,37             ,25             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
28             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 117, 11, 4, 20, 1, 8, 0.018, 6, 37, 25, True, 28, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (16h:49)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_188 (Flatten)           (None, 196)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_189 (Flatten)           (None, 132)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_190 (Flatten)           (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_191 (Flatten)           (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_68 (Concatenate)    (None, 346)          0           flatten_188[0][0]                
                                                                 flatten_189[0][0]                
                                                                 flatten_190[0][0]                
                                                                 flatten_191[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 25)           8675        concatenate_68[0][0]             
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 152)          3952        posDense[0][0]                   
==================================================================================================
Total params: 237,069
Trainable params: 237,069
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_192 (Flatten)           (None, 196)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_193 (Flatten)           (None, 132)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_194 (Flatten)           (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_195 (Flatten)           (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_196 (Flatten)           (None, 196)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_197 (Flatten)           (None, 132)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_198 (Flatten)           (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_199 (Flatten)           (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_200 (Flatten)           (None, 196)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_201 (Flatten)           (None, 132)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_202 (Flatten)           (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_203 (Flatten)           (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_204 (Flatten)           (None, 196)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_205 (Flatten)           (None, 132)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_206 (Flatten)           (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_207 (Flatten)           (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_208 (Flatten)           (None, 196)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_209 (Flatten)           (None, 132)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_210 (Flatten)           (None, 12)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_211 (Flatten)           (None, 6)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_69 (Concatenate)    (None, 346)          0           flatten_192[0][0]                
                                                                 flatten_193[0][0]                
                                                                 flatten_194[0][0]                
                                                                 flatten_195[0][0]                
__________________________________________________________________________________________________
concatenate_70 (Concatenate)    (None, 346)          0           flatten_196[0][0]                
                                                                 flatten_197[0][0]                
                                                                 flatten_198[0][0]                
                                                                 flatten_199[0][0]                
__________________________________________________________________________________________________
concatenate_71 (Concatenate)    (None, 346)          0           flatten_200[0][0]                
                                                                 flatten_201[0][0]                
                                                                 flatten_202[0][0]                
                                                                 flatten_203[0][0]                
__________________________________________________________________________________________________
concatenate_72 (Concatenate)    (None, 346)          0           flatten_204[0][0]                
                                                                 flatten_205[0][0]                
                                                                 flatten_206[0][0]                
                                                                 flatten_207[0][0]                
__________________________________________________________________________________________________
concatenate_73 (Concatenate)    (None, 346)          0           flatten_208[0][0]                
                                                                 flatten_209[0][0]                
                                                                 flatten_210[0][0]                
                                                                 flatten_211[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 25)           8675        concatenate_69[0][0]             
                                                                 concatenate_70[0][0]             
                                                                 concatenate_71[0][0]             
                                                                 concatenate_72[0][0]             
                                                                 concatenate_73[0][0]             
__________________________________________________________________________________________________
concatenate_74 (Concatenate)    (None, 125)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 117)          14742       concatenate_74[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            472         idenDense[0][0]                  
==================================================================================================
Total params: 248,331
Trainable params: 248,331
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.3884 - acc: 0.9082
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1542 - acc: 0.9662
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0754 - acc: 0.9808
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1371 - acc: 0.9684
MWE identification:
Epoch 1/1
 - 52s - loss: 0.0582 - acc: 0.9856
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1092 - acc: 0.9737
MWE identification:
Epoch 1/1
 - 51s - loss: 0.0538 - acc: 0.9868
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0946 - acc: 0.9762
MWE identification:
Epoch 1/1
 - 51s - loss: 0.0515 - acc: 0.9874
POS tagging accuracy = 95.0
Loss = 0.186, 
POS tagging accuracy = 95.0
Loss = 0.186, 
	TRAINING TIME: 5.07 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0.594
	P, R  : 0.741, 0.496

==================================================================================================
	XP Ends: 23/4 (16 h:56)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,25             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,1              ,8              ,2              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.046          ,14             ,27             ,31             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
69             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 25, 8, 1, 8, 2, 13, 0.046, 14, 27, 31, True, 69, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (16h:56)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 69)        520605      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_212 (Flatten)           (None, 483)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_213 (Flatten)           (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_214 (Flatten)           (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_215 (Flatten)           (None, 14)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_75 (Concatenate)    (None, 596)          0           flatten_212[0][0]                
                                                                 flatten_213[0][0]                
                                                                 flatten_214[0][0]                
                                                                 flatten_215[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 31)           18507       concatenate_75[0][0]             
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 152)          4864        posDense[0][0]                   
==================================================================================================
Total params: 553,748
Trainable params: 553,748
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 69)        520605      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_216 (Flatten)           (None, 483)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_217 (Flatten)           (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_218 (Flatten)           (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_219 (Flatten)           (None, 14)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_220 (Flatten)           (None, 483)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_221 (Flatten)           (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_222 (Flatten)           (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_223 (Flatten)           (None, 14)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_224 (Flatten)           (None, 483)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_225 (Flatten)           (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_226 (Flatten)           (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_227 (Flatten)           (None, 14)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_228 (Flatten)           (None, 483)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_229 (Flatten)           (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_230 (Flatten)           (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_231 (Flatten)           (None, 14)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_232 (Flatten)           (None, 483)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_233 (Flatten)           (None, 96)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_234 (Flatten)           (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_235 (Flatten)           (None, 14)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_76 (Concatenate)    (None, 596)          0           flatten_216[0][0]                
                                                                 flatten_217[0][0]                
                                                                 flatten_218[0][0]                
                                                                 flatten_219[0][0]                
__________________________________________________________________________________________________
concatenate_77 (Concatenate)    (None, 596)          0           flatten_220[0][0]                
                                                                 flatten_221[0][0]                
                                                                 flatten_222[0][0]                
                                                                 flatten_223[0][0]                
__________________________________________________________________________________________________
concatenate_78 (Concatenate)    (None, 596)          0           flatten_224[0][0]                
                                                                 flatten_225[0][0]                
                                                                 flatten_226[0][0]                
                                                                 flatten_227[0][0]                
__________________________________________________________________________________________________
concatenate_79 (Concatenate)    (None, 596)          0           flatten_228[0][0]                
                                                                 flatten_229[0][0]                
                                                                 flatten_230[0][0]                
                                                                 flatten_231[0][0]                
__________________________________________________________________________________________________
concatenate_80 (Concatenate)    (None, 596)          0           flatten_232[0][0]                
                                                                 flatten_233[0][0]                
                                                                 flatten_234[0][0]                
                                                                 flatten_235[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 31)           18507       concatenate_76[0][0]             
                                                                 concatenate_77[0][0]             
                                                                 concatenate_78[0][0]             
                                                                 concatenate_79[0][0]             
                                                                 concatenate_80[0][0]             
__________________________________________________________________________________________________
concatenate_81 (Concatenate)    (None, 155)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 25)           3900        concatenate_81[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            104         idenDense[0][0]                  
==================================================================================================
Total params: 552,888
Trainable params: 552,888
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2090 - acc: 0.9486
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0728 - acc: 0.9804
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0454 - acc: 0.9880
MWE identification:
Epoch 1/1
 - 142s - loss: 0.0638 - acc: 0.9837
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0768 - acc: 0.9792
MWE identification:
Epoch 1/1
 - 133s - loss: 0.0502 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0402 - acc: 0.9901
MWE identification:
Epoch 1/1
 - 143s - loss: 0.0468 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0277 - acc: 0.9936
MWE identification:
Epoch 1/1
 - 137s - loss: 0.0454 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0215 - acc: 0.9951
MWE identification:
Epoch 1/1
 - 129s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0176 - acc: 0.9961
MWE identification:
Epoch 1/1
 - 144s - loss: 0.0445 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0150 - acc: 0.9966
POS tagging accuracy = 95.2
Loss = 0.251, 
POS tagging accuracy = 95.2
Loss = 0.251, 
	TRAINING TIME: 15.8 minutes 
==================================================================================================
	PARSING TIME: 1.28 minutes 
==================================================================================================
	Identification : 0.581
	P, R  : 0.741, 0.478

==================================================================================================
	XP Ends: 23/4 (17 h:13)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,171            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,7              ,8              ,4              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.113          ,8              ,11             ,58             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
62             ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 171, 6, 7, 8, 4, 17, 0.113, 8, 11, 58, True, 62, False, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (17h:13)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.113
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 62)        467790      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_236 (Flatten)           (None, 434)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_237 (Flatten)           (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_238 (Flatten)           (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_82 (Concatenate)    (None, 514)          0           flatten_236[0][0]                
                                                                 flatten_237[0][0]                
                                                                 flatten_238[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 58)           29870       concatenate_82[0][0]             
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 152)          8968        posDense[0][0]                   
==================================================================================================
Total params: 513,904
Trainable params: 513,904
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.113
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 62)        467790      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_239 (Flatten)           (None, 434)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_240 (Flatten)           (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_241 (Flatten)           (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_242 (Flatten)           (None, 434)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_243 (Flatten)           (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_244 (Flatten)           (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_245 (Flatten)           (None, 434)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_246 (Flatten)           (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_247 (Flatten)           (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_248 (Flatten)           (None, 434)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_249 (Flatten)           (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_250 (Flatten)           (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_83 (Concatenate)    (None, 514)          0           flatten_239[0][0]                
                                                                 flatten_240[0][0]                
                                                                 flatten_241[0][0]                
__________________________________________________________________________________________________
concatenate_84 (Concatenate)    (None, 514)          0           flatten_242[0][0]                
                                                                 flatten_243[0][0]                
                                                                 flatten_244[0][0]                
__________________________________________________________________________________________________
concatenate_85 (Concatenate)    (None, 514)          0           flatten_245[0][0]                
                                                                 flatten_246[0][0]                
                                                                 flatten_247[0][0]                
__________________________________________________________________________________________________
concatenate_86 (Concatenate)    (None, 514)          0           flatten_248[0][0]                
                                                                 flatten_249[0][0]                
                                                                 flatten_250[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 58)           29870       concatenate_83[0][0]             
                                                                 concatenate_84[0][0]             
                                                                 concatenate_85[0][0]             
                                                                 concatenate_86[0][0]             
__________________________________________________________________________________________________
concatenate_87 (Concatenate)    (None, 232)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 171)          39843       concatenate_87[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            688         idenDense[0][0]                  
==================================================================================================
Total params: 545,467
Trainable params: 545,467
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.2414 - acc: 0.9412
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0792 - acc: 0.9793
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0489 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0347 - acc: 0.9920
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0274 - acc: 0.9940
MWE identification:
Epoch 1/1
 - 94s - loss: 4.6968 - acc: 0.7080
POS tagging:
Epoch 1/1
 - 10s - loss: 0.1028 - acc: 0.9760
MWE identification:
Epoch 1/1
 - 94s - loss: 4.4242 - acc: 0.7251
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0408 - acc: 0.9903
MWE identification:
Epoch 1/1
 - 94s - loss: 4.3505 - acc: 0.7298
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0284 - acc: 0.9940
MWE identification:
Epoch 1/1
 - 96s - loss: 4.3299 - acc: 0.7311
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0242 - acc: 0.9952
MWE identification:
Epoch 1/1
 - 94s - loss: 4.3225 - acc: 0.7317
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0215 - acc: 0.9958
MWE identification:
Epoch 1/1
 - 94s - loss: 4.3197 - acc: 0.7318
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0200 - acc: 0.9962
MWE identification:
Epoch 1/1
 - 94s - loss: 4.3152 - acc: 0.7321
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0188 - acc: 0.9964
MWE identification:
Epoch 1/1
 - 95s - loss: 4.3118 - acc: 0.7323
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0180 - acc: 0.9967
POS tagging accuracy = 94.5
Loss = 0.331, 
POS tagging accuracy = 94.5
Loss = 0.331, 
	TRAINING TIME: 15.52 minutes 
==================================================================================================
	PARSING TIME: 0.95 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (17 h:30)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,62             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
10             ,5              ,27             ,2              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.012          ,8              ,107            ,174            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
139            ,True           ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 62, 10, 5, 27, 2, 15, 0.012, 8, 107, 174, True, 139, True, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (17h:30)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 139)       1048755     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_251 (Flatten)           (None, 973)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_252 (Flatten)           (None, 120)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_253 (Flatten)           (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_88 (Concatenate)    (None, 1108)         0           flatten_251[0][0]                
                                                                 flatten_252[0][0]                
                                                                 flatten_253[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 174)          192966      concatenate_88[0][0]             
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 152)          26600       posDense[0][0]                   
==================================================================================================
Total params: 1,280,201
Trainable params: 1,280,201
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 139)       1048755     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_254 (Flatten)           (None, 973)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_255 (Flatten)           (None, 120)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_256 (Flatten)           (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_257 (Flatten)           (None, 973)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_258 (Flatten)           (None, 120)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_259 (Flatten)           (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_260 (Flatten)           (None, 973)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_261 (Flatten)           (None, 120)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_262 (Flatten)           (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_263 (Flatten)           (None, 973)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_264 (Flatten)           (None, 120)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_265 (Flatten)           (None, 15)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_89 (Concatenate)    (None, 1108)         0           flatten_254[0][0]                
                                                                 flatten_255[0][0]                
                                                                 flatten_256[0][0]                
__________________________________________________________________________________________________
concatenate_90 (Concatenate)    (None, 1108)         0           flatten_257[0][0]                
                                                                 flatten_258[0][0]                
                                                                 flatten_259[0][0]                
__________________________________________________________________________________________________
concatenate_91 (Concatenate)    (None, 1108)         0           flatten_260[0][0]                
                                                                 flatten_261[0][0]                
                                                                 flatten_262[0][0]                
__________________________________________________________________________________________________
concatenate_92 (Concatenate)    (None, 1108)         0           flatten_263[0][0]                
                                                                 flatten_264[0][0]                
                                                                 flatten_265[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 174)          192966      concatenate_89[0][0]             
                                                                 concatenate_90[0][0]             
                                                                 concatenate_91[0][0]             
                                                                 concatenate_92[0][0]             
__________________________________________________________________________________________________
concatenate_93 (Concatenate)    (None, 696)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 62)           43214       concatenate_93[0][0]             
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            252         idenDense[0][0]                  
==================================================================================================
Total params: 1,297,067
Trainable params: 1,297,067
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2767 - acc: 0.9350
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0963 - acc: 0.9763
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0655 - acc: 0.9834
MWE identification:
Epoch 1/1
 - 31s - loss: 0.0652 - acc: 0.9835
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0674 - acc: 0.9829
MWE identification:
Epoch 1/1
 - 31s - loss: 0.0505 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0474 - acc: 0.9888
MWE identification:
Epoch 1/1
 - 31s - loss: 0.0476 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0369 - acc: 0.9916
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0462 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0302 - acc: 0.9933
MWE identification:
Epoch 1/1
 - 31s - loss: 0.0454 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0251 - acc: 0.9949
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0450 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0213 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0447 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0183 - acc: 0.9963
POS tagging accuracy = 95.1
Loss = 0.218, 
POS tagging accuracy = 95.1
Loss = 0.218, 
	TRAINING TIME: 4.95 minutes 
==================================================================================================
	PARSING TIME: 0.92 minutes 
==================================================================================================
	Identification : 0.583
	P, R  : 0.785, 0.464

==================================================================================================
	XP Ends: 23/4 (17 h:36)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,127            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
21             ,2              ,24             ,3              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.16           ,7              ,24             ,196            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
122            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 127, 21, 2, 24, 3, 12, 0.16, 7, 24, 196, True, 122, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (17h:36)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.16
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 122)       920490      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 21)       24906       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_266 (Flatten)           (None, 854)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_267 (Flatten)           (None, 252)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_268 (Flatten)           (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_269 (Flatten)           (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_94 (Concatenate)    (None, 1119)         0           flatten_266[0][0]                
                                                                 flatten_267[0][0]                
                                                                 flatten_268[0][0]                
                                                                 flatten_269[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 196)          219520      concatenate_94[0][0]             
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 152)          29944       posDense[0][0]                   
==================================================================================================
Total params: 1,195,008
Trainable params: 1,195,008
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.16
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 122)       920490      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 21)       24906       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_270 (Flatten)           (None, 854)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_271 (Flatten)           (None, 252)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_272 (Flatten)           (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_273 (Flatten)           (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_274 (Flatten)           (None, 854)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_275 (Flatten)           (None, 252)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_276 (Flatten)           (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_277 (Flatten)           (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_278 (Flatten)           (None, 854)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_279 (Flatten)           (None, 252)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_280 (Flatten)           (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_281 (Flatten)           (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_282 (Flatten)           (None, 854)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_283 (Flatten)           (None, 252)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_284 (Flatten)           (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_285 (Flatten)           (None, 7)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_286 (Flatten)           (None, 854)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_287 (Flatten)           (None, 252)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_288 (Flatten)           (None, 6)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_289 (Flatten)           (None, 7)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_95 (Concatenate)    (None, 1119)         0           flatten_270[0][0]                
                                                                 flatten_271[0][0]                
                                                                 flatten_272[0][0]                
                                                                 flatten_273[0][0]                
__________________________________________________________________________________________________
concatenate_96 (Concatenate)    (None, 1119)         0           flatten_274[0][0]                
                                                                 flatten_275[0][0]                
                                                                 flatten_276[0][0]                
                                                                 flatten_277[0][0]                
__________________________________________________________________________________________________
concatenate_97 (Concatenate)    (None, 1119)         0           flatten_278[0][0]                
                                                                 flatten_279[0][0]                
                                                                 flatten_280[0][0]                
                                                                 flatten_281[0][0]                
__________________________________________________________________________________________________
concatenate_98 (Concatenate)    (None, 1119)         0           flatten_282[0][0]                
                                                                 flatten_283[0][0]                
                                                                 flatten_284[0][0]                
                                                                 flatten_285[0][0]                
__________________________________________________________________________________________________
concatenate_99 (Concatenate)    (None, 1119)         0           flatten_286[0][0]                
                                                                 flatten_287[0][0]                
                                                                 flatten_288[0][0]                
                                                                 flatten_289[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 196)          219520      concatenate_95[0][0]             
                                                                 concatenate_96[0][0]             
                                                                 concatenate_97[0][0]             
                                                                 concatenate_98[0][0]             
                                                                 concatenate_99[0][0]             
__________________________________________________________________________________________________
concatenate_100 (Concatenate)   (None, 980)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 127)          124587      concatenate_100[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            512         idenDense[0][0]                  
==================================================================================================
Total params: 1,290,163
Trainable params: 1,290,163
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.3867 - acc: 0.9143
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1455 - acc: 0.9686
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1034 - acc: 0.9767
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0824 - acc: 0.9809
MWE identification:
Epoch 1/1
 - 45s - loss: 12.0789 - acc: 0.2506
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1213 - acc: 0.9710
MWE identification:
Epoch 1/1
 - 45s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0694 - acc: 0.9836
MWE identification:
Epoch 1/1
 - 45s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0606 - acc: 0.9861
MWE identification:
Epoch 1/1
 - 45s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0577 - acc: 0.9869
MWE identification:
Epoch 1/1
 - 45s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0542 - acc: 0.9877
MWE identification:
Epoch 1/1
 - 45s - loss: 12.0886 - acc: 0.2500
POS tagging accuracy = 94.5
Loss = 0.308, 
POS tagging accuracy = 94.5
Loss = 0.308, 
	TRAINING TIME: 6.67 minutes 
==================================================================================================
	PARSING TIME: 2.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (17 h:45)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,178            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
10             ,2              ,73             ,1              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.057          ,7              ,10             ,112            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
28             ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 178, 10, 2, 73, 1, 17, 0.057, 7, 10, 112, True, 28, False, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (17h:45)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.057
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_290 (Flatten)           (None, 196)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_291 (Flatten)           (None, 120)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_292 (Flatten)           (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_293 (Flatten)           (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_101 (Concatenate)   (None, 329)          0           flatten_290[0][0]                
                                                                 flatten_291[0][0]                
                                                                 flatten_292[0][0]                
                                                                 flatten_293[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 112)          36960       concatenate_101[0][0]            
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 152)          17176       posDense[0][0]                   
==================================================================================================
Total params: 277,404
Trainable params: 277,404
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.057
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_294 (Flatten)           (None, 196)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_295 (Flatten)           (None, 120)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_296 (Flatten)           (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_297 (Flatten)           (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_298 (Flatten)           (None, 196)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_299 (Flatten)           (None, 120)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_300 (Flatten)           (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_301 (Flatten)           (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_302 (Flatten)           (None, 196)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_303 (Flatten)           (None, 120)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_304 (Flatten)           (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_305 (Flatten)           (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_102 (Concatenate)   (None, 329)          0           flatten_294[0][0]                
                                                                 flatten_295[0][0]                
                                                                 flatten_296[0][0]                
                                                                 flatten_297[0][0]                
__________________________________________________________________________________________________
concatenate_103 (Concatenate)   (None, 329)          0           flatten_298[0][0]                
                                                                 flatten_299[0][0]                
                                                                 flatten_300[0][0]                
                                                                 flatten_301[0][0]                
__________________________________________________________________________________________________
concatenate_104 (Concatenate)   (None, 329)          0           flatten_302[0][0]                
                                                                 flatten_303[0][0]                
                                                                 flatten_304[0][0]                
                                                                 flatten_305[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 112)          36960       concatenate_102[0][0]            
                                                                 concatenate_103[0][0]            
                                                                 concatenate_104[0][0]            
__________________________________________________________________________________________________
concatenate_105 (Concatenate)   (None, 336)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 178)          59986       concatenate_105[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            716         idenDense[0][0]                  
==================================================================================================
Total params: 320,930
Trainable params: 320,930
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 11s - loss: 0.1999 - acc: 0.9501
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0671 - acc: 0.9815
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0577 - acc: 0.4999
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0521 - acc: 0.9863
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0284 - acc: 0.9927
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0194 - acc: 0.9954
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0144 - acc: 0.9968
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0114 - acc: 0.9976
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0093 - acc: 0.9981
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0081 - acc: 0.9983
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0070 - acc: 0.9986
POS tagging accuracy = 95.2
Loss = 0.234, 
POS tagging accuracy = 95.2
Loss = 0.234, 
	TRAINING TIME: 4.1 minutes 
==================================================================================================
	PARSING TIME: 1.55 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (17 h:51)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,79             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
20             ,7              ,33             ,2              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.025          ,13             ,26             ,124            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
98             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 79, 20, 7, 33, 2, 16, 0.025, 13, 26, 124, True, 98, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (17h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 98)        739410      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_306 (Flatten)           (None, 686)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_307 (Flatten)           (None, 240)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_308 (Flatten)           (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_309 (Flatten)           (None, 13)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_106 (Concatenate)   (None, 960)          0           flatten_306[0][0]                
                                                                 flatten_307[0][0]                
                                                                 flatten_308[0][0]                
                                                                 flatten_309[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 124)          119164      concatenate_106[0][0]            
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 152)          19000       posDense[0][0]                   
==================================================================================================
Total params: 901,582
Trainable params: 901,582
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 98)        739410      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_310 (Flatten)           (None, 686)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_311 (Flatten)           (None, 240)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_312 (Flatten)           (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_313 (Flatten)           (None, 13)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_314 (Flatten)           (None, 686)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_315 (Flatten)           (None, 240)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_316 (Flatten)           (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_317 (Flatten)           (None, 13)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_318 (Flatten)           (None, 686)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_319 (Flatten)           (None, 240)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_320 (Flatten)           (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_321 (Flatten)           (None, 13)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_322 (Flatten)           (None, 686)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_323 (Flatten)           (None, 240)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_324 (Flatten)           (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_325 (Flatten)           (None, 13)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_107 (Concatenate)   (None, 960)          0           flatten_310[0][0]                
                                                                 flatten_311[0][0]                
                                                                 flatten_312[0][0]                
                                                                 flatten_313[0][0]                
__________________________________________________________________________________________________
concatenate_108 (Concatenate)   (None, 960)          0           flatten_314[0][0]                
                                                                 flatten_315[0][0]                
                                                                 flatten_316[0][0]                
                                                                 flatten_317[0][0]                
__________________________________________________________________________________________________
concatenate_109 (Concatenate)   (None, 960)          0           flatten_318[0][0]                
                                                                 flatten_319[0][0]                
                                                                 flatten_320[0][0]                
                                                                 flatten_321[0][0]                
__________________________________________________________________________________________________
concatenate_110 (Concatenate)   (None, 960)          0           flatten_322[0][0]                
                                                                 flatten_323[0][0]                
                                                                 flatten_324[0][0]                
                                                                 flatten_325[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 124)          119164      concatenate_107[0][0]            
                                                                 concatenate_108[0][0]            
                                                                 concatenate_109[0][0]            
                                                                 concatenate_110[0][0]            
__________________________________________________________________________________________________
concatenate_111 (Concatenate)   (None, 496)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 79)           39263       concatenate_111[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            320         idenDense[0][0]                  
==================================================================================================
Total params: 922,165
Trainable params: 922,165
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1974 - acc: 0.9513
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0670 - acc: 0.9821
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0396 - acc: 0.9895
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0628 - acc: 0.9841
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0553 - acc: 0.9855
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0491 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0287 - acc: 0.9934
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0463 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0190 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0451 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0139 - acc: 0.9971
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0446 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0105 - acc: 0.9978
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0084 - acc: 0.9982
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0070 - acc: 0.9985
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0442 - acc: 0.9895
POS tagging accuracy = 95.1
Loss = 0.253, 
POS tagging accuracy = 95.1
Loss = 0.253, 
	TRAINING TIME: 5.67 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.584
	P, R  : 0.734, 0.485

==================================================================================================
	XP Ends: 23/4 (17 h:58)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,176            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,4              ,114            ,2              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.149          ,5              ,57             ,86             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
48             ,True           ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 176, 13, 4, 114, 2, 15, 0.149, 5, 57, 86, True, 48, True, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (17h:58)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.149
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 48)        549024      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_326 (Flatten)           (None, 336)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_327 (Flatten)           (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_328 (Flatten)           (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_112 (Concatenate)   (None, 504)          0           flatten_326[0][0]                
                                                                 flatten_327[0][0]                
                                                                 flatten_328[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 86)           43430       concatenate_112[0][0]            
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 152)          13224       posDense[0][0]                   
==================================================================================================
Total params: 621,112
Trainable params: 621,112
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.149
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 48)        549024      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_329 (Flatten)           (None, 336)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_330 (Flatten)           (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_331 (Flatten)           (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_332 (Flatten)           (None, 336)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_333 (Flatten)           (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_334 (Flatten)           (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_335 (Flatten)           (None, 336)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_336 (Flatten)           (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_337 (Flatten)           (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_338 (Flatten)           (None, 336)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_339 (Flatten)           (None, 156)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_340 (Flatten)           (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_113 (Concatenate)   (None, 504)          0           flatten_329[0][0]                
                                                                 flatten_330[0][0]                
                                                                 flatten_331[0][0]                
__________________________________________________________________________________________________
concatenate_114 (Concatenate)   (None, 504)          0           flatten_332[0][0]                
                                                                 flatten_333[0][0]                
                                                                 flatten_334[0][0]                
__________________________________________________________________________________________________
concatenate_115 (Concatenate)   (None, 504)          0           flatten_335[0][0]                
                                                                 flatten_336[0][0]                
                                                                 flatten_337[0][0]                
__________________________________________________________________________________________________
concatenate_116 (Concatenate)   (None, 504)          0           flatten_338[0][0]                
                                                                 flatten_339[0][0]                
                                                                 flatten_340[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 86)           43430       concatenate_113[0][0]            
                                                                 concatenate_114[0][0]            
                                                                 concatenate_115[0][0]            
                                                                 concatenate_116[0][0]            
__________________________________________________________________________________________________
concatenate_117 (Concatenate)   (None, 344)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 176)          60720       concatenate_117[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            708         idenDense[0][0]                  
==================================================================================================
Total params: 669,316
Trainable params: 669,316
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2886 - acc: 0.9284
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1077 - acc: 0.9721
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0644 - acc: 0.9834
MWE identification:
Epoch 1/1
 - 8s - loss: 12.0844 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0874 - acc: 0.9788
MWE identification:
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0416 - acc: 0.9901
MWE identification:
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0324 - acc: 0.9926
MWE identification:
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0277 - acc: 0.9940
MWE identification:
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0246 - acc: 0.9950
MWE identification:
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0221 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 8s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0205 - acc: 0.9962
POS tagging accuracy = 93.7
Loss = 0.341, 
POS tagging accuracy = 93.7
Loss = 0.341, 
	TRAINING TIME: 2.17 minutes 
==================================================================================================
	PARSING TIME: 1.57 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (18 h:2)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,56             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
10             ,2              ,62             ,1              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.117          ,8              ,98             ,181            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
199            ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 56, 10, 2, 62, 1, 16, 0.117, 8, 98, 181, True, 199, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (18h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.117
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 199)       2276162     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_341 (Flatten)           (None, 1393)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_342 (Flatten)           (None, 120)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_343 (Flatten)           (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_344 (Flatten)           (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_118 (Concatenate)   (None, 1527)         0           flatten_341[0][0]                
                                                                 flatten_342[0][0]                
                                                                 flatten_343[0][0]                
                                                                 flatten_344[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 181)          276568      concatenate_118[0][0]            
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 152)          27664       posDense[0][0]                   
==================================================================================================
Total params: 2,592,422
Trainable params: 2,592,422
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.117
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 199)       2276162     bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_345 (Flatten)           (None, 1393)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_346 (Flatten)           (None, 120)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_347 (Flatten)           (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_348 (Flatten)           (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_349 (Flatten)           (None, 1393)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_350 (Flatten)           (None, 120)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_351 (Flatten)           (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_352 (Flatten)           (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_353 (Flatten)           (None, 1393)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_354 (Flatten)           (None, 120)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_355 (Flatten)           (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_356 (Flatten)           (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_357 (Flatten)           (None, 1393)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_358 (Flatten)           (None, 120)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_359 (Flatten)           (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_360 (Flatten)           (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_119 (Concatenate)   (None, 1527)         0           flatten_345[0][0]                
                                                                 flatten_346[0][0]                
                                                                 flatten_347[0][0]                
                                                                 flatten_348[0][0]                
__________________________________________________________________________________________________
concatenate_120 (Concatenate)   (None, 1527)         0           flatten_349[0][0]                
                                                                 flatten_350[0][0]                
                                                                 flatten_351[0][0]                
                                                                 flatten_352[0][0]                
__________________________________________________________________________________________________
concatenate_121 (Concatenate)   (None, 1527)         0           flatten_353[0][0]                
                                                                 flatten_354[0][0]                
                                                                 flatten_355[0][0]                
                                                                 flatten_356[0][0]                
__________________________________________________________________________________________________
concatenate_122 (Concatenate)   (None, 1527)         0           flatten_357[0][0]                
                                                                 flatten_358[0][0]                
                                                                 flatten_359[0][0]                
                                                                 flatten_360[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 181)          276568      concatenate_119[0][0]            
                                                                 concatenate_120[0][0]            
                                                                 concatenate_121[0][0]            
                                                                 concatenate_122[0][0]            
__________________________________________________________________________________________________
concatenate_123 (Concatenate)   (None, 724)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 56)           40600       concatenate_123[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            228         idenDense[0][0]                  
==================================================================================================
Total params: 2,605,586
Trainable params: 2,605,586
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.3386 - acc: 0.9215
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1046 - acc: 0.9739
MWE identification:
Epoch 1/1
 - 18s - loss: 4.1742 - acc: 0.7407
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2185 - acc: 0.9600
MWE identification:
Epoch 1/1
 - 18s - loss: 4.0734 - acc: 0.7469
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0920 - acc: 0.9787
MWE identification:
Epoch 1/1
 - 18s - loss: 4.0441 - acc: 0.7488
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0597 - acc: 0.9863
MWE identification:
Epoch 1/1
 - 18s - loss: 4.0396 - acc: 0.7493
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0472 - acc: 0.9890
MWE identification:
Epoch 1/1
 - 18s - loss: 2.9032 - acc: 0.8152
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0595 - acc: 0.9855
MWE identification:
Epoch 1/1
 - 18s - loss: 0.1068 - acc: 0.9799
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0545 - acc: 0.9865
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0770 - acc: 0.9852
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0407 - acc: 0.9906
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0677 - acc: 0.9871
POS tagging accuracy = 92.9
Loss = 0.402, 
POS tagging accuracy = 92.9
Loss = 0.402, 
	TRAINING TIME: 3.82 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.461
	P, R  : 0.422, 0.507

==================================================================================================
	XP Ends: 23/4 (18 h:7)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,76             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,1              ,9              ,1              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.014          ,11             ,10             ,152            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
171            ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 76, 8, 1, 9, 1, 16, 0.014, 11, 10, 152, True, 171, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (18h:7)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 171)       1955898     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 11)        220         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_361 (Flatten)           (None, 1197)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_362 (Flatten)           (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_363 (Flatten)           (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_364 (Flatten)           (None, 11)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_124 (Concatenate)   (None, 1307)         0           flatten_361[0][0]                
                                                                 flatten_362[0][0]                
                                                                 flatten_363[0][0]                
                                                                 flatten_364[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 152)          198816      concatenate_124[0][0]            
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 152)          23256       posDense[0][0]                   
==================================================================================================
Total params: 2,187,682
Trainable params: 2,187,682
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 171)       1955898     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 11)        220         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_365 (Flatten)           (None, 1197)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_366 (Flatten)           (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_367 (Flatten)           (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_368 (Flatten)           (None, 11)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_369 (Flatten)           (None, 1197)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_370 (Flatten)           (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_371 (Flatten)           (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_372 (Flatten)           (None, 11)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_373 (Flatten)           (None, 1197)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_374 (Flatten)           (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_375 (Flatten)           (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_376 (Flatten)           (None, 11)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_377 (Flatten)           (None, 1197)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_378 (Flatten)           (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_379 (Flatten)           (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_380 (Flatten)           (None, 11)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_125 (Concatenate)   (None, 1307)         0           flatten_365[0][0]                
                                                                 flatten_366[0][0]                
                                                                 flatten_367[0][0]                
                                                                 flatten_368[0][0]                
__________________________________________________________________________________________________
concatenate_126 (Concatenate)   (None, 1307)         0           flatten_369[0][0]                
                                                                 flatten_370[0][0]                
                                                                 flatten_371[0][0]                
                                                                 flatten_372[0][0]                
__________________________________________________________________________________________________
concatenate_127 (Concatenate)   (None, 1307)         0           flatten_373[0][0]                
                                                                 flatten_374[0][0]                
                                                                 flatten_375[0][0]                
                                                                 flatten_376[0][0]                
__________________________________________________________________________________________________
concatenate_128 (Concatenate)   (None, 1307)         0           flatten_377[0][0]                
                                                                 flatten_378[0][0]                
                                                                 flatten_379[0][0]                
                                                                 flatten_380[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 152)          198816      concatenate_125[0][0]            
                                                                 concatenate_126[0][0]            
                                                                 concatenate_127[0][0]            
                                                                 concatenate_128[0][0]            
__________________________________________________________________________________________________
concatenate_129 (Concatenate)   (None, 608)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 76)           46284       concatenate_129[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            308         idenDense[0][0]                  
==================================================================================================
Total params: 2,211,018
Trainable params: 2,211,018
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 14s - loss: 0.2590 - acc: 0.9341
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1171 - acc: 0.9708
MWE identification:
Epoch 1/1
 - 114s - loss: 0.0633 - acc: 0.9840
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1010 - acc: 0.9746
MWE identification:
Epoch 1/1
 - 112s - loss: 0.0482 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0651 - acc: 0.9839
MWE identification:
Epoch 1/1
 - 112s - loss: 0.0457 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0490 - acc: 0.9882
MWE identification:
Epoch 1/1
 - 114s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0389 - acc: 0.9910
MWE identification:
Epoch 1/1
 - 113s - loss: 0.0446 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0321 - acc: 0.9928
MWE identification:
Epoch 1/1
 - 113s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0271 - acc: 0.9939
MWE identification:
Epoch 1/1
 - 113s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0233 - acc: 0.9950
MWE identification:
Epoch 1/1
 - 113s - loss: 0.0443 - acc: 0.9895
POS tagging accuracy = 93.9
Loss = 0.248, 
POS tagging accuracy = 93.9
Loss = 0.248, 
	TRAINING TIME: 18.28 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.526
	P, R  : 0.515, 0.537

==================================================================================================
	XP Ends: 23/4 (18 h:27)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,82             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
22             ,2              ,111            ,2              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.056          ,11             ,51             ,83             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
97             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 82, 22, 2, 111, 2, 16, 0.056, 11, 51, 83, True, 97, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (18h:27)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.056
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 97)        1109486     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 22)       26092       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_381 (Flatten)           (None, 679)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_382 (Flatten)           (None, 264)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_383 (Flatten)           (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_130 (Concatenate)   (None, 949)          0           flatten_381[0][0]                
                                                                 flatten_382[0][0]                
                                                                 flatten_383[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 83)           78850       concatenate_130[0][0]            
__________________________________________________________________________________________________
dense_21 (Dense)                (None, 152)          12768       posDense[0][0]                   
==================================================================================================
Total params: 1,227,204
Trainable params: 1,227,204
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.056
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 97)        1109486     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 22)       26092       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_384 (Flatten)           (None, 679)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_385 (Flatten)           (None, 264)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_386 (Flatten)           (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_387 (Flatten)           (None, 679)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_388 (Flatten)           (None, 264)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_389 (Flatten)           (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_390 (Flatten)           (None, 679)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_391 (Flatten)           (None, 264)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_392 (Flatten)           (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_393 (Flatten)           (None, 679)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_394 (Flatten)           (None, 264)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_395 (Flatten)           (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_396 (Flatten)           (None, 679)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_397 (Flatten)           (None, 264)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_398 (Flatten)           (None, 6)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_131 (Concatenate)   (None, 949)          0           flatten_384[0][0]                
                                                                 flatten_385[0][0]                
                                                                 flatten_386[0][0]                
__________________________________________________________________________________________________
concatenate_132 (Concatenate)   (None, 949)          0           flatten_387[0][0]                
                                                                 flatten_388[0][0]                
                                                                 flatten_389[0][0]                
__________________________________________________________________________________________________
concatenate_133 (Concatenate)   (None, 949)          0           flatten_390[0][0]                
                                                                 flatten_391[0][0]                
                                                                 flatten_392[0][0]                
__________________________________________________________________________________________________
concatenate_134 (Concatenate)   (None, 949)          0           flatten_393[0][0]                
                                                                 flatten_394[0][0]                
                                                                 flatten_395[0][0]                
__________________________________________________________________________________________________
concatenate_135 (Concatenate)   (None, 949)          0           flatten_396[0][0]                
                                                                 flatten_397[0][0]                
                                                                 flatten_398[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 83)           78850       concatenate_131[0][0]            
                                                                 concatenate_132[0][0]            
                                                                 concatenate_133[0][0]            
                                                                 concatenate_134[0][0]            
                                                                 concatenate_135[0][0]            
__________________________________________________________________________________________________
concatenate_136 (Concatenate)   (None, 415)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 82)           34112       concatenate_136[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            332         idenDense[0][0]                  
==================================================================================================
Total params: 1,248,880
Trainable params: 1,248,880
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2313 - acc: 0.9423
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0824 - acc: 0.9784
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0452 - acc: 0.9889
MWE identification:
Epoch 1/1
 - 10s - loss: 1.1444 - acc: 0.9166
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0853 - acc: 0.9777
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0519 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0368 - acc: 0.9912
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0461 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0198 - acc: 0.9954
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0448 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0136 - acc: 0.9969
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0104 - acc: 0.9978
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0083 - acc: 0.9983
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0070 - acc: 0.9986
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0443 - acc: 0.9895
POS tagging accuracy = 93.7
Loss = 0.298, 
POS tagging accuracy = 93.7
Loss = 0.298, 
	TRAINING TIME: 2.87 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.522
	P, R  : 0.506, 0.54

==================================================================================================
	XP Ends: 23/4 (18 h:31)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,71             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
22             ,3              ,28             ,1              ,19             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.174          ,7              ,105            ,109            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
33             ,True           ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 71, 22, 3, 28, 1, 19, 0.174, 7, 105, 109, True, 33, True, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (18h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.174
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 33)        248985      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 22)       26092       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_399 (Flatten)           (None, 231)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_400 (Flatten)           (None, 264)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_401 (Flatten)           (None, 9)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_137 (Concatenate)   (None, 504)          0           flatten_399[0][0]                
                                                                 flatten_400[0][0]                
                                                                 flatten_401[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 109)          55045       concatenate_137[0][0]            
__________________________________________________________________________________________________
dense_22 (Dense)                (None, 152)          16720       posDense[0][0]                   
==================================================================================================
Total params: 346,854
Trainable params: 346,854
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.174
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 33)        248985      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 22)       26092       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_402 (Flatten)           (None, 231)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_403 (Flatten)           (None, 264)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_404 (Flatten)           (None, 9)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_405 (Flatten)           (None, 231)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_406 (Flatten)           (None, 264)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_407 (Flatten)           (None, 9)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_408 (Flatten)           (None, 231)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_409 (Flatten)           (None, 264)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_410 (Flatten)           (None, 9)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_411 (Flatten)           (None, 231)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_412 (Flatten)           (None, 264)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_413 (Flatten)           (None, 9)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_138 (Concatenate)   (None, 504)          0           flatten_402[0][0]                
                                                                 flatten_403[0][0]                
                                                                 flatten_404[0][0]                
__________________________________________________________________________________________________
concatenate_139 (Concatenate)   (None, 504)          0           flatten_405[0][0]                
                                                                 flatten_406[0][0]                
                                                                 flatten_407[0][0]                
__________________________________________________________________________________________________
concatenate_140 (Concatenate)   (None, 504)          0           flatten_408[0][0]                
                                                                 flatten_409[0][0]                
                                                                 flatten_410[0][0]                
__________________________________________________________________________________________________
concatenate_141 (Concatenate)   (None, 504)          0           flatten_411[0][0]                
                                                                 flatten_412[0][0]                
                                                                 flatten_413[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 109)          55045       concatenate_138[0][0]            
                                                                 concatenate_139[0][0]            
                                                                 concatenate_140[0][0]            
                                                                 concatenate_141[0][0]            
__________________________________________________________________________________________________
concatenate_142 (Concatenate)   (None, 436)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 71)           31027       concatenate_142[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            288         idenDense[0][0]                  
==================================================================================================
Total params: 361,449
Trainable params: 361,449
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.3383 - acc: 0.9291
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0989 - acc: 0.9752
MWE identification:
Epoch 1/1
 - 27s - loss: 12.0879 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0858 - acc: 0.9776
MWE identification:
Epoch 1/1
 - 27s - loss: 4.2700 - acc: 0.7350
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1160 - acc: 0.9726
MWE identification:
Epoch 1/1
 - 27s - loss: 4.2389 - acc: 0.7369
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1013 - acc: 0.9769
MWE identification:
Epoch 1/1
 - 27s - loss: 4.1202 - acc: 0.7443
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0627 - acc: 0.9847
MWE identification:
Epoch 1/1
 - 27s - loss: 4.0544 - acc: 0.7484
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0445 - acc: 0.9893
MWE identification:
Epoch 1/1
 - 27s - loss: 4.0475 - acc: 0.7488
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0359 - acc: 0.9918
MWE identification:
Epoch 1/1
 - 27s - loss: 4.0440 - acc: 0.7490
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0319 - acc: 0.9928
MWE identification:
Epoch 1/1
 - 29s - loss: 4.0439 - acc: 0.7491
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0292 - acc: 0.9934
MWE identification:
Epoch 1/1
 - 27s - loss: 4.0428 - acc: 0.7492
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0263 - acc: 0.9943
POS tagging accuracy = 94.4
Loss = 0.333, 
POS tagging accuracy = 94.4
Loss = 0.333, 
	TRAINING TIME: 5.32 minutes 
==================================================================================================
	PARSING TIME: 1.68 minutes 
==================================================================================================
	Identification : 0.022
	P, R  : 0.013, 0.082

==================================================================================================
	XP Ends: 23/4 (18 h:38)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,83             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
11             ,7              ,81             ,3              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.176          ,7              ,30             ,93             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
39             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 83, 11, 7, 81, 3, 11, 0.176, 7, 30, 93, True, 39, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (18h:38)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.176
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 39)        446082      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_414 (Flatten)           (None, 273)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_415 (Flatten)           (None, 132)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_416 (Flatten)           (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_417 (Flatten)           (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_143 (Concatenate)   (None, 433)          0           flatten_414[0][0]                
                                                                 flatten_415[0][0]                
                                                                 flatten_416[0][0]                
                                                                 flatten_417[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 93)           40362       concatenate_143[0][0]            
__________________________________________________________________________________________________
dense_23 (Dense)                (None, 152)          14288       posDense[0][0]                   
==================================================================================================
Total params: 513,946
Trainable params: 513,946
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.176
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 39)        446082      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_418 (Flatten)           (None, 273)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_419 (Flatten)           (None, 132)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_420 (Flatten)           (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_421 (Flatten)           (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_422 (Flatten)           (None, 273)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_423 (Flatten)           (None, 132)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_424 (Flatten)           (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_425 (Flatten)           (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_426 (Flatten)           (None, 273)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_427 (Flatten)           (None, 132)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_428 (Flatten)           (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_429 (Flatten)           (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_430 (Flatten)           (None, 273)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_431 (Flatten)           (None, 132)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_432 (Flatten)           (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_433 (Flatten)           (None, 7)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_434 (Flatten)           (None, 273)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_435 (Flatten)           (None, 132)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_436 (Flatten)           (None, 21)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_437 (Flatten)           (None, 7)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_144 (Concatenate)   (None, 433)          0           flatten_418[0][0]                
                                                                 flatten_419[0][0]                
                                                                 flatten_420[0][0]                
                                                                 flatten_421[0][0]                
__________________________________________________________________________________________________
concatenate_145 (Concatenate)   (None, 433)          0           flatten_422[0][0]                
                                                                 flatten_423[0][0]                
                                                                 flatten_424[0][0]                
                                                                 flatten_425[0][0]                
__________________________________________________________________________________________________
concatenate_146 (Concatenate)   (None, 433)          0           flatten_426[0][0]                
                                                                 flatten_427[0][0]                
                                                                 flatten_428[0][0]                
                                                                 flatten_429[0][0]                
__________________________________________________________________________________________________
concatenate_147 (Concatenate)   (None, 433)          0           flatten_430[0][0]                
                                                                 flatten_431[0][0]                
                                                                 flatten_432[0][0]                
                                                                 flatten_433[0][0]                
__________________________________________________________________________________________________
concatenate_148 (Concatenate)   (None, 433)          0           flatten_434[0][0]                
                                                                 flatten_435[0][0]                
                                                                 flatten_436[0][0]                
                                                                 flatten_437[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 93)           40362       concatenate_144[0][0]            
                                                                 concatenate_145[0][0]            
                                                                 concatenate_146[0][0]            
                                                                 concatenate_147[0][0]            
                                                                 concatenate_148[0][0]            
__________________________________________________________________________________________________
concatenate_149 (Concatenate)   (None, 465)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 83)           38678       concatenate_149[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            336         idenDense[0][0]                  
==================================================================================================
Total params: 538,672
Trainable params: 538,672
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.3311 - acc: 0.9226
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1391 - acc: 0.9658
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0963 - acc: 0.9758
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0753 - acc: 0.9808
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0855 - acc: 0.2501
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1063 - acc: 0.9734
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0847 - acc: 0.2502
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0900 - acc: 0.9781
MWE identification:
Epoch 1/1
 - 14s - loss: 8.0617 - acc: 0.4998
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0895 - acc: 0.9789
MWE identification:
Epoch 1/1
 - 14s - loss: 8.0614 - acc: 0.4998
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0596 - acc: 0.9856
MWE identification:
Epoch 1/1
 - 14s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0487 - acc: 0.9885
POS tagging accuracy = 93.2
Loss = 0.367, 
POS tagging accuracy = 93.2
Loss = 0.367, 
	TRAINING TIME: 3.12 minutes 
==================================================================================================
	PARSING TIME: 2.28 minutes 
==================================================================================================
	Identification : 0.001
	P, R  : 0.001, 0.001

==================================================================================================
	XP Ends: 23/4 (18 h:44)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,30             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
10             ,1              ,95             ,4              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.012          ,8              ,12             ,26             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
127            ,True           ,True           ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 30, 10, 1, 95, 4, 16, 0.012, 8, 12, 26, True, 127, True, True, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (18h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 127)       958215      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       affixes[0][0]                    
__________________________________________________________________________________________________
flatten_438 (Flatten)           (None, 889)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_439 (Flatten)           (None, 120)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_150 (Concatenate)   (None, 1009)         0           flatten_438[0][0]                
                                                                 flatten_439[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 26)           26260       concatenate_150[0][0]            
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 152)          4104        posDense[0][0]                   
==================================================================================================
Total params: 1,000,439
Trainable params: 1,000,439
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 127)       958215      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_440 (Flatten)           (None, 889)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_441 (Flatten)           (None, 120)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_442 (Flatten)           (None, 889)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_443 (Flatten)           (None, 120)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_444 (Flatten)           (None, 889)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_445 (Flatten)           (None, 120)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_446 (Flatten)           (None, 889)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_447 (Flatten)           (None, 120)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_448 (Flatten)           (None, 889)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_449 (Flatten)           (None, 120)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
concatenate_151 (Concatenate)   (None, 1009)         0           flatten_440[0][0]                
                                                                 flatten_441[0][0]                
__________________________________________________________________________________________________
concatenate_152 (Concatenate)   (None, 1009)         0           flatten_442[0][0]                
                                                                 flatten_443[0][0]                
__________________________________________________________________________________________________
concatenate_153 (Concatenate)   (None, 1009)         0           flatten_444[0][0]                
                                                                 flatten_445[0][0]                
__________________________________________________________________________________________________
concatenate_154 (Concatenate)   (None, 1009)         0           flatten_446[0][0]                
                                                                 flatten_447[0][0]                
__________________________________________________________________________________________________
concatenate_155 (Concatenate)   (None, 1009)         0           flatten_448[0][0]                
                                                                 flatten_449[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 26)           26260       concatenate_151[0][0]            
                                                                 concatenate_152[0][0]            
                                                                 concatenate_153[0][0]            
                                                                 concatenate_154[0][0]            
                                                                 concatenate_155[0][0]            
__________________________________________________________________________________________________
concatenate_156 (Concatenate)   (None, 130)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 30)           3930        concatenate_156[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            124         idenDense[0][0]                  
==================================================================================================
Total params: 1,000,389
Trainable params: 1,000,389
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.3643 - acc: 0.9163
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1411 - acc: 0.9694
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1060 - acc: 0.9755
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0872 - acc: 0.9791
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0745 - acc: 0.9818
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0825 - acc: 0.9796
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0853 - acc: 0.9789
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0580 - acc: 0.9859
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0699 - acc: 0.9827
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0535 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0608 - acc: 0.9858
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0511 - acc: 0.9878
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0543 - acc: 0.9876
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0496 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0490 - acc: 0.9892
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0485 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0447 - acc: 0.9902
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0477 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0410 - acc: 0.9914
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0471 - acc: 0.9889
POS tagging accuracy = 95.2
Loss = 0.22, 
POS tagging accuracy = 95.2
Loss = 0.22, 
	TRAINING TIME: 3.87 minutes 
==================================================================================================
	PARSING TIME: 0.83 minutes 
==================================================================================================
	Identification : 0.604
	P, R  : 0.764, 0.499

==================================================================================================
	XP Ends: 23/4 (18 h:49)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,176            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,8              ,14             ,2              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.116          ,6              ,33             ,48             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
68             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 176, 6, 8, 14, 2, 10, 0.116, 6, 33, 48, True, 68, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (18h:49)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.116
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 68)        513060      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_450 (Flatten)           (None, 476)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_451 (Flatten)           (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_452 (Flatten)           (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_453 (Flatten)           (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_157 (Concatenate)   (None, 578)          0           flatten_450[0][0]                
                                                                 flatten_451[0][0]                
                                                                 flatten_452[0][0]                
                                                                 flatten_453[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 48)           27792       concatenate_157[0][0]            
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 152)          7448        posDense[0][0]                   
==================================================================================================
Total params: 555,568
Trainable params: 555,568
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.116
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 68)        513060      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_454 (Flatten)           (None, 476)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_455 (Flatten)           (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_456 (Flatten)           (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_457 (Flatten)           (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_458 (Flatten)           (None, 476)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_459 (Flatten)           (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_460 (Flatten)           (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_461 (Flatten)           (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_462 (Flatten)           (None, 476)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_463 (Flatten)           (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_464 (Flatten)           (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_465 (Flatten)           (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_466 (Flatten)           (None, 476)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_467 (Flatten)           (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_468 (Flatten)           (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_469 (Flatten)           (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_158 (Concatenate)   (None, 578)          0           flatten_454[0][0]                
                                                                 flatten_455[0][0]                
                                                                 flatten_456[0][0]                
                                                                 flatten_457[0][0]                
__________________________________________________________________________________________________
concatenate_159 (Concatenate)   (None, 578)          0           flatten_458[0][0]                
                                                                 flatten_459[0][0]                
                                                                 flatten_460[0][0]                
                                                                 flatten_461[0][0]                
__________________________________________________________________________________________________
concatenate_160 (Concatenate)   (None, 578)          0           flatten_462[0][0]                
                                                                 flatten_463[0][0]                
                                                                 flatten_464[0][0]                
                                                                 flatten_465[0][0]                
__________________________________________________________________________________________________
concatenate_161 (Concatenate)   (None, 578)          0           flatten_466[0][0]                
                                                                 flatten_467[0][0]                
                                                                 flatten_468[0][0]                
                                                                 flatten_469[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 48)           27792       concatenate_158[0][0]            
                                                                 concatenate_159[0][0]            
                                                                 concatenate_160[0][0]            
                                                                 concatenate_161[0][0]            
__________________________________________________________________________________________________
concatenate_162 (Concatenate)   (None, 192)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 176)          33968       concatenate_162[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            708         idenDense[0][0]                  
==================================================================================================
Total params: 582,796
Trainable params: 582,796
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2267 - acc: 0.9440
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0703 - acc: 0.9805
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0419 - acc: 0.9888
MWE identification:
Epoch 1/1
 - 64s - loss: 12.0881 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0410 - acc: 0.9895
MWE identification:
Epoch 1/1
 - 66s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0239 - acc: 0.9942
MWE identification:
Epoch 1/1
 - 64s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0190 - acc: 0.9955
MWE identification:
Epoch 1/1
 - 64s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0162 - acc: 0.9963
MWE identification:
Epoch 1/1
 - 64s - loss: 12.0886 - acc: 0.2500
POS tagging accuracy = 95.1
Loss = 0.26, 
POS tagging accuracy = 95.1
Loss = 0.26, 
	TRAINING TIME: 6.85 minutes 
==================================================================================================
	PARSING TIME: 2.12 minutes 
==================================================================================================
	Identification : 0.029
	P, R  : 0.016, 0.143

==================================================================================================
	XP Ends: 23/4 (18 h:58)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,119            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
9              ,7              ,24             ,3              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.028          ,9              ,109            ,53             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
46             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 119, 9, 7, 24, 3, 9, 0.028, 9, 109, 53, True, 46, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (18h:58)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 46)        526148      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_470 (Flatten)           (None, 322)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_471 (Flatten)           (None, 108)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_472 (Flatten)           (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_473 (Flatten)           (None, 9)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_163 (Concatenate)   (None, 460)          0           flatten_470[0][0]                
                                                                 flatten_471[0][0]                
                                                                 flatten_472[0][0]                
                                                                 flatten_473[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 53)           24433       concatenate_163[0][0]            
__________________________________________________________________________________________________
dense_26 (Dense)                (None, 152)          8208        posDense[0][0]                   
==================================================================================================
Total params: 569,671
Trainable params: 569,671
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 46)        526148      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_474 (Flatten)           (None, 322)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_475 (Flatten)           (None, 108)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_476 (Flatten)           (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_477 (Flatten)           (None, 9)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_478 (Flatten)           (None, 322)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_479 (Flatten)           (None, 108)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_480 (Flatten)           (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_481 (Flatten)           (None, 9)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_482 (Flatten)           (None, 322)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_483 (Flatten)           (None, 108)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_484 (Flatten)           (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_485 (Flatten)           (None, 9)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_486 (Flatten)           (None, 322)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_487 (Flatten)           (None, 108)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_488 (Flatten)           (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_489 (Flatten)           (None, 9)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_490 (Flatten)           (None, 322)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_491 (Flatten)           (None, 108)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_492 (Flatten)           (None, 21)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_493 (Flatten)           (None, 9)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_164 (Concatenate)   (None, 460)          0           flatten_474[0][0]                
                                                                 flatten_475[0][0]                
                                                                 flatten_476[0][0]                
                                                                 flatten_477[0][0]                
__________________________________________________________________________________________________
concatenate_165 (Concatenate)   (None, 460)          0           flatten_478[0][0]                
                                                                 flatten_479[0][0]                
                                                                 flatten_480[0][0]                
                                                                 flatten_481[0][0]                
__________________________________________________________________________________________________
concatenate_166 (Concatenate)   (None, 460)          0           flatten_482[0][0]                
                                                                 flatten_483[0][0]                
                                                                 flatten_484[0][0]                
                                                                 flatten_485[0][0]                
__________________________________________________________________________________________________
concatenate_167 (Concatenate)   (None, 460)          0           flatten_486[0][0]                
                                                                 flatten_487[0][0]                
                                                                 flatten_488[0][0]                
                                                                 flatten_489[0][0]                
__________________________________________________________________________________________________
concatenate_168 (Concatenate)   (None, 460)          0           flatten_490[0][0]                
                                                                 flatten_491[0][0]                
                                                                 flatten_492[0][0]                
                                                                 flatten_493[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 53)           24433       concatenate_164[0][0]            
                                                                 concatenate_165[0][0]            
                                                                 concatenate_166[0][0]            
                                                                 concatenate_167[0][0]            
                                                                 concatenate_168[0][0]            
__________________________________________________________________________________________________
concatenate_169 (Concatenate)   (None, 265)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 119)          31654       concatenate_169[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            480         idenDense[0][0]                  
==================================================================================================
Total params: 593,597
Trainable params: 593,597
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2980 - acc: 0.9260
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1314 - acc: 0.9674
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0936 - acc: 0.9770
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0704 - acc: 0.9827
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0727 - acc: 0.9824
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0885 - acc: 0.9784
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0511 - acc: 0.9877
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0606 - acc: 0.9858
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0472 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0469 - acc: 0.9892
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0457 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0384 - acc: 0.9913
POS tagging accuracy = 94.0
Loss = 0.24, 
POS tagging accuracy = 94.0
Loss = 0.24, 
	TRAINING TIME: 4.48 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.517
	P, R  : 0.674, 0.419

==================================================================================================
	XP Ends: 23/4 (19 h:4)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,73             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,4              ,76             ,1              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.034          ,7              ,57             ,114            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
194            ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 73, 13, 4, 76, 1, 17, 0.034, 7, 57, 114, True, 194, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (19h:4)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 194)       1463730     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_494 (Flatten)           (None, 1358)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_495 (Flatten)           (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_496 (Flatten)           (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_497 (Flatten)           (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_170 (Concatenate)   (None, 1533)         0           flatten_494[0][0]                
                                                                 flatten_495[0][0]                
                                                                 flatten_496[0][0]                
                                                                 flatten_497[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 114)          174876      concatenate_170[0][0]            
__________________________________________________________________________________________________
dense_27 (Dense)                (None, 152)          17480       posDense[0][0]                   
==================================================================================================
Total params: 1,671,660
Trainable params: 1,671,660
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 194)       1463730     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_498 (Flatten)           (None, 1358)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_499 (Flatten)           (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_500 (Flatten)           (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_501 (Flatten)           (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_502 (Flatten)           (None, 1358)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_503 (Flatten)           (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_504 (Flatten)           (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_505 (Flatten)           (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_506 (Flatten)           (None, 1358)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_507 (Flatten)           (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_508 (Flatten)           (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_509 (Flatten)           (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_510 (Flatten)           (None, 1358)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_511 (Flatten)           (None, 156)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_512 (Flatten)           (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_513 (Flatten)           (None, 7)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_171 (Concatenate)   (None, 1533)         0           flatten_498[0][0]                
                                                                 flatten_499[0][0]                
                                                                 flatten_500[0][0]                
                                                                 flatten_501[0][0]                
__________________________________________________________________________________________________
concatenate_172 (Concatenate)   (None, 1533)         0           flatten_502[0][0]                
                                                                 flatten_503[0][0]                
                                                                 flatten_504[0][0]                
                                                                 flatten_505[0][0]                
__________________________________________________________________________________________________
concatenate_173 (Concatenate)   (None, 1533)         0           flatten_506[0][0]                
                                                                 flatten_507[0][0]                
                                                                 flatten_508[0][0]                
                                                                 flatten_509[0][0]                
__________________________________________________________________________________________________
concatenate_174 (Concatenate)   (None, 1533)         0           flatten_510[0][0]                
                                                                 flatten_511[0][0]                
                                                                 flatten_512[0][0]                
                                                                 flatten_513[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 114)          174876      concatenate_171[0][0]            
                                                                 concatenate_172[0][0]            
                                                                 concatenate_173[0][0]            
                                                                 concatenate_174[0][0]            
__________________________________________________________________________________________________
concatenate_175 (Concatenate)   (None, 456)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 73)           33361       concatenate_175[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            296         idenDense[0][0]                  
==================================================================================================
Total params: 1,687,837
Trainable params: 1,687,837
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1940 - acc: 0.9515
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0534 - acc: 0.9855
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0702 - acc: 0.9828
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0612 - acc: 0.9845
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0494 - acc: 0.9881
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0273 - acc: 0.9936
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0461 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0161 - acc: 0.9967
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0450 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0111 - acc: 0.9977
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0085 - acc: 0.9982
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0068 - acc: 0.9984
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0058 - acc: 0.9986
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0442 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0050 - acc: 0.9988
POS tagging accuracy = 95.0
Loss = 0.265, 
POS tagging accuracy = 95.0
Loss = 0.265, 
	TRAINING TIME: 3.45 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.6
	P, R  : 0.779, 0.488

==================================================================================================
	XP Ends: 23/4 (19 h:9)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,136            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
20             ,5              ,24             ,2              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.025          ,7              ,9              ,158            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
71             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 136, 20, 5, 24, 2, 12, 0.025, 7, 9, 158, True, 71, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (19h:9)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 71)        535695      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_514 (Flatten)           (None, 497)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_515 (Flatten)           (None, 240)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_516 (Flatten)           (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_517 (Flatten)           (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_176 (Concatenate)   (None, 759)          0           flatten_514[0][0]                
                                                                 flatten_515[0][0]                
                                                                 flatten_516[0][0]                
                                                                 flatten_517[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 158)          120080      concatenate_176[0][0]            
__________________________________________________________________________________________________
dense_28 (Dense)                (None, 152)          24168       posDense[0][0]                   
==================================================================================================
Total params: 703,823
Trainable params: 703,823
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 71)        535695      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_518 (Flatten)           (None, 497)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_519 (Flatten)           (None, 240)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_520 (Flatten)           (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_521 (Flatten)           (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_522 (Flatten)           (None, 497)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_523 (Flatten)           (None, 240)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_524 (Flatten)           (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_525 (Flatten)           (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_526 (Flatten)           (None, 497)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_527 (Flatten)           (None, 240)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_528 (Flatten)           (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_529 (Flatten)           (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_530 (Flatten)           (None, 497)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_531 (Flatten)           (None, 240)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_532 (Flatten)           (None, 15)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_533 (Flatten)           (None, 7)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_177 (Concatenate)   (None, 759)          0           flatten_518[0][0]                
                                                                 flatten_519[0][0]                
                                                                 flatten_520[0][0]                
                                                                 flatten_521[0][0]                
__________________________________________________________________________________________________
concatenate_178 (Concatenate)   (None, 759)          0           flatten_522[0][0]                
                                                                 flatten_523[0][0]                
                                                                 flatten_524[0][0]                
                                                                 flatten_525[0][0]                
__________________________________________________________________________________________________
concatenate_179 (Concatenate)   (None, 759)          0           flatten_526[0][0]                
                                                                 flatten_527[0][0]                
                                                                 flatten_528[0][0]                
                                                                 flatten_529[0][0]                
__________________________________________________________________________________________________
concatenate_180 (Concatenate)   (None, 759)          0           flatten_530[0][0]                
                                                                 flatten_531[0][0]                
                                                                 flatten_532[0][0]                
                                                                 flatten_533[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 158)          120080      concatenate_177[0][0]            
                                                                 concatenate_178[0][0]            
                                                                 concatenate_179[0][0]            
                                                                 concatenate_180[0][0]            
__________________________________________________________________________________________________
concatenate_181 (Concatenate)   (None, 632)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 136)          86088       concatenate_181[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            548         idenDense[0][0]                  
==================================================================================================
Total params: 766,291
Trainable params: 766,291
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 13s - loss: 0.1965 - acc: 0.9515
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0699 - acc: 0.9814
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0427 - acc: 0.9887
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0635 - acc: 0.9840
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0583 - acc: 0.9850
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0492 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0316 - acc: 0.9925
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0465 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 13s - loss: 0.0213 - acc: 0.9954
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0452 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 13s - loss: 0.0158 - acc: 0.9966
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0447 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 13s - loss: 0.0122 - acc: 0.9975
MWE identification:
Epoch 1/1
 - 38s - loss: 0.0444 - acc: 0.9895
POS tagging accuracy = 94.9
Loss = 0.233, 
POS tagging accuracy = 94.9
Loss = 0.233, 
	TRAINING TIME: 6.8 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.607
	P, R  : 0.708, 0.531

==================================================================================================
	XP Ends: 23/4 (19 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,160            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
16             ,4              ,37             ,1              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.173          ,10             ,52             ,32             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
99             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 160, 16, 4, 37, 1, 11, 0.173, 10, 52, 32, True, 99, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (19h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.173
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 99)        1132362     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 16)       18976       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_534 (Flatten)           (None, 693)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_535 (Flatten)           (None, 192)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_536 (Flatten)           (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_182 (Concatenate)   (None, 897)          0           flatten_534[0][0]                
                                                                 flatten_535[0][0]                
                                                                 flatten_536[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 32)           28736       concatenate_182[0][0]            
__________________________________________________________________________________________________
dense_29 (Dense)                (None, 152)          5016        posDense[0][0]                   
==================================================================================================
Total params: 1,185,106
Trainable params: 1,185,106
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.173
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 99)        1132362     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 16)       18976       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_537 (Flatten)           (None, 693)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_538 (Flatten)           (None, 192)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_539 (Flatten)           (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_540 (Flatten)           (None, 693)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_541 (Flatten)           (None, 192)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_542 (Flatten)           (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_543 (Flatten)           (None, 693)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_544 (Flatten)           (None, 192)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_545 (Flatten)           (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_546 (Flatten)           (None, 693)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_547 (Flatten)           (None, 192)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_548 (Flatten)           (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_549 (Flatten)           (None, 693)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_550 (Flatten)           (None, 192)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_551 (Flatten)           (None, 12)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_183 (Concatenate)   (None, 897)          0           flatten_537[0][0]                
                                                                 flatten_538[0][0]                
                                                                 flatten_539[0][0]                
__________________________________________________________________________________________________
concatenate_184 (Concatenate)   (None, 897)          0           flatten_540[0][0]                
                                                                 flatten_541[0][0]                
                                                                 flatten_542[0][0]                
__________________________________________________________________________________________________
concatenate_185 (Concatenate)   (None, 897)          0           flatten_543[0][0]                
                                                                 flatten_544[0][0]                
                                                                 flatten_545[0][0]                
__________________________________________________________________________________________________
concatenate_186 (Concatenate)   (None, 897)          0           flatten_546[0][0]                
                                                                 flatten_547[0][0]                
                                                                 flatten_548[0][0]                
__________________________________________________________________________________________________
concatenate_187 (Concatenate)   (None, 897)          0           flatten_549[0][0]                
                                                                 flatten_550[0][0]                
                                                                 flatten_551[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 32)           28736       concatenate_183[0][0]            
                                                                 concatenate_184[0][0]            
                                                                 concatenate_185[0][0]            
                                                                 concatenate_186[0][0]            
                                                                 concatenate_187[0][0]            
__________________________________________________________________________________________________
concatenate_188 (Concatenate)   (None, 160)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 160)          25760       concatenate_188[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            644         idenDense[0][0]                  
==================================================================================================
Total params: 1,206,494
Trainable params: 1,206,494
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.3478 - acc: 0.9163
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1394 - acc: 0.9676
MWE identification:
Epoch 1/1
 - 26s - loss: 12.0878 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1324 - acc: 0.9687
MWE identification:
Epoch 1/1
 - 26s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0806 - acc: 0.9825
MWE identification:
Epoch 1/1
 - 26s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0669 - acc: 0.9859
MWE identification:
Epoch 1/1
 - 26s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0581 - acc: 0.9881
MWE identification:
Epoch 1/1
 - 26s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0530 - acc: 0.9899
POS tagging accuracy = 93.3
Loss = 0.352, 
POS tagging accuracy = 93.3
Loss = 0.352, 
	TRAINING TIME: 3.62 minutes 
==================================================================================================
	PARSING TIME: 1.02 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (19 h:22)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,58             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,9              ,53             ,1              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.147          ,10             ,35             ,47             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
26             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 58, 5, 9, 53, 1, 11, 0.147, 10, 35, 47, True, 26, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (19h:22)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.147
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 26)        196170      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_552 (Flatten)           (None, 182)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_553 (Flatten)           (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_554 (Flatten)           (None, 27)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_555 (Flatten)           (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_189 (Concatenate)   (None, 279)          0           flatten_552[0][0]                
                                                                 flatten_553[0][0]                
                                                                 flatten_554[0][0]                
                                                                 flatten_555[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 47)           13160       concatenate_189[0][0]            
__________________________________________________________________________________________________
dense_30 (Dense)                (None, 152)          7296        posDense[0][0]                   
==================================================================================================
Total params: 222,792
Trainable params: 222,792
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.147
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 26)        196170      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_556 (Flatten)           (None, 182)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_557 (Flatten)           (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_558 (Flatten)           (None, 27)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_559 (Flatten)           (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_560 (Flatten)           (None, 182)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_561 (Flatten)           (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_562 (Flatten)           (None, 27)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_563 (Flatten)           (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_564 (Flatten)           (None, 182)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_565 (Flatten)           (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_566 (Flatten)           (None, 27)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_567 (Flatten)           (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_568 (Flatten)           (None, 182)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_569 (Flatten)           (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_570 (Flatten)           (None, 27)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_571 (Flatten)           (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_572 (Flatten)           (None, 182)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_573 (Flatten)           (None, 60)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_574 (Flatten)           (None, 27)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_575 (Flatten)           (None, 10)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_190 (Concatenate)   (None, 279)          0           flatten_556[0][0]                
                                                                 flatten_557[0][0]                
                                                                 flatten_558[0][0]                
                                                                 flatten_559[0][0]                
__________________________________________________________________________________________________
concatenate_191 (Concatenate)   (None, 279)          0           flatten_560[0][0]                
                                                                 flatten_561[0][0]                
                                                                 flatten_562[0][0]                
                                                                 flatten_563[0][0]                
__________________________________________________________________________________________________
concatenate_192 (Concatenate)   (None, 279)          0           flatten_564[0][0]                
                                                                 flatten_565[0][0]                
                                                                 flatten_566[0][0]                
                                                                 flatten_567[0][0]                
__________________________________________________________________________________________________
concatenate_193 (Concatenate)   (None, 279)          0           flatten_568[0][0]                
                                                                 flatten_569[0][0]                
                                                                 flatten_570[0][0]                
                                                                 flatten_571[0][0]                
__________________________________________________________________________________________________
concatenate_194 (Concatenate)   (None, 279)          0           flatten_572[0][0]                
                                                                 flatten_573[0][0]                
                                                                 flatten_574[0][0]                
                                                                 flatten_575[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 47)           13160       concatenate_190[0][0]            
                                                                 concatenate_191[0][0]            
                                                                 concatenate_192[0][0]            
                                                                 concatenate_193[0][0]            
                                                                 concatenate_194[0][0]            
__________________________________________________________________________________________________
concatenate_195 (Concatenate)   (None, 235)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 58)           13688       concatenate_195[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            236         idenDense[0][0]                  
==================================================================================================
Total params: 229,420
Trainable params: 229,420
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2395 - acc: 0.9410
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0849 - acc: 0.9773
MWE identification:
Epoch 1/1
 - 20s - loss: 8.0445 - acc: 0.4999
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1324 - acc: 0.9658
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0933 - acc: 0.9799
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1085 - acc: 0.9730
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0550 - acc: 0.9861
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0648 - acc: 0.9828
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0500 - acc: 0.9877
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0476 - acc: 0.9878
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0476 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0379 - acc: 0.9903
POS tagging accuracy = 94.5
Loss = 0.283, 
POS tagging accuracy = 94.5
Loss = 0.283, 
	TRAINING TIME: 3.42 minutes 
==================================================================================================
	PARSING TIME: 1.42 minutes 
==================================================================================================
	Identification : 0.435
	P, R  : 0.355, 0.563

==================================================================================================
	XP Ends: 23/4 (19 h:27)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,44             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
17             ,3              ,18             ,2              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.01           ,9              ,25             ,27             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
76             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 44, 17, 3, 18, 2, 10, 0.01, 9, 25, 27, True, 76, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (19h:27)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 76)        573420      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_576 (Flatten)           (None, 532)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_577 (Flatten)           (None, 204)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_578 (Flatten)           (None, 9)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_196 (Concatenate)   (None, 745)          0           flatten_576[0][0]                
                                                                 flatten_577[0][0]                
                                                                 flatten_578[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 27)           20142       concatenate_196[0][0]            
__________________________________________________________________________________________________
dense_31 (Dense)                (None, 152)          4256        posDense[0][0]                   
==================================================================================================
Total params: 617,992
Trainable params: 617,992
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 76)        573420      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_579 (Flatten)           (None, 532)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_580 (Flatten)           (None, 204)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_581 (Flatten)           (None, 9)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_582 (Flatten)           (None, 532)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_583 (Flatten)           (None, 204)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_584 (Flatten)           (None, 9)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_585 (Flatten)           (None, 532)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_586 (Flatten)           (None, 204)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_587 (Flatten)           (None, 9)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_588 (Flatten)           (None, 532)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_589 (Flatten)           (None, 204)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_590 (Flatten)           (None, 9)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_591 (Flatten)           (None, 532)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_592 (Flatten)           (None, 204)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_593 (Flatten)           (None, 9)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_197 (Concatenate)   (None, 745)          0           flatten_579[0][0]                
                                                                 flatten_580[0][0]                
                                                                 flatten_581[0][0]                
__________________________________________________________________________________________________
concatenate_198 (Concatenate)   (None, 745)          0           flatten_582[0][0]                
                                                                 flatten_583[0][0]                
                                                                 flatten_584[0][0]                
__________________________________________________________________________________________________
concatenate_199 (Concatenate)   (None, 745)          0           flatten_585[0][0]                
                                                                 flatten_586[0][0]                
                                                                 flatten_587[0][0]                
__________________________________________________________________________________________________
concatenate_200 (Concatenate)   (None, 745)          0           flatten_588[0][0]                
                                                                 flatten_589[0][0]                
                                                                 flatten_590[0][0]                
__________________________________________________________________________________________________
concatenate_201 (Concatenate)   (None, 745)          0           flatten_591[0][0]                
                                                                 flatten_592[0][0]                
                                                                 flatten_593[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 27)           20142       concatenate_197[0][0]            
                                                                 concatenate_198[0][0]            
                                                                 concatenate_199[0][0]            
                                                                 concatenate_200[0][0]            
                                                                 concatenate_201[0][0]            
__________________________________________________________________________________________________
concatenate_202 (Concatenate)   (None, 135)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 44)           5984        concatenate_202[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            180         idenDense[0][0]                  
==================================================================================================
Total params: 619,900
Trainable params: 619,900
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.4628 - acc: 0.8911
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1737 - acc: 0.9626
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1321 - acc: 0.9707
MWE identification:
Epoch 1/1
 - 50s - loss: 0.0812 - acc: 0.9792
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1261 - acc: 0.9715
MWE identification:
Epoch 1/1
 - 50s - loss: 0.0603 - acc: 0.9849
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1051 - acc: 0.9750
MWE identification:
Epoch 1/1
 - 51s - loss: 0.0558 - acc: 0.9862
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0931 - acc: 0.9774
MWE identification:
Epoch 1/1
 - 50s - loss: 0.0534 - acc: 0.9869
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0844 - acc: 0.9794
MWE identification:
Epoch 1/1
 - 50s - loss: 0.0518 - acc: 0.9875
POS tagging accuracy = 94.7
Loss = 0.198, 
POS tagging accuracy = 94.7
Loss = 0.198, 
	TRAINING TIME: 6.07 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.602
	P, R  : 0.743, 0.506

==================================================================================================
	XP Ends: 23/4 (19 h:35)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,29             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,8              ,16             ,4              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.032          ,10             ,27             ,146            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
27             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 29, 8, 8, 16, 4, 14, 0.032, 10, 27, 146, True, 27, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (19h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 27)        203715      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_594 (Flatten)           (None, 189)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_595 (Flatten)           (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_596 (Flatten)           (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_597 (Flatten)           (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_203 (Concatenate)   (None, 319)          0           flatten_594[0][0]                
                                                                 flatten_595[0][0]                
                                                                 flatten_596[0][0]                
                                                                 flatten_597[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 146)          46720       concatenate_203[0][0]            
__________________________________________________________________________________________________
dense_32 (Dense)                (None, 152)          22344       posDense[0][0]                   
==================================================================================================
Total params: 282,499
Trainable params: 282,499
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 27)        203715      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_598 (Flatten)           (None, 189)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_599 (Flatten)           (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_600 (Flatten)           (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_601 (Flatten)           (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_602 (Flatten)           (None, 189)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_603 (Flatten)           (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_604 (Flatten)           (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_605 (Flatten)           (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_606 (Flatten)           (None, 189)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_607 (Flatten)           (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_608 (Flatten)           (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_609 (Flatten)           (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_610 (Flatten)           (None, 189)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_611 (Flatten)           (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_612 (Flatten)           (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_613 (Flatten)           (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_614 (Flatten)           (None, 189)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_615 (Flatten)           (None, 96)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_616 (Flatten)           (None, 24)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_617 (Flatten)           (None, 10)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_204 (Concatenate)   (None, 319)          0           flatten_598[0][0]                
                                                                 flatten_599[0][0]                
                                                                 flatten_600[0][0]                
                                                                 flatten_601[0][0]                
__________________________________________________________________________________________________
concatenate_205 (Concatenate)   (None, 319)          0           flatten_602[0][0]                
                                                                 flatten_603[0][0]                
                                                                 flatten_604[0][0]                
                                                                 flatten_605[0][0]                
__________________________________________________________________________________________________
concatenate_206 (Concatenate)   (None, 319)          0           flatten_606[0][0]                
                                                                 flatten_607[0][0]                
                                                                 flatten_608[0][0]                
                                                                 flatten_609[0][0]                
__________________________________________________________________________________________________
concatenate_207 (Concatenate)   (None, 319)          0           flatten_610[0][0]                
                                                                 flatten_611[0][0]                
                                                                 flatten_612[0][0]                
                                                                 flatten_613[0][0]                
__________________________________________________________________________________________________
concatenate_208 (Concatenate)   (None, 319)          0           flatten_614[0][0]                
                                                                 flatten_615[0][0]                
                                                                 flatten_616[0][0]                
                                                                 flatten_617[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 146)          46720       concatenate_204[0][0]            
                                                                 concatenate_205[0][0]            
                                                                 concatenate_206[0][0]            
                                                                 concatenate_207[0][0]            
                                                                 concatenate_208[0][0]            
__________________________________________________________________________________________________
concatenate_209 (Concatenate)   (None, 730)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 29)           21199       concatenate_209[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            120         idenDense[0][0]                  
==================================================================================================
Total params: 281,474
Trainable params: 281,474
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2105 - acc: 0.9477
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0789 - acc: 0.9789
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0501 - acc: 0.9866
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0347 - acc: 0.9910
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0251 - acc: 0.9937
MWE identification:
Epoch 1/1
 - 63s - loss: 0.0657 - acc: 0.9835
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0543 - acc: 0.9852
MWE identification:
Epoch 1/1
 - 63s - loss: 0.0508 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0298 - acc: 0.9928
MWE identification:
Epoch 1/1
 - 64s - loss: 0.0475 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0208 - acc: 0.9954
MWE identification:
Epoch 1/1
 - 64s - loss: 0.0460 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0154 - acc: 0.9967
MWE identification:
Epoch 1/1
 - 63s - loss: 0.0453 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0120 - acc: 0.9976
MWE identification:
Epoch 1/1
 - 63s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0095 - acc: 0.9982
MWE identification:
Epoch 1/1
 - 63s - loss: 0.0445 - acc: 0.9895
POS tagging accuracy = 94.9
Loss = 0.245, 
POS tagging accuracy = 94.9
Loss = 0.245, 
	TRAINING TIME: 9.53 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.589
	P, R  : 0.732, 0.493

==================================================================================================
	XP Ends: 23/4 (19 h:46)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,108            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,3              ,31             ,3              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.1            ,10             ,8              ,108            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
152            ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 108, 8, 3, 31, 3, 17, 0.1, 10, 8, 108, True, 152, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (19h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.1
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 152)       1738576     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_618 (Flatten)           (None, 1064)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_619 (Flatten)           (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_620 (Flatten)           (None, 9)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_621 (Flatten)           (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_210 (Concatenate)   (None, 1179)         0           flatten_618[0][0]                
                                                                 flatten_619[0][0]                
                                                                 flatten_620[0][0]                
                                                                 flatten_621[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 108)          127440      concatenate_210[0][0]            
__________________________________________________________________________________________________
dense_33 (Dense)                (None, 152)          16568       posDense[0][0]                   
==================================================================================================
Total params: 1,892,284
Trainable params: 1,892,284
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.1
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 152)       1738576     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_622 (Flatten)           (None, 1064)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_623 (Flatten)           (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_624 (Flatten)           (None, 9)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_625 (Flatten)           (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_626 (Flatten)           (None, 1064)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_627 (Flatten)           (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_628 (Flatten)           (None, 9)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_629 (Flatten)           (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_630 (Flatten)           (None, 1064)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_631 (Flatten)           (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_632 (Flatten)           (None, 9)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_633 (Flatten)           (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_634 (Flatten)           (None, 1064)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_635 (Flatten)           (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_636 (Flatten)           (None, 9)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_637 (Flatten)           (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_211 (Concatenate)   (None, 1179)         0           flatten_622[0][0]                
                                                                 flatten_623[0][0]                
                                                                 flatten_624[0][0]                
                                                                 flatten_625[0][0]                
__________________________________________________________________________________________________
concatenate_212 (Concatenate)   (None, 1179)         0           flatten_626[0][0]                
                                                                 flatten_627[0][0]                
                                                                 flatten_628[0][0]                
                                                                 flatten_629[0][0]                
__________________________________________________________________________________________________
concatenate_213 (Concatenate)   (None, 1179)         0           flatten_630[0][0]                
                                                                 flatten_631[0][0]                
                                                                 flatten_632[0][0]                
                                                                 flatten_633[0][0]                
__________________________________________________________________________________________________
concatenate_214 (Concatenate)   (None, 1179)         0           flatten_634[0][0]                
                                                                 flatten_635[0][0]                
                                                                 flatten_636[0][0]                
                                                                 flatten_637[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 108)          127440      concatenate_211[0][0]            
                                                                 concatenate_212[0][0]            
                                                                 concatenate_213[0][0]            
                                                                 concatenate_214[0][0]            
__________________________________________________________________________________________________
concatenate_215 (Concatenate)   (None, 432)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 108)          46764       concatenate_215[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            436         idenDense[0][0]                  
==================================================================================================
Total params: 1,922,916
Trainable params: 1,922,916
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 17s - loss: 0.2932 - acc: 0.9290
POS tagging:
Epoch 1/1
 - 17s - loss: 0.1045 - acc: 0.9741
POS tagging:
Epoch 1/1
 - 17s - loss: 0.0650 - acc: 0.9837
POS tagging:
Epoch 1/1
 - 17s - loss: 0.0472 - acc: 0.9883
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0877 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 17s - loss: 0.0569 - acc: 0.9860
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 17s - loss: 0.0360 - acc: 0.9924
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 18s - loss: 0.0300 - acc: 0.9940
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 17s - loss: 0.0268 - acc: 0.9950
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 17s - loss: 0.0247 - acc: 0.9957
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 17s - loss: 0.0228 - acc: 0.9961
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 17s - loss: 0.0220 - acc: 0.9963
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 18s - loss: 0.0208 - acc: 0.9966
POS tagging accuracy = 93.6
Loss = 0.352, 
POS tagging accuracy = 93.6
Loss = 0.352, 
	TRAINING TIME: 8.97 minutes 
==================================================================================================
	PARSING TIME: 2.15 minutes 
==================================================================================================
	Identification : 0.009
	P, R  : 0.005, 0.073

==================================================================================================
	XP Ends: 23/4 (19 h:57)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,55             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
17             ,9              ,15             ,3              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.136          ,6              ,13             ,46             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
179            ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 55, 17, 9, 15, 3, 18, 0.136, 6, 13, 46, True, 179, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (19h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.136
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 179)       1350555     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_638 (Flatten)           (None, 1253)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_639 (Flatten)           (None, 204)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_640 (Flatten)           (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_216 (Concatenate)   (None, 1463)         0           flatten_638[0][0]                
                                                                 flatten_639[0][0]                
                                                                 flatten_640[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 46)           67344       concatenate_216[0][0]            
__________________________________________________________________________________________________
dense_34 (Dense)                (None, 152)          7144        posDense[0][0]                   
==================================================================================================
Total params: 1,445,325
Trainable params: 1,445,325
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.136
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 179)       1350555     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_641 (Flatten)           (None, 1253)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_642 (Flatten)           (None, 204)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_643 (Flatten)           (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_644 (Flatten)           (None, 1253)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_645 (Flatten)           (None, 204)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_646 (Flatten)           (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_647 (Flatten)           (None, 1253)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_648 (Flatten)           (None, 204)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_649 (Flatten)           (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_650 (Flatten)           (None, 1253)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_651 (Flatten)           (None, 204)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_652 (Flatten)           (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_653 (Flatten)           (None, 1253)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_654 (Flatten)           (None, 204)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_655 (Flatten)           (None, 6)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_217 (Concatenate)   (None, 1463)         0           flatten_641[0][0]                
                                                                 flatten_642[0][0]                
                                                                 flatten_643[0][0]                
__________________________________________________________________________________________________
concatenate_218 (Concatenate)   (None, 1463)         0           flatten_644[0][0]                
                                                                 flatten_645[0][0]                
                                                                 flatten_646[0][0]                
__________________________________________________________________________________________________
concatenate_219 (Concatenate)   (None, 1463)         0           flatten_647[0][0]                
                                                                 flatten_648[0][0]                
                                                                 flatten_649[0][0]                
__________________________________________________________________________________________________
concatenate_220 (Concatenate)   (None, 1463)         0           flatten_650[0][0]                
                                                                 flatten_651[0][0]                
                                                                 flatten_652[0][0]                
__________________________________________________________________________________________________
concatenate_221 (Concatenate)   (None, 1463)         0           flatten_653[0][0]                
                                                                 flatten_654[0][0]                
                                                                 flatten_655[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 46)           67344       concatenate_217[0][0]            
                                                                 concatenate_218[0][0]            
                                                                 concatenate_219[0][0]            
                                                                 concatenate_220[0][0]            
                                                                 concatenate_221[0][0]            
__________________________________________________________________________________________________
concatenate_222 (Concatenate)   (None, 230)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 55)           12705       concatenate_222[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            224         idenDense[0][0]                  
==================================================================================================
Total params: 1,451,110
Trainable params: 1,451,110
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.3621 - acc: 0.9164
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1311 - acc: 0.9709
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0918 - acc: 0.9791
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0745 - acc: 0.9833
MWE identification:
Epoch 1/1
 - 64s - loss: 8.1729 - acc: 0.4928
POS tagging:
Epoch 1/1
 - 9s - loss: 0.2842 - acc: 0.9567
MWE identification:
Epoch 1/1
 - 63s - loss: 8.1173 - acc: 0.4963
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0931 - acc: 0.9795
MWE identification:
Epoch 1/1
 - 63s - loss: 8.0980 - acc: 0.4975
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0723 - acc: 0.9844
MWE identification:
Epoch 1/1
 - 64s - loss: 8.0909 - acc: 0.4980
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0632 - acc: 0.9869
MWE identification:
Epoch 1/1
 - 63s - loss: 8.0870 - acc: 0.4982
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0568 - acc: 0.9883
MWE identification:
Epoch 1/1
 - 64s - loss: 5.6001 - acc: 0.6520
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0708 - acc: 0.9848
MWE identification:
Epoch 1/1
 - 63s - loss: 4.3643 - acc: 0.7287
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0652 - acc: 0.9866
MWE identification:
Epoch 1/1
 - 63s - loss: 4.3313 - acc: 0.7308
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0566 - acc: 0.9888
MWE identification:
Epoch 1/1
 - 64s - loss: 4.3208 - acc: 0.7315
POS tagging accuracy = 93.8
Loss = 0.423, 
POS tagging accuracy = 93.8
Loss = 0.423, 
	TRAINING TIME: 12.53 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (20 h:11)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,44             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,2              ,31             ,1              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.023          ,6              ,17             ,36             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
125            ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 44, 13, 2, 31, 1, 10, 0.023, 6, 17, 36, True, 125, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (20h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 125)       943125      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_656 (Flatten)           (None, 875)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_657 (Flatten)           (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_658 (Flatten)           (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_659 (Flatten)           (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_223 (Concatenate)   (None, 1043)         0           flatten_656[0][0]                
                                                                 flatten_657[0][0]                
                                                                 flatten_658[0][0]                
                                                                 flatten_659[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           37584       concatenate_223[0][0]            
__________________________________________________________________________________________________
dense_35 (Dense)                (None, 152)          5624        posDense[0][0]                   
==================================================================================================
Total params: 1,001,879
Trainable params: 1,001,879
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 125)       943125      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_660 (Flatten)           (None, 875)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_661 (Flatten)           (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_662 (Flatten)           (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_663 (Flatten)           (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_664 (Flatten)           (None, 875)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_665 (Flatten)           (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_666 (Flatten)           (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_667 (Flatten)           (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_668 (Flatten)           (None, 875)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_669 (Flatten)           (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_670 (Flatten)           (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_671 (Flatten)           (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_672 (Flatten)           (None, 875)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_673 (Flatten)           (None, 156)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_674 (Flatten)           (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_675 (Flatten)           (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_224 (Concatenate)   (None, 1043)         0           flatten_660[0][0]                
                                                                 flatten_661[0][0]                
                                                                 flatten_662[0][0]                
                                                                 flatten_663[0][0]                
__________________________________________________________________________________________________
concatenate_225 (Concatenate)   (None, 1043)         0           flatten_664[0][0]                
                                                                 flatten_665[0][0]                
                                                                 flatten_666[0][0]                
                                                                 flatten_667[0][0]                
__________________________________________________________________________________________________
concatenate_226 (Concatenate)   (None, 1043)         0           flatten_668[0][0]                
                                                                 flatten_669[0][0]                
                                                                 flatten_670[0][0]                
                                                                 flatten_671[0][0]                
__________________________________________________________________________________________________
concatenate_227 (Concatenate)   (None, 1043)         0           flatten_672[0][0]                
                                                                 flatten_673[0][0]                
                                                                 flatten_674[0][0]                
                                                                 flatten_675[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           37584       concatenate_224[0][0]            
                                                                 concatenate_225[0][0]            
                                                                 concatenate_226[0][0]            
                                                                 concatenate_227[0][0]            
__________________________________________________________________________________________________
concatenate_228 (Concatenate)   (None, 144)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 44)           6380        concatenate_228[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            180         idenDense[0][0]                  
==================================================================================================
Total params: 1,002,815
Trainable params: 1,002,815
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 7s - loss: 0.2320 - acc: 0.9452
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0873 - acc: 0.9781
MWE identification:
Epoch 1/1
 - 31s - loss: 0.0661 - acc: 0.9833
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0848 - acc: 0.9781
MWE identification:
Epoch 1/1
 - 31s - loss: 0.0510 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0565 - acc: 0.9859
MWE identification:
Epoch 1/1
 - 31s - loss: 0.0479 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0428 - acc: 0.9902
MWE identification:
Epoch 1/1
 - 31s - loss: 0.0464 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0339 - acc: 0.9925
MWE identification:
Epoch 1/1
 - 31s - loss: 0.0455 - acc: 0.9892
POS tagging accuracy = 94.7
Loss = 0.219, 
POS tagging accuracy = 94.7
Loss = 0.219, 
	TRAINING TIME: 4.37 minutes 
==================================================================================================
	PARSING TIME: 1.05 minutes 
==================================================================================================
	Identification : 0.605
	P, R  : 0.787, 0.491

==================================================================================================
	XP Ends: 23/4 (20 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,26             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,7              ,18             ,4              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.152          ,5              ,21             ,36             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
85             ,False          ,True           ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 26, 13, 7, 18, 4, 13, 0.152, 5, 21, 36, True, 85, False, True, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (20h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.152
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 85)        972230      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
flatten_676 (Flatten)           (None, 595)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_677 (Flatten)           (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_229 (Concatenate)   (None, 751)          0           flatten_676[0][0]                
                                                                 flatten_677[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           27072       concatenate_229[0][0]            
__________________________________________________________________________________________________
dense_36 (Dense)                (None, 152)          5624        posDense[0][0]                   
==================================================================================================
Total params: 1,020,344
Trainable params: 1,020,344
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.152
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 85)        972230      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_678 (Flatten)           (None, 595)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_679 (Flatten)           (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_680 (Flatten)           (None, 595)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_681 (Flatten)           (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_682 (Flatten)           (None, 595)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_683 (Flatten)           (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_684 (Flatten)           (None, 595)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_685 (Flatten)           (None, 156)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
concatenate_230 (Concatenate)   (None, 751)          0           flatten_678[0][0]                
                                                                 flatten_679[0][0]                
__________________________________________________________________________________________________
concatenate_231 (Concatenate)   (None, 751)          0           flatten_680[0][0]                
                                                                 flatten_681[0][0]                
__________________________________________________________________________________________________
concatenate_232 (Concatenate)   (None, 751)          0           flatten_682[0][0]                
                                                                 flatten_683[0][0]                
__________________________________________________________________________________________________
concatenate_233 (Concatenate)   (None, 751)          0           flatten_684[0][0]                
                                                                 flatten_685[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           27072       concatenate_230[0][0]            
                                                                 concatenate_231[0][0]            
                                                                 concatenate_232[0][0]            
                                                                 concatenate_233[0][0]            
__________________________________________________________________________________________________
concatenate_234 (Concatenate)   (None, 144)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 26)           3770        concatenate_234[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            108         idenDense[0][0]                  
==================================================================================================
Total params: 1,018,598
Trainable params: 1,018,598
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.3470 - acc: 0.9153
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1372 - acc: 0.9680
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0865 - acc: 0.9803
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0650 - acc: 0.9854
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0546 - acc: 0.9886
MWE identification:
Epoch 1/1
 - 38s - loss: 8.0603 - acc: 0.4999
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1039 - acc: 0.9758
MWE identification:
Epoch 1/1
 - 38s - loss: 8.0592 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0574 - acc: 0.9880
MWE identification:
Epoch 1/1
 - 39s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0448 - acc: 0.9913
MWE identification:
Epoch 1/1
 - 38s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0406 - acc: 0.9924
MWE identification:
Epoch 1/1
 - 38s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0381 - acc: 0.9931
MWE identification:
Epoch 1/1
 - 38s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0366 - acc: 0.9935
POS tagging accuracy = 93.1
Loss = 0.398, 
POS tagging accuracy = 93.1
Loss = 0.398, 
	TRAINING TIME: 5.53 minutes 
==================================================================================================
	PARSING TIME: 1.22 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (20 h:24)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,35             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
18             ,6              ,81             ,1              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.173          ,14             ,31             ,44             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
67             ,False          ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 35, 18, 6, 81, 1, 17, 0.173, 14, 31, 44, True, 67, False, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (20h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.173
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 67)        505515      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_686 (Flatten)           (None, 469)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_687 (Flatten)           (None, 216)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_688 (Flatten)           (None, 18)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_235 (Concatenate)   (None, 703)          0           flatten_686[0][0]                
                                                                 flatten_687[0][0]                
                                                                 flatten_688[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 44)           30976       concatenate_235[0][0]            
__________________________________________________________________________________________________
dense_37 (Dense)                (None, 152)          6840        posDense[0][0]                   
==================================================================================================
Total params: 564,703
Trainable params: 564,703
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.173
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 67)        505515      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_689 (Flatten)           (None, 469)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_690 (Flatten)           (None, 216)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_691 (Flatten)           (None, 18)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_692 (Flatten)           (None, 469)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_693 (Flatten)           (None, 216)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_694 (Flatten)           (None, 18)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_695 (Flatten)           (None, 469)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_696 (Flatten)           (None, 216)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_697 (Flatten)           (None, 18)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_698 (Flatten)           (None, 469)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_699 (Flatten)           (None, 216)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_700 (Flatten)           (None, 18)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_236 (Concatenate)   (None, 703)          0           flatten_689[0][0]                
                                                                 flatten_690[0][0]                
                                                                 flatten_691[0][0]                
__________________________________________________________________________________________________
concatenate_237 (Concatenate)   (None, 703)          0           flatten_692[0][0]                
                                                                 flatten_693[0][0]                
                                                                 flatten_694[0][0]                
__________________________________________________________________________________________________
concatenate_238 (Concatenate)   (None, 703)          0           flatten_695[0][0]                
                                                                 flatten_696[0][0]                
                                                                 flatten_697[0][0]                
__________________________________________________________________________________________________
concatenate_239 (Concatenate)   (None, 703)          0           flatten_698[0][0]                
                                                                 flatten_699[0][0]                
                                                                 flatten_700[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 44)           30976       concatenate_236[0][0]            
                                                                 concatenate_237[0][0]            
                                                                 concatenate_238[0][0]            
                                                                 concatenate_239[0][0]            
__________________________________________________________________________________________________
concatenate_240 (Concatenate)   (None, 176)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 35)           6195        concatenate_240[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            144         idenDense[0][0]                  
==================================================================================================
Total params: 564,202
Trainable params: 564,202
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.3288 - acc: 0.9239
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1285 - acc: 0.9710
MWE identification:
Epoch 1/1
 - 10s - loss: 8.0614 - acc: 0.4997
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1548 - acc: 0.9637
MWE identification:
Epoch 1/1
 - 10s - loss: 8.0592 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0832 - acc: 0.9800
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0584 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0892 - acc: 0.9786
MWE identification:
Epoch 1/1
 - 10s - loss: 4.3445 - acc: 0.7303
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0920 - acc: 0.9772
MWE identification:
Epoch 1/1
 - 10s - loss: 4.2996 - acc: 0.7332
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0638 - acc: 0.9847
MWE identification:
Epoch 1/1
 - 10s - loss: 4.2965 - acc: 0.7334
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0578 - acc: 0.9861
MWE identification:
Epoch 1/1
 - 10s - loss: 4.2936 - acc: 0.7335
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0582 - acc: 0.9855
MWE identification:
Epoch 1/1
 - 11s - loss: 4.2647 - acc: 0.7351
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0646 - acc: 0.9841
POS tagging accuracy = 94.6
Loss = 0.306, 
POS tagging accuracy = 94.6
Loss = 0.306, 
	TRAINING TIME: 3.0 minutes 
==================================================================================================
	PARSING TIME: 0.88 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (20 h:28)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,42             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
10             ,1              ,124            ,1              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.014          ,9              ,111            ,180            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
126            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 42, 10, 1, 124, 1, 15, 0.014, 9, 111, 180, True, 126, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (20h:28)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 126)       950670      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_701 (Flatten)           (None, 882)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_702 (Flatten)           (None, 120)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_703 (Flatten)           (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_704 (Flatten)           (None, 9)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_241 (Concatenate)   (None, 1014)         0           flatten_701[0][0]                
                                                                 flatten_702[0][0]                
                                                                 flatten_703[0][0]                
                                                                 flatten_704[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 180)          182700      concatenate_241[0][0]            
__________________________________________________________________________________________________
dense_38 (Dense)                (None, 152)          27512       posDense[0][0]                   
==================================================================================================
Total params: 1,172,926
Trainable params: 1,172,926
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 126)       950670      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_705 (Flatten)           (None, 882)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_706 (Flatten)           (None, 120)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_707 (Flatten)           (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_708 (Flatten)           (None, 9)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_709 (Flatten)           (None, 882)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_710 (Flatten)           (None, 120)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_711 (Flatten)           (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_712 (Flatten)           (None, 9)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_713 (Flatten)           (None, 882)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_714 (Flatten)           (None, 120)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_715 (Flatten)           (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_716 (Flatten)           (None, 9)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_717 (Flatten)           (None, 882)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_718 (Flatten)           (None, 120)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_719 (Flatten)           (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_720 (Flatten)           (None, 9)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_721 (Flatten)           (None, 882)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_722 (Flatten)           (None, 120)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_723 (Flatten)           (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_724 (Flatten)           (None, 9)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_242 (Concatenate)   (None, 1014)         0           flatten_705[0][0]                
                                                                 flatten_706[0][0]                
                                                                 flatten_707[0][0]                
                                                                 flatten_708[0][0]                
__________________________________________________________________________________________________
concatenate_243 (Concatenate)   (None, 1014)         0           flatten_709[0][0]                
                                                                 flatten_710[0][0]                
                                                                 flatten_711[0][0]                
                                                                 flatten_712[0][0]                
__________________________________________________________________________________________________
concatenate_244 (Concatenate)   (None, 1014)         0           flatten_713[0][0]                
                                                                 flatten_714[0][0]                
                                                                 flatten_715[0][0]                
                                                                 flatten_716[0][0]                
__________________________________________________________________________________________________
concatenate_245 (Concatenate)   (None, 1014)         0           flatten_717[0][0]                
                                                                 flatten_718[0][0]                
                                                                 flatten_719[0][0]                
                                                                 flatten_720[0][0]                
__________________________________________________________________________________________________
concatenate_246 (Concatenate)   (None, 1014)         0           flatten_721[0][0]                
                                                                 flatten_722[0][0]                
                                                                 flatten_723[0][0]                
                                                                 flatten_724[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 180)          182700      concatenate_242[0][0]            
                                                                 concatenate_243[0][0]            
                                                                 concatenate_244[0][0]            
                                                                 concatenate_245[0][0]            
                                                                 concatenate_246[0][0]            
__________________________________________________________________________________________________
concatenate_247 (Concatenate)   (None, 900)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 42)           37842       concatenate_247[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            172         idenDense[0][0]                  
==================================================================================================
Total params: 1,183,428
Trainable params: 1,183,428
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2557 - acc: 0.9395
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0870 - acc: 0.9780
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0719 - acc: 0.9820
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0762 - acc: 0.9801
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0516 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0508 - acc: 0.9876
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0484 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0382 - acc: 0.9911
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0469 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0301 - acc: 0.9930
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0461 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0245 - acc: 0.9949
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0455 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0201 - acc: 0.9958
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0452 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0170 - acc: 0.9965
POS tagging accuracy = 94.6
Loss = 0.221, 
POS tagging accuracy = 94.6
Loss = 0.221, 
	TRAINING TIME: 3.07 minutes 
==================================================================================================
	PARSING TIME: 1.27 minutes 
==================================================================================================
	Identification : 0.581
	P, R  : 0.767, 0.467

==================================================================================================
	XP Ends: 23/4 (20 h:33)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,51             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,3              ,99             ,3              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.022          ,13             ,20             ,172            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
186            ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 51, 6, 3, 99, 3, 10, 0.022, 13, 20, 172, True, 186, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (20h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 186)       2127468     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_725 (Flatten)           (None, 1302)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_726 (Flatten)           (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_727 (Flatten)           (None, 9)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_728 (Flatten)           (None, 13)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_248 (Concatenate)   (None, 1396)         0           flatten_725[0][0]                
                                                                 flatten_726[0][0]                
                                                                 flatten_727[0][0]                
                                                                 flatten_728[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 172)          240284      concatenate_248[0][0]            
__________________________________________________________________________________________________
dense_39 (Dense)                (None, 152)          26296       posDense[0][0]                   
==================================================================================================
Total params: 2,401,436
Trainable params: 2,401,436
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 186)       2127468     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_729 (Flatten)           (None, 1302)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_730 (Flatten)           (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_731 (Flatten)           (None, 9)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_732 (Flatten)           (None, 13)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_733 (Flatten)           (None, 1302)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_734 (Flatten)           (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_735 (Flatten)           (None, 9)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_736 (Flatten)           (None, 13)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_737 (Flatten)           (None, 1302)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_738 (Flatten)           (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_739 (Flatten)           (None, 9)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_740 (Flatten)           (None, 13)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_741 (Flatten)           (None, 1302)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_742 (Flatten)           (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_743 (Flatten)           (None, 9)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_744 (Flatten)           (None, 13)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_249 (Concatenate)   (None, 1396)         0           flatten_729[0][0]                
                                                                 flatten_730[0][0]                
                                                                 flatten_731[0][0]                
                                                                 flatten_732[0][0]                
__________________________________________________________________________________________________
concatenate_250 (Concatenate)   (None, 1396)         0           flatten_733[0][0]                
                                                                 flatten_734[0][0]                
                                                                 flatten_735[0][0]                
                                                                 flatten_736[0][0]                
__________________________________________________________________________________________________
concatenate_251 (Concatenate)   (None, 1396)         0           flatten_737[0][0]                
                                                                 flatten_738[0][0]                
                                                                 flatten_739[0][0]                
                                                                 flatten_740[0][0]                
__________________________________________________________________________________________________
concatenate_252 (Concatenate)   (None, 1396)         0           flatten_741[0][0]                
                                                                 flatten_742[0][0]                
                                                                 flatten_743[0][0]                
                                                                 flatten_744[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 172)          240284      concatenate_249[0][0]            
                                                                 concatenate_250[0][0]            
                                                                 concatenate_251[0][0]            
                                                                 concatenate_252[0][0]            
__________________________________________________________________________________________________
concatenate_253 (Concatenate)   (None, 688)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 51)           35139       concatenate_253[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            208         idenDense[0][0]                  
==================================================================================================
Total params: 2,410,487
Trainable params: 2,410,487
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 7s - loss: 0.2372 - acc: 0.9389
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0914 - acc: 0.9760
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0536 - acc: 0.9861
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0352 - acc: 0.9912
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0678 - acc: 0.9834
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0559 - acc: 0.9851
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0475 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0281 - acc: 0.9933
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0452 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0193 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0446 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0145 - acc: 0.9967
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0444 - acc: 0.9895
POS tagging accuracy = 93.7
Loss = 0.27, 
POS tagging accuracy = 93.7
Loss = 0.27, 
	TRAINING TIME: 3.17 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.536
	P, R  : 0.533, 0.539

==================================================================================================
	XP Ends: 23/4 (20 h:37)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,76             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
19             ,1              ,17             ,1              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.063          ,5              ,51             ,32             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
180            ,False          ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 76, 19, 1, 17, 1, 18, 0.063, 5, 51, 32, True, 180, False, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (20h:37)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 180)       2058840     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 19)       22534       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_745 (Flatten)           (None, 1260)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_746 (Flatten)           (None, 228)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_747 (Flatten)           (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_254 (Concatenate)   (None, 1491)         0           flatten_745[0][0]                
                                                                 flatten_746[0][0]                
                                                                 flatten_747[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 32)           47744       concatenate_254[0][0]            
__________________________________________________________________________________________________
dense_40 (Dense)                (None, 152)          5016        posDense[0][0]                   
==================================================================================================
Total params: 2,134,138
Trainable params: 2,134,138
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.063
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 180)       2058840     b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 19)       22534       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_748 (Flatten)           (None, 1260)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_749 (Flatten)           (None, 228)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_750 (Flatten)           (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_751 (Flatten)           (None, 1260)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_752 (Flatten)           (None, 228)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_753 (Flatten)           (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_754 (Flatten)           (None, 1260)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_755 (Flatten)           (None, 228)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_756 (Flatten)           (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
concatenate_255 (Concatenate)   (None, 1491)         0           flatten_748[0][0]                
                                                                 flatten_749[0][0]                
                                                                 flatten_750[0][0]                
__________________________________________________________________________________________________
concatenate_256 (Concatenate)   (None, 1491)         0           flatten_751[0][0]                
                                                                 flatten_752[0][0]                
                                                                 flatten_753[0][0]                
__________________________________________________________________________________________________
concatenate_257 (Concatenate)   (None, 1491)         0           flatten_754[0][0]                
                                                                 flatten_755[0][0]                
                                                                 flatten_756[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 32)           47744       concatenate_255[0][0]            
                                                                 concatenate_256[0][0]            
                                                                 concatenate_257[0][0]            
__________________________________________________________________________________________________
concatenate_258 (Concatenate)   (None, 96)           0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 76)           7372        concatenate_258[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            308         idenDense[0][0]                  
==================================================================================================
Total params: 2,136,802
Trainable params: 2,136,802
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2445 - acc: 0.9383
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0827 - acc: 0.9780
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0683 - acc: 0.9826
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1019 - acc: 0.9728
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0502 - acc: 0.9878
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0481 - acc: 0.9874
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0458 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0300 - acc: 0.9923
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0218 - acc: 0.9947
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0171 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0142 - acc: 0.9968
MWE identification:
Epoch 1/1
 - 48s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0122 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0442 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0106 - acc: 0.9977
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0442 - acc: 0.9895
POS tagging accuracy = 93.5
Loss = 0.322, 
POS tagging accuracy = 93.5
Loss = 0.322, 
	TRAINING TIME: 8.22 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.528
	P, R  : 0.507, 0.551

==================================================================================================
	XP Ends: 23/4 (20 h:46)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,33             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
19             ,5              ,57             ,3              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.012          ,13             ,34             ,195            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
132            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 33, 19, 5, 57, 3, 11, 0.012, 13, 34, 195, True, 132, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (20h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 132)       995940      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 19)       22534       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_757 (Flatten)           (None, 924)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_758 (Flatten)           (None, 228)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_759 (Flatten)           (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_760 (Flatten)           (None, 13)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_259 (Concatenate)   (None, 1180)         0           flatten_757[0][0]                
                                                                 flatten_758[0][0]                
                                                                 flatten_759[0][0]                
                                                                 flatten_760[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 195)          230295      concatenate_259[0][0]            
__________________________________________________________________________________________________
dense_41 (Dense)                (None, 152)          29792       posDense[0][0]                   
==================================================================================================
Total params: 1,278,841
Trainable params: 1,278,841
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 132)       995940      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 19)       22534       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_761 (Flatten)           (None, 924)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_762 (Flatten)           (None, 228)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_763 (Flatten)           (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_764 (Flatten)           (None, 13)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_765 (Flatten)           (None, 924)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_766 (Flatten)           (None, 228)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_767 (Flatten)           (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_768 (Flatten)           (None, 13)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_769 (Flatten)           (None, 924)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_770 (Flatten)           (None, 228)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_771 (Flatten)           (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_772 (Flatten)           (None, 13)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_773 (Flatten)           (None, 924)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_774 (Flatten)           (None, 228)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_775 (Flatten)           (None, 15)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_776 (Flatten)           (None, 13)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_777 (Flatten)           (None, 924)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_778 (Flatten)           (None, 228)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_779 (Flatten)           (None, 15)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_780 (Flatten)           (None, 13)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_260 (Concatenate)   (None, 1180)         0           flatten_761[0][0]                
                                                                 flatten_762[0][0]                
                                                                 flatten_763[0][0]                
                                                                 flatten_764[0][0]                
__________________________________________________________________________________________________
concatenate_261 (Concatenate)   (None, 1180)         0           flatten_765[0][0]                
                                                                 flatten_766[0][0]                
                                                                 flatten_767[0][0]                
                                                                 flatten_768[0][0]                
__________________________________________________________________________________________________
concatenate_262 (Concatenate)   (None, 1180)         0           flatten_769[0][0]                
                                                                 flatten_770[0][0]                
                                                                 flatten_771[0][0]                
                                                                 flatten_772[0][0]                
__________________________________________________________________________________________________
concatenate_263 (Concatenate)   (None, 1180)         0           flatten_773[0][0]                
                                                                 flatten_774[0][0]                
                                                                 flatten_775[0][0]                
                                                                 flatten_776[0][0]                
__________________________________________________________________________________________________
concatenate_264 (Concatenate)   (None, 1180)         0           flatten_777[0][0]                
                                                                 flatten_778[0][0]                
                                                                 flatten_779[0][0]                
                                                                 flatten_780[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 195)          230295      concatenate_260[0][0]            
                                                                 concatenate_261[0][0]            
                                                                 concatenate_262[0][0]            
                                                                 concatenate_263[0][0]            
                                                                 concatenate_264[0][0]            
__________________________________________________________________________________________________
concatenate_265 (Concatenate)   (None, 975)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 33)           32208       concatenate_265[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            136         idenDense[0][0]                  
==================================================================================================
Total params: 1,281,393
Trainable params: 1,281,393
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2285 - acc: 0.9452
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0876 - acc: 0.9778
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0587 - acc: 0.9854
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0427 - acc: 0.9896
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0686 - acc: 0.9830
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0523 - acc: 0.9869
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0510 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0350 - acc: 0.9919
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0480 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0269 - acc: 0.9940
MWE identification:
Epoch 1/1
 - 21s - loss: 0.0466 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0218 - acc: 0.9953
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0458 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0180 - acc: 0.9963
POS tagging accuracy = 95.2
Loss = 0.221, 
POS tagging accuracy = 95.2
Loss = 0.221, 
	TRAINING TIME: 3.62 minutes 
==================================================================================================
	PARSING TIME: 1.28 minutes 
==================================================================================================
	Identification : 0.58
	P, R  : 0.831, 0.446

==================================================================================================
	XP Ends: 23/4 (20 h:51)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,178            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
14             ,1              ,103            ,1              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.055          ,10             ,31             ,129            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
174            ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 178, 14, 1, 103, 1, 15, 0.055, 10, 31, 129, True, 174, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (20h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 174)       1312830     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_781 (Flatten)           (None, 1218)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_782 (Flatten)           (None, 168)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_783 (Flatten)           (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_266 (Concatenate)   (None, 1396)         0           flatten_781[0][0]                
                                                                 flatten_782[0][0]                
                                                                 flatten_783[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 129)          180213      concatenate_266[0][0]            
__________________________________________________________________________________________________
dense_42 (Dense)                (None, 152)          19760       posDense[0][0]                   
==================================================================================================
Total params: 1,529,607
Trainable params: 1,529,607
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 174)       1312830     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_784 (Flatten)           (None, 1218)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_785 (Flatten)           (None, 168)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_786 (Flatten)           (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_787 (Flatten)           (None, 1218)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_788 (Flatten)           (None, 168)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_789 (Flatten)           (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_790 (Flatten)           (None, 1218)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_791 (Flatten)           (None, 168)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_792 (Flatten)           (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_793 (Flatten)           (None, 1218)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_794 (Flatten)           (None, 168)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_795 (Flatten)           (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_796 (Flatten)           (None, 1218)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_797 (Flatten)           (None, 168)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_798 (Flatten)           (None, 10)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_267 (Concatenate)   (None, 1396)         0           flatten_784[0][0]                
                                                                 flatten_785[0][0]                
                                                                 flatten_786[0][0]                
__________________________________________________________________________________________________
concatenate_268 (Concatenate)   (None, 1396)         0           flatten_787[0][0]                
                                                                 flatten_788[0][0]                
                                                                 flatten_789[0][0]                
__________________________________________________________________________________________________
concatenate_269 (Concatenate)   (None, 1396)         0           flatten_790[0][0]                
                                                                 flatten_791[0][0]                
                                                                 flatten_792[0][0]                
__________________________________________________________________________________________________
concatenate_270 (Concatenate)   (None, 1396)         0           flatten_793[0][0]                
                                                                 flatten_794[0][0]                
                                                                 flatten_795[0][0]                
__________________________________________________________________________________________________
concatenate_271 (Concatenate)   (None, 1396)         0           flatten_796[0][0]                
                                                                 flatten_797[0][0]                
                                                                 flatten_798[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 129)          180213      concatenate_267[0][0]            
                                                                 concatenate_268[0][0]            
                                                                 concatenate_269[0][0]            
                                                                 concatenate_270[0][0]            
                                                                 concatenate_271[0][0]            
__________________________________________________________________________________________________
concatenate_272 (Concatenate)   (None, 645)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 178)          114988      concatenate_272[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            716         idenDense[0][0]                  
==================================================================================================
Total params: 1,625,551
Trainable params: 1,625,551
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2026 - acc: 0.9504
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0534 - acc: 0.9849
MWE identification:
Epoch 1/1
 - 11s - loss: 12.0851 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0350 - acc: 0.9907
MWE identification:
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0174 - acc: 0.9958
MWE identification:
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0121 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0095 - acc: 0.9978
MWE identification:
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0079 - acc: 0.9982
MWE identification:
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0067 - acc: 0.9985
MWE identification:
Epoch 1/1
 - 11s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0061 - acc: 0.9987
POS tagging accuracy = 95.5
Loss = 0.258, 
POS tagging accuracy = 95.5
Loss = 0.258, 
	TRAINING TIME: 3.0 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (20 h:57)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,26             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
24             ,2              ,103            ,1              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.016          ,11             ,47             ,50             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
107            ,True           ,False          ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 26, 24, 2, 103, 1, 10, 0.016, 11, 47, 50, True, 107, True, False, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (20h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 107)       1223866     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 24)       28464       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 11)        220         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_799 (Flatten)           (None, 749)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_800 (Flatten)           (None, 288)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_801 (Flatten)           (None, 11)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_273 (Concatenate)   (None, 1048)         0           flatten_799[0][0]                
                                                                 flatten_800[0][0]                
                                                                 flatten_801[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 50)           52450       concatenate_273[0][0]            
__________________________________________________________________________________________________
dense_43 (Dense)                (None, 152)          7752        posDense[0][0]                   
==================================================================================================
Total params: 1,312,752
Trainable params: 1,312,752
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 107)       1223866     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 24)       28464       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 11)        220         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_802 (Flatten)           (None, 749)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_803 (Flatten)           (None, 288)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_804 (Flatten)           (None, 11)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_805 (Flatten)           (None, 749)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_806 (Flatten)           (None, 288)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_807 (Flatten)           (None, 11)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_808 (Flatten)           (None, 749)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_809 (Flatten)           (None, 288)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_810 (Flatten)           (None, 11)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_811 (Flatten)           (None, 749)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_812 (Flatten)           (None, 288)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_813 (Flatten)           (None, 11)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_274 (Concatenate)   (None, 1048)         0           flatten_802[0][0]                
                                                                 flatten_803[0][0]                
                                                                 flatten_804[0][0]                
__________________________________________________________________________________________________
concatenate_275 (Concatenate)   (None, 1048)         0           flatten_805[0][0]                
                                                                 flatten_806[0][0]                
                                                                 flatten_807[0][0]                
__________________________________________________________________________________________________
concatenate_276 (Concatenate)   (None, 1048)         0           flatten_808[0][0]                
                                                                 flatten_809[0][0]                
                                                                 flatten_810[0][0]                
__________________________________________________________________________________________________
concatenate_277 (Concatenate)   (None, 1048)         0           flatten_811[0][0]                
                                                                 flatten_812[0][0]                
                                                                 flatten_813[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 50)           52450       concatenate_274[0][0]            
                                                                 concatenate_275[0][0]            
                                                                 concatenate_276[0][0]            
                                                                 concatenate_277[0][0]            
__________________________________________________________________________________________________
concatenate_278 (Concatenate)   (None, 200)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 26)           5226        concatenate_278[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            108         idenDense[0][0]                  
==================================================================================================
Total params: 1,310,334
Trainable params: 1,310,334
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2981 - acc: 0.9276
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1425 - acc: 0.9653
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0793 - acc: 0.9799
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1203 - acc: 0.9709
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0533 - acc: 0.9872
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0892 - acc: 0.9788
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0489 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0717 - acc: 0.9830
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0470 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0596 - acc: 0.9859
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0460 - acc: 0.9893
POS tagging accuracy = 94.0
Loss = 0.217, 
POS tagging accuracy = 94.0
Loss = 0.217, 
	TRAINING TIME: 1.93 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.534
	P, R  : 0.519, 0.549

==================================================================================================
	XP Ends: 23/4 (21 h:0)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,29             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,2              ,47             ,4              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.011          ,6              ,16             ,158            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
99             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 29, 6, 2, 47, 4, 9, 0.011, 6, 16, 158, True, 99, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (21h:0)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 99)        1132362     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_814 (Flatten)           (None, 693)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_815 (Flatten)           (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_816 (Flatten)           (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_817 (Flatten)           (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_279 (Concatenate)   (None, 777)          0           flatten_814[0][0]                
                                                                 flatten_815[0][0]                
                                                                 flatten_816[0][0]                
                                                                 flatten_817[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 158)          122924      concatenate_279[0][0]            
__________________________________________________________________________________________________
dense_44 (Dense)                (None, 152)          24168       posDense[0][0]                   
==================================================================================================
Total params: 1,286,698
Trainable params: 1,286,698
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 99)        1132362     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_818 (Flatten)           (None, 693)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_819 (Flatten)           (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_820 (Flatten)           (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_821 (Flatten)           (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_822 (Flatten)           (None, 693)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_823 (Flatten)           (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_824 (Flatten)           (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_825 (Flatten)           (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_826 (Flatten)           (None, 693)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_827 (Flatten)           (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_828 (Flatten)           (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_829 (Flatten)           (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_830 (Flatten)           (None, 693)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_831 (Flatten)           (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_832 (Flatten)           (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_833 (Flatten)           (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_834 (Flatten)           (None, 693)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_835 (Flatten)           (None, 72)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_836 (Flatten)           (None, 6)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_837 (Flatten)           (None, 6)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_280 (Concatenate)   (None, 777)          0           flatten_818[0][0]                
                                                                 flatten_819[0][0]                
                                                                 flatten_820[0][0]                
                                                                 flatten_821[0][0]                
__________________________________________________________________________________________________
concatenate_281 (Concatenate)   (None, 777)          0           flatten_822[0][0]                
                                                                 flatten_823[0][0]                
                                                                 flatten_824[0][0]                
                                                                 flatten_825[0][0]                
__________________________________________________________________________________________________
concatenate_282 (Concatenate)   (None, 777)          0           flatten_826[0][0]                
                                                                 flatten_827[0][0]                
                                                                 flatten_828[0][0]                
                                                                 flatten_829[0][0]                
__________________________________________________________________________________________________
concatenate_283 (Concatenate)   (None, 777)          0           flatten_830[0][0]                
                                                                 flatten_831[0][0]                
                                                                 flatten_832[0][0]                
                                                                 flatten_833[0][0]                
__________________________________________________________________________________________________
concatenate_284 (Concatenate)   (None, 777)          0           flatten_834[0][0]                
                                                                 flatten_835[0][0]                
                                                                 flatten_836[0][0]                
                                                                 flatten_837[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 158)          122924      concatenate_280[0][0]            
                                                                 concatenate_281[0][0]            
                                                                 concatenate_282[0][0]            
                                                                 concatenate_283[0][0]            
                                                                 concatenate_284[0][0]            
__________________________________________________________________________________________________
concatenate_285 (Concatenate)   (None, 790)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 29)           22939       concatenate_285[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            120         idenDense[0][0]                  
==================================================================================================
Total params: 1,285,589
Trainable params: 1,285,589
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 8s - loss: 0.3046 - acc: 0.9233
POS tagging:
Epoch 1/1
 - 8s - loss: 0.1489 - acc: 0.9643
POS tagging:
Epoch 1/1
 - 8s - loss: 0.1126 - acc: 0.9735
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0895 - acc: 0.9793
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0736 - acc: 0.9827
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0750 - acc: 0.9818
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0836 - acc: 0.9796
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0542 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0642 - acc: 0.9847
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0501 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0544 - acc: 0.9873
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0482 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0475 - acc: 0.9890
POS tagging accuracy = 93.5
Loss = 0.232, 
POS tagging accuracy = 93.5
Loss = 0.232, 
	TRAINING TIME: 4.18 minutes 
==================================================================================================
	PARSING TIME: 1.27 minutes 
==================================================================================================
	Identification : 0.512
	P, R  : 0.614, 0.439

==================================================================================================
	XP Ends: 23/4 (21 h:6)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,37             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,1              ,13             ,1              ,19             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.135          ,7              ,32             ,109            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
108            ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 37, 13, 1, 13, 1, 19, 0.135, 7, 32, 109, True, 108, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (21h:6)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.135
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 108)       814860      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_838 (Flatten)           (None, 756)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_839 (Flatten)           (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_840 (Flatten)           (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_286 (Concatenate)   (None, 915)          0           flatten_838[0][0]                
                                                                 flatten_839[0][0]                
                                                                 flatten_840[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 109)          99844       concatenate_286[0][0]            
__________________________________________________________________________________________________
dense_45 (Dense)                (None, 152)          16720       posDense[0][0]                   
==================================================================================================
Total params: 946,846
Trainable params: 946,846
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.135
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 108)       814860      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_841 (Flatten)           (None, 756)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_842 (Flatten)           (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_843 (Flatten)           (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_844 (Flatten)           (None, 756)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_845 (Flatten)           (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_846 (Flatten)           (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_847 (Flatten)           (None, 756)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_848 (Flatten)           (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_849 (Flatten)           (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_850 (Flatten)           (None, 756)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_851 (Flatten)           (None, 156)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_852 (Flatten)           (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_853 (Flatten)           (None, 756)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_854 (Flatten)           (None, 156)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_855 (Flatten)           (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_287 (Concatenate)   (None, 915)          0           flatten_841[0][0]                
                                                                 flatten_842[0][0]                
                                                                 flatten_843[0][0]                
__________________________________________________________________________________________________
concatenate_288 (Concatenate)   (None, 915)          0           flatten_844[0][0]                
                                                                 flatten_845[0][0]                
                                                                 flatten_846[0][0]                
__________________________________________________________________________________________________
concatenate_289 (Concatenate)   (None, 915)          0           flatten_847[0][0]                
                                                                 flatten_848[0][0]                
                                                                 flatten_849[0][0]                
__________________________________________________________________________________________________
concatenate_290 (Concatenate)   (None, 915)          0           flatten_850[0][0]                
                                                                 flatten_851[0][0]                
                                                                 flatten_852[0][0]                
__________________________________________________________________________________________________
concatenate_291 (Concatenate)   (None, 915)          0           flatten_853[0][0]                
                                                                 flatten_854[0][0]                
                                                                 flatten_855[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 109)          99844       concatenate_287[0][0]            
                                                                 concatenate_288[0][0]            
                                                                 concatenate_289[0][0]            
                                                                 concatenate_290[0][0]            
                                                                 concatenate_291[0][0]            
__________________________________________________________________________________________________
concatenate_292 (Concatenate)   (None, 545)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 37)           20202       concatenate_292[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            152         idenDense[0][0]                  
==================================================================================================
Total params: 950,480
Trainable params: 950,480
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2830 - acc: 0.9339
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0991 - acc: 0.9760
MWE identification:
Epoch 1/1
 - 71s - loss: 0.0773 - acc: 0.9801
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1905 - acc: 0.9533
MWE identification:
Epoch 1/1
 - 72s - loss: 0.0548 - acc: 0.9862
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0971 - acc: 0.9755
MWE identification:
Epoch 1/1
 - 71s - loss: 0.0487 - acc: 0.9881
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0705 - acc: 0.9826
MWE identification:
Epoch 1/1
 - 71s - loss: 0.0461 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0565 - acc: 0.9859
MWE identification:
Epoch 1/1
 - 71s - loss: 0.0452 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0501 - acc: 0.9878
MWE identification:
Epoch 1/1
 - 71s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0459 - acc: 0.9889
MWE identification:
Epoch 1/1
 - 71s - loss: 0.0447 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0430 - acc: 0.9898
MWE identification:
Epoch 1/1
 - 71s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0414 - acc: 0.9906
MWE identification:
Epoch 1/1
 - 71s - loss: 0.0442 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0399 - acc: 0.9909
POS tagging accuracy = 94.6
Loss = 0.327, 
POS tagging accuracy = 94.6
Loss = 0.327, 
	TRAINING TIME: 12.52 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.645, 0.537

==================================================================================================
	XP Ends: 23/4 (21 h:19)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,43             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,2              ,21             ,1              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.058          ,14             ,86             ,38             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
123            ,True           ,False          ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 43, 6, 2, 21, 1, 14, 0.058, 14, 86, 38, True, 123, True, False, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (21h:19)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.058
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 123)       1406874     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_856 (Flatten)           (None, 861)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_857 (Flatten)           (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_858 (Flatten)           (None, 14)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_293 (Concatenate)   (None, 947)          0           flatten_856[0][0]                
                                                                 flatten_857[0][0]                
                                                                 flatten_858[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 38)           36024       concatenate_293[0][0]            
__________________________________________________________________________________________________
dense_46 (Dense)                (None, 152)          5928        posDense[0][0]                   
==================================================================================================
Total params: 1,456,222
Trainable params: 1,456,222
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.058
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 123)       1406874     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_859 (Flatten)           (None, 861)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_860 (Flatten)           (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_861 (Flatten)           (None, 14)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_862 (Flatten)           (None, 861)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_863 (Flatten)           (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_864 (Flatten)           (None, 14)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_865 (Flatten)           (None, 861)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_866 (Flatten)           (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_867 (Flatten)           (None, 14)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_868 (Flatten)           (None, 861)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_869 (Flatten)           (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_870 (Flatten)           (None, 14)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_294 (Concatenate)   (None, 947)          0           flatten_859[0][0]                
                                                                 flatten_860[0][0]                
                                                                 flatten_861[0][0]                
__________________________________________________________________________________________________
concatenate_295 (Concatenate)   (None, 947)          0           flatten_862[0][0]                
                                                                 flatten_863[0][0]                
                                                                 flatten_864[0][0]                
__________________________________________________________________________________________________
concatenate_296 (Concatenate)   (None, 947)          0           flatten_865[0][0]                
                                                                 flatten_866[0][0]                
                                                                 flatten_867[0][0]                
__________________________________________________________________________________________________
concatenate_297 (Concatenate)   (None, 947)          0           flatten_868[0][0]                
                                                                 flatten_869[0][0]                
                                                                 flatten_870[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 38)           36024       concatenate_294[0][0]            
                                                                 concatenate_295[0][0]            
                                                                 concatenate_296[0][0]            
                                                                 concatenate_297[0][0]            
__________________________________________________________________________________________________
concatenate_298 (Concatenate)   (None, 152)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 43)           6579        concatenate_298[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            176         idenDense[0][0]                  
==================================================================================================
Total params: 1,457,049
Trainable params: 1,457,049
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2478 - acc: 0.9366
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0889 - acc: 0.9774
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0660 - acc: 0.9832
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1014 - acc: 0.9732
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0480 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0504 - acc: 0.9877
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0452 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0338 - acc: 0.9922
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0446 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0254 - acc: 0.9946
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0206 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0174 - acc: 0.9966
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0443 - acc: 0.9895
POS tagging accuracy = 93.6
Loss = 0.302, 
POS tagging accuracy = 93.6
Loss = 0.302, 
	TRAINING TIME: 5.85 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.523
	P, R  : 0.5, 0.548

==================================================================================================
	XP Ends: 23/4 (21 h:26)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,49             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,2              ,29             ,2              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.01           ,9              ,13             ,47             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
119            ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 49, 7, 2, 29, 2, 14, 0.01, 9, 13, 47, True, 119, False, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (21h:26)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 119)       1361122     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_871 (Flatten)           (None, 833)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_872 (Flatten)           (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_873 (Flatten)           (None, 9)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_299 (Concatenate)   (None, 926)          0           flatten_871[0][0]                
                                                                 flatten_872[0][0]                
                                                                 flatten_873[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 47)           43569       concatenate_299[0][0]            
__________________________________________________________________________________________________
dense_47 (Dense)                (None, 152)          7296        posDense[0][0]                   
==================================================================================================
Total params: 1,420,469
Trainable params: 1,420,469
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 119)       1361122     bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_874 (Flatten)           (None, 833)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_875 (Flatten)           (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_876 (Flatten)           (None, 9)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_877 (Flatten)           (None, 833)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_878 (Flatten)           (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_879 (Flatten)           (None, 9)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_880 (Flatten)           (None, 833)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_881 (Flatten)           (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_882 (Flatten)           (None, 9)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_883 (Flatten)           (None, 833)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_884 (Flatten)           (None, 84)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_885 (Flatten)           (None, 9)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_300 (Concatenate)   (None, 926)          0           flatten_874[0][0]                
                                                                 flatten_875[0][0]                
                                                                 flatten_876[0][0]                
__________________________________________________________________________________________________
concatenate_301 (Concatenate)   (None, 926)          0           flatten_877[0][0]                
                                                                 flatten_878[0][0]                
                                                                 flatten_879[0][0]                
__________________________________________________________________________________________________
concatenate_302 (Concatenate)   (None, 926)          0           flatten_880[0][0]                
                                                                 flatten_881[0][0]                
                                                                 flatten_882[0][0]                
__________________________________________________________________________________________________
concatenate_303 (Concatenate)   (None, 926)          0           flatten_883[0][0]                
                                                                 flatten_884[0][0]                
                                                                 flatten_885[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 47)           43569       concatenate_300[0][0]            
                                                                 concatenate_301[0][0]            
                                                                 concatenate_302[0][0]            
                                                                 concatenate_303[0][0]            
__________________________________________________________________________________________________
concatenate_304 (Concatenate)   (None, 188)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 49)           9261        concatenate_304[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            200         idenDense[0][0]                  
==================================================================================================
Total params: 1,422,634
Trainable params: 1,422,634
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.3942 - acc: 0.9021
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1919 - acc: 0.9551
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1531 - acc: 0.9644
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0787 - acc: 0.9800
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1440 - acc: 0.9659
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0572 - acc: 0.9860
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1187 - acc: 0.9726
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0521 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1030 - acc: 0.9766
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0494 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0914 - acc: 0.9793
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0478 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0823 - acc: 0.9812
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0469 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0750 - acc: 0.9827
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0462 - acc: 0.9892
POS tagging accuracy = 93.6
Loss = 0.223, 
POS tagging accuracy = 93.6
Loss = 0.223, 
	TRAINING TIME: 5.73 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.506
	P, R  : 0.523, 0.491

==================================================================================================
	XP Ends: 23/4 (21 h:33)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,97             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
11             ,1              ,18             ,2              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.028          ,5              ,83             ,196            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
57             ,False          ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 97, 11, 1, 18, 2, 15, 0.028, 5, 83, 196, True, 57, False, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (21h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 57)        430065      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_886 (Flatten)           (None, 399)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_887 (Flatten)           (None, 132)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_888 (Flatten)           (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_305 (Concatenate)   (None, 534)          0           flatten_886[0][0]                
                                                                 flatten_887[0][0]                
                                                                 flatten_888[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 196)          104860      concatenate_305[0][0]            
__________________________________________________________________________________________________
dense_48 (Dense)                (None, 152)          29944       posDense[0][0]                   
==================================================================================================
Total params: 577,919
Trainable params: 577,919
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 57)        430065      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_889 (Flatten)           (None, 399)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_890 (Flatten)           (None, 132)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_891 (Flatten)           (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_892 (Flatten)           (None, 399)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_893 (Flatten)           (None, 132)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_894 (Flatten)           (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_895 (Flatten)           (None, 399)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_896 (Flatten)           (None, 132)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_897 (Flatten)           (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_898 (Flatten)           (None, 399)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_899 (Flatten)           (None, 132)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_900 (Flatten)           (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_306 (Concatenate)   (None, 534)          0           flatten_889[0][0]                
                                                                 flatten_890[0][0]                
                                                                 flatten_891[0][0]                
__________________________________________________________________________________________________
concatenate_307 (Concatenate)   (None, 534)          0           flatten_892[0][0]                
                                                                 flatten_893[0][0]                
                                                                 flatten_894[0][0]                
__________________________________________________________________________________________________
concatenate_308 (Concatenate)   (None, 534)          0           flatten_895[0][0]                
                                                                 flatten_896[0][0]                
                                                                 flatten_897[0][0]                
__________________________________________________________________________________________________
concatenate_309 (Concatenate)   (None, 534)          0           flatten_898[0][0]                
                                                                 flatten_899[0][0]                
                                                                 flatten_900[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 196)          104860      concatenate_306[0][0]            
                                                                 concatenate_307[0][0]            
                                                                 concatenate_308[0][0]            
                                                                 concatenate_309[0][0]            
__________________________________________________________________________________________________
concatenate_310 (Concatenate)   (None, 784)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 97)           76145       concatenate_310[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            392         idenDense[0][0]                  
==================================================================================================
Total params: 624,512
Trainable params: 624,512
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2184 - acc: 0.9468
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0691 - acc: 0.9819
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0400 - acc: 0.9893
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0632 - acc: 0.9842
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0573 - acc: 0.9848
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0493 - acc: 0.9878
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0294 - acc: 0.9931
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0463 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0190 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0451 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0134 - acc: 0.9970
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0446 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0099 - acc: 0.9979
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0076 - acc: 0.9984
MWE identification:
Epoch 1/1
 - 44s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0060 - acc: 0.9987
POS tagging accuracy = 95.0
Loss = 0.254, 
POS tagging accuracy = 95.0
Loss = 0.254, 
	TRAINING TIME: 6.53 minutes 
==================================================================================================
	PARSING TIME: 0.88 minutes 
==================================================================================================
	Identification : 0.594
	P, R  : 0.77, 0.484

==================================================================================================
	XP Ends: 23/4 (21 h:41)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,78             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,7              ,11             ,2              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.053          ,10             ,8              ,30             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
93             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 78, 6, 7, 11, 2, 12, 0.053, 10, 8, 30, True, 93, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (21h:41)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 93)        701685      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_901 (Flatten)           (None, 651)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_902 (Flatten)           (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_903 (Flatten)           (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_904 (Flatten)           (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_311 (Concatenate)   (None, 754)          0           flatten_901[0][0]                
                                                                 flatten_902[0][0]                
                                                                 flatten_903[0][0]                
                                                                 flatten_904[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 30)           22650       concatenate_311[0][0]            
__________________________________________________________________________________________________
dense_49 (Dense)                (None, 152)          4712        posDense[0][0]                   
==================================================================================================
Total params: 736,391
Trainable params: 736,391
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.053
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 93)        701685      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_905 (Flatten)           (None, 651)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_906 (Flatten)           (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_907 (Flatten)           (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_908 (Flatten)           (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_909 (Flatten)           (None, 651)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_910 (Flatten)           (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_911 (Flatten)           (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_912 (Flatten)           (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_913 (Flatten)           (None, 651)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_914 (Flatten)           (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_915 (Flatten)           (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_916 (Flatten)           (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_917 (Flatten)           (None, 651)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_918 (Flatten)           (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_919 (Flatten)           (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_920 (Flatten)           (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_312 (Concatenate)   (None, 754)          0           flatten_905[0][0]                
                                                                 flatten_906[0][0]                
                                                                 flatten_907[0][0]                
                                                                 flatten_908[0][0]                
__________________________________________________________________________________________________
concatenate_313 (Concatenate)   (None, 754)          0           flatten_909[0][0]                
                                                                 flatten_910[0][0]                
                                                                 flatten_911[0][0]                
                                                                 flatten_912[0][0]                
__________________________________________________________________________________________________
concatenate_314 (Concatenate)   (None, 754)          0           flatten_913[0][0]                
                                                                 flatten_914[0][0]                
                                                                 flatten_915[0][0]                
                                                                 flatten_916[0][0]                
__________________________________________________________________________________________________
concatenate_315 (Concatenate)   (None, 754)          0           flatten_917[0][0]                
                                                                 flatten_918[0][0]                
                                                                 flatten_919[0][0]                
                                                                 flatten_920[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 30)           22650       concatenate_312[0][0]            
                                                                 concatenate_313[0][0]            
                                                                 concatenate_314[0][0]            
                                                                 concatenate_315[0][0]            
__________________________________________________________________________________________________
concatenate_316 (Concatenate)   (None, 120)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 78)           9438        concatenate_316[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            316         idenDense[0][0]                  
==================================================================================================
Total params: 741,433
Trainable params: 741,433
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 15s - loss: 0.2073 - acc: 0.9481
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0665 - acc: 0.9819
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0398 - acc: 0.9895
MWE identification:
Epoch 1/1
 - 82s - loss: 0.0649 - acc: 0.9833
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0756 - acc: 0.9800
MWE identification:
Epoch 1/1
 - 83s - loss: 0.0502 - acc: 0.9877
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0363 - acc: 0.9914
MWE identification:
Epoch 1/1
 - 83s - loss: 0.0465 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0245 - acc: 0.9941
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0452 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0189 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0447 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0154 - acc: 0.9964
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0445 - acc: 0.9895
POS tagging accuracy = 95.1
Loss = 0.256, 
POS tagging accuracy = 95.1
Loss = 0.256, 
	TRAINING TIME: 11.45 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.583
	P, R  : 0.685, 0.507

==================================================================================================
	XP Ends: 23/4 (21 h:54)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,144            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,1              ,10             ,2              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.046          ,5              ,9              ,54             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
80             ,True           ,False          ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 144, 7, 1, 10, 2, 18, 0.046, 5, 9, 54, True, 80, True, False, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (21h:54)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 80)        915040      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
flatten_921 (Flatten)           (None, 560)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_922 (Flatten)           (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_317 (Concatenate)   (None, 644)          0           flatten_921[0][0]                
                                                                 flatten_922[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 54)           34830       concatenate_317[0][0]            
__________________________________________________________________________________________________
dense_50 (Dense)                (None, 152)          8360        posDense[0][0]                   
==================================================================================================
Total params: 966,532
Trainable params: 966,532
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.046
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 80)        915040      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_923 (Flatten)           (None, 560)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_924 (Flatten)           (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_925 (Flatten)           (None, 560)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_926 (Flatten)           (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_927 (Flatten)           (None, 560)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_928 (Flatten)           (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_929 (Flatten)           (None, 560)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_930 (Flatten)           (None, 84)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
concatenate_318 (Concatenate)   (None, 644)          0           flatten_923[0][0]                
                                                                 flatten_924[0][0]                
__________________________________________________________________________________________________
concatenate_319 (Concatenate)   (None, 644)          0           flatten_925[0][0]                
                                                                 flatten_926[0][0]                
__________________________________________________________________________________________________
concatenate_320 (Concatenate)   (None, 644)          0           flatten_927[0][0]                
                                                                 flatten_928[0][0]                
__________________________________________________________________________________________________
concatenate_321 (Concatenate)   (None, 644)          0           flatten_929[0][0]                
                                                                 flatten_930[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 54)           34830       concatenate_318[0][0]            
                                                                 concatenate_319[0][0]            
                                                                 concatenate_320[0][0]            
                                                                 concatenate_321[0][0]            
__________________________________________________________________________________________________
concatenate_322 (Concatenate)   (None, 216)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 144)          31248       concatenate_322[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            580         idenDense[0][0]                  
==================================================================================================
Total params: 990,000
Trainable params: 990,000
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 11s - loss: 0.2399 - acc: 0.9389
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0951 - acc: 0.9754
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0565 - acc: 0.9853
MWE identification:
Epoch 1/1
 - 68s - loss: 4.4047 - acc: 0.7177
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0801 - acc: 0.9785
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0524 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0426 - acc: 0.9894
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0473 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0286 - acc: 0.9934
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0462 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0216 - acc: 0.9952
MWE identification:
Epoch 1/1
 - 68s - loss: 0.0459 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0172 - acc: 0.9962
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0457 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0141 - acc: 0.9969
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0456 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0120 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0456 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0104 - acc: 0.9978
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0456 - acc: 0.9894
POS tagging accuracy = 93.4
Loss = 0.322, 
POS tagging accuracy = 93.4
Loss = 0.322, 
	TRAINING TIME: 12.93 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.523
	P, R  : 0.494, 0.555

==================================================================================================
	XP Ends: 23/4 (22 h:8)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,145            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,8              ,25             ,2              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.061          ,12             ,41             ,27             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
133            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 145, 6, 8, 25, 2, 9, 0.061, 12, 41, 27, True, 133, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (22h:8)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 133)       1003485     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_931 (Flatten)           (None, 931)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_932 (Flatten)           (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_933 (Flatten)           (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_934 (Flatten)           (None, 12)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_323 (Concatenate)   (None, 1039)         0           flatten_931[0][0]                
                                                                 flatten_932[0][0]                
                                                                 flatten_933[0][0]                
                                                                 flatten_934[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 27)           28080       concatenate_323[0][0]            
__________________________________________________________________________________________________
dense_51 (Dense)                (None, 152)          4256        posDense[0][0]                   
==================================================================================================
Total params: 1,043,209
Trainable params: 1,043,209
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 133)       1003485     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_935 (Flatten)           (None, 931)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_936 (Flatten)           (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_937 (Flatten)           (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_938 (Flatten)           (None, 12)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_939 (Flatten)           (None, 931)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_940 (Flatten)           (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_941 (Flatten)           (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_942 (Flatten)           (None, 12)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_943 (Flatten)           (None, 931)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_944 (Flatten)           (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_945 (Flatten)           (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_946 (Flatten)           (None, 12)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_947 (Flatten)           (None, 931)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_948 (Flatten)           (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_949 (Flatten)           (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_950 (Flatten)           (None, 12)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_951 (Flatten)           (None, 931)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_952 (Flatten)           (None, 72)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_953 (Flatten)           (None, 24)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_954 (Flatten)           (None, 12)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_324 (Concatenate)   (None, 1039)         0           flatten_935[0][0]                
                                                                 flatten_936[0][0]                
                                                                 flatten_937[0][0]                
                                                                 flatten_938[0][0]                
__________________________________________________________________________________________________
concatenate_325 (Concatenate)   (None, 1039)         0           flatten_939[0][0]                
                                                                 flatten_940[0][0]                
                                                                 flatten_941[0][0]                
                                                                 flatten_942[0][0]                
__________________________________________________________________________________________________
concatenate_326 (Concatenate)   (None, 1039)         0           flatten_943[0][0]                
                                                                 flatten_944[0][0]                
                                                                 flatten_945[0][0]                
                                                                 flatten_946[0][0]                
__________________________________________________________________________________________________
concatenate_327 (Concatenate)   (None, 1039)         0           flatten_947[0][0]                
                                                                 flatten_948[0][0]                
                                                                 flatten_949[0][0]                
                                                                 flatten_950[0][0]                
__________________________________________________________________________________________________
concatenate_328 (Concatenate)   (None, 1039)         0           flatten_951[0][0]                
                                                                 flatten_952[0][0]                
                                                                 flatten_953[0][0]                
                                                                 flatten_954[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 27)           28080       concatenate_324[0][0]            
                                                                 concatenate_325[0][0]            
                                                                 concatenate_326[0][0]            
                                                                 concatenate_327[0][0]            
                                                                 concatenate_328[0][0]            
__________________________________________________________________________________________________
concatenate_329 (Concatenate)   (None, 135)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 145)          19720       concatenate_329[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            584         idenDense[0][0]                  
==================================================================================================
Total params: 1,059,257
Trainable params: 1,059,257
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2083 - acc: 0.9480
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0625 - acc: 0.9825
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0347 - acc: 0.9906
MWE identification:
Epoch 1/1
 - 43s - loss: 8.0640 - acc: 0.4990
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0636 - acc: 0.9827
MWE identification:
Epoch 1/1
 - 43s - loss: 8.0602 - acc: 0.4998
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0264 - acc: 0.9936
MWE identification:
Epoch 1/1
 - 43s - loss: 8.0592 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0166 - acc: 0.9961
MWE identification:
Epoch 1/1
 - 43s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0131 - acc: 0.9969
POS tagging accuracy = 94.9
Loss = 0.269, 
POS tagging accuracy = 94.9
Loss = 0.269, 
	TRAINING TIME: 4.6 minutes 
==================================================================================================
	PARSING TIME: 1.25 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (22 h:14)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,28             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,7              ,30             ,3              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.066          ,12             ,30             ,134            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
47             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 28, 6, 7, 30, 3, 13, 0.066, 12, 30, 134, True, 47, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (22h:14)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 47)        354615      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_955 (Flatten)           (None, 329)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_956 (Flatten)           (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_957 (Flatten)           (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_958 (Flatten)           (None, 12)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_330 (Concatenate)   (None, 434)          0           flatten_955[0][0]                
                                                                 flatten_956[0][0]                
                                                                 flatten_957[0][0]                
                                                                 flatten_958[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 134)          58290       concatenate_330[0][0]            
__________________________________________________________________________________________________
dense_52 (Dense)                (None, 152)          20520       posDense[0][0]                   
==================================================================================================
Total params: 440,809
Trainable params: 440,809
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.066
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 47)        354615      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_959 (Flatten)           (None, 329)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_960 (Flatten)           (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_961 (Flatten)           (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_962 (Flatten)           (None, 12)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_963 (Flatten)           (None, 329)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_964 (Flatten)           (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_965 (Flatten)           (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_966 (Flatten)           (None, 12)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_967 (Flatten)           (None, 329)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_968 (Flatten)           (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_969 (Flatten)           (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_970 (Flatten)           (None, 12)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_971 (Flatten)           (None, 329)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_972 (Flatten)           (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_973 (Flatten)           (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_974 (Flatten)           (None, 12)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_975 (Flatten)           (None, 329)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_976 (Flatten)           (None, 72)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_977 (Flatten)           (None, 21)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_978 (Flatten)           (None, 12)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_331 (Concatenate)   (None, 434)          0           flatten_959[0][0]                
                                                                 flatten_960[0][0]                
                                                                 flatten_961[0][0]                
                                                                 flatten_962[0][0]                
__________________________________________________________________________________________________
concatenate_332 (Concatenate)   (None, 434)          0           flatten_963[0][0]                
                                                                 flatten_964[0][0]                
                                                                 flatten_965[0][0]                
                                                                 flatten_966[0][0]                
__________________________________________________________________________________________________
concatenate_333 (Concatenate)   (None, 434)          0           flatten_967[0][0]                
                                                                 flatten_968[0][0]                
                                                                 flatten_969[0][0]                
                                                                 flatten_970[0][0]                
__________________________________________________________________________________________________
concatenate_334 (Concatenate)   (None, 434)          0           flatten_971[0][0]                
                                                                 flatten_972[0][0]                
                                                                 flatten_973[0][0]                
                                                                 flatten_974[0][0]                
__________________________________________________________________________________________________
concatenate_335 (Concatenate)   (None, 434)          0           flatten_975[0][0]                
                                                                 flatten_976[0][0]                
                                                                 flatten_977[0][0]                
                                                                 flatten_978[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 134)          58290       concatenate_331[0][0]            
                                                                 concatenate_332[0][0]            
                                                                 concatenate_333[0][0]            
                                                                 concatenate_334[0][0]            
                                                                 concatenate_335[0][0]            
__________________________________________________________________________________________________
concatenate_336 (Concatenate)   (None, 670)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 28)           18788       concatenate_336[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            116         idenDense[0][0]                  
==================================================================================================
Total params: 439,193
Trainable params: 439,193
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1997 - acc: 0.9510
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0585 - acc: 0.9839
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0308 - acc: 0.9913
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0185 - acc: 0.9953
MWE identification:
Epoch 1/1
 - 35s - loss: 0.0771 - acc: 0.9822
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0707 - acc: 0.9806
MWE identification:
Epoch 1/1
 - 35s - loss: 0.0498 - acc: 0.9878
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0244 - acc: 0.9940
MWE identification:
Epoch 1/1
 - 35s - loss: 0.0463 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0142 - acc: 0.9970
MWE identification:
Epoch 1/1
 - 35s - loss: 0.0451 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0104 - acc: 0.9978
MWE identification:
Epoch 1/1
 - 35s - loss: 0.0446 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0080 - acc: 0.9983
MWE identification:
Epoch 1/1
 - 35s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0067 - acc: 0.9986
POS tagging accuracy = 94.3
Loss = 0.319, 
POS tagging accuracy = 94.3
Loss = 0.319, 
	TRAINING TIME: 5.5 minutes 
==================================================================================================
	PARSING TIME: 1.28 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.656, 0.515

==================================================================================================
	XP Ends: 23/4 (22 h:21)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,48             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,1              ,11             ,3              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.025          ,5              ,76             ,117            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
25             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 48, 5, 1, 11, 3, 9, 0.025, 5, 76, 117, True, 25, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (22h:21)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 25)        188625      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_979 (Flatten)           (None, 175)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_980 (Flatten)           (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_981 (Flatten)           (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_982 (Flatten)           (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_337 (Concatenate)   (None, 243)          0           flatten_979[0][0]                
                                                                 flatten_980[0][0]                
                                                                 flatten_981[0][0]                
                                                                 flatten_982[0][0]                
__________________________________________________________________________________________________
posDense (Dense)                (None, 117)          28548       concatenate_337[0][0]            
__________________________________________________________________________________________________
dense_53 (Dense)                (None, 152)          17936       posDense[0][0]                   
==================================================================================================
Total params: 241,143
Trainable params: 241,143
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 25)        188625      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_983 (Flatten)           (None, 175)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_984 (Flatten)           (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_985 (Flatten)           (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_986 (Flatten)           (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_987 (Flatten)           (None, 175)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_988 (Flatten)           (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_989 (Flatten)           (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_990 (Flatten)           (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_991 (Flatten)           (None, 175)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_992 (Flatten)           (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_993 (Flatten)           (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_994 (Flatten)           (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_995 (Flatten)           (None, 175)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_996 (Flatten)           (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_997 (Flatten)           (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_998 (Flatten)           (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_999 (Flatten)           (None, 175)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1000 (Flatten)          (None, 60)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1001 (Flatten)          (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1002 (Flatten)          (None, 5)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_338 (Concatenate)   (None, 243)          0           flatten_983[0][0]                
                                                                 flatten_984[0][0]                
                                                                 flatten_985[0][0]                
                                                                 flatten_986[0][0]                
__________________________________________________________________________________________________
concatenate_339 (Concatenate)   (None, 243)          0           flatten_987[0][0]                
                                                                 flatten_988[0][0]                
                                                                 flatten_989[0][0]                
                                                                 flatten_990[0][0]                
__________________________________________________________________________________________________
concatenate_340 (Concatenate)   (None, 243)          0           flatten_991[0][0]                
                                                                 flatten_992[0][0]                
                                                                 flatten_993[0][0]                
                                                                 flatten_994[0][0]                
__________________________________________________________________________________________________
concatenate_341 (Concatenate)   (None, 243)          0           flatten_995[0][0]                
                                                                 flatten_996[0][0]                
                                                                 flatten_997[0][0]                
                                                                 flatten_998[0][0]                
__________________________________________________________________________________________________
concatenate_342 (Concatenate)   (None, 243)          0           flatten_999[0][0]                
                                                                 flatten_1000[0][0]               
                                                                 flatten_1001[0][0]               
                                                                 flatten_1002[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 117)          28548       concatenate_338[0][0]            
                                                                 concatenate_339[0][0]            
                                                                 concatenate_340[0][0]            
                                                                 concatenate_341[0][0]            
                                                                 concatenate_342[0][0]            
__________________________________________________________________________________________________
concatenate_343 (Concatenate)   (None, 585)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 48)           28128       concatenate_343[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            196         idenDense[0][0]                  
==================================================================================================
Total params: 251,531
Trainable params: 251,531
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2626 - acc: 0.9361
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0986 - acc: 0.9754
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0688 - acc: 0.9828
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0523 - acc: 0.9869
MWE identification:
Epoch 1/1
 - 94s - loss: 0.0745 - acc: 0.9825
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0823 - acc: 0.9789
MWE identification:
Epoch 1/1
 - 92s - loss: 0.0523 - acc: 0.9872
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0571 - acc: 0.9857
MWE identification:
Epoch 1/1
 - 94s - loss: 0.0488 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0449 - acc: 0.9891
MWE identification:
Epoch 1/1
 - 92s - loss: 0.0472 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0371 - acc: 0.9911
POS tagging accuracy = 94.6
Loss = 0.221, 
POS tagging accuracy = 94.6
Loss = 0.221, 
	TRAINING TIME: 7.78 minutes 
==================================================================================================
	PARSING TIME: 1.32 minutes 
==================================================================================================
	Identification : 0.578
	P, R  : 0.84, 0.44

==================================================================================================
	XP Ends: 23/4 (22 h:30)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,136            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,2              ,104            ,4              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.111          ,6              ,9              ,76             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
28             ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 136, 8, 2, 104, 4, 11, 0.111, 6, 9, 76, True, 28, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (22h:30)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.111
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        320264      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1003 (Flatten)          (None, 196)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1004 (Flatten)          (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1005 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_344 (Concatenate)   (None, 298)          0           flatten_1003[0][0]               
                                                                 flatten_1004[0][0]               
                                                                 flatten_1005[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 76)           22724       concatenate_344[0][0]            
__________________________________________________________________________________________________
dense_54 (Dense)                (None, 152)          11704       posDense[0][0]                   
==================================================================================================
Total params: 364,300
Trainable params: 364,300
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.111
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        320264      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1006 (Flatten)          (None, 196)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1007 (Flatten)          (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1008 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1009 (Flatten)          (None, 196)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1010 (Flatten)          (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1011 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1012 (Flatten)          (None, 196)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1013 (Flatten)          (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1014 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1015 (Flatten)          (None, 196)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1016 (Flatten)          (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1017 (Flatten)          (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1018 (Flatten)          (None, 196)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1019 (Flatten)          (None, 96)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1020 (Flatten)          (None, 6)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_345 (Concatenate)   (None, 298)          0           flatten_1006[0][0]               
                                                                 flatten_1007[0][0]               
                                                                 flatten_1008[0][0]               
__________________________________________________________________________________________________
concatenate_346 (Concatenate)   (None, 298)          0           flatten_1009[0][0]               
                                                                 flatten_1010[0][0]               
                                                                 flatten_1011[0][0]               
__________________________________________________________________________________________________
concatenate_347 (Concatenate)   (None, 298)          0           flatten_1012[0][0]               
                                                                 flatten_1013[0][0]               
                                                                 flatten_1014[0][0]               
__________________________________________________________________________________________________
concatenate_348 (Concatenate)   (None, 298)          0           flatten_1015[0][0]               
                                                                 flatten_1016[0][0]               
                                                                 flatten_1017[0][0]               
__________________________________________________________________________________________________
concatenate_349 (Concatenate)   (None, 298)          0           flatten_1018[0][0]               
                                                                 flatten_1019[0][0]               
                                                                 flatten_1020[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 76)           22724       concatenate_345[0][0]            
                                                                 concatenate_346[0][0]            
                                                                 concatenate_347[0][0]            
                                                                 concatenate_348[0][0]            
                                                                 concatenate_349[0][0]            
__________________________________________________________________________________________________
concatenate_350 (Concatenate)   (None, 380)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 136)          51816       concatenate_350[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            548         idenDense[0][0]                  
==================================================================================================
Total params: 404,960
Trainable params: 404,960
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 12s - loss: 0.2549 - acc: 0.9358
POS tagging:
Epoch 1/1
 - 12s - loss: 0.1012 - acc: 0.9729
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0609 - acc: 0.9835
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0402 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0286 - acc: 0.9928
MWE identification:
Epoch 1/1
 - 9s - loss: 12.0849 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0417 - acc: 0.9888
MWE identification:
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0206 - acc: 0.9951
MWE identification:
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0155 - acc: 0.9965
MWE identification:
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0128 - acc: 0.9972
MWE identification:
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0110 - acc: 0.9977
POS tagging accuracy = 93.7
Loss = 0.326, 
POS tagging accuracy = 93.7
Loss = 0.326, 
	TRAINING TIME: 3.82 minutes 
==================================================================================================
	PARSING TIME: 1.87 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (22 h:36)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,35             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,8              ,69             ,4              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.1            ,13             ,13             ,65             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
26             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 35, 5, 8, 69, 4, 13, 0.1, 13, 13, 65, True, 26, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (22h:36)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.1
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 26)        196170      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1021 (Flatten)          (None, 182)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1022 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1023 (Flatten)          (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1024 (Flatten)          (None, 13)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_351 (Concatenate)   (None, 279)          0           flatten_1021[0][0]               
                                                                 flatten_1022[0][0]               
                                                                 flatten_1023[0][0]               
                                                                 flatten_1024[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 65)           18200       concatenate_351[0][0]            
__________________________________________________________________________________________________
dense_55 (Dense)                (None, 152)          10032       posDense[0][0]                   
==================================================================================================
Total params: 230,624
Trainable params: 230,624
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.1
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 26)        196170      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1025 (Flatten)          (None, 182)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1026 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1027 (Flatten)          (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1028 (Flatten)          (None, 13)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1029 (Flatten)          (None, 182)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1030 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1031 (Flatten)          (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1032 (Flatten)          (None, 13)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1033 (Flatten)          (None, 182)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1034 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1035 (Flatten)          (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1036 (Flatten)          (None, 13)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1037 (Flatten)          (None, 182)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1038 (Flatten)          (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1039 (Flatten)          (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1040 (Flatten)          (None, 13)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_352 (Concatenate)   (None, 279)          0           flatten_1025[0][0]               
                                                                 flatten_1026[0][0]               
                                                                 flatten_1027[0][0]               
                                                                 flatten_1028[0][0]               
__________________________________________________________________________________________________
concatenate_353 (Concatenate)   (None, 279)          0           flatten_1029[0][0]               
                                                                 flatten_1030[0][0]               
                                                                 flatten_1031[0][0]               
                                                                 flatten_1032[0][0]               
__________________________________________________________________________________________________
concatenate_354 (Concatenate)   (None, 279)          0           flatten_1033[0][0]               
                                                                 flatten_1034[0][0]               
                                                                 flatten_1035[0][0]               
                                                                 flatten_1036[0][0]               
__________________________________________________________________________________________________
concatenate_355 (Concatenate)   (None, 279)          0           flatten_1037[0][0]               
                                                                 flatten_1038[0][0]               
                                                                 flatten_1039[0][0]               
                                                                 flatten_1040[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 65)           18200       concatenate_352[0][0]            
                                                                 concatenate_353[0][0]            
                                                                 concatenate_354[0][0]            
                                                                 concatenate_355[0][0]            
__________________________________________________________________________________________________
concatenate_356 (Concatenate)   (None, 260)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 35)           9135        concatenate_356[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            144         idenDense[0][0]                  
==================================================================================================
Total params: 229,871
Trainable params: 229,871
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 8s - loss: 0.2229 - acc: 0.9442
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0741 - acc: 0.9798
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0435 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0285 - acc: 0.9926
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0202 - acc: 0.9950
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0677 - acc: 0.9825
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0880 - acc: 0.9758
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0513 - acc: 0.9872
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0354 - acc: 0.9908
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0472 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0216 - acc: 0.9948
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0455 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0153 - acc: 0.9967
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0120 - acc: 0.9974
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0100 - acc: 0.9980
POS tagging accuracy = 94.8
Loss = 0.304, 
POS tagging accuracy = 94.8
Loss = 0.304, 
	TRAINING TIME: 4.03 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.576
	P, R  : 0.627, 0.533

==================================================================================================
	XP Ends: 23/4 (22 h:42)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,44             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,3              ,18             ,3              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.01           ,12             ,8              ,85             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
140            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 44, 13, 3, 18, 3, 17, 0.01, 12, 8, 85, True, 140, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (22h:42)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 140)       1056300     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1041 (Flatten)          (None, 980)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1042 (Flatten)          (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1043 (Flatten)          (None, 9)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1044 (Flatten)          (None, 12)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_357 (Concatenate)   (None, 1157)         0           flatten_1041[0][0]               
                                                                 flatten_1042[0][0]               
                                                                 flatten_1043[0][0]               
                                                                 flatten_1044[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 85)           98430       concatenate_357[0][0]            
__________________________________________________________________________________________________
dense_56 (Dense)                (None, 152)          13072       posDense[0][0]                   
==================================================================================================
Total params: 1,183,472
Trainable params: 1,183,472
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 140)       1056300     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1045 (Flatten)          (None, 980)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1046 (Flatten)          (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1047 (Flatten)          (None, 9)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1048 (Flatten)          (None, 12)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1049 (Flatten)          (None, 980)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1050 (Flatten)          (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1051 (Flatten)          (None, 9)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1052 (Flatten)          (None, 12)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1053 (Flatten)          (None, 980)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1054 (Flatten)          (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1055 (Flatten)          (None, 9)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1056 (Flatten)          (None, 12)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1057 (Flatten)          (None, 980)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1058 (Flatten)          (None, 156)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1059 (Flatten)          (None, 9)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1060 (Flatten)          (None, 12)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1061 (Flatten)          (None, 980)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1062 (Flatten)          (None, 156)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1063 (Flatten)          (None, 9)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1064 (Flatten)          (None, 12)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_358 (Concatenate)   (None, 1157)         0           flatten_1045[0][0]               
                                                                 flatten_1046[0][0]               
                                                                 flatten_1047[0][0]               
                                                                 flatten_1048[0][0]               
__________________________________________________________________________________________________
concatenate_359 (Concatenate)   (None, 1157)         0           flatten_1049[0][0]               
                                                                 flatten_1050[0][0]               
                                                                 flatten_1051[0][0]               
                                                                 flatten_1052[0][0]               
__________________________________________________________________________________________________
concatenate_360 (Concatenate)   (None, 1157)         0           flatten_1053[0][0]               
                                                                 flatten_1054[0][0]               
                                                                 flatten_1055[0][0]               
                                                                 flatten_1056[0][0]               
__________________________________________________________________________________________________
concatenate_361 (Concatenate)   (None, 1157)         0           flatten_1057[0][0]               
                                                                 flatten_1058[0][0]               
                                                                 flatten_1059[0][0]               
                                                                 flatten_1060[0][0]               
__________________________________________________________________________________________________
concatenate_362 (Concatenate)   (None, 1157)         0           flatten_1061[0][0]               
                                                                 flatten_1062[0][0]               
                                                                 flatten_1063[0][0]               
                                                                 flatten_1064[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 85)           98430       concatenate_358[0][0]            
                                                                 concatenate_359[0][0]            
                                                                 concatenate_360[0][0]            
                                                                 concatenate_361[0][0]            
                                                                 concatenate_362[0][0]            
__________________________________________________________________________________________________
concatenate_363 (Concatenate)   (None, 425)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 44)           18744       concatenate_363[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            180         idenDense[0][0]                  
==================================================================================================
Total params: 1,189,324
Trainable params: 1,189,324
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 15s - loss: 0.2731 - acc: 0.9363
POS tagging:
Epoch 1/1
 - 15s - loss: 0.1136 - acc: 0.9733
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0843 - acc: 0.9790
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0676 - acc: 0.9826
MWE identification:
Epoch 1/1
 - 60s - loss: 0.0680 - acc: 0.9829
POS tagging:
Epoch 1/1
 - 16s - loss: 0.0765 - acc: 0.9800
MWE identification:
Epoch 1/1
 - 62s - loss: 0.0527 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0588 - acc: 0.9855
MWE identification:
Epoch 1/1
 - 60s - loss: 0.0495 - acc: 0.9881
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0494 - acc: 0.9884
MWE identification:
Epoch 1/1
 - 61s - loss: 0.0479 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0427 - acc: 0.9904
MWE identification:
Epoch 1/1
 - 62s - loss: 0.0468 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0374 - acc: 0.9920
MWE identification:
Epoch 1/1
 - 60s - loss: 0.0462 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0334 - acc: 0.9929
MWE identification:
Epoch 1/1
 - 60s - loss: 0.0457 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0300 - acc: 0.9939
MWE identification:
Epoch 1/1
 - 60s - loss: 0.0454 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0272 - acc: 0.9946
POS tagging accuracy = 94.8
Loss = 0.21, 
POS tagging accuracy = 94.8
Loss = 0.21, 
	TRAINING TIME: 12.57 minutes 
==================================================================================================
	PARSING TIME: 1.28 minutes 
==================================================================================================
	Identification : 0.6
	P, R  : 0.788, 0.484

==================================================================================================
	XP Ends: 23/4 (22 h:56)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,127            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,5              ,16             ,1              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.031          ,12             ,14             ,182            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
32             ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 127, 13, 5, 16, 1, 9, 0.031, 12, 14, 182, True, 32, False, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (22h:56)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 32)        241440      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1065 (Flatten)          (None, 224)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1066 (Flatten)          (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1067 (Flatten)          (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1068 (Flatten)          (None, 12)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_364 (Concatenate)   (None, 407)          0           flatten_1065[0][0]               
                                                                 flatten_1066[0][0]               
                                                                 flatten_1067[0][0]               
                                                                 flatten_1068[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 182)          74256       concatenate_364[0][0]            
__________________________________________________________________________________________________
dense_57 (Dense)                (None, 152)          27816       posDense[0][0]                   
==================================================================================================
Total params: 359,190
Trainable params: 359,190
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 32)        241440      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1069 (Flatten)          (None, 224)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1070 (Flatten)          (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1071 (Flatten)          (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1072 (Flatten)          (None, 12)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1073 (Flatten)          (None, 224)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1074 (Flatten)          (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1075 (Flatten)          (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1076 (Flatten)          (None, 12)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1077 (Flatten)          (None, 224)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1078 (Flatten)          (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1079 (Flatten)          (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1080 (Flatten)          (None, 12)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_365 (Concatenate)   (None, 407)          0           flatten_1069[0][0]               
                                                                 flatten_1070[0][0]               
                                                                 flatten_1071[0][0]               
                                                                 flatten_1072[0][0]               
__________________________________________________________________________________________________
concatenate_366 (Concatenate)   (None, 407)          0           flatten_1073[0][0]               
                                                                 flatten_1074[0][0]               
                                                                 flatten_1075[0][0]               
                                                                 flatten_1076[0][0]               
__________________________________________________________________________________________________
concatenate_367 (Concatenate)   (None, 407)          0           flatten_1077[0][0]               
                                                                 flatten_1078[0][0]               
                                                                 flatten_1079[0][0]               
                                                                 flatten_1080[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 182)          74256       concatenate_365[0][0]            
                                                                 concatenate_366[0][0]            
                                                                 concatenate_367[0][0]            
__________________________________________________________________________________________________
concatenate_368 (Concatenate)   (None, 546)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 127)          69469       concatenate_368[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            512         idenDense[0][0]                  
==================================================================================================
Total params: 401,355
Trainable params: 401,355
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 8s - loss: 0.1995 - acc: 0.9503
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0727 - acc: 0.9806
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0627 - acc: 0.9839
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0749 - acc: 0.9799
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0499 - acc: 0.9877
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0448 - acc: 0.9886
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0469 - acc: 0.9887
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0314 - acc: 0.9920
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0456 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0229 - acc: 0.9944
POS tagging accuracy = 94.8
Loss = 0.217, 
POS tagging accuracy = 94.8
Loss = 0.217, 
	TRAINING TIME: 4.72 minutes 
==================================================================================================
	PARSING TIME: 0.87 minutes 
==================================================================================================
	Identification : 0.583
	P, R  : 0.71, 0.494

==================================================================================================
	XP Ends: 23/4 (23 h:2)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,119            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,7              ,87             ,1              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.119          ,7              ,12             ,33             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
187            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 119, 6, 7, 87, 1, 17, 0.119, 7, 12, 33, True, 187, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (23h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.119
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 187)       1410915     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1081 (Flatten)          (None, 1309)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1082 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1083 (Flatten)          (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1084 (Flatten)          (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_369 (Concatenate)   (None, 1409)         0           flatten_1081[0][0]               
                                                                 flatten_1082[0][0]               
                                                                 flatten_1083[0][0]               
                                                                 flatten_1084[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 33)           46530       concatenate_369[0][0]            
__________________________________________________________________________________________________
dense_58 (Dense)                (None, 152)          5168        posDense[0][0]                   
==================================================================================================
Total params: 1,469,897
Trainable params: 1,469,897
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.119
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 187)       1410915     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1085 (Flatten)          (None, 1309)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1086 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1087 (Flatten)          (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1088 (Flatten)          (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1089 (Flatten)          (None, 1309)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1090 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1091 (Flatten)          (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1092 (Flatten)          (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1093 (Flatten)          (None, 1309)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1094 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1095 (Flatten)          (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1096 (Flatten)          (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1097 (Flatten)          (None, 1309)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1098 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1099 (Flatten)          (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1100 (Flatten)          (None, 7)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1101 (Flatten)          (None, 1309)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1102 (Flatten)          (None, 72)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1103 (Flatten)          (None, 21)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1104 (Flatten)          (None, 7)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_370 (Concatenate)   (None, 1409)         0           flatten_1085[0][0]               
                                                                 flatten_1086[0][0]               
                                                                 flatten_1087[0][0]               
                                                                 flatten_1088[0][0]               
__________________________________________________________________________________________________
concatenate_371 (Concatenate)   (None, 1409)         0           flatten_1089[0][0]               
                                                                 flatten_1090[0][0]               
                                                                 flatten_1091[0][0]               
                                                                 flatten_1092[0][0]               
__________________________________________________________________________________________________
concatenate_372 (Concatenate)   (None, 1409)         0           flatten_1093[0][0]               
                                                                 flatten_1094[0][0]               
                                                                 flatten_1095[0][0]               
                                                                 flatten_1096[0][0]               
__________________________________________________________________________________________________
concatenate_373 (Concatenate)   (None, 1409)         0           flatten_1097[0][0]               
                                                                 flatten_1098[0][0]               
                                                                 flatten_1099[0][0]               
                                                                 flatten_1100[0][0]               
__________________________________________________________________________________________________
concatenate_374 (Concatenate)   (None, 1409)         0           flatten_1101[0][0]               
                                                                 flatten_1102[0][0]               
                                                                 flatten_1103[0][0]               
                                                                 flatten_1104[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 33)           46530       concatenate_370[0][0]            
                                                                 concatenate_371[0][0]            
                                                                 concatenate_372[0][0]            
                                                                 concatenate_373[0][0]            
                                                                 concatenate_374[0][0]            
__________________________________________________________________________________________________
concatenate_375 (Concatenate)   (None, 165)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 119)          19754       concatenate_375[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            480         idenDense[0][0]                  
==================================================================================================
Total params: 1,484,963
Trainable params: 1,484,963
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 11s - loss: 0.3147 - acc: 0.9241
POS tagging:
Epoch 1/1
 - 11s - loss: 0.1128 - acc: 0.9727
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0869 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0996 - acc: 0.9746
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0658 - acc: 0.9831
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0561 - acc: 0.9858
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0502 - acc: 0.9873
MWE identification:
Epoch 1/1
 - 15s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0463 - acc: 0.9889
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0438 - acc: 0.9897
MWE identification:
Epoch 1/1
 - 16s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0416 - acc: 0.9903
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0398 - acc: 0.9907
POS tagging accuracy = 94.8
Loss = 0.294, 
POS tagging accuracy = 94.8
Loss = 0.294, 
	TRAINING TIME: 5.25 minutes 
==================================================================================================
	PARSING TIME: 2.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (23 h:10)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,74             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
10             ,2              ,72             ,4              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.025          ,10             ,11             ,31             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
161            ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 74, 10, 2, 72, 4, 14, 0.025, 10, 11, 31, True, 161, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (23h:10)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 161)       1841518     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1105 (Flatten)          (None, 1127)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1106 (Flatten)          (None, 120)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1107 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_376 (Concatenate)   (None, 1253)         0           flatten_1105[0][0]               
                                                                 flatten_1106[0][0]               
                                                                 flatten_1107[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 31)           38874       concatenate_376[0][0]            
__________________________________________________________________________________________________
dense_59 (Dense)                (None, 152)          4864        posDense[0][0]                   
==================================================================================================
Total params: 1,897,124
Trainable params: 1,897,124
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.025
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 161)       1841518     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1108 (Flatten)          (None, 1127)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1109 (Flatten)          (None, 120)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1110 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1111 (Flatten)          (None, 1127)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1112 (Flatten)          (None, 120)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1113 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1114 (Flatten)          (None, 1127)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1115 (Flatten)          (None, 120)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1116 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1117 (Flatten)          (None, 1127)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1118 (Flatten)          (None, 120)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1119 (Flatten)          (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1120 (Flatten)          (None, 1127)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1121 (Flatten)          (None, 120)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1122 (Flatten)          (None, 6)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_377 (Concatenate)   (None, 1253)         0           flatten_1108[0][0]               
                                                                 flatten_1109[0][0]               
                                                                 flatten_1110[0][0]               
__________________________________________________________________________________________________
concatenate_378 (Concatenate)   (None, 1253)         0           flatten_1111[0][0]               
                                                                 flatten_1112[0][0]               
                                                                 flatten_1113[0][0]               
__________________________________________________________________________________________________
concatenate_379 (Concatenate)   (None, 1253)         0           flatten_1114[0][0]               
                                                                 flatten_1115[0][0]               
                                                                 flatten_1116[0][0]               
__________________________________________________________________________________________________
concatenate_380 (Concatenate)   (None, 1253)         0           flatten_1117[0][0]               
                                                                 flatten_1118[0][0]               
                                                                 flatten_1119[0][0]               
__________________________________________________________________________________________________
concatenate_381 (Concatenate)   (None, 1253)         0           flatten_1120[0][0]               
                                                                 flatten_1121[0][0]               
                                                                 flatten_1122[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 31)           38874       concatenate_377[0][0]            
                                                                 concatenate_378[0][0]            
                                                                 concatenate_379[0][0]            
                                                                 concatenate_380[0][0]            
                                                                 concatenate_381[0][0]            
__________________________________________________________________________________________________
concatenate_382 (Concatenate)   (None, 155)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 74)           11544       concatenate_382[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            300         idenDense[0][0]                  
==================================================================================================
Total params: 1,904,104
Trainable params: 1,904,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 12s - loss: 0.2732 - acc: 0.9329
POS tagging:
Epoch 1/1
 - 12s - loss: 0.1218 - acc: 0.9710
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0814 - acc: 0.9803
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0592 - acc: 0.9859
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0461 - acc: 0.9892
MWE identification:
Epoch 1/1
 - 15s - loss: 0.0694 - acc: 0.9826
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0691 - acc: 0.9824
MWE identification:
Epoch 1/1
 - 15s - loss: 0.0489 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0434 - acc: 0.9898
MWE identification:
Epoch 1/1
 - 16s - loss: 0.0458 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0339 - acc: 0.9923
MWE identification:
Epoch 1/1
 - 15s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0283 - acc: 0.9936
MWE identification:
Epoch 1/1
 - 15s - loss: 0.0446 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0243 - acc: 0.9946
MWE identification:
Epoch 1/1
 - 15s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0213 - acc: 0.9953
MWE identification:
Epoch 1/1
 - 15s - loss: 0.0444 - acc: 0.9895
POS tagging accuracy = 93.2
Loss = 0.289, 
POS tagging accuracy = 93.2
Loss = 0.289, 
	TRAINING TIME: 5.17 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.529
	P, R  : 0.509, 0.551

==================================================================================================
	XP Ends: 23/4 (23 h:16)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,60             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
17             ,3              ,8              ,3              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.02           ,5              ,24             ,32             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
51             ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 60, 17, 3, 8, 3, 12, 0.02, 5, 24, 32, True, 51, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (23h:16)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 51)        583338      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1123 (Flatten)          (None, 357)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1124 (Flatten)          (None, 204)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1125 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_383 (Concatenate)   (None, 566)          0           flatten_1123[0][0]               
                                                                 flatten_1124[0][0]               
                                                                 flatten_1125[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 32)           18144       concatenate_383[0][0]            
__________________________________________________________________________________________________
dense_60 (Dense)                (None, 152)          5016        posDense[0][0]                   
==================================================================================================
Total params: 626,760
Trainable params: 626,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.02
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 51)        583338      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1126 (Flatten)          (None, 357)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1127 (Flatten)          (None, 204)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1128 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1129 (Flatten)          (None, 357)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1130 (Flatten)          (None, 204)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1131 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1132 (Flatten)          (None, 357)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1133 (Flatten)          (None, 204)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1134 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1135 (Flatten)          (None, 357)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1136 (Flatten)          (None, 204)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1137 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1138 (Flatten)          (None, 357)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1139 (Flatten)          (None, 204)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1140 (Flatten)          (None, 5)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_384 (Concatenate)   (None, 566)          0           flatten_1126[0][0]               
                                                                 flatten_1127[0][0]               
                                                                 flatten_1128[0][0]               
__________________________________________________________________________________________________
concatenate_385 (Concatenate)   (None, 566)          0           flatten_1129[0][0]               
                                                                 flatten_1130[0][0]               
                                                                 flatten_1131[0][0]               
__________________________________________________________________________________________________
concatenate_386 (Concatenate)   (None, 566)          0           flatten_1132[0][0]               
                                                                 flatten_1133[0][0]               
                                                                 flatten_1134[0][0]               
__________________________________________________________________________________________________
concatenate_387 (Concatenate)   (None, 566)          0           flatten_1135[0][0]               
                                                                 flatten_1136[0][0]               
                                                                 flatten_1137[0][0]               
__________________________________________________________________________________________________
concatenate_388 (Concatenate)   (None, 566)          0           flatten_1138[0][0]               
                                                                 flatten_1139[0][0]               
                                                                 flatten_1140[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 32)           18144       concatenate_384[0][0]            
                                                                 concatenate_385[0][0]            
                                                                 concatenate_386[0][0]            
                                                                 concatenate_387[0][0]            
                                                                 concatenate_388[0][0]            
__________________________________________________________________________________________________
concatenate_389 (Concatenate)   (None, 160)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 60)           9660        concatenate_389[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            244         idenDense[0][0]                  
==================================================================================================
Total params: 631,648
Trainable params: 631,648
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.3128 - acc: 0.9238
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1584 - acc: 0.9616
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1237 - acc: 0.9703
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1014 - acc: 0.9761
MWE identification:
Epoch 1/1
 - 107s - loss: 0.0724 - acc: 0.9813
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1135 - acc: 0.9724
MWE identification:
Epoch 1/1
 - 107s - loss: 0.0533 - acc: 0.9869
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0865 - acc: 0.9793
MWE identification:
Epoch 1/1
 - 107s - loss: 0.0491 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0724 - acc: 0.9829
MWE identification:
Epoch 1/1
 - 107s - loss: 0.0471 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0627 - acc: 0.9852
MWE identification:
Epoch 1/1
 - 109s - loss: 0.0461 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0555 - acc: 0.9868
MWE identification:
Epoch 1/1
 - 107s - loss: 0.0455 - acc: 0.9893
POS tagging accuracy = 93.9
Loss = 0.229, 
POS tagging accuracy = 93.9
Loss = 0.229, 
	TRAINING TIME: 12.57 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.508
	P, R  : 0.479, 0.54

==================================================================================================
	XP Ends: 23/4 (23 h:30)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,112            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
9              ,1              ,53             ,4              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.15           ,10             ,59             ,30             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
49             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 112, 9, 1, 53, 4, 13, 0.15, 10, 59, 30, True, 49, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (23h:30)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.15
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 49)        369705      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1141 (Flatten)          (None, 343)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1142 (Flatten)          (None, 108)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1143 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1144 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_390 (Concatenate)   (None, 464)          0           flatten_1141[0][0]               
                                                                 flatten_1142[0][0]               
                                                                 flatten_1143[0][0]               
                                                                 flatten_1144[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 30)           13950       concatenate_390[0][0]            
__________________________________________________________________________________________________
dense_61 (Dense)                (None, 152)          4712        posDense[0][0]                   
==================================================================================================
Total params: 399,245
Trainable params: 399,245
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.15
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 49)        369705      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1145 (Flatten)          (None, 343)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1146 (Flatten)          (None, 108)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1147 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1148 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1149 (Flatten)          (None, 343)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1150 (Flatten)          (None, 108)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1151 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1152 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1153 (Flatten)          (None, 343)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1154 (Flatten)          (None, 108)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1155 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1156 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1157 (Flatten)          (None, 343)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1158 (Flatten)          (None, 108)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1159 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1160 (Flatten)          (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_391 (Concatenate)   (None, 464)          0           flatten_1145[0][0]               
                                                                 flatten_1146[0][0]               
                                                                 flatten_1147[0][0]               
                                                                 flatten_1148[0][0]               
__________________________________________________________________________________________________
concatenate_392 (Concatenate)   (None, 464)          0           flatten_1149[0][0]               
                                                                 flatten_1150[0][0]               
                                                                 flatten_1151[0][0]               
                                                                 flatten_1152[0][0]               
__________________________________________________________________________________________________
concatenate_393 (Concatenate)   (None, 464)          0           flatten_1153[0][0]               
                                                                 flatten_1154[0][0]               
                                                                 flatten_1155[0][0]               
                                                                 flatten_1156[0][0]               
__________________________________________________________________________________________________
concatenate_394 (Concatenate)   (None, 464)          0           flatten_1157[0][0]               
                                                                 flatten_1158[0][0]               
                                                                 flatten_1159[0][0]               
                                                                 flatten_1160[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 30)           13950       concatenate_391[0][0]            
                                                                 concatenate_392[0][0]            
                                                                 concatenate_393[0][0]            
                                                                 concatenate_394[0][0]            
__________________________________________________________________________________________________
concatenate_395 (Concatenate)   (None, 120)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 112)          13552       concatenate_395[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            452         idenDense[0][0]                  
==================================================================================================
Total params: 408,537
Trainable params: 408,537
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2546 - acc: 0.9373
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0884 - acc: 0.9762
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0588 - acc: 0.9837
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0427 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0335 - acc: 0.9915
MWE identification:
Epoch 1/1
 - 18s - loss: 12.0875 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0417 - acc: 0.9890
MWE identification:
Epoch 1/1
 - 18s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0271 - acc: 0.9936
MWE identification:
Epoch 1/1
 - 18s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0231 - acc: 0.9947
MWE identification:
Epoch 1/1
 - 18s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0210 - acc: 0.9952
MWE identification:
Epoch 1/1
 - 18s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0196 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 18s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0183 - acc: 0.9960
POS tagging accuracy = 94.9
Loss = 0.301, 
POS tagging accuracy = 94.9
Loss = 0.301, 
	TRAINING TIME: 3.3 minutes 
==================================================================================================
	PARSING TIME: 1.6 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (23 h:35)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,50             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
12             ,8              ,94             ,3              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.141          ,9              ,62             ,136            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
124            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 50, 12, 8, 94, 3, 12, 0.141, 9, 62, 136, True, 124, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (23h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.141
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 124)       935580      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1161 (Flatten)          (None, 868)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1162 (Flatten)          (None, 144)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1163 (Flatten)          (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1164 (Flatten)          (None, 9)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_396 (Concatenate)   (None, 1045)         0           flatten_1161[0][0]               
                                                                 flatten_1162[0][0]               
                                                                 flatten_1163[0][0]               
                                                                 flatten_1164[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 136)          142256      concatenate_396[0][0]            
__________________________________________________________________________________________________
dense_62 (Dense)                (None, 152)          20824       posDense[0][0]                   
==================================================================================================
Total params: 1,113,104
Trainable params: 1,113,104
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.141
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 124)       935580      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1165 (Flatten)          (None, 868)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1166 (Flatten)          (None, 144)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1167 (Flatten)          (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1168 (Flatten)          (None, 9)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1169 (Flatten)          (None, 868)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1170 (Flatten)          (None, 144)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1171 (Flatten)          (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1172 (Flatten)          (None, 9)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1173 (Flatten)          (None, 868)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1174 (Flatten)          (None, 144)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1175 (Flatten)          (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1176 (Flatten)          (None, 9)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1177 (Flatten)          (None, 868)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1178 (Flatten)          (None, 144)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1179 (Flatten)          (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1180 (Flatten)          (None, 9)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1181 (Flatten)          (None, 868)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1182 (Flatten)          (None, 144)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1183 (Flatten)          (None, 24)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1184 (Flatten)          (None, 9)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_397 (Concatenate)   (None, 1045)         0           flatten_1165[0][0]               
                                                                 flatten_1166[0][0]               
                                                                 flatten_1167[0][0]               
                                                                 flatten_1168[0][0]               
__________________________________________________________________________________________________
concatenate_398 (Concatenate)   (None, 1045)         0           flatten_1169[0][0]               
                                                                 flatten_1170[0][0]               
                                                                 flatten_1171[0][0]               
                                                                 flatten_1172[0][0]               
__________________________________________________________________________________________________
concatenate_399 (Concatenate)   (None, 1045)         0           flatten_1173[0][0]               
                                                                 flatten_1174[0][0]               
                                                                 flatten_1175[0][0]               
                                                                 flatten_1176[0][0]               
__________________________________________________________________________________________________
concatenate_400 (Concatenate)   (None, 1045)         0           flatten_1177[0][0]               
                                                                 flatten_1178[0][0]               
                                                                 flatten_1179[0][0]               
                                                                 flatten_1180[0][0]               
__________________________________________________________________________________________________
concatenate_401 (Concatenate)   (None, 1045)         0           flatten_1181[0][0]               
                                                                 flatten_1182[0][0]               
                                                                 flatten_1183[0][0]               
                                                                 flatten_1184[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 136)          142256      concatenate_397[0][0]            
                                                                 concatenate_398[0][0]            
                                                                 concatenate_399[0][0]            
                                                                 concatenate_400[0][0]            
                                                                 concatenate_401[0][0]            
__________________________________________________________________________________________________
concatenate_402 (Concatenate)   (None, 680)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 50)           34050       concatenate_402[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            204         idenDense[0][0]                  
==================================================================================================
Total params: 1,126,534
Trainable params: 1,126,534
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2926 - acc: 0.9338
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0973 - acc: 0.9773
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0678 - acc: 0.9846
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0544 - acc: 0.9880
MWE identification:
Epoch 1/1
 - 13s - loss: 8.1340 - acc: 0.4951
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1192 - acc: 0.9724
MWE identification:
Epoch 1/1
 - 13s - loss: 8.1047 - acc: 0.4970
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0753 - acc: 0.9820
MWE identification:
Epoch 1/1
 - 13s - loss: 8.0863 - acc: 0.4981
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0569 - acc: 0.9867
MWE identification:
Epoch 1/1
 - 13s - loss: 8.0706 - acc: 0.4991
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0448 - acc: 0.9903
MWE identification:
Epoch 1/1
 - 13s - loss: 8.0679 - acc: 0.4994
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0393 - acc: 0.9919
MWE identification:
Epoch 1/1
 - 13s - loss: 8.0664 - acc: 0.4995
POS tagging accuracy = 94.7
Loss = 0.317, 
POS tagging accuracy = 94.7
Loss = 0.317, 
	TRAINING TIME: 3.05 minutes 
==================================================================================================
	PARSING TIME: 1.28 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (23 h:40)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,45             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
21             ,1              ,27             ,2              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.083          ,13             ,112            ,60             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
34             ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 45, 21, 1, 27, 2, 11, 0.083, 13, 112, 60, True, 34, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (23h:40)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 34)        388892      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 21)       24906       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1185 (Flatten)          (None, 238)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1186 (Flatten)          (None, 252)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1187 (Flatten)          (None, 13)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_403 (Concatenate)   (None, 503)          0           flatten_1185[0][0]               
                                                                 flatten_1186[0][0]               
                                                                 flatten_1187[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 60)           30240       concatenate_403[0][0]            
__________________________________________________________________________________________________
dense_63 (Dense)                (None, 152)          9272        posDense[0][0]                   
==================================================================================================
Total params: 453,570
Trainable params: 453,570
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 34)        388892      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 21)       24906       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1188 (Flatten)          (None, 238)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1189 (Flatten)          (None, 252)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1190 (Flatten)          (None, 13)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1191 (Flatten)          (None, 238)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1192 (Flatten)          (None, 252)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1193 (Flatten)          (None, 13)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1194 (Flatten)          (None, 238)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1195 (Flatten)          (None, 252)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1196 (Flatten)          (None, 13)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1197 (Flatten)          (None, 238)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1198 (Flatten)          (None, 252)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1199 (Flatten)          (None, 13)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1200 (Flatten)          (None, 238)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1201 (Flatten)          (None, 252)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1202 (Flatten)          (None, 13)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_404 (Concatenate)   (None, 503)          0           flatten_1188[0][0]               
                                                                 flatten_1189[0][0]               
                                                                 flatten_1190[0][0]               
__________________________________________________________________________________________________
concatenate_405 (Concatenate)   (None, 503)          0           flatten_1191[0][0]               
                                                                 flatten_1192[0][0]               
                                                                 flatten_1193[0][0]               
__________________________________________________________________________________________________
concatenate_406 (Concatenate)   (None, 503)          0           flatten_1194[0][0]               
                                                                 flatten_1195[0][0]               
                                                                 flatten_1196[0][0]               
__________________________________________________________________________________________________
concatenate_407 (Concatenate)   (None, 503)          0           flatten_1197[0][0]               
                                                                 flatten_1198[0][0]               
                                                                 flatten_1199[0][0]               
__________________________________________________________________________________________________
concatenate_408 (Concatenate)   (None, 503)          0           flatten_1200[0][0]               
                                                                 flatten_1201[0][0]               
                                                                 flatten_1202[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 60)           30240       concatenate_404[0][0]            
                                                                 concatenate_405[0][0]            
                                                                 concatenate_406[0][0]            
                                                                 concatenate_407[0][0]            
                                                                 concatenate_408[0][0]            
__________________________________________________________________________________________________
concatenate_409 (Concatenate)   (None, 300)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 45)           13545       concatenate_409[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            184         idenDense[0][0]                  
==================================================================================================
Total params: 458,027
Trainable params: 458,027
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2533 - acc: 0.9370
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0912 - acc: 0.9756
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0526 - acc: 0.9859
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0878 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0472 - acc: 0.9875
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0251 - acc: 0.9938
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0174 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0132 - acc: 0.9967
MWE identification:
Epoch 1/1
 - 33s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0103 - acc: 0.9976
POS tagging accuracy = 94.1
Loss = 0.278, 
POS tagging accuracy = 94.1
Loss = 0.278, 
	TRAINING TIME: 4.03 minutes 
==================================================================================================
	PARSING TIME: 1.9 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 23/4 (23 h:46)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,128            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
23             ,2              ,25             ,1              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.128          ,11             ,8              ,49             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
30             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 128, 23, 2, 25, 1, 9, 0.128, 11, 8, 49, True, 30, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (23h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.128
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 30)        226350      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 23)       27278       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 11)        220         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1203 (Flatten)          (None, 210)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1204 (Flatten)          (None, 276)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1205 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1206 (Flatten)          (None, 11)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_410 (Concatenate)   (None, 503)          0           flatten_1203[0][0]               
                                                                 flatten_1204[0][0]               
                                                                 flatten_1205[0][0]               
                                                                 flatten_1206[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 49)           24696       concatenate_410[0][0]            
__________________________________________________________________________________________________
dense_64 (Dense)                (None, 152)          7600        posDense[0][0]                   
==================================================================================================
Total params: 286,152
Trainable params: 286,152
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.128
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 30)        226350      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 23)       27278       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 11)        220         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1207 (Flatten)          (None, 210)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1208 (Flatten)          (None, 276)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1209 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1210 (Flatten)          (None, 11)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1211 (Flatten)          (None, 210)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1212 (Flatten)          (None, 276)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1213 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1214 (Flatten)          (None, 11)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1215 (Flatten)          (None, 210)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1216 (Flatten)          (None, 276)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1217 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1218 (Flatten)          (None, 11)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1219 (Flatten)          (None, 210)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1220 (Flatten)          (None, 276)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1221 (Flatten)          (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1222 (Flatten)          (None, 11)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1223 (Flatten)          (None, 210)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1224 (Flatten)          (None, 276)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1225 (Flatten)          (None, 6)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1226 (Flatten)          (None, 11)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_411 (Concatenate)   (None, 503)          0           flatten_1207[0][0]               
                                                                 flatten_1208[0][0]               
                                                                 flatten_1209[0][0]               
                                                                 flatten_1210[0][0]               
__________________________________________________________________________________________________
concatenate_412 (Concatenate)   (None, 503)          0           flatten_1211[0][0]               
                                                                 flatten_1212[0][0]               
                                                                 flatten_1213[0][0]               
                                                                 flatten_1214[0][0]               
__________________________________________________________________________________________________
concatenate_413 (Concatenate)   (None, 503)          0           flatten_1215[0][0]               
                                                                 flatten_1216[0][0]               
                                                                 flatten_1217[0][0]               
                                                                 flatten_1218[0][0]               
__________________________________________________________________________________________________
concatenate_414 (Concatenate)   (None, 503)          0           flatten_1219[0][0]               
                                                                 flatten_1220[0][0]               
                                                                 flatten_1221[0][0]               
                                                                 flatten_1222[0][0]               
__________________________________________________________________________________________________
concatenate_415 (Concatenate)   (None, 503)          0           flatten_1223[0][0]               
                                                                 flatten_1224[0][0]               
                                                                 flatten_1225[0][0]               
                                                                 flatten_1226[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 49)           24696       concatenate_411[0][0]            
                                                                 concatenate_412[0][0]            
                                                                 concatenate_413[0][0]            
                                                                 concatenate_414[0][0]            
                                                                 concatenate_415[0][0]            
__________________________________________________________________________________________________
concatenate_416 (Concatenate)   (None, 245)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 128)          31488       concatenate_416[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            516         idenDense[0][0]                  
==================================================================================================
Total params: 310,556
Trainable params: 310,556
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 13s - loss: 0.2559 - acc: 0.9377
POS tagging:
Epoch 1/1
 - 13s - loss: 0.0936 - acc: 0.9763
MWE identification:
Epoch 1/1
 - 41s - loss: 12.0774 - acc: 0.2506
POS tagging:
Epoch 1/1
 - 13s - loss: 0.1074 - acc: 0.9730
MWE identification:
Epoch 1/1
 - 41s - loss: 4.2730 - acc: 0.7349
POS tagging:
Epoch 1/1
 - 13s - loss: 0.0738 - acc: 0.9814
MWE identification:
Epoch 1/1
 - 41s - loss: 4.2620 - acc: 0.7356
POS tagging:
Epoch 1/1
 - 13s - loss: 0.0468 - acc: 0.9885
MWE identification:
Epoch 1/1
 - 41s - loss: 4.2619 - acc: 0.7356
POS tagging:
Epoch 1/1
 - 13s - loss: 0.0354 - acc: 0.9918
POS tagging accuracy = 94.8
Loss = 0.255, 
POS tagging accuracy = 94.8
Loss = 0.255, 
	TRAINING TIME: 5.5 minutes 
==================================================================================================
	PARSING TIME: 3.5 minutes 
==================================================================================================
	Identification : 0.002
	P, R  : 0.001, 0.066

==================================================================================================
	XP Ends: 23/4 (23 h:55)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,172            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
20             ,2              ,41             ,1              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.067          ,14             ,31             ,77             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
32             ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 172, 20, 2, 41, 1, 18, 0.067, 14, 31, 77, True, 32, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 23/4 (23h:55)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.067
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 32)        241440      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1227 (Flatten)          (None, 224)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1228 (Flatten)          (None, 240)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1229 (Flatten)          (None, 14)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_417 (Concatenate)   (None, 478)          0           flatten_1227[0][0]               
                                                                 flatten_1228[0][0]               
                                                                 flatten_1229[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 77)           36883       concatenate_417[0][0]            
__________________________________________________________________________________________________
dense_65 (Dense)                (None, 152)          11856       posDense[0][0]                   
==================================================================================================
Total params: 314,179
Trainable params: 314,179
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.067
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 32)        241440      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1230 (Flatten)          (None, 224)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1231 (Flatten)          (None, 240)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1232 (Flatten)          (None, 14)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1233 (Flatten)          (None, 224)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1234 (Flatten)          (None, 240)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1235 (Flatten)          (None, 14)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1236 (Flatten)          (None, 224)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1237 (Flatten)          (None, 240)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1238 (Flatten)          (None, 14)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1239 (Flatten)          (None, 224)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1240 (Flatten)          (None, 240)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1241 (Flatten)          (None, 14)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1242 (Flatten)          (None, 224)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1243 (Flatten)          (None, 240)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1244 (Flatten)          (None, 14)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_418 (Concatenate)   (None, 478)          0           flatten_1230[0][0]               
                                                                 flatten_1231[0][0]               
                                                                 flatten_1232[0][0]               
__________________________________________________________________________________________________
concatenate_419 (Concatenate)   (None, 478)          0           flatten_1233[0][0]               
                                                                 flatten_1234[0][0]               
                                                                 flatten_1235[0][0]               
__________________________________________________________________________________________________
concatenate_420 (Concatenate)   (None, 478)          0           flatten_1236[0][0]               
                                                                 flatten_1237[0][0]               
                                                                 flatten_1238[0][0]               
__________________________________________________________________________________________________
concatenate_421 (Concatenate)   (None, 478)          0           flatten_1239[0][0]               
                                                                 flatten_1240[0][0]               
                                                                 flatten_1241[0][0]               
__________________________________________________________________________________________________
concatenate_422 (Concatenate)   (None, 478)          0           flatten_1242[0][0]               
                                                                 flatten_1243[0][0]               
                                                                 flatten_1244[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 77)           36883       concatenate_418[0][0]            
                                                                 concatenate_419[0][0]            
                                                                 concatenate_420[0][0]            
                                                                 concatenate_421[0][0]            
                                                                 concatenate_422[0][0]            
__________________________________________________________________________________________________
concatenate_423 (Concatenate)   (None, 385)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 172)          66392       concatenate_423[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            692         idenDense[0][0]                  
==================================================================================================
Total params: 369,407
Trainable params: 369,407
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2007 - acc: 0.9507
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0662 - acc: 0.9819
MWE identification:
Epoch 1/1
 - 22s - loss: 12.0870 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0469 - acc: 0.9873
MWE identification:
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0248 - acc: 0.9935
MWE identification:
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0166 - acc: 0.9961
MWE identification:
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0120 - acc: 0.9972
MWE identification:
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0093 - acc: 0.9979
MWE identification:
Epoch 1/1
 - 22s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0075 - acc: 0.9983
MWE identification:
Epoch 1/1
 - 22s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0065 - acc: 0.9985
MWE identification:
Epoch 1/1
 - 21s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0056 - acc: 0.9986
MWE identification:
Epoch 1/1
 - 22s - loss: 12.0886 - acc: 0.2500
POS tagging accuracy = 95.5
Loss = 0.258, 
POS tagging accuracy = 95.5
Loss = 0.258, 
	TRAINING TIME: 5.25 minutes 
==================================================================================================
	PARSING TIME: 1.03 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (0 h:2)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,177            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,4              ,12             ,3              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.013          ,8              ,48             ,153            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
27             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 177, 6, 4, 12, 3, 16, 0.013, 8, 48, 153, True, 27, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (0h:2)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 27)        308826      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1245 (Flatten)          (None, 189)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1246 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1247 (Flatten)          (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1248 (Flatten)          (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_424 (Concatenate)   (None, 281)          0           flatten_1245[0][0]               
                                                                 flatten_1246[0][0]               
                                                                 flatten_1247[0][0]               
                                                                 flatten_1248[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 153)          43146       concatenate_424[0][0]            
__________________________________________________________________________________________________
dense_66 (Dense)                (None, 152)          23408       posDense[0][0]                   
==================================================================================================
Total params: 382,672
Trainable params: 382,672
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 27)        308826      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1249 (Flatten)          (None, 189)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1250 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1251 (Flatten)          (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1252 (Flatten)          (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1253 (Flatten)          (None, 189)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1254 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1255 (Flatten)          (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1256 (Flatten)          (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1257 (Flatten)          (None, 189)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1258 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1259 (Flatten)          (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1260 (Flatten)          (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1261 (Flatten)          (None, 189)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1262 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1263 (Flatten)          (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1264 (Flatten)          (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_425 (Concatenate)   (None, 281)          0           flatten_1249[0][0]               
                                                                 flatten_1250[0][0]               
                                                                 flatten_1251[0][0]               
                                                                 flatten_1252[0][0]               
__________________________________________________________________________________________________
concatenate_426 (Concatenate)   (None, 281)          0           flatten_1253[0][0]               
                                                                 flatten_1254[0][0]               
                                                                 flatten_1255[0][0]               
                                                                 flatten_1256[0][0]               
__________________________________________________________________________________________________
concatenate_427 (Concatenate)   (None, 281)          0           flatten_1257[0][0]               
                                                                 flatten_1258[0][0]               
                                                                 flatten_1259[0][0]               
                                                                 flatten_1260[0][0]               
__________________________________________________________________________________________________
concatenate_428 (Concatenate)   (None, 281)          0           flatten_1261[0][0]               
                                                                 flatten_1262[0][0]               
                                                                 flatten_1263[0][0]               
                                                                 flatten_1264[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 153)          43146       concatenate_425[0][0]            
                                                                 concatenate_426[0][0]            
                                                                 concatenate_427[0][0]            
                                                                 concatenate_428[0][0]            
__________________________________________________________________________________________________
concatenate_429 (Concatenate)   (None, 612)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 177)          108501      concatenate_429[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            712         idenDense[0][0]                  
==================================================================================================
Total params: 468,477
Trainable params: 468,477
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.3588 - acc: 0.9104
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1762 - acc: 0.9563
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1416 - acc: 0.9647
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1196 - acc: 0.9709
MWE identification:
Epoch 1/1
 - 73s - loss: 0.0736 - acc: 0.9808
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1247 - acc: 0.9696
MWE identification:
Epoch 1/1
 - 73s - loss: 0.0541 - acc: 0.9867
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1019 - acc: 0.9755
MWE identification:
Epoch 1/1
 - 79s - loss: 0.0498 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0879 - acc: 0.9786
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0477 - acc: 0.9887
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0777 - acc: 0.9813
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0465 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0696 - acc: 0.9832
MWE identification:
Epoch 1/1
 - 78s - loss: 0.0458 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0629 - acc: 0.9849
MWE identification:
Epoch 1/1
 - 73s - loss: 0.0453 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0575 - acc: 0.9864
MWE identification:
Epoch 1/1
 - 73s - loss: 0.0450 - acc: 0.9894
POS tagging accuracy = 93.9
Loss = 0.221, 
POS tagging accuracy = 93.9
Loss = 0.221, 
	TRAINING TIME: 11.82 minutes 
==================================================================================================
	PARSING TIME: 1.13 minutes 
==================================================================================================
	Identification : 0.493
	P, R  : 0.45, 0.545

==================================================================================================
	XP Ends: 24/4 (0 h:15)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,44             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,7              ,96             ,3              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.09           ,8              ,39             ,166            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
97             ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 44, 7, 7, 96, 3, 14, 0.09, 8, 39, 166, True, 97, False, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (0h:15)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.09
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 97)        731865      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1265 (Flatten)          (None, 679)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1266 (Flatten)          (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1267 (Flatten)          (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1268 (Flatten)          (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_430 (Concatenate)   (None, 792)          0           flatten_1265[0][0]               
                                                                 flatten_1266[0][0]               
                                                                 flatten_1267[0][0]               
                                                                 flatten_1268[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 166)          131638      concatenate_430[0][0]            
__________________________________________________________________________________________________
dense_67 (Dense)                (None, 152)          25384       posDense[0][0]                   
==================================================================================================
Total params: 897,377
Trainable params: 897,377
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.09
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 97)        731865      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1269 (Flatten)          (None, 679)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1270 (Flatten)          (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1271 (Flatten)          (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1272 (Flatten)          (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1273 (Flatten)          (None, 679)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1274 (Flatten)          (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1275 (Flatten)          (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1276 (Flatten)          (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1277 (Flatten)          (None, 679)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1278 (Flatten)          (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1279 (Flatten)          (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1280 (Flatten)          (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_431 (Concatenate)   (None, 792)          0           flatten_1269[0][0]               
                                                                 flatten_1270[0][0]               
                                                                 flatten_1271[0][0]               
                                                                 flatten_1272[0][0]               
__________________________________________________________________________________________________
concatenate_432 (Concatenate)   (None, 792)          0           flatten_1273[0][0]               
                                                                 flatten_1274[0][0]               
                                                                 flatten_1275[0][0]               
                                                                 flatten_1276[0][0]               
__________________________________________________________________________________________________
concatenate_433 (Concatenate)   (None, 792)          0           flatten_1277[0][0]               
                                                                 flatten_1278[0][0]               
                                                                 flatten_1279[0][0]               
                                                                 flatten_1280[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 166)          131638      concatenate_431[0][0]            
                                                                 concatenate_432[0][0]            
                                                                 concatenate_433[0][0]            
__________________________________________________________________________________________________
concatenate_434 (Concatenate)   (None, 498)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 44)           21956       concatenate_434[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            180         idenDense[0][0]                  
==================================================================================================
Total params: 894,129
Trainable params: 894,129
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2274 - acc: 0.9457
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0664 - acc: 0.9825
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0376 - acc: 0.9905
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0251 - acc: 0.9939
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0832 - acc: 0.9806
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0847 - acc: 0.9793
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0527 - acc: 0.9870
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0339 - acc: 0.9921
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0468 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0197 - acc: 0.9957
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0451 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0154 - acc: 0.9969
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0446 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0131 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0120 - acc: 0.9976
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0442 - acc: 0.9895
POS tagging accuracy = 94.6
Loss = 0.334, 
POS tagging accuracy = 94.6
Loss = 0.334, 
	TRAINING TIME: 2.53 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.599
	P, R  : 0.683, 0.534

==================================================================================================
	XP Ends: 24/4 (0 h:19)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,87             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,1              ,112            ,3              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.022          ,8              ,16             ,126            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
154            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 87, 5, 1, 112, 3, 10, 0.022, 8, 16, 126, True, 154, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (0h:19)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 154)       1761452     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1281 (Flatten)          (None, 1078)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1282 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1283 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1284 (Flatten)          (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_435 (Concatenate)   (None, 1149)         0           flatten_1281[0][0]               
                                                                 flatten_1282[0][0]               
                                                                 flatten_1283[0][0]               
                                                                 flatten_1284[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 126)          144900      concatenate_435[0][0]            
__________________________________________________________________________________________________
dense_68 (Dense)                (None, 152)          19304       posDense[0][0]                   
==================================================================================================
Total params: 1,931,750
Trainable params: 1,931,750
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 154)       1761452     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1285 (Flatten)          (None, 1078)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1286 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1287 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1288 (Flatten)          (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1289 (Flatten)          (None, 1078)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1290 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1291 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1292 (Flatten)          (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1293 (Flatten)          (None, 1078)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1294 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1295 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1296 (Flatten)          (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1297 (Flatten)          (None, 1078)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1298 (Flatten)          (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1299 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1300 (Flatten)          (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1301 (Flatten)          (None, 1078)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1302 (Flatten)          (None, 60)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1303 (Flatten)          (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1304 (Flatten)          (None, 8)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_436 (Concatenate)   (None, 1149)         0           flatten_1285[0][0]               
                                                                 flatten_1286[0][0]               
                                                                 flatten_1287[0][0]               
                                                                 flatten_1288[0][0]               
__________________________________________________________________________________________________
concatenate_437 (Concatenate)   (None, 1149)         0           flatten_1289[0][0]               
                                                                 flatten_1290[0][0]               
                                                                 flatten_1291[0][0]               
                                                                 flatten_1292[0][0]               
__________________________________________________________________________________________________
concatenate_438 (Concatenate)   (None, 1149)         0           flatten_1293[0][0]               
                                                                 flatten_1294[0][0]               
                                                                 flatten_1295[0][0]               
                                                                 flatten_1296[0][0]               
__________________________________________________________________________________________________
concatenate_439 (Concatenate)   (None, 1149)         0           flatten_1297[0][0]               
                                                                 flatten_1298[0][0]               
                                                                 flatten_1299[0][0]               
                                                                 flatten_1300[0][0]               
__________________________________________________________________________________________________
concatenate_440 (Concatenate)   (None, 1149)         0           flatten_1301[0][0]               
                                                                 flatten_1302[0][0]               
                                                                 flatten_1303[0][0]               
                                                                 flatten_1304[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 126)          144900      concatenate_436[0][0]            
                                                                 concatenate_437[0][0]            
                                                                 concatenate_438[0][0]            
                                                                 concatenate_439[0][0]            
                                                                 concatenate_440[0][0]            
__________________________________________________________________________________________________
concatenate_441 (Concatenate)   (None, 630)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 87)           54897       concatenate_441[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            352         idenDense[0][0]                  
==================================================================================================
Total params: 1,967,695
Trainable params: 1,967,695
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.2476 - acc: 0.9362
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1006 - acc: 0.9744
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0619 - acc: 0.9841
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0421 - acc: 0.9896
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0706 - acc: 0.9829
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0603 - acc: 0.9845
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0484 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0346 - acc: 0.9918
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0457 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0247 - acc: 0.9947
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0449 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0193 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0446 - acc: 0.9895
POS tagging accuracy = 93.5
Loss = 0.269, 
POS tagging accuracy = 93.5
Loss = 0.269, 
	TRAINING TIME: 3.65 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.547
	P, R  : 0.566, 0.53

==================================================================================================
	XP Ends: 24/4 (0 h:24)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,114            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,5              ,65             ,4              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.034          ,10             ,25             ,64             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
148            ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 114, 7, 5, 65, 4, 11, 0.034, 10, 25, 64, True, 148, False, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (0h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 148)       1116660     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1305 (Flatten)          (None, 1036)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1306 (Flatten)          (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1307 (Flatten)          (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1308 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_442 (Concatenate)   (None, 1145)         0           flatten_1305[0][0]               
                                                                 flatten_1306[0][0]               
                                                                 flatten_1307[0][0]               
                                                                 flatten_1308[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 64)           73344       concatenate_442[0][0]            
__________________________________________________________________________________________________
dense_69 (Dense)                (None, 152)          9880        posDense[0][0]                   
==================================================================================================
Total params: 1,208,406
Trainable params: 1,208,406
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.034
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 148)       1116660     b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1309 (Flatten)          (None, 1036)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1310 (Flatten)          (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1311 (Flatten)          (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1312 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1313 (Flatten)          (None, 1036)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1314 (Flatten)          (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1315 (Flatten)          (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1316 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1317 (Flatten)          (None, 1036)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1318 (Flatten)          (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1319 (Flatten)          (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1320 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_443 (Concatenate)   (None, 1145)         0           flatten_1309[0][0]               
                                                                 flatten_1310[0][0]               
                                                                 flatten_1311[0][0]               
                                                                 flatten_1312[0][0]               
__________________________________________________________________________________________________
concatenate_444 (Concatenate)   (None, 1145)         0           flatten_1313[0][0]               
                                                                 flatten_1314[0][0]               
                                                                 flatten_1315[0][0]               
                                                                 flatten_1316[0][0]               
__________________________________________________________________________________________________
concatenate_445 (Concatenate)   (None, 1145)         0           flatten_1317[0][0]               
                                                                 flatten_1318[0][0]               
                                                                 flatten_1319[0][0]               
                                                                 flatten_1320[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 64)           73344       concatenate_443[0][0]            
                                                                 concatenate_444[0][0]            
                                                                 concatenate_445[0][0]            
__________________________________________________________________________________________________
concatenate_446 (Concatenate)   (None, 192)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 114)          22002       concatenate_446[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            460         idenDense[0][0]                  
==================================================================================================
Total params: 1,220,988
Trainable params: 1,220,988
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.2019 - acc: 0.9495
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0624 - acc: 0.9830
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0355 - acc: 0.9904
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0228 - acc: 0.9943
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0161 - acc: 0.9961
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0679 - acc: 0.9834
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0444 - acc: 0.9882
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0495 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0197 - acc: 0.9958
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0462 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0127 - acc: 0.9972
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0451 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0095 - acc: 0.9980
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0446 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0076 - acc: 0.9982
POS tagging accuracy = 95.0
Loss = 0.256, 
POS tagging accuracy = 95.0
Loss = 0.256, 
	TRAINING TIME: 3.18 minutes 
==================================================================================================
	PARSING TIME: 0.85 minutes 
==================================================================================================
	Identification : 0.599
	P, R  : 0.746, 0.5

==================================================================================================
	XP Ends: 24/4 (0 h:28)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,57             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
18             ,4              ,21             ,3              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.01           ,8              ,8              ,28             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
46             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 57, 18, 4, 21, 3, 9, 0.01, 8, 8, 28, True, 46, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (0h:28)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 46)        347070      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1321 (Flatten)          (None, 322)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1322 (Flatten)          (None, 216)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1323 (Flatten)          (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1324 (Flatten)          (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_447 (Concatenate)   (None, 558)          0           flatten_1321[0][0]               
                                                                 flatten_1322[0][0]               
                                                                 flatten_1323[0][0]               
                                                                 flatten_1324[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 28)           15652       concatenate_447[0][0]            
__________________________________________________________________________________________________
dense_70 (Dense)                (None, 152)          4408        posDense[0][0]                   
==================================================================================================
Total params: 388,654
Trainable params: 388,654
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 46)        347070      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1325 (Flatten)          (None, 322)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1326 (Flatten)          (None, 216)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1327 (Flatten)          (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1328 (Flatten)          (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1329 (Flatten)          (None, 322)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1330 (Flatten)          (None, 216)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1331 (Flatten)          (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1332 (Flatten)          (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1333 (Flatten)          (None, 322)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1334 (Flatten)          (None, 216)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1335 (Flatten)          (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1336 (Flatten)          (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1337 (Flatten)          (None, 322)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1338 (Flatten)          (None, 216)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1339 (Flatten)          (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1340 (Flatten)          (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_448 (Concatenate)   (None, 558)          0           flatten_1325[0][0]               
                                                                 flatten_1326[0][0]               
                                                                 flatten_1327[0][0]               
                                                                 flatten_1328[0][0]               
__________________________________________________________________________________________________
concatenate_449 (Concatenate)   (None, 558)          0           flatten_1329[0][0]               
                                                                 flatten_1330[0][0]               
                                                                 flatten_1331[0][0]               
                                                                 flatten_1332[0][0]               
__________________________________________________________________________________________________
concatenate_450 (Concatenate)   (None, 558)          0           flatten_1333[0][0]               
                                                                 flatten_1334[0][0]               
                                                                 flatten_1335[0][0]               
                                                                 flatten_1336[0][0]               
__________________________________________________________________________________________________
concatenate_451 (Concatenate)   (None, 558)          0           flatten_1337[0][0]               
                                                                 flatten_1338[0][0]               
                                                                 flatten_1339[0][0]               
                                                                 flatten_1340[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 28)           15652       concatenate_448[0][0]            
                                                                 concatenate_449[0][0]            
                                                                 concatenate_450[0][0]            
                                                                 concatenate_451[0][0]            
__________________________________________________________________________________________________
concatenate_452 (Concatenate)   (None, 112)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 57)           6441        concatenate_452[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            232         idenDense[0][0]                  
==================================================================================================
Total params: 390,919
Trainable params: 390,919
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 14s - loss: 0.4598 - acc: 0.8917
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1879 - acc: 0.9602
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1450 - acc: 0.9691
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1231 - acc: 0.9725
MWE identification:
Epoch 1/1
 - 42s - loss: 0.0807 - acc: 0.9792
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1236 - acc: 0.9717
MWE identification:
Epoch 1/1
 - 43s - loss: 0.0610 - acc: 0.9849
POS tagging:
Epoch 1/1
 - 14s - loss: 0.1070 - acc: 0.9749
MWE identification:
Epoch 1/1
 - 42s - loss: 0.0569 - acc: 0.9860
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0972 - acc: 0.9764
MWE identification:
Epoch 1/1
 - 42s - loss: 0.0545 - acc: 0.9867
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0897 - acc: 0.9780
POS tagging accuracy = 95.0
Loss = 0.186, 
POS tagging accuracy = 95.0
Loss = 0.186, 
	TRAINING TIME: 5.78 minutes 
==================================================================================================
	PARSING TIME: 1.05 minutes 
==================================================================================================
	Identification : 0.58
	P, R  : 0.802, 0.454

==================================================================================================
	XP Ends: 24/4 (0 h:35)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,61             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,9              ,16             ,1              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.011          ,7              ,60             ,152            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
116            ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 61, 13, 9, 16, 1, 16, 0.011, 7, 60, 152, True, 116, False, False, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (0h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 116)       1326808     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1341 (Flatten)          (None, 812)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1342 (Flatten)          (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1343 (Flatten)          (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_453 (Concatenate)   (None, 975)          0           flatten_1341[0][0]               
                                                                 flatten_1342[0][0]               
                                                                 flatten_1343[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 152)          148352      concatenate_453[0][0]            
__________________________________________________________________________________________________
dense_71 (Dense)                (None, 152)          23256       posDense[0][0]                   
==================================================================================================
Total params: 1,513,974
Trainable params: 1,513,974
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 116)       1326808     b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1344 (Flatten)          (None, 812)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1345 (Flatten)          (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1346 (Flatten)          (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1347 (Flatten)          (None, 812)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1348 (Flatten)          (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1349 (Flatten)          (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1350 (Flatten)          (None, 812)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1351 (Flatten)          (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1352 (Flatten)          (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_454 (Concatenate)   (None, 975)          0           flatten_1344[0][0]               
                                                                 flatten_1345[0][0]               
                                                                 flatten_1346[0][0]               
__________________________________________________________________________________________________
concatenate_455 (Concatenate)   (None, 975)          0           flatten_1347[0][0]               
                                                                 flatten_1348[0][0]               
                                                                 flatten_1349[0][0]               
__________________________________________________________________________________________________
concatenate_456 (Concatenate)   (None, 975)          0           flatten_1350[0][0]               
                                                                 flatten_1351[0][0]               
                                                                 flatten_1352[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 152)          148352      concatenate_454[0][0]            
                                                                 concatenate_455[0][0]            
                                                                 concatenate_456[0][0]            
__________________________________________________________________________________________________
concatenate_457 (Concatenate)   (None, 456)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 61)           27877       concatenate_457[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            248         idenDense[0][0]                  
==================================================================================================
Total params: 1,518,843
Trainable params: 1,518,843
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.3109 - acc: 0.9242
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1457 - acc: 0.9646
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0673 - acc: 0.9826
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1230 - acc: 0.9701
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0505 - acc: 0.9877
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0907 - acc: 0.9783
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0474 - acc: 0.9887
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0732 - acc: 0.9826
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0460 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0609 - acc: 0.9857
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0452 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0521 - acc: 0.9878
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0454 - acc: 0.9893
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0447 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0401 - acc: 0.9909
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0445 - acc: 0.9895
POS tagging accuracy = 94.1
Loss = 0.228, 
POS tagging accuracy = 94.1
Loss = 0.228, 
	TRAINING TIME: 7.12 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.515
	P, R  : 0.502, 0.528

==================================================================================================
	XP Ends: 24/4 (0 h:43)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,57             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,1              ,35             ,1              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.011          ,10             ,28             ,52             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
55             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 57, 8, 1, 35, 1, 9, 0.011, 10, 28, 52, True, 55, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (0h:43)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 55)        414975      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1353 (Flatten)          (None, 385)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1354 (Flatten)          (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1355 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1356 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_458 (Concatenate)   (None, 494)          0           flatten_1353[0][0]               
                                                                 flatten_1354[0][0]               
                                                                 flatten_1355[0][0]               
                                                                 flatten_1356[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 52)           25740       concatenate_458[0][0]            
__________________________________________________________________________________________________
dense_72 (Dense)                (None, 152)          8056        posDense[0][0]                   
==================================================================================================
Total params: 458,463
Trainable params: 458,463
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 55)        414975      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1357 (Flatten)          (None, 385)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1358 (Flatten)          (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1359 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1360 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1361 (Flatten)          (None, 385)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1362 (Flatten)          (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1363 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1364 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1365 (Flatten)          (None, 385)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1366 (Flatten)          (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1367 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1368 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1369 (Flatten)          (None, 385)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1370 (Flatten)          (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1371 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1372 (Flatten)          (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1373 (Flatten)          (None, 385)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1374 (Flatten)          (None, 96)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1375 (Flatten)          (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1376 (Flatten)          (None, 10)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_459 (Concatenate)   (None, 494)          0           flatten_1357[0][0]               
                                                                 flatten_1358[0][0]               
                                                                 flatten_1359[0][0]               
                                                                 flatten_1360[0][0]               
__________________________________________________________________________________________________
concatenate_460 (Concatenate)   (None, 494)          0           flatten_1361[0][0]               
                                                                 flatten_1362[0][0]               
                                                                 flatten_1363[0][0]               
                                                                 flatten_1364[0][0]               
__________________________________________________________________________________________________
concatenate_461 (Concatenate)   (None, 494)          0           flatten_1365[0][0]               
                                                                 flatten_1366[0][0]               
                                                                 flatten_1367[0][0]               
                                                                 flatten_1368[0][0]               
__________________________________________________________________________________________________
concatenate_462 (Concatenate)   (None, 494)          0           flatten_1369[0][0]               
                                                                 flatten_1370[0][0]               
                                                                 flatten_1371[0][0]               
                                                                 flatten_1372[0][0]               
__________________________________________________________________________________________________
concatenate_463 (Concatenate)   (None, 494)          0           flatten_1373[0][0]               
                                                                 flatten_1374[0][0]               
                                                                 flatten_1375[0][0]               
                                                                 flatten_1376[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 52)           25740       concatenate_459[0][0]            
                                                                 concatenate_460[0][0]            
                                                                 concatenate_461[0][0]            
                                                                 concatenate_462[0][0]            
                                                                 concatenate_463[0][0]            
__________________________________________________________________________________________________
concatenate_464 (Concatenate)   (None, 260)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 57)           14877       concatenate_464[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            232         idenDense[0][0]                  
==================================================================================================
Total params: 465,516
Trainable params: 465,516
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.3985 - acc: 0.9072
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1546 - acc: 0.9663
MWE identification:
Epoch 1/1
 - 32s - loss: 0.0765 - acc: 0.9804
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1332 - acc: 0.9699
MWE identification:
Epoch 1/1
 - 32s - loss: 0.0580 - acc: 0.9858
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1080 - acc: 0.9748
MWE identification:
Epoch 1/1
 - 32s - loss: 0.0538 - acc: 0.9869
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0939 - acc: 0.9769
MWE identification:
Epoch 1/1
 - 32s - loss: 0.0515 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0839 - acc: 0.9795
POS tagging accuracy = 95.0
Loss = 0.202, 
POS tagging accuracy = 95.0
Loss = 0.202, 
	TRAINING TIME: 3.97 minutes 
==================================================================================================
	PARSING TIME: 1.27 minutes 
==================================================================================================
	Identification : 0.571
	P, R  : 0.838, 0.433

==================================================================================================
	XP Ends: 24/4 (0 h:49)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,54             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,1              ,37             ,1              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.013          ,5              ,50             ,46             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
25             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 54, 8, 1, 37, 1, 18, 0.013, 5, 50, 46, True, 25, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (0h:49)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 25)        188625      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1377 (Flatten)          (None, 175)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1378 (Flatten)          (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1379 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1380 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_465 (Concatenate)   (None, 279)          0           flatten_1377[0][0]               
                                                                 flatten_1378[0][0]               
                                                                 flatten_1379[0][0]               
                                                                 flatten_1380[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 46)           12880       concatenate_465[0][0]            
__________________________________________________________________________________________________
dense_73 (Dense)                (None, 152)          7144        posDense[0][0]                   
==================================================================================================
Total params: 218,241
Trainable params: 218,241
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 25)        188625      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1381 (Flatten)          (None, 175)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1382 (Flatten)          (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1383 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1384 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1385 (Flatten)          (None, 175)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1386 (Flatten)          (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1387 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1388 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1389 (Flatten)          (None, 175)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1390 (Flatten)          (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1391 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1392 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1393 (Flatten)          (None, 175)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1394 (Flatten)          (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1395 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1396 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_466 (Concatenate)   (None, 279)          0           flatten_1381[0][0]               
                                                                 flatten_1382[0][0]               
                                                                 flatten_1383[0][0]               
                                                                 flatten_1384[0][0]               
__________________________________________________________________________________________________
concatenate_467 (Concatenate)   (None, 279)          0           flatten_1385[0][0]               
                                                                 flatten_1386[0][0]               
                                                                 flatten_1387[0][0]               
                                                                 flatten_1388[0][0]               
__________________________________________________________________________________________________
concatenate_468 (Concatenate)   (None, 279)          0           flatten_1389[0][0]               
                                                                 flatten_1390[0][0]               
                                                                 flatten_1391[0][0]               
                                                                 flatten_1392[0][0]               
__________________________________________________________________________________________________
concatenate_469 (Concatenate)   (None, 279)          0           flatten_1393[0][0]               
                                                                 flatten_1394[0][0]               
                                                                 flatten_1395[0][0]               
                                                                 flatten_1396[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 46)           12880       concatenate_466[0][0]            
                                                                 concatenate_467[0][0]            
                                                                 concatenate_468[0][0]            
                                                                 concatenate_469[0][0]            
__________________________________________________________________________________________________
concatenate_470 (Concatenate)   (None, 184)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 54)           9990        concatenate_470[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            220         idenDense[0][0]                  
==================================================================================================
Total params: 221,307
Trainable params: 221,307
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.4734 - acc: 0.8858
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1774 - acc: 0.9605
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0792 - acc: 0.9795
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1486 - acc: 0.9666
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0594 - acc: 0.9852
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1199 - acc: 0.9719
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0551 - acc: 0.9864
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1046 - acc: 0.9744
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0528 - acc: 0.9870
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0939 - acc: 0.9765
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0511 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0857 - acc: 0.9785
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0500 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0791 - acc: 0.9803
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0491 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0736 - acc: 0.9820
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0484 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0688 - acc: 0.9832
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0478 - acc: 0.9886
POS tagging accuracy = 95.2
Loss = 0.204, 
POS tagging accuracy = 95.2
Loss = 0.204, 
	TRAINING TIME: 5.2 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.6
	P, R  : 0.757, 0.497

==================================================================================================
	XP Ends: 24/4 (0 h:56)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,37             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
18             ,1              ,47             ,4              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.151          ,6              ,27             ,60             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
145            ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 37, 18, 1, 47, 4, 18, 0.151, 6, 27, 60, True, 145, False, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (0h:56)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.151
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 145)       1094025     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1397 (Flatten)          (None, 1015)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1398 (Flatten)          (None, 216)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1399 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_471 (Concatenate)   (None, 1237)         0           flatten_1397[0][0]               
                                                                 flatten_1398[0][0]               
                                                                 flatten_1399[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 60)           74280       concatenate_471[0][0]            
__________________________________________________________________________________________________
dense_74 (Dense)                (None, 152)          9272        posDense[0][0]                   
==================================================================================================
Total params: 1,199,045
Trainable params: 1,199,045
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.151
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 145)       1094025     bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1400 (Flatten)          (None, 1015)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1401 (Flatten)          (None, 216)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1402 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1403 (Flatten)          (None, 1015)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1404 (Flatten)          (None, 216)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1405 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1406 (Flatten)          (None, 1015)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1407 (Flatten)          (None, 216)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1408 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1409 (Flatten)          (None, 1015)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1410 (Flatten)          (None, 216)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1411 (Flatten)          (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_472 (Concatenate)   (None, 1237)         0           flatten_1400[0][0]               
                                                                 flatten_1401[0][0]               
                                                                 flatten_1402[0][0]               
__________________________________________________________________________________________________
concatenate_473 (Concatenate)   (None, 1237)         0           flatten_1403[0][0]               
                                                                 flatten_1404[0][0]               
                                                                 flatten_1405[0][0]               
__________________________________________________________________________________________________
concatenate_474 (Concatenate)   (None, 1237)         0           flatten_1406[0][0]               
                                                                 flatten_1407[0][0]               
                                                                 flatten_1408[0][0]               
__________________________________________________________________________________________________
concatenate_475 (Concatenate)   (None, 1237)         0           flatten_1409[0][0]               
                                                                 flatten_1410[0][0]               
                                                                 flatten_1411[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 60)           74280       concatenate_472[0][0]            
                                                                 concatenate_473[0][0]            
                                                                 concatenate_474[0][0]            
                                                                 concatenate_475[0][0]            
__________________________________________________________________________________________________
concatenate_476 (Concatenate)   (None, 240)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 37)           8917        concatenate_476[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            152         idenDense[0][0]                  
==================================================================================================
Total params: 1,198,842
Trainable params: 1,198,842
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.3367 - acc: 0.9250
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1253 - acc: 0.9728
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0863 - acc: 0.9809
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0701 - acc: 0.9853
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0624 - acc: 0.9878
MWE identification:
Epoch 1/1
 - 18s - loss: 4.2756 - acc: 0.7346
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1320 - acc: 0.9719
MWE identification:
Epoch 1/1
 - 18s - loss: 0.4444 - acc: 0.9660
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1650 - acc: 0.9666
MWE identification:
Epoch 1/1
 - 18s - loss: 0.1165 - acc: 0.9800
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0897 - acc: 0.9832
MWE identification:
Epoch 1/1
 - 18s - loss: 0.1043 - acc: 0.9831
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0744 - acc: 0.9865
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0847 - acc: 0.9848
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0714 - acc: 0.9869
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0588 - acc: 0.9869
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0627 - acc: 0.9890
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0526 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0584 - acc: 0.9903
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0499 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0558 - acc: 0.9909
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0486 - acc: 0.9889
POS tagging accuracy = 94.3
Loss = 0.379, 
POS tagging accuracy = 94.3
Loss = 0.379, 
	TRAINING TIME: 4.65 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.553
	P, R  : 0.597, 0.515

==================================================================================================
	XP Ends: 24/4 (1 h:1)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,196            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,2              ,107            ,3              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.042          ,5              ,11             ,31             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
71             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 196, 5, 2, 107, 3, 12, 0.042, 5, 11, 31, True, 71, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (1h:1)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.042
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 71)        535695      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1412 (Flatten)          (None, 497)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1413 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1414 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1415 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_477 (Concatenate)   (None, 568)          0           flatten_1412[0][0]               
                                                                 flatten_1413[0][0]               
                                                                 flatten_1414[0][0]               
                                                                 flatten_1415[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 31)           17639       concatenate_477[0][0]            
__________________________________________________________________________________________________
dense_75 (Dense)                (None, 152)          4864        posDense[0][0]                   
==================================================================================================
Total params: 564,236
Trainable params: 564,236
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.042
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 71)        535695      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1416 (Flatten)          (None, 497)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1417 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1418 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1419 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1420 (Flatten)          (None, 497)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1421 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1422 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1423 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1424 (Flatten)          (None, 497)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1425 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1426 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1427 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1428 (Flatten)          (None, 497)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1429 (Flatten)          (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1430 (Flatten)          (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1431 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1432 (Flatten)          (None, 497)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1433 (Flatten)          (None, 60)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1434 (Flatten)          (None, 6)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1435 (Flatten)          (None, 5)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_478 (Concatenate)   (None, 568)          0           flatten_1416[0][0]               
                                                                 flatten_1417[0][0]               
                                                                 flatten_1418[0][0]               
                                                                 flatten_1419[0][0]               
__________________________________________________________________________________________________
concatenate_479 (Concatenate)   (None, 568)          0           flatten_1420[0][0]               
                                                                 flatten_1421[0][0]               
                                                                 flatten_1422[0][0]               
                                                                 flatten_1423[0][0]               
__________________________________________________________________________________________________
concatenate_480 (Concatenate)   (None, 568)          0           flatten_1424[0][0]               
                                                                 flatten_1425[0][0]               
                                                                 flatten_1426[0][0]               
                                                                 flatten_1427[0][0]               
__________________________________________________________________________________________________
concatenate_481 (Concatenate)   (None, 568)          0           flatten_1428[0][0]               
                                                                 flatten_1429[0][0]               
                                                                 flatten_1430[0][0]               
                                                                 flatten_1431[0][0]               
__________________________________________________________________________________________________
concatenate_482 (Concatenate)   (None, 568)          0           flatten_1432[0][0]               
                                                                 flatten_1433[0][0]               
                                                                 flatten_1434[0][0]               
                                                                 flatten_1435[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 31)           17639       concatenate_478[0][0]            
                                                                 concatenate_479[0][0]            
                                                                 concatenate_480[0][0]            
                                                                 concatenate_481[0][0]            
                                                                 concatenate_482[0][0]            
__________________________________________________________________________________________________
concatenate_483 (Concatenate)   (None, 155)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 196)          30576       concatenate_483[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            788         idenDense[0][0]                  
==================================================================================================
Total params: 590,736
Trainable params: 590,736
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 10s - loss: 0.2152 - acc: 0.9467
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0759 - acc: 0.9798
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0481 - acc: 0.9873
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0335 - acc: 0.9917
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0821 - acc: 0.4983
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0363 - acc: 0.9914
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0220 - acc: 0.9947
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0171 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0144 - acc: 0.9967
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0123 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 11s - loss: 8.0591 - acc: 0.5000
POS tagging accuracy = 95.1
Loss = 0.222, 
POS tagging accuracy = 95.1
Loss = 0.222, 
	TRAINING TIME: 4.03 minutes 
==================================================================================================
	PARSING TIME: 2.32 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (1 h:8)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,161            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
16             ,1              ,13             ,2              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.054          ,10             ,98             ,84             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
36             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 161, 16, 1, 13, 2, 11, 0.054, 10, 98, 84, True, 36, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (1h:8)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 36)        271620      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 16)       18976       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1436 (Flatten)          (None, 252)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1437 (Flatten)          (None, 192)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1438 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1439 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_484 (Concatenate)   (None, 457)          0           flatten_1436[0][0]               
                                                                 flatten_1437[0][0]               
                                                                 flatten_1438[0][0]               
                                                                 flatten_1439[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 84)           38472       concatenate_484[0][0]            
__________________________________________________________________________________________________
dense_76 (Dense)                (None, 152)          12920       posDense[0][0]                   
==================================================================================================
Total params: 342,192
Trainable params: 342,192
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 36)        271620      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 16)       18976       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1440 (Flatten)          (None, 252)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1441 (Flatten)          (None, 192)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1442 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1443 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1444 (Flatten)          (None, 252)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1445 (Flatten)          (None, 192)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1446 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1447 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1448 (Flatten)          (None, 252)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1449 (Flatten)          (None, 192)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1450 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1451 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1452 (Flatten)          (None, 252)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1453 (Flatten)          (None, 192)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1454 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1455 (Flatten)          (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_485 (Concatenate)   (None, 457)          0           flatten_1440[0][0]               
                                                                 flatten_1441[0][0]               
                                                                 flatten_1442[0][0]               
                                                                 flatten_1443[0][0]               
__________________________________________________________________________________________________
concatenate_486 (Concatenate)   (None, 457)          0           flatten_1444[0][0]               
                                                                 flatten_1445[0][0]               
                                                                 flatten_1446[0][0]               
                                                                 flatten_1447[0][0]               
__________________________________________________________________________________________________
concatenate_487 (Concatenate)   (None, 457)          0           flatten_1448[0][0]               
                                                                 flatten_1449[0][0]               
                                                                 flatten_1450[0][0]               
                                                                 flatten_1451[0][0]               
__________________________________________________________________________________________________
concatenate_488 (Concatenate)   (None, 457)          0           flatten_1452[0][0]               
                                                                 flatten_1453[0][0]               
                                                                 flatten_1454[0][0]               
                                                                 flatten_1455[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 84)           38472       concatenate_485[0][0]            
                                                                 concatenate_486[0][0]            
                                                                 concatenate_487[0][0]            
                                                                 concatenate_488[0][0]            
__________________________________________________________________________________________________
concatenate_489 (Concatenate)   (None, 336)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 161)          54257       concatenate_489[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            648         idenDense[0][0]                  
==================================================================================================
Total params: 384,177
Trainable params: 384,177
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2090 - acc: 0.9480
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0647 - acc: 0.9824
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0366 - acc: 0.9898
MWE identification:
Epoch 1/1
 - 71s - loss: 0.0702 - acc: 0.9829
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0639 - acc: 0.9823
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0503 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0295 - acc: 0.9926
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0468 - acc: 0.9887
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0175 - acc: 0.9962
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0453 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0120 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 74s - loss: 0.0447 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0086 - acc: 0.9982
POS tagging accuracy = 94.4
Loss = 0.268, 
POS tagging accuracy = 94.4
Loss = 0.268, 
	TRAINING TIME: 7.08 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.706, 0.488

==================================================================================================
	XP Ends: 24/4 (1 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,108            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
21             ,7              ,23             ,4              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.028          ,14             ,12             ,99             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
29             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 108, 21, 7, 23, 4, 8, 0.028, 14, 12, 99, True, 29, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (1h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 29)        218805      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 21)       24906       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1456 (Flatten)          (None, 203)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1457 (Flatten)          (None, 252)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1458 (Flatten)          (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_490 (Concatenate)   (None, 476)          0           flatten_1456[0][0]               
                                                                 flatten_1457[0][0]               
                                                                 flatten_1458[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 99)           47223       concatenate_490[0][0]            
__________________________________________________________________________________________________
dense_77 (Dense)                (None, 152)          15200       posDense[0][0]                   
==================================================================================================
Total params: 306,162
Trainable params: 306,162
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 29)        218805      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 21)       24906       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1459 (Flatten)          (None, 203)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1460 (Flatten)          (None, 252)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1461 (Flatten)          (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1462 (Flatten)          (None, 203)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1463 (Flatten)          (None, 252)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1464 (Flatten)          (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1465 (Flatten)          (None, 203)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1466 (Flatten)          (None, 252)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1467 (Flatten)          (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1468 (Flatten)          (None, 203)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1469 (Flatten)          (None, 252)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1470 (Flatten)          (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1471 (Flatten)          (None, 203)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1472 (Flatten)          (None, 252)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1473 (Flatten)          (None, 21)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_491 (Concatenate)   (None, 476)          0           flatten_1459[0][0]               
                                                                 flatten_1460[0][0]               
                                                                 flatten_1461[0][0]               
__________________________________________________________________________________________________
concatenate_492 (Concatenate)   (None, 476)          0           flatten_1462[0][0]               
                                                                 flatten_1463[0][0]               
                                                                 flatten_1464[0][0]               
__________________________________________________________________________________________________
concatenate_493 (Concatenate)   (None, 476)          0           flatten_1465[0][0]               
                                                                 flatten_1466[0][0]               
                                                                 flatten_1467[0][0]               
__________________________________________________________________________________________________
concatenate_494 (Concatenate)   (None, 476)          0           flatten_1468[0][0]               
                                                                 flatten_1469[0][0]               
                                                                 flatten_1470[0][0]               
__________________________________________________________________________________________________
concatenate_495 (Concatenate)   (None, 476)          0           flatten_1471[0][0]               
                                                                 flatten_1472[0][0]               
                                                                 flatten_1473[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 99)           47223       concatenate_491[0][0]            
                                                                 concatenate_492[0][0]            
                                                                 concatenate_493[0][0]            
                                                                 concatenate_494[0][0]            
                                                                 concatenate_495[0][0]            
__________________________________________________________________________________________________
concatenate_496 (Concatenate)   (None, 495)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 108)          53568       concatenate_496[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            436         idenDense[0][0]                  
==================================================================================================
Total params: 344,966
Trainable params: 344,966
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 8s - loss: 0.2163 - acc: 0.9471
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0872 - acc: 0.9771
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0584 - acc: 0.9846
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0423 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0320 - acc: 0.9920
MWE identification:
Epoch 1/1
 - 38s - loss: 0.0674 - acc: 0.9833
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0596 - acc: 0.9838
MWE identification:
Epoch 1/1
 - 38s - loss: 0.0514 - acc: 0.9873
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0364 - acc: 0.9907
MWE identification:
Epoch 1/1
 - 38s - loss: 0.0479 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0265 - acc: 0.9937
MWE identification:
Epoch 1/1
 - 38s - loss: 0.0462 - acc: 0.9889
POS tagging accuracy = 95.0
Loss = 0.222, 
POS tagging accuracy = 95.0
Loss = 0.222, 
	TRAINING TIME: 4.78 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.582
	P, R  : 0.667, 0.516

==================================================================================================
	XP Ends: 24/4 (1 h:23)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,86             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,2              ,12             ,3              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.106          ,6              ,10             ,62             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
153            ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 86, 6, 2, 12, 3, 18, 0.106, 6, 10, 62, True, 153, False, False, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (1h:23)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.106
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 153)       1154385     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1474 (Flatten)          (None, 1071)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1475 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1476 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_497 (Concatenate)   (None, 1149)         0           flatten_1474[0][0]               
                                                                 flatten_1475[0][0]               
                                                                 flatten_1476[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 62)           71300       concatenate_497[0][0]            
__________________________________________________________________________________________________
dense_78 (Dense)                (None, 152)          9576        posDense[0][0]                   
==================================================================================================
Total params: 1,242,497
Trainable params: 1,242,497
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.106
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 153)       1154385     b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1477 (Flatten)          (None, 1071)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1478 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1479 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1480 (Flatten)          (None, 1071)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1481 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1482 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1483 (Flatten)          (None, 1071)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1484 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1485 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_498 (Concatenate)   (None, 1149)         0           flatten_1477[0][0]               
                                                                 flatten_1478[0][0]               
                                                                 flatten_1479[0][0]               
__________________________________________________________________________________________________
concatenate_499 (Concatenate)   (None, 1149)         0           flatten_1480[0][0]               
                                                                 flatten_1481[0][0]               
                                                                 flatten_1482[0][0]               
__________________________________________________________________________________________________
concatenate_500 (Concatenate)   (None, 1149)         0           flatten_1483[0][0]               
                                                                 flatten_1484[0][0]               
                                                                 flatten_1485[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 62)           71300       concatenate_498[0][0]            
                                                                 concatenate_499[0][0]            
                                                                 concatenate_500[0][0]            
__________________________________________________________________________________________________
concatenate_501 (Concatenate)   (None, 186)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 86)           16082       concatenate_501[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            348         idenDense[0][0]                  
==================================================================================================
Total params: 1,249,351
Trainable params: 1,249,351
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 12s - loss: 0.2707 - acc: 0.9349
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0910 - acc: 0.9765
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0599 - acc: 0.9843
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0461 - acc: 0.9886
MWE identification:
Epoch 1/1
 - 59s - loss: 0.0760 - acc: 0.9807
POS tagging:
Epoch 1/1
 - 12s - loss: 0.1551 - acc: 0.9688
MWE identification:
Epoch 1/1
 - 59s - loss: 0.0537 - acc: 0.9865
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0834 - acc: 0.9848
MWE identification:
Epoch 1/1
 - 59s - loss: 0.0484 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0634 - acc: 0.9895
MWE identification:
Epoch 1/1
 - 59s - loss: 0.0463 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0503 - acc: 0.9920
MWE identification:
Epoch 1/1
 - 60s - loss: 0.0453 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0450 - acc: 0.9931
MWE identification:
Epoch 1/1
 - 59s - loss: 0.0449 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0391 - acc: 0.9941
MWE identification:
Epoch 1/1
 - 59s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0345 - acc: 0.9948
MWE identification:
Epoch 1/1
 - 59s - loss: 0.0442 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0322 - acc: 0.9953
MWE identification:
Epoch 1/1
 - 59s - loss: 0.0441 - acc: 0.9895
POS tagging accuracy = 93.9
Loss = 0.363, 
POS tagging accuracy = 93.9
Loss = 0.363, 
	TRAINING TIME: 12.03 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.707, 0.51

==================================================================================================
	XP Ends: 24/4 (1 h:36)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,80             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,3              ,23             ,1              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.044          ,5              ,42             ,106            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
198            ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 80, 6, 3, 23, 1, 18, 0.044, 5, 42, 106, True, 198, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (1h:36)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 198)       2264724     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1486 (Flatten)          (None, 1386)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1487 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1488 (Flatten)          (None, 9)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_502 (Concatenate)   (None, 1467)         0           flatten_1486[0][0]               
                                                                 flatten_1487[0][0]               
                                                                 flatten_1488[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 106)          155608      concatenate_502[0][0]            
__________________________________________________________________________________________________
dense_79 (Dense)                (None, 152)          16264       posDense[0][0]                   
==================================================================================================
Total params: 2,443,724
Trainable params: 2,443,724
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.044
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 198)       2264724     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1489 (Flatten)          (None, 1386)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1490 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1491 (Flatten)          (None, 9)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1492 (Flatten)          (None, 1386)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1493 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1494 (Flatten)          (None, 9)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1495 (Flatten)          (None, 1386)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1496 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1497 (Flatten)          (None, 9)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1498 (Flatten)          (None, 1386)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1499 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1500 (Flatten)          (None, 9)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1501 (Flatten)          (None, 1386)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1502 (Flatten)          (None, 72)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1503 (Flatten)          (None, 9)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_503 (Concatenate)   (None, 1467)         0           flatten_1489[0][0]               
                                                                 flatten_1490[0][0]               
                                                                 flatten_1491[0][0]               
__________________________________________________________________________________________________
concatenate_504 (Concatenate)   (None, 1467)         0           flatten_1492[0][0]               
                                                                 flatten_1493[0][0]               
                                                                 flatten_1494[0][0]               
__________________________________________________________________________________________________
concatenate_505 (Concatenate)   (None, 1467)         0           flatten_1495[0][0]               
                                                                 flatten_1496[0][0]               
                                                                 flatten_1497[0][0]               
__________________________________________________________________________________________________
concatenate_506 (Concatenate)   (None, 1467)         0           flatten_1498[0][0]               
                                                                 flatten_1499[0][0]               
                                                                 flatten_1500[0][0]               
__________________________________________________________________________________________________
concatenate_507 (Concatenate)   (None, 1467)         0           flatten_1501[0][0]               
                                                                 flatten_1502[0][0]               
                                                                 flatten_1503[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 106)          155608      concatenate_503[0][0]            
                                                                 concatenate_504[0][0]            
                                                                 concatenate_505[0][0]            
                                                                 concatenate_506[0][0]            
                                                                 concatenate_507[0][0]            
__________________________________________________________________________________________________
concatenate_508 (Concatenate)   (None, 530)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 80)           42480       concatenate_508[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            324         idenDense[0][0]                  
==================================================================================================
Total params: 2,470,264
Trainable params: 2,470,264
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2438 - acc: 0.9380
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0777 - acc: 0.9787
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0657 - acc: 0.9836
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0907 - acc: 0.9759
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0476 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0382 - acc: 0.9909
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0452 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0232 - acc: 0.9945
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0164 - acc: 0.9964
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0125 - acc: 0.9972
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0442 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0100 - acc: 0.9978
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0083 - acc: 0.9983
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0442 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0070 - acc: 0.9985
MWE identification:
Epoch 1/1
 - 46s - loss: 0.0442 - acc: 0.9895
POS tagging accuracy = 93.6
Loss = 0.322, 
POS tagging accuracy = 93.6
Loss = 0.322, 
	TRAINING TIME: 8.77 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.531
	P, R  : 0.515, 0.549

==================================================================================================
	XP Ends: 24/4 (1 h:46)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,25             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
14             ,7              ,46             ,3              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.136          ,5              ,16             ,76             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
87             ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 25, 14, 7, 46, 3, 10, 0.136, 5, 16, 76, True, 87, False, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (1h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.136
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 87)        656415      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1504 (Flatten)          (None, 609)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1505 (Flatten)          (None, 168)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1506 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_509 (Concatenate)   (None, 782)          0           flatten_1504[0][0]               
                                                                 flatten_1505[0][0]               
                                                                 flatten_1506[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 76)           59508       concatenate_509[0][0]            
__________________________________________________________________________________________________
dense_80 (Dense)                (None, 152)          11704       posDense[0][0]                   
==================================================================================================
Total params: 744,331
Trainable params: 744,331
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.136
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 87)        656415      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1507 (Flatten)          (None, 609)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1508 (Flatten)          (None, 168)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1509 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1510 (Flatten)          (None, 609)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1511 (Flatten)          (None, 168)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1512 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1513 (Flatten)          (None, 609)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1514 (Flatten)          (None, 168)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1515 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1516 (Flatten)          (None, 609)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1517 (Flatten)          (None, 168)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1518 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_510 (Concatenate)   (None, 782)          0           flatten_1507[0][0]               
                                                                 flatten_1508[0][0]               
                                                                 flatten_1509[0][0]               
__________________________________________________________________________________________________
concatenate_511 (Concatenate)   (None, 782)          0           flatten_1510[0][0]               
                                                                 flatten_1511[0][0]               
                                                                 flatten_1512[0][0]               
__________________________________________________________________________________________________
concatenate_512 (Concatenate)   (None, 782)          0           flatten_1513[0][0]               
                                                                 flatten_1514[0][0]               
                                                                 flatten_1515[0][0]               
__________________________________________________________________________________________________
concatenate_513 (Concatenate)   (None, 782)          0           flatten_1516[0][0]               
                                                                 flatten_1517[0][0]               
                                                                 flatten_1518[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 76)           59508       concatenate_510[0][0]            
                                                                 concatenate_511[0][0]            
                                                                 concatenate_512[0][0]            
                                                                 concatenate_513[0][0]            
__________________________________________________________________________________________________
concatenate_514 (Concatenate)   (None, 304)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 25)           7625        concatenate_514[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            104         idenDense[0][0]                  
==================================================================================================
Total params: 740,356
Trainable params: 740,356
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 7s - loss: 0.2915 - acc: 0.9308
POS tagging:
Epoch 1/1
 - 7s - loss: 0.1025 - acc: 0.9758
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0696 - acc: 0.9833
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0546 - acc: 0.9878
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0771 - acc: 0.9798
POS tagging:
Epoch 1/1
 - 7s - loss: 0.1898 - acc: 0.9617
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0536 - acc: 0.9865
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0814 - acc: 0.9812
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0485 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0594 - acc: 0.9871
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0465 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0488 - acc: 0.9896
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0456 - acc: 0.9891
POS tagging accuracy = 93.9
Loss = 0.33, 
POS tagging accuracy = 93.9
Loss = 0.33, 
	TRAINING TIME: 3.35 minutes 
==================================================================================================
	PARSING TIME: 0.87 minutes 
==================================================================================================
	Identification : 0.564
	P, R  : 0.74, 0.455

==================================================================================================
	XP Ends: 24/4 (1 h:50)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,80             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
9              ,1              ,9              ,1              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.073          ,10             ,22             ,58             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
60             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 80, 9, 1, 9, 1, 15, 0.073, 10, 22, 58, True, 60, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (1h:50)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.073
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 60)        686280      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1519 (Flatten)          (None, 420)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1520 (Flatten)          (None, 108)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1521 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_515 (Concatenate)   (None, 531)          0           flatten_1519[0][0]               
                                                                 flatten_1520[0][0]               
                                                                 flatten_1521[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 58)           30856       concatenate_515[0][0]            
__________________________________________________________________________________________________
dense_81 (Dense)                (None, 152)          8968        posDense[0][0]                   
==================================================================================================
Total params: 736,782
Trainable params: 736,782
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.073
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 60)        686280      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1522 (Flatten)          (None, 420)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1523 (Flatten)          (None, 108)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1524 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1525 (Flatten)          (None, 420)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1526 (Flatten)          (None, 108)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1527 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1528 (Flatten)          (None, 420)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1529 (Flatten)          (None, 108)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1530 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1531 (Flatten)          (None, 420)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1532 (Flatten)          (None, 108)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1533 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1534 (Flatten)          (None, 420)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1535 (Flatten)          (None, 108)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1536 (Flatten)          (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_516 (Concatenate)   (None, 531)          0           flatten_1522[0][0]               
                                                                 flatten_1523[0][0]               
                                                                 flatten_1524[0][0]               
__________________________________________________________________________________________________
concatenate_517 (Concatenate)   (None, 531)          0           flatten_1525[0][0]               
                                                                 flatten_1526[0][0]               
                                                                 flatten_1527[0][0]               
__________________________________________________________________________________________________
concatenate_518 (Concatenate)   (None, 531)          0           flatten_1528[0][0]               
                                                                 flatten_1529[0][0]               
                                                                 flatten_1530[0][0]               
__________________________________________________________________________________________________
concatenate_519 (Concatenate)   (None, 531)          0           flatten_1531[0][0]               
                                                                 flatten_1532[0][0]               
                                                                 flatten_1533[0][0]               
__________________________________________________________________________________________________
concatenate_520 (Concatenate)   (None, 531)          0           flatten_1534[0][0]               
                                                                 flatten_1535[0][0]               
                                                                 flatten_1536[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 58)           30856       concatenate_516[0][0]            
                                                                 concatenate_517[0][0]            
                                                                 concatenate_518[0][0]            
                                                                 concatenate_519[0][0]            
                                                                 concatenate_520[0][0]            
__________________________________________________________________________________________________
concatenate_521 (Concatenate)   (None, 290)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 80)           23280       concatenate_521[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            324         idenDense[0][0]                  
==================================================================================================
Total params: 751,418
Trainable params: 751,418
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.2439 - acc: 0.9381
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0922 - acc: 0.9763
MWE identification:
Epoch 1/1
 - 102s - loss: 0.0724 - acc: 0.9823
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1186 - acc: 0.9683
MWE identification:
Epoch 1/1
 - 101s - loss: 0.0494 - acc: 0.9880
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0575 - acc: 0.9857
MWE identification:
Epoch 1/1
 - 103s - loss: 0.0458 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0374 - acc: 0.9911
MWE identification:
Epoch 1/1
 - 103s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0276 - acc: 0.9940
MWE identification:
Epoch 1/1
 - 103s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0221 - acc: 0.9955
MWE identification:
Epoch 1/1
 - 103s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0185 - acc: 0.9963
MWE identification:
Epoch 1/1
 - 103s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0162 - acc: 0.9969
POS tagging accuracy = 93.3
Loss = 0.339, 
POS tagging accuracy = 93.3
Loss = 0.339, 
	TRAINING TIME: 13.9 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.527
	P, R  : 0.527, 0.528

==================================================================================================
	XP Ends: 24/4 (2 h:6)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,177            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,5              ,14             ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.06           ,14             ,10             ,51             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
64             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 177, 8, 5, 14, 1, 8, 0.06, 14, 10, 51, True, 64, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (2h:6)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.06
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 64)        482880      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1537 (Flatten)          (None, 448)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1538 (Flatten)          (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1539 (Flatten)          (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1540 (Flatten)          (None, 14)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_522 (Concatenate)   (None, 573)          0           flatten_1537[0][0]               
                                                                 flatten_1538[0][0]               
                                                                 flatten_1539[0][0]               
                                                                 flatten_1540[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 51)           29274       concatenate_522[0][0]            
__________________________________________________________________________________________________
dense_82 (Dense)                (None, 152)          7904        posDense[0][0]                   
==================================================================================================
Total params: 529,846
Trainable params: 529,846
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.06
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 64)        482880      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1541 (Flatten)          (None, 448)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1542 (Flatten)          (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1543 (Flatten)          (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1544 (Flatten)          (None, 14)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1545 (Flatten)          (None, 448)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1546 (Flatten)          (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1547 (Flatten)          (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1548 (Flatten)          (None, 14)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1549 (Flatten)          (None, 448)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1550 (Flatten)          (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1551 (Flatten)          (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1552 (Flatten)          (None, 14)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1553 (Flatten)          (None, 448)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1554 (Flatten)          (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1555 (Flatten)          (None, 15)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1556 (Flatten)          (None, 14)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_523 (Concatenate)   (None, 573)          0           flatten_1541[0][0]               
                                                                 flatten_1542[0][0]               
                                                                 flatten_1543[0][0]               
                                                                 flatten_1544[0][0]               
__________________________________________________________________________________________________
concatenate_524 (Concatenate)   (None, 573)          0           flatten_1545[0][0]               
                                                                 flatten_1546[0][0]               
                                                                 flatten_1547[0][0]               
                                                                 flatten_1548[0][0]               
__________________________________________________________________________________________________
concatenate_525 (Concatenate)   (None, 573)          0           flatten_1549[0][0]               
                                                                 flatten_1550[0][0]               
                                                                 flatten_1551[0][0]               
                                                                 flatten_1552[0][0]               
__________________________________________________________________________________________________
concatenate_526 (Concatenate)   (None, 573)          0           flatten_1553[0][0]               
                                                                 flatten_1554[0][0]               
                                                                 flatten_1555[0][0]               
                                                                 flatten_1556[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 51)           29274       concatenate_523[0][0]            
                                                                 concatenate_524[0][0]            
                                                                 concatenate_525[0][0]            
                                                                 concatenate_526[0][0]            
__________________________________________________________________________________________________
concatenate_527 (Concatenate)   (None, 204)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 177)          36285       concatenate_527[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            712         idenDense[0][0]                  
==================================================================================================
Total params: 558,939
Trainable params: 558,939
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 11s - loss: 0.1990 - acc: 0.9508
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0626 - acc: 0.9823
MWE identification:
Epoch 1/1
 - 63s - loss: 0.4302 - acc: 0.9612
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0809 - acc: 0.9781
MWE identification:
Epoch 1/1
 - 65s - loss: 0.0504 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0386 - acc: 0.9898
MWE identification:
Epoch 1/1
 - 65s - loss: 0.0465 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0242 - acc: 0.9941
MWE identification:
Epoch 1/1
 - 65s - loss: 0.0451 - acc: 0.9893
POS tagging accuracy = 94.8
Loss = 0.237, 
POS tagging accuracy = 94.8
Loss = 0.237, 
	TRAINING TIME: 6.42 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.594
	P, R  : 0.674, 0.531

==================================================================================================
	XP Ends: 24/4 (2 h:13)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,141            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
11             ,2              ,51             ,2              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.102          ,5              ,97             ,32             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
124            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 141, 11, 2, 51, 2, 8, 0.102, 5, 97, 32, True, 124, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (2h:13)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.102
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 124)       935580      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1557 (Flatten)          (None, 868)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1558 (Flatten)          (None, 132)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1559 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1560 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_528 (Concatenate)   (None, 1011)         0           flatten_1557[0][0]               
                                                                 flatten_1558[0][0]               
                                                                 flatten_1559[0][0]               
                                                                 flatten_1560[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 32)           32384       concatenate_528[0][0]            
__________________________________________________________________________________________________
dense_83 (Dense)                (None, 152)          5016        posDense[0][0]                   
==================================================================================================
Total params: 986,134
Trainable params: 986,134
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.102
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 124)       935580      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1561 (Flatten)          (None, 868)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1562 (Flatten)          (None, 132)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1563 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1564 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1565 (Flatten)          (None, 868)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1566 (Flatten)          (None, 132)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1567 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1568 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1569 (Flatten)          (None, 868)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1570 (Flatten)          (None, 132)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1571 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1572 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1573 (Flatten)          (None, 868)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1574 (Flatten)          (None, 132)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1575 (Flatten)          (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1576 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1577 (Flatten)          (None, 868)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1578 (Flatten)          (None, 132)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1579 (Flatten)          (None, 6)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1580 (Flatten)          (None, 5)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_529 (Concatenate)   (None, 1011)         0           flatten_1561[0][0]               
                                                                 flatten_1562[0][0]               
                                                                 flatten_1563[0][0]               
                                                                 flatten_1564[0][0]               
__________________________________________________________________________________________________
concatenate_530 (Concatenate)   (None, 1011)         0           flatten_1565[0][0]               
                                                                 flatten_1566[0][0]               
                                                                 flatten_1567[0][0]               
                                                                 flatten_1568[0][0]               
__________________________________________________________________________________________________
concatenate_531 (Concatenate)   (None, 1011)         0           flatten_1569[0][0]               
                                                                 flatten_1570[0][0]               
                                                                 flatten_1571[0][0]               
                                                                 flatten_1572[0][0]               
__________________________________________________________________________________________________
concatenate_532 (Concatenate)   (None, 1011)         0           flatten_1573[0][0]               
                                                                 flatten_1574[0][0]               
                                                                 flatten_1575[0][0]               
                                                                 flatten_1576[0][0]               
__________________________________________________________________________________________________
concatenate_533 (Concatenate)   (None, 1011)         0           flatten_1577[0][0]               
                                                                 flatten_1578[0][0]               
                                                                 flatten_1579[0][0]               
                                                                 flatten_1580[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 32)           32384       concatenate_529[0][0]            
                                                                 concatenate_530[0][0]            
                                                                 concatenate_531[0][0]            
                                                                 concatenate_532[0][0]            
                                                                 concatenate_533[0][0]            
__________________________________________________________________________________________________
concatenate_534 (Concatenate)   (None, 160)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 141)          22701       concatenate_534[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            568         idenDense[0][0]                  
==================================================================================================
Total params: 1,004,387
Trainable params: 1,004,387
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2453 - acc: 0.9413
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0685 - acc: 0.9817
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0395 - acc: 0.9900
MWE identification:
Epoch 1/1
 - 22s - loss: 12.0873 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0353 - acc: 0.9911
MWE identification:
Epoch 1/1
 - 22s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0228 - acc: 0.9948
MWE identification:
Epoch 1/1
 - 22s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0186 - acc: 0.9958
MWE identification:
Epoch 1/1
 - 22s - loss: 12.0886 - acc: 0.2500
POS tagging accuracy = 95.0
Loss = 0.239, 
POS tagging accuracy = 95.0
Loss = 0.239, 
	TRAINING TIME: 3.05 minutes 
==================================================================================================
	PARSING TIME: 2.45 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (2 h:19)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,53             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
17             ,7              ,99             ,1              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.011          ,10             ,44             ,141            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
53             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 53, 17, 7, 99, 1, 12, 0.011, 10, 44, 141, True, 53, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (2h:19)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 53)        399885      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1581 (Flatten)          (None, 371)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1582 (Flatten)          (None, 204)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1583 (Flatten)          (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_535 (Concatenate)   (None, 596)          0           flatten_1581[0][0]               
                                                                 flatten_1582[0][0]               
                                                                 flatten_1583[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 141)          84177       concatenate_535[0][0]            
__________________________________________________________________________________________________
dense_84 (Dense)                (None, 152)          21584       posDense[0][0]                   
==================================================================================================
Total params: 525,836
Trainable params: 525,836
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 53)        399885      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1584 (Flatten)          (None, 371)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1585 (Flatten)          (None, 204)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1586 (Flatten)          (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1587 (Flatten)          (None, 371)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1588 (Flatten)          (None, 204)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1589 (Flatten)          (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1590 (Flatten)          (None, 371)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1591 (Flatten)          (None, 204)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1592 (Flatten)          (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1593 (Flatten)          (None, 371)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1594 (Flatten)          (None, 204)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1595 (Flatten)          (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1596 (Flatten)          (None, 371)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1597 (Flatten)          (None, 204)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1598 (Flatten)          (None, 21)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_536 (Concatenate)   (None, 596)          0           flatten_1584[0][0]               
                                                                 flatten_1585[0][0]               
                                                                 flatten_1586[0][0]               
__________________________________________________________________________________________________
concatenate_537 (Concatenate)   (None, 596)          0           flatten_1587[0][0]               
                                                                 flatten_1588[0][0]               
                                                                 flatten_1589[0][0]               
__________________________________________________________________________________________________
concatenate_538 (Concatenate)   (None, 596)          0           flatten_1590[0][0]               
                                                                 flatten_1591[0][0]               
                                                                 flatten_1592[0][0]               
__________________________________________________________________________________________________
concatenate_539 (Concatenate)   (None, 596)          0           flatten_1593[0][0]               
                                                                 flatten_1594[0][0]               
                                                                 flatten_1595[0][0]               
__________________________________________________________________________________________________
concatenate_540 (Concatenate)   (None, 596)          0           flatten_1596[0][0]               
                                                                 flatten_1597[0][0]               
                                                                 flatten_1598[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 141)          84177       concatenate_536[0][0]            
                                                                 concatenate_537[0][0]            
                                                                 concatenate_538[0][0]            
                                                                 concatenate_539[0][0]            
                                                                 concatenate_540[0][0]            
__________________________________________________________________________________________________
concatenate_541 (Concatenate)   (None, 705)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 53)           37418       concatenate_541[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            216         idenDense[0][0]                  
==================================================================================================
Total params: 541,886
Trainable params: 541,886
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.3055 - acc: 0.9276
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1243 - acc: 0.9704
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0769 - acc: 0.9805
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1043 - acc: 0.9738
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0548 - acc: 0.9866
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0810 - acc: 0.9794
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0512 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0679 - acc: 0.9827
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0493 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0584 - acc: 0.9853
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0480 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0510 - acc: 0.9875
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0471 - acc: 0.9888
POS tagging accuracy = 95.3
Loss = 0.198, 
POS tagging accuracy = 95.3
Loss = 0.198, 
	TRAINING TIME: 2.52 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.593
	P, R  : 0.745, 0.493

==================================================================================================
	XP Ends: 24/4 (2 h:23)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,49             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,5              ,78             ,2              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.064          ,5              ,33             ,52             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
83             ,False          ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 49, 5, 5, 78, 2, 15, 0.064, 5, 33, 52, True, 83, False, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (2h:23)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 83)        949354      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1599 (Flatten)          (None, 581)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1600 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1601 (Flatten)          (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_542 (Concatenate)   (None, 656)          0           flatten_1599[0][0]               
                                                                 flatten_1600[0][0]               
                                                                 flatten_1601[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 52)           34164       concatenate_542[0][0]            
__________________________________________________________________________________________________
dense_85 (Dense)                (None, 152)          8056        posDense[0][0]                   
==================================================================================================
Total params: 997,524
Trainable params: 997,524
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.064
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 83)        949354      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1602 (Flatten)          (None, 581)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1603 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1604 (Flatten)          (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1605 (Flatten)          (None, 581)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1606 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1607 (Flatten)          (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1608 (Flatten)          (None, 581)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1609 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1610 (Flatten)          (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1611 (Flatten)          (None, 581)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1612 (Flatten)          (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1613 (Flatten)          (None, 15)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_543 (Concatenate)   (None, 656)          0           flatten_1602[0][0]               
                                                                 flatten_1603[0][0]               
                                                                 flatten_1604[0][0]               
__________________________________________________________________________________________________
concatenate_544 (Concatenate)   (None, 656)          0           flatten_1605[0][0]               
                                                                 flatten_1606[0][0]               
                                                                 flatten_1607[0][0]               
__________________________________________________________________________________________________
concatenate_545 (Concatenate)   (None, 656)          0           flatten_1608[0][0]               
                                                                 flatten_1609[0][0]               
                                                                 flatten_1610[0][0]               
__________________________________________________________________________________________________
concatenate_546 (Concatenate)   (None, 656)          0           flatten_1611[0][0]               
                                                                 flatten_1612[0][0]               
                                                                 flatten_1613[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 52)           34164       concatenate_543[0][0]            
                                                                 concatenate_544[0][0]            
                                                                 concatenate_545[0][0]            
                                                                 concatenate_546[0][0]            
__________________________________________________________________________________________________
concatenate_547 (Concatenate)   (None, 208)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 49)           10241       concatenate_547[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            200         idenDense[0][0]                  
==================================================================================================
Total params: 999,909
Trainable params: 999,909
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2456 - acc: 0.9369
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0916 - acc: 0.9763
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0526 - acc: 0.9870
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0721 - acc: 0.9822
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0847 - acc: 0.9773
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0489 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0403 - acc: 0.9908
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0456 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0264 - acc: 0.9946
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0447 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0204 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0168 - acc: 0.9968
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0144 - acc: 0.9974
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0128 - acc: 0.9977
POS tagging accuracy = 93.4
Loss = 0.32, 
POS tagging accuracy = 93.4
Loss = 0.32, 
	TRAINING TIME: 2.9 minutes 
==================================================================================================
	PARSING TIME: 0.88 minutes 
==================================================================================================
	Identification : 0.546
	P, R  : 0.558, 0.534

==================================================================================================
	XP Ends: 24/4 (2 h:27)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,31             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
14             ,8              ,8              ,3              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.011          ,13             ,19             ,35             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
55             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 31, 14, 8, 8, 3, 14, 0.011, 13, 19, 35, True, 55, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (2h:27)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 55)        414975      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1614 (Flatten)          (None, 385)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1615 (Flatten)          (None, 168)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1616 (Flatten)          (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1617 (Flatten)          (None, 13)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_548 (Concatenate)   (None, 590)          0           flatten_1614[0][0]               
                                                                 flatten_1615[0][0]               
                                                                 flatten_1616[0][0]               
                                                                 flatten_1617[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           20685       concatenate_548[0][0]            
__________________________________________________________________________________________________
dense_86 (Dense)                (None, 152)          5472        posDense[0][0]                   
==================================================================================================
Total params: 458,028
Trainable params: 458,028
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 55)        414975      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1618 (Flatten)          (None, 385)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1619 (Flatten)          (None, 168)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1620 (Flatten)          (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1621 (Flatten)          (None, 13)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1622 (Flatten)          (None, 385)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1623 (Flatten)          (None, 168)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1624 (Flatten)          (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1625 (Flatten)          (None, 13)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1626 (Flatten)          (None, 385)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1627 (Flatten)          (None, 168)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1628 (Flatten)          (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1629 (Flatten)          (None, 13)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1630 (Flatten)          (None, 385)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1631 (Flatten)          (None, 168)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1632 (Flatten)          (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1633 (Flatten)          (None, 13)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1634 (Flatten)          (None, 385)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1635 (Flatten)          (None, 168)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1636 (Flatten)          (None, 24)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1637 (Flatten)          (None, 13)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_549 (Concatenate)   (None, 590)          0           flatten_1618[0][0]               
                                                                 flatten_1619[0][0]               
                                                                 flatten_1620[0][0]               
                                                                 flatten_1621[0][0]               
__________________________________________________________________________________________________
concatenate_550 (Concatenate)   (None, 590)          0           flatten_1622[0][0]               
                                                                 flatten_1623[0][0]               
                                                                 flatten_1624[0][0]               
                                                                 flatten_1625[0][0]               
__________________________________________________________________________________________________
concatenate_551 (Concatenate)   (None, 590)          0           flatten_1626[0][0]               
                                                                 flatten_1627[0][0]               
                                                                 flatten_1628[0][0]               
                                                                 flatten_1629[0][0]               
__________________________________________________________________________________________________
concatenate_552 (Concatenate)   (None, 590)          0           flatten_1630[0][0]               
                                                                 flatten_1631[0][0]               
                                                                 flatten_1632[0][0]               
                                                                 flatten_1633[0][0]               
__________________________________________________________________________________________________
concatenate_553 (Concatenate)   (None, 590)          0           flatten_1634[0][0]               
                                                                 flatten_1635[0][0]               
                                                                 flatten_1636[0][0]               
                                                                 flatten_1637[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           20685       concatenate_549[0][0]            
                                                                 concatenate_550[0][0]            
                                                                 concatenate_551[0][0]            
                                                                 concatenate_552[0][0]            
                                                                 concatenate_553[0][0]            
__________________________________________________________________________________________________
concatenate_554 (Concatenate)   (None, 175)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 31)           5456        concatenate_554[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            128         idenDense[0][0]                  
==================================================================================================
Total params: 458,140
Trainable params: 458,140
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 6s - loss: 0.3921 - acc: 0.9083
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1596 - acc: 0.9651
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1229 - acc: 0.9719
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1033 - acc: 0.9756
MWE identification:
Epoch 1/1
 - 129s - loss: 0.0788 - acc: 0.9795
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1125 - acc: 0.9731
MWE identification:
Epoch 1/1
 - 136s - loss: 0.0598 - acc: 0.9851
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0924 - acc: 0.9773
MWE identification:
Epoch 1/1
 - 125s - loss: 0.0554 - acc: 0.9863
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0820 - acc: 0.9800
MWE identification:
Epoch 1/1
 - 125s - loss: 0.0530 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0746 - acc: 0.9817
MWE identification:
Epoch 1/1
 - 125s - loss: 0.0514 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0686 - acc: 0.9836
MWE identification:
Epoch 1/1
 - 138s - loss: 0.0503 - acc: 0.9878
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0637 - acc: 0.9847
MWE identification:
Epoch 1/1
 - 126s - loss: 0.0493 - acc: 0.9881
POS tagging accuracy = 95.0
Loss = 0.205, 
POS tagging accuracy = 95.0
Loss = 0.205, 
	TRAINING TIME: 17.55 minutes 
==================================================================================================
	PARSING TIME: 1.43 minutes 
==================================================================================================
	Identification : 0.604
	P, R  : 0.783, 0.491

==================================================================================================
	XP Ends: 24/4 (2 h:46)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,31             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,6              ,17             ,1              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.023          ,10             ,8              ,54             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
71             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 31, 5, 6, 17, 1, 18, 0.023, 10, 8, 54, True, 71, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (2h:46)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 71)        535695      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1638 (Flatten)          (None, 497)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1639 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1640 (Flatten)          (None, 18)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1641 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_555 (Concatenate)   (None, 585)          0           flatten_1638[0][0]               
                                                                 flatten_1639[0][0]               
                                                                 flatten_1640[0][0]               
                                                                 flatten_1641[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 54)           31644       concatenate_555[0][0]            
__________________________________________________________________________________________________
dense_87 (Dense)                (None, 152)          8360        posDense[0][0]                   
==================================================================================================
Total params: 581,853
Trainable params: 581,853
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 71)        535695      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1642 (Flatten)          (None, 497)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1643 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1644 (Flatten)          (None, 18)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1645 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1646 (Flatten)          (None, 497)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1647 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1648 (Flatten)          (None, 18)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1649 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1650 (Flatten)          (None, 497)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1651 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1652 (Flatten)          (None, 18)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1653 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1654 (Flatten)          (None, 497)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1655 (Flatten)          (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1656 (Flatten)          (None, 18)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1657 (Flatten)          (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1658 (Flatten)          (None, 497)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1659 (Flatten)          (None, 60)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1660 (Flatten)          (None, 18)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1661 (Flatten)          (None, 10)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_556 (Concatenate)   (None, 585)          0           flatten_1642[0][0]               
                                                                 flatten_1643[0][0]               
                                                                 flatten_1644[0][0]               
                                                                 flatten_1645[0][0]               
__________________________________________________________________________________________________
concatenate_557 (Concatenate)   (None, 585)          0           flatten_1646[0][0]               
                                                                 flatten_1647[0][0]               
                                                                 flatten_1648[0][0]               
                                                                 flatten_1649[0][0]               
__________________________________________________________________________________________________
concatenate_558 (Concatenate)   (None, 585)          0           flatten_1650[0][0]               
                                                                 flatten_1651[0][0]               
                                                                 flatten_1652[0][0]               
                                                                 flatten_1653[0][0]               
__________________________________________________________________________________________________
concatenate_559 (Concatenate)   (None, 585)          0           flatten_1654[0][0]               
                                                                 flatten_1655[0][0]               
                                                                 flatten_1656[0][0]               
                                                                 flatten_1657[0][0]               
__________________________________________________________________________________________________
concatenate_560 (Concatenate)   (None, 585)          0           flatten_1658[0][0]               
                                                                 flatten_1659[0][0]               
                                                                 flatten_1660[0][0]               
                                                                 flatten_1661[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 54)           31644       concatenate_556[0][0]            
                                                                 concatenate_557[0][0]            
                                                                 concatenate_558[0][0]            
                                                                 concatenate_559[0][0]            
                                                                 concatenate_560[0][0]            
__________________________________________________________________________________________________
concatenate_561 (Concatenate)   (None, 270)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 31)           8401        concatenate_561[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            128         idenDense[0][0]                  
==================================================================================================
Total params: 582,022
Trainable params: 582,022
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 15s - loss: 0.2389 - acc: 0.9436
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0908 - acc: 0.9770
MWE identification:
Epoch 1/1
 - 62s - loss: 0.0663 - acc: 0.9833
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0925 - acc: 0.9763
MWE identification:
Epoch 1/1
 - 61s - loss: 0.0519 - acc: 0.9873
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0624 - acc: 0.9842
MWE identification:
Epoch 1/1
 - 64s - loss: 0.0485 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0476 - acc: 0.9887
MWE identification:
Epoch 1/1
 - 61s - loss: 0.0468 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0379 - acc: 0.9913
MWE identification:
Epoch 1/1
 - 61s - loss: 0.0459 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 15s - loss: 0.0311 - acc: 0.9928
MWE identification:
Epoch 1/1
 - 69s - loss: 0.0453 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0260 - acc: 0.9944
MWE identification:
Epoch 1/1
 - 62s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0221 - acc: 0.9954
MWE identification:
Epoch 1/1
 - 62s - loss: 0.0447 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 14s - loss: 0.0192 - acc: 0.9962
MWE identification:
Epoch 1/1
 - 68s - loss: 0.0445 - acc: 0.9895
POS tagging accuracy = 95.1
Loss = 0.227, 
POS tagging accuracy = 95.1
Loss = 0.227, 
	TRAINING TIME: 13.32 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.602
	P, R  : 0.762, 0.497

==================================================================================================
	XP Ends: 24/4 (3 h:1)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,96             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,1              ,72             ,3              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.133          ,10             ,35             ,36             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
85             ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 96, 7, 1, 72, 3, 8, 0.133, 10, 35, 36, True, 85, False, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:1)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.133
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 85)        641325      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1662 (Flatten)          (None, 595)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1663 (Flatten)          (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1664 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_562 (Concatenate)   (None, 689)          0           flatten_1662[0][0]               
                                                                 flatten_1663[0][0]               
                                                                 flatten_1664[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           24840       concatenate_562[0][0]            
__________________________________________________________________________________________________
dense_88 (Dense)                (None, 152)          5624        posDense[0][0]                   
==================================================================================================
Total params: 680,291
Trainable params: 680,291
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.133
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 85)        641325      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1665 (Flatten)          (None, 595)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1666 (Flatten)          (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1667 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1668 (Flatten)          (None, 595)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1669 (Flatten)          (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1670 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1671 (Flatten)          (None, 595)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1672 (Flatten)          (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1673 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1674 (Flatten)          (None, 595)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1675 (Flatten)          (None, 84)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1676 (Flatten)          (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_563 (Concatenate)   (None, 689)          0           flatten_1665[0][0]               
                                                                 flatten_1666[0][0]               
                                                                 flatten_1667[0][0]               
__________________________________________________________________________________________________
concatenate_564 (Concatenate)   (None, 689)          0           flatten_1668[0][0]               
                                                                 flatten_1669[0][0]               
                                                                 flatten_1670[0][0]               
__________________________________________________________________________________________________
concatenate_565 (Concatenate)   (None, 689)          0           flatten_1671[0][0]               
                                                                 flatten_1672[0][0]               
                                                                 flatten_1673[0][0]               
__________________________________________________________________________________________________
concatenate_566 (Concatenate)   (None, 689)          0           flatten_1674[0][0]               
                                                                 flatten_1675[0][0]               
                                                                 flatten_1676[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           24840       concatenate_563[0][0]            
                                                                 concatenate_564[0][0]            
                                                                 concatenate_565[0][0]            
                                                                 concatenate_566[0][0]            
__________________________________________________________________________________________________
concatenate_567 (Concatenate)   (None, 144)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 96)           13920       concatenate_567[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            388         idenDense[0][0]                  
==================================================================================================
Total params: 688,975
Trainable params: 688,975
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2533 - acc: 0.9379
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0809 - acc: 0.9789
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0513 - acc: 0.9865
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0381 - acc: 0.9908
MWE identification:
Epoch 1/1
 - 12s - loss: 12.0869 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0445 - acc: 0.9891
MWE identification:
Epoch 1/1
 - 12s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0293 - acc: 0.9933
MWE identification:
Epoch 1/1
 - 12s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0252 - acc: 0.9943
MWE identification:
Epoch 1/1
 - 12s - loss: 12.0886 - acc: 0.2500
POS tagging accuracy = 95.0
Loss = 0.269, 
POS tagging accuracy = 95.0
Loss = 0.269, 
	TRAINING TIME: 2.15 minutes 
==================================================================================================
	PARSING TIME: 1.65 minutes 
==================================================================================================
	Identification : 0.005
	P, R  : 0.007, 0.004

==================================================================================================
	XP Ends: 24/4 (3 h:5)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,104            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
14             ,1              ,75             ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.177          ,13             ,83             ,132            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
27             ,True           ,True           ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 104, 14, 1, 75, 1, 8, 0.177, 13, 83, 132, True, 27, True, True, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:5)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.177
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 27)        203715      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       affixes[0][0]                    
__________________________________________________________________________________________________
flatten_1677 (Flatten)          (None, 189)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1678 (Flatten)          (None, 168)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_568 (Concatenate)   (None, 357)          0           flatten_1677[0][0]               
                                                                 flatten_1678[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 132)          47256       concatenate_568[0][0]            
__________________________________________________________________________________________________
dense_89 (Dense)                (None, 152)          20216       posDense[0][0]                   
==================================================================================================
Total params: 287,791
Trainable params: 287,791
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.177
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 27)        203715      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_1679 (Flatten)          (None, 189)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1680 (Flatten)          (None, 168)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1681 (Flatten)          (None, 189)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1682 (Flatten)          (None, 168)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1683 (Flatten)          (None, 189)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1684 (Flatten)          (None, 168)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1685 (Flatten)          (None, 189)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1686 (Flatten)          (None, 168)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1687 (Flatten)          (None, 189)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1688 (Flatten)          (None, 168)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
concatenate_569 (Concatenate)   (None, 357)          0           flatten_1679[0][0]               
                                                                 flatten_1680[0][0]               
__________________________________________________________________________________________________
concatenate_570 (Concatenate)   (None, 357)          0           flatten_1681[0][0]               
                                                                 flatten_1682[0][0]               
__________________________________________________________________________________________________
concatenate_571 (Concatenate)   (None, 357)          0           flatten_1683[0][0]               
                                                                 flatten_1684[0][0]               
__________________________________________________________________________________________________
concatenate_572 (Concatenate)   (None, 357)          0           flatten_1685[0][0]               
                                                                 flatten_1686[0][0]               
__________________________________________________________________________________________________
concatenate_573 (Concatenate)   (None, 357)          0           flatten_1687[0][0]               
                                                                 flatten_1688[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 132)          47256       concatenate_569[0][0]            
                                                                 concatenate_570[0][0]            
                                                                 concatenate_571[0][0]            
                                                                 concatenate_572[0][0]            
                                                                 concatenate_573[0][0]            
__________________________________________________________________________________________________
concatenate_574 (Concatenate)   (None, 660)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 104)          68744       concatenate_574[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            420         idenDense[0][0]                  
==================================================================================================
Total params: 336,739
Trainable params: 336,739
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2949 - acc: 0.9325
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0928 - acc: 0.9760
MWE identification:
Epoch 1/1
 - 10s - loss: 8.1711 - acc: 0.4929
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1262 - acc: 0.9692
MWE identification:
Epoch 1/1
 - 10s - loss: 8.1157 - acc: 0.4965
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0716 - acc: 0.9819
MWE identification:
Epoch 1/1
 - 10s - loss: 8.1130 - acc: 0.4966
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0570 - acc: 0.9856
MWE identification:
Epoch 1/1
 - 10s - loss: 8.1150 - acc: 0.4965
POS tagging accuracy = 92.6
Loss = 0.385, 
POS tagging accuracy = 92.6
Loss = 0.385, 
	TRAINING TIME: 1.73 minutes 
==================================================================================================
	PARSING TIME: 0.8 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (3 h:8)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,33             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,8              ,25             ,1              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.038          ,5              ,13             ,33             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
71             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 33, 8, 8, 25, 1, 17, 0.038, 5, 13, 33, True, 71, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:8)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 71)        812098      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1689 (Flatten)          (None, 497)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1690 (Flatten)          (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1691 (Flatten)          (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_575 (Concatenate)   (None, 617)          0           flatten_1689[0][0]               
                                                                 flatten_1690[0][0]               
                                                                 flatten_1691[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 33)           20394       concatenate_575[0][0]            
__________________________________________________________________________________________________
dense_90 (Dense)                (None, 152)          5168        posDense[0][0]                   
==================================================================================================
Total params: 847,180
Trainable params: 847,180
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.038
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 71)        812098      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1692 (Flatten)          (None, 497)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1693 (Flatten)          (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1694 (Flatten)          (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1695 (Flatten)          (None, 497)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1696 (Flatten)          (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1697 (Flatten)          (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1698 (Flatten)          (None, 497)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1699 (Flatten)          (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1700 (Flatten)          (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1701 (Flatten)          (None, 497)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1702 (Flatten)          (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1703 (Flatten)          (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1704 (Flatten)          (None, 497)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1705 (Flatten)          (None, 96)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1706 (Flatten)          (None, 24)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_576 (Concatenate)   (None, 617)          0           flatten_1692[0][0]               
                                                                 flatten_1693[0][0]               
                                                                 flatten_1694[0][0]               
__________________________________________________________________________________________________
concatenate_577 (Concatenate)   (None, 617)          0           flatten_1695[0][0]               
                                                                 flatten_1696[0][0]               
                                                                 flatten_1697[0][0]               
__________________________________________________________________________________________________
concatenate_578 (Concatenate)   (None, 617)          0           flatten_1698[0][0]               
                                                                 flatten_1699[0][0]               
                                                                 flatten_1700[0][0]               
__________________________________________________________________________________________________
concatenate_579 (Concatenate)   (None, 617)          0           flatten_1701[0][0]               
                                                                 flatten_1702[0][0]               
                                                                 flatten_1703[0][0]               
__________________________________________________________________________________________________
concatenate_580 (Concatenate)   (None, 617)          0           flatten_1704[0][0]               
                                                                 flatten_1705[0][0]               
                                                                 flatten_1706[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 33)           20394       concatenate_576[0][0]            
                                                                 concatenate_577[0][0]            
                                                                 concatenate_578[0][0]            
                                                                 concatenate_579[0][0]            
                                                                 concatenate_580[0][0]            
__________________________________________________________________________________________________
concatenate_581 (Concatenate)   (None, 165)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 33)           5478        concatenate_581[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            136         idenDense[0][0]                  
==================================================================================================
Total params: 847,626
Trainable params: 847,626
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.2565 - acc: 0.9351
POS tagging:
Epoch 1/1
 - 8s - loss: 0.1145 - acc: 0.9716
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0675 - acc: 0.9830
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1108 - acc: 0.9718
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0499 - acc: 0.9880
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0693 - acc: 0.9831
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0464 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0510 - acc: 0.9878
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0453 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0402 - acc: 0.9904
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0447 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0329 - acc: 0.9922
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0278 - acc: 0.9935
MWE identification:
Epoch 1/1
 - 37s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0238 - acc: 0.9944
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0208 - acc: 0.9951
POS tagging accuracy = 93.4
Loss = 0.275, 
POS tagging accuracy = 93.4
Loss = 0.275, 
	TRAINING TIME: 7.57 minutes 
==================================================================================================
	PARSING TIME: 1.2 minutes 
==================================================================================================
	Identification : 0.524
	P, R  : 0.558, 0.494

==================================================================================================
	XP Ends: 24/4 (3 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,41             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
12             ,6              ,121            ,4              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.029          ,7              ,84             ,35             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
110            ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 41, 12, 6, 121, 4, 16, 0.029, 7, 84, 35, True, 110, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 110)       829950      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1707 (Flatten)          (None, 770)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1708 (Flatten)          (None, 144)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1709 (Flatten)          (None, 18)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1710 (Flatten)          (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_582 (Concatenate)   (None, 939)          0           flatten_1707[0][0]               
                                                                 flatten_1708[0][0]               
                                                                 flatten_1709[0][0]               
                                                                 flatten_1710[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           32900       concatenate_582[0][0]            
__________________________________________________________________________________________________
dense_91 (Dense)                (None, 152)          5472        posDense[0][0]                   
==================================================================================================
Total params: 882,718
Trainable params: 882,718
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 110)       829950      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1711 (Flatten)          (None, 770)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1712 (Flatten)          (None, 144)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1713 (Flatten)          (None, 18)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1714 (Flatten)          (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1715 (Flatten)          (None, 770)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1716 (Flatten)          (None, 144)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1717 (Flatten)          (None, 18)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1718 (Flatten)          (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1719 (Flatten)          (None, 770)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1720 (Flatten)          (None, 144)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1721 (Flatten)          (None, 18)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1722 (Flatten)          (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1723 (Flatten)          (None, 770)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1724 (Flatten)          (None, 144)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1725 (Flatten)          (None, 18)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1726 (Flatten)          (None, 7)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_583 (Concatenate)   (None, 939)          0           flatten_1711[0][0]               
                                                                 flatten_1712[0][0]               
                                                                 flatten_1713[0][0]               
                                                                 flatten_1714[0][0]               
__________________________________________________________________________________________________
concatenate_584 (Concatenate)   (None, 939)          0           flatten_1715[0][0]               
                                                                 flatten_1716[0][0]               
                                                                 flatten_1717[0][0]               
                                                                 flatten_1718[0][0]               
__________________________________________________________________________________________________
concatenate_585 (Concatenate)   (None, 939)          0           flatten_1719[0][0]               
                                                                 flatten_1720[0][0]               
                                                                 flatten_1721[0][0]               
                                                                 flatten_1722[0][0]               
__________________________________________________________________________________________________
concatenate_586 (Concatenate)   (None, 939)          0           flatten_1723[0][0]               
                                                                 flatten_1724[0][0]               
                                                                 flatten_1725[0][0]               
                                                                 flatten_1726[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           32900       concatenate_583[0][0]            
                                                                 concatenate_584[0][0]            
                                                                 concatenate_585[0][0]            
                                                                 concatenate_586[0][0]            
__________________________________________________________________________________________________
concatenate_587 (Concatenate)   (None, 140)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 41)           5781        concatenate_587[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            168         idenDense[0][0]                  
==================================================================================================
Total params: 883,195
Trainable params: 883,195
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2405 - acc: 0.9422
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0799 - acc: 0.9795
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0508 - acc: 0.9874
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0356 - acc: 0.9914
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0264 - acc: 0.9939
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0790 - acc: 0.9812
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0520 - acc: 0.9864
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0523 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0294 - acc: 0.9932
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0481 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0214 - acc: 0.9954
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0464 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0169 - acc: 0.9965
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0456 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0139 - acc: 0.9972
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0451 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0117 - acc: 0.9977
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0100 - acc: 0.9979
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0446 - acc: 0.9895
POS tagging accuracy = 94.8
Loss = 0.257, 
POS tagging accuracy = 94.8
Loss = 0.257, 
	TRAINING TIME: 2.62 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.591
	P, R  : 0.765, 0.482

==================================================================================================
	XP Ends: 24/4 (3 h:21)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,36             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,1              ,12             ,2              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.076          ,11             ,56             ,27             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
99             ,False          ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 36, 6, 1, 12, 2, 16, 0.076, 11, 56, 27, True, 99, False, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:21)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 99)        1132362     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1727 (Flatten)          (None, 693)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1728 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1729 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_588 (Concatenate)   (None, 768)          0           flatten_1727[0][0]               
                                                                 flatten_1728[0][0]               
                                                                 flatten_1729[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 27)           20763       concatenate_588[0][0]            
__________________________________________________________________________________________________
dense_92 (Dense)                (None, 152)          4256        posDense[0][0]                   
==================================================================================================
Total params: 1,164,501
Trainable params: 1,164,501
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.076
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 99)        1132362     bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1730 (Flatten)          (None, 693)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1731 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1732 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1733 (Flatten)          (None, 693)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1734 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1735 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1736 (Flatten)          (None, 693)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1737 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1738 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1739 (Flatten)          (None, 693)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1740 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1741 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_589 (Concatenate)   (None, 768)          0           flatten_1730[0][0]               
                                                                 flatten_1731[0][0]               
                                                                 flatten_1732[0][0]               
__________________________________________________________________________________________________
concatenate_590 (Concatenate)   (None, 768)          0           flatten_1733[0][0]               
                                                                 flatten_1734[0][0]               
                                                                 flatten_1735[0][0]               
__________________________________________________________________________________________________
concatenate_591 (Concatenate)   (None, 768)          0           flatten_1736[0][0]               
                                                                 flatten_1737[0][0]               
                                                                 flatten_1738[0][0]               
__________________________________________________________________________________________________
concatenate_592 (Concatenate)   (None, 768)          0           flatten_1739[0][0]               
                                                                 flatten_1740[0][0]               
                                                                 flatten_1741[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 27)           20763       concatenate_589[0][0]            
                                                                 concatenate_590[0][0]            
                                                                 concatenate_591[0][0]            
                                                                 concatenate_592[0][0]            
__________________________________________________________________________________________________
concatenate_593 (Concatenate)   (None, 108)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 36)           3924        concatenate_593[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            148         idenDense[0][0]                  
==================================================================================================
Total params: 1,164,317
Trainable params: 1,164,317
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2542 - acc: 0.9358
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0941 - acc: 0.9758
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0553 - acc: 0.9865
MWE identification:
Epoch 1/1
 - 70s - loss: 0.0690 - acc: 0.9822
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1077 - acc: 0.9728
MWE identification:
Epoch 1/1
 - 70s - loss: 0.0497 - acc: 0.9880
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0502 - acc: 0.9887
MWE identification:
Epoch 1/1
 - 69s - loss: 0.0460 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0335 - acc: 0.9932
MWE identification:
Epoch 1/1
 - 70s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0255 - acc: 0.9950
MWE identification:
Epoch 1/1
 - 69s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0208 - acc: 0.9962
MWE identification:
Epoch 1/1
 - 69s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0178 - acc: 0.9969
MWE identification:
Epoch 1/1
 - 69s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0156 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 70s - loss: 0.0442 - acc: 0.9895
POS tagging accuracy = 93.1
Loss = 0.353, 
POS tagging accuracy = 93.1
Loss = 0.353, 
	TRAINING TIME: 10.65 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.499
	P, R  : 0.46, 0.545

==================================================================================================
	XP Ends: 24/4 (3 h:33)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,71             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,1              ,13             ,2              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.102          ,5              ,105            ,77             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
62             ,True           ,False          ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 71, 7, 1, 13, 2, 11, 0.102, 5, 105, 77, True, 62, True, False, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.102
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 62)        467790      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
flatten_1742 (Flatten)          (None, 434)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1743 (Flatten)          (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_594 (Concatenate)   (None, 518)          0           flatten_1742[0][0]               
                                                                 flatten_1743[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 77)           39963       concatenate_594[0][0]            
__________________________________________________________________________________________________
dense_93 (Dense)                (None, 152)          11856       posDense[0][0]                   
==================================================================================================
Total params: 527,911
Trainable params: 527,911
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.102
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 62)        467790      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_1744 (Flatten)          (None, 434)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1745 (Flatten)          (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1746 (Flatten)          (None, 434)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1747 (Flatten)          (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1748 (Flatten)          (None, 434)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1749 (Flatten)          (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1750 (Flatten)          (None, 434)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1751 (Flatten)          (None, 84)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
concatenate_595 (Concatenate)   (None, 518)          0           flatten_1744[0][0]               
                                                                 flatten_1745[0][0]               
__________________________________________________________________________________________________
concatenate_596 (Concatenate)   (None, 518)          0           flatten_1746[0][0]               
                                                                 flatten_1747[0][0]               
__________________________________________________________________________________________________
concatenate_597 (Concatenate)   (None, 518)          0           flatten_1748[0][0]               
                                                                 flatten_1749[0][0]               
__________________________________________________________________________________________________
concatenate_598 (Concatenate)   (None, 518)          0           flatten_1750[0][0]               
                                                                 flatten_1751[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 77)           39963       concatenate_595[0][0]            
                                                                 concatenate_596[0][0]            
                                                                 concatenate_597[0][0]            
                                                                 concatenate_598[0][0]            
__________________________________________________________________________________________________
concatenate_599 (Concatenate)   (None, 308)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 71)           21939       concatenate_599[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            288         idenDense[0][0]                  
==================================================================================================
Total params: 538,282
Trainable params: 538,282
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2367 - acc: 0.9436
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0648 - acc: 0.9823
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0347 - acc: 0.9906
MWE identification:
Epoch 1/1
 - 50s - loss: 12.0883 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0295 - acc: 0.9926
MWE identification:
Epoch 1/1
 - 49s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0172 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 49s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0134 - acc: 0.9971
MWE identification:
Epoch 1/1
 - 49s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0113 - acc: 0.9976
MWE identification:
Epoch 1/1
 - 50s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0099 - acc: 0.9979
POS tagging accuracy = 94.9
Loss = 0.264, 
POS tagging accuracy = 94.9
Loss = 0.264, 
	TRAINING TIME: 5.02 minutes 
==================================================================================================
	PARSING TIME: 1.27 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (3 h:39)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,56             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,2              ,99             ,1              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.013          ,9              ,17             ,34             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
90             ,True           ,False          ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 56, 5, 2, 99, 1, 18, 0.013, 9, 17, 34, True, 90, True, False, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 90)        679050      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1752 (Flatten)          (None, 630)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1753 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1754 (Flatten)          (None, 9)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_600 (Concatenate)   (None, 699)          0           flatten_1752[0][0]               
                                                                 flatten_1753[0][0]               
                                                                 flatten_1754[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 34)           23800       concatenate_600[0][0]            
__________________________________________________________________________________________________
dense_94 (Dense)                (None, 152)          5320        posDense[0][0]                   
==================================================================================================
Total params: 714,280
Trainable params: 714,280
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 90)        679050      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1755 (Flatten)          (None, 630)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1756 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1757 (Flatten)          (None, 9)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1758 (Flatten)          (None, 630)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1759 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1760 (Flatten)          (None, 9)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1761 (Flatten)          (None, 630)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1762 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1763 (Flatten)          (None, 9)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1764 (Flatten)          (None, 630)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1765 (Flatten)          (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1766 (Flatten)          (None, 9)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_601 (Concatenate)   (None, 699)          0           flatten_1755[0][0]               
                                                                 flatten_1756[0][0]               
                                                                 flatten_1757[0][0]               
__________________________________________________________________________________________________
concatenate_602 (Concatenate)   (None, 699)          0           flatten_1758[0][0]               
                                                                 flatten_1759[0][0]               
                                                                 flatten_1760[0][0]               
__________________________________________________________________________________________________
concatenate_603 (Concatenate)   (None, 699)          0           flatten_1761[0][0]               
                                                                 flatten_1762[0][0]               
                                                                 flatten_1763[0][0]               
__________________________________________________________________________________________________
concatenate_604 (Concatenate)   (None, 699)          0           flatten_1764[0][0]               
                                                                 flatten_1765[0][0]               
                                                                 flatten_1766[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 34)           23800       concatenate_601[0][0]            
                                                                 concatenate_602[0][0]            
                                                                 concatenate_603[0][0]            
                                                                 concatenate_604[0][0]            
__________________________________________________________________________________________________
concatenate_605 (Concatenate)   (None, 136)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 56)           7672        concatenate_605[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            228         idenDense[0][0]                  
==================================================================================================
Total params: 716,860
Trainable params: 716,860
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 6s - loss: 0.3596 - acc: 0.9147
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1386 - acc: 0.9691
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0817 - acc: 0.9792
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1181 - acc: 0.9720
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0571 - acc: 0.9860
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0944 - acc: 0.9768
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0528 - acc: 0.9872
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0812 - acc: 0.9794
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0505 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0714 - acc: 0.9824
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0490 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0636 - acc: 0.9848
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0479 - acc: 0.9887
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0573 - acc: 0.9867
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0472 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0520 - acc: 0.9882
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0466 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0475 - acc: 0.9892
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0462 - acc: 0.9891
POS tagging accuracy = 94.6
Loss = 0.212, 
POS tagging accuracy = 94.6
Loss = 0.212, 
	TRAINING TIME: 3.37 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.594
	P, R  : 0.753, 0.491

==================================================================================================
	XP Ends: 24/4 (3 h:44)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,174            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,4              ,93             ,1              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.01           ,10             ,84             ,142            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
58             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 174, 7, 4, 93, 1, 13, 0.01, 10, 84, 142, True, 58, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 58)        437610      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1767 (Flatten)          (None, 406)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1768 (Flatten)          (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1769 (Flatten)          (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1770 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_606 (Concatenate)   (None, 512)          0           flatten_1767[0][0]               
                                                                 flatten_1768[0][0]               
                                                                 flatten_1769[0][0]               
                                                                 flatten_1770[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 142)          72846       concatenate_606[0][0]            
__________________________________________________________________________________________________
dense_95 (Dense)                (None, 152)          21736       posDense[0][0]                   
==================================================================================================
Total params: 540,710
Trainable params: 540,710
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.01
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 58)        437610      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1771 (Flatten)          (None, 406)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1772 (Flatten)          (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1773 (Flatten)          (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1774 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1775 (Flatten)          (None, 406)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1776 (Flatten)          (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1777 (Flatten)          (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1778 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1779 (Flatten)          (None, 406)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1780 (Flatten)          (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1781 (Flatten)          (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1782 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1783 (Flatten)          (None, 406)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1784 (Flatten)          (None, 84)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1785 (Flatten)          (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1786 (Flatten)          (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_607 (Concatenate)   (None, 512)          0           flatten_1771[0][0]               
                                                                 flatten_1772[0][0]               
                                                                 flatten_1773[0][0]               
                                                                 flatten_1774[0][0]               
__________________________________________________________________________________________________
concatenate_608 (Concatenate)   (None, 512)          0           flatten_1775[0][0]               
                                                                 flatten_1776[0][0]               
                                                                 flatten_1777[0][0]               
                                                                 flatten_1778[0][0]               
__________________________________________________________________________________________________
concatenate_609 (Concatenate)   (None, 512)          0           flatten_1779[0][0]               
                                                                 flatten_1780[0][0]               
                                                                 flatten_1781[0][0]               
                                                                 flatten_1782[0][0]               
__________________________________________________________________________________________________
concatenate_610 (Concatenate)   (None, 512)          0           flatten_1783[0][0]               
                                                                 flatten_1784[0][0]               
                                                                 flatten_1785[0][0]               
                                                                 flatten_1786[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 142)          72846       concatenate_607[0][0]            
                                                                 concatenate_608[0][0]            
                                                                 concatenate_609[0][0]            
                                                                 concatenate_610[0][0]            
__________________________________________________________________________________________________
concatenate_611 (Concatenate)   (None, 568)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 174)          99006       concatenate_611[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            700         idenDense[0][0]                  
==================================================================================================
Total params: 618,680
Trainable params: 618,680
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.3762 - acc: 0.9118
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1353 - acc: 0.9694
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0790 - acc: 0.9806
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1139 - acc: 0.9730
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0551 - acc: 0.9865
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0906 - acc: 0.9776
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0513 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0773 - acc: 0.9806
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0494 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0674 - acc: 0.9832
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0480 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0597 - acc: 0.9852
MWE identification:
Epoch 1/1
 - 11s - loss: 0.0471 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0534 - acc: 0.9873
POS tagging accuracy = 95.3
Loss = 0.195, 
POS tagging accuracy = 95.3
Loss = 0.195, 
	TRAINING TIME: 2.43 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.597
	P, R  : 0.809, 0.473

==================================================================================================
	XP Ends: 24/4 (3 h:48)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,131            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,1              ,96             ,3              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.052          ,13             ,12             ,160            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
68             ,True           ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 131, 5, 1, 96, 3, 8, 0.052, 13, 12, 160, True, 68, True, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:48)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.052
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 68)        513060      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1787 (Flatten)          (None, 476)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1788 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1789 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_612 (Concatenate)   (None, 539)          0           flatten_1787[0][0]               
                                                                 flatten_1788[0][0]               
                                                                 flatten_1789[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 160)          86400       concatenate_612[0][0]            
__________________________________________________________________________________________________
dense_96 (Dense)                (None, 152)          24472       posDense[0][0]                   
==================================================================================================
Total params: 629,866
Trainable params: 629,866
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.052
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 68)        513060      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1790 (Flatten)          (None, 476)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1791 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1792 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1793 (Flatten)          (None, 476)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1794 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1795 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1796 (Flatten)          (None, 476)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1797 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1798 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1799 (Flatten)          (None, 476)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1800 (Flatten)          (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1801 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_613 (Concatenate)   (None, 539)          0           flatten_1790[0][0]               
                                                                 flatten_1791[0][0]               
                                                                 flatten_1792[0][0]               
__________________________________________________________________________________________________
concatenate_614 (Concatenate)   (None, 539)          0           flatten_1793[0][0]               
                                                                 flatten_1794[0][0]               
                                                                 flatten_1795[0][0]               
__________________________________________________________________________________________________
concatenate_615 (Concatenate)   (None, 539)          0           flatten_1796[0][0]               
                                                                 flatten_1797[0][0]               
                                                                 flatten_1798[0][0]               
__________________________________________________________________________________________________
concatenate_616 (Concatenate)   (None, 539)          0           flatten_1799[0][0]               
                                                                 flatten_1800[0][0]               
                                                                 flatten_1801[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 160)          86400       concatenate_613[0][0]            
                                                                 concatenate_614[0][0]            
                                                                 concatenate_615[0][0]            
                                                                 concatenate_616[0][0]            
__________________________________________________________________________________________________
concatenate_617 (Concatenate)   (None, 640)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 131)          83971       concatenate_617[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            528         idenDense[0][0]                  
==================================================================================================
Total params: 689,893
Trainable params: 689,893
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.2049 - acc: 0.9493
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0617 - acc: 0.9839
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0340 - acc: 0.9918
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0226 - acc: 0.9953
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0778 - acc: 0.9821
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0621 - acc: 0.9843
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0494 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0254 - acc: 0.9949
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0460 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0162 - acc: 0.9972
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0448 - acc: 0.9894
POS tagging accuracy = 94.7
Loss = 0.253, 
POS tagging accuracy = 94.7
Loss = 0.253, 
	TRAINING TIME: 2.68 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.579
	P, R  : 0.695, 0.496

==================================================================================================
	XP Ends: 24/4 (3 h:52)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,150            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,1              ,24             ,3              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.011          ,6              ,12             ,28             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
98             ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 150, 5, 1, 24, 3, 16, 0.011, 6, 12, 28, True, 98, False, False, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:52)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 98)        739410      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1802 (Flatten)          (None, 686)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1803 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1804 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_618 (Concatenate)   (None, 752)          0           flatten_1802[0][0]               
                                                                 flatten_1803[0][0]               
                                                                 flatten_1804[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 28)           21084       concatenate_618[0][0]            
__________________________________________________________________________________________________
dense_97 (Dense)                (None, 152)          4408        posDense[0][0]                   
==================================================================================================
Total params: 770,952
Trainable params: 770,952
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.011
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 98)        739410      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1805 (Flatten)          (None, 686)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1806 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1807 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1808 (Flatten)          (None, 686)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1809 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1810 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1811 (Flatten)          (None, 686)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1812 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1813 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_619 (Concatenate)   (None, 752)          0           flatten_1805[0][0]               
                                                                 flatten_1806[0][0]               
                                                                 flatten_1807[0][0]               
__________________________________________________________________________________________________
concatenate_620 (Concatenate)   (None, 752)          0           flatten_1808[0][0]               
                                                                 flatten_1809[0][0]               
                                                                 flatten_1810[0][0]               
__________________________________________________________________________________________________
concatenate_621 (Concatenate)   (None, 752)          0           flatten_1811[0][0]               
                                                                 flatten_1812[0][0]               
                                                                 flatten_1813[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 28)           21084       concatenate_619[0][0]            
                                                                 concatenate_620[0][0]            
                                                                 concatenate_621[0][0]            
__________________________________________________________________________________________________
concatenate_622 (Concatenate)   (None, 84)           0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 150)          12750       concatenate_622[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            604         idenDense[0][0]                  
==================================================================================================
Total params: 779,898
Trainable params: 779,898
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.4205 - acc: 0.9006
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1589 - acc: 0.9661
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1193 - acc: 0.9731
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0992 - acc: 0.9767
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0715 - acc: 0.9814
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1052 - acc: 0.9751
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0548 - acc: 0.9863
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0870 - acc: 0.9790
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0512 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0768 - acc: 0.9814
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0493 - acc: 0.9881
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0694 - acc: 0.9833
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0481 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0636 - acc: 0.9849
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0472 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0588 - acc: 0.9865
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0466 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0546 - acc: 0.9878
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0462 - acc: 0.9891
POS tagging accuracy = 94.6
Loss = 0.211, 
POS tagging accuracy = 94.6
Loss = 0.211, 
	TRAINING TIME: 6.28 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.591
	P, R  : 0.767, 0.481

==================================================================================================
	XP Ends: 24/4 (3 h:59)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,44             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
22             ,6              ,10             ,4              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.017          ,8              ,20             ,66             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
58             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 44, 22, 6, 10, 4, 9, 0.017, 8, 20, 66, True, 58, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (3h:59)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 58)        437610      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 22)       26092       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1814 (Flatten)          (None, 406)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1815 (Flatten)          (None, 264)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1816 (Flatten)          (None, 18)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1817 (Flatten)          (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_623 (Concatenate)   (None, 696)          0           flatten_1814[0][0]               
                                                                 flatten_1815[0][0]               
                                                                 flatten_1816[0][0]               
                                                                 flatten_1817[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 66)           46002       concatenate_623[0][0]            
__________________________________________________________________________________________________
dense_98 (Dense)                (None, 152)          10184       posDense[0][0]                   
==================================================================================================
Total params: 520,072
Trainable params: 520,072
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.017
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 58)        437610      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 22)       26092       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1818 (Flatten)          (None, 406)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1819 (Flatten)          (None, 264)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1820 (Flatten)          (None, 18)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1821 (Flatten)          (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1822 (Flatten)          (None, 406)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1823 (Flatten)          (None, 264)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1824 (Flatten)          (None, 18)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1825 (Flatten)          (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1826 (Flatten)          (None, 406)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1827 (Flatten)          (None, 264)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1828 (Flatten)          (None, 18)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1829 (Flatten)          (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1830 (Flatten)          (None, 406)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1831 (Flatten)          (None, 264)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1832 (Flatten)          (None, 18)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1833 (Flatten)          (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_624 (Concatenate)   (None, 696)          0           flatten_1818[0][0]               
                                                                 flatten_1819[0][0]               
                                                                 flatten_1820[0][0]               
                                                                 flatten_1821[0][0]               
__________________________________________________________________________________________________
concatenate_625 (Concatenate)   (None, 696)          0           flatten_1822[0][0]               
                                                                 flatten_1823[0][0]               
                                                                 flatten_1824[0][0]               
                                                                 flatten_1825[0][0]               
__________________________________________________________________________________________________
concatenate_626 (Concatenate)   (None, 696)          0           flatten_1826[0][0]               
                                                                 flatten_1827[0][0]               
                                                                 flatten_1828[0][0]               
                                                                 flatten_1829[0][0]               
__________________________________________________________________________________________________
concatenate_627 (Concatenate)   (None, 696)          0           flatten_1830[0][0]               
                                                                 flatten_1831[0][0]               
                                                                 flatten_1832[0][0]               
                                                                 flatten_1833[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 66)           46002       concatenate_624[0][0]            
                                                                 concatenate_625[0][0]            
                                                                 concatenate_626[0][0]            
                                                                 concatenate_627[0][0]            
__________________________________________________________________________________________________
concatenate_628 (Concatenate)   (None, 264)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 44)           11660       concatenate_628[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            180         idenDense[0][0]                  
==================================================================================================
Total params: 521,728
Trainable params: 521,728
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 6s - loss: 0.2540 - acc: 0.9403
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1052 - acc: 0.9745
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0751 - acc: 0.9813
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0587 - acc: 0.9857
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0475 - acc: 0.9884
MWE identification:
Epoch 1/1
 - 88s - loss: 0.0672 - acc: 0.9827
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0682 - acc: 0.9824
MWE identification:
Epoch 1/1
 - 87s - loss: 0.0533 - acc: 0.9868
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0489 - acc: 0.9884
MWE identification:
Epoch 1/1
 - 88s - loss: 0.0497 - acc: 0.9880
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0394 - acc: 0.9912
MWE identification:
Epoch 1/1
 - 90s - loss: 0.0477 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0333 - acc: 0.9927
POS tagging accuracy = 95.0
Loss = 0.224, 
POS tagging accuracy = 95.0
Loss = 0.224, 
	TRAINING TIME: 7.9 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.596
	P, R  : 0.801, 0.475

==================================================================================================
	XP Ends: 24/4 (4 h:8)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,72             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,1              ,32             ,3              ,18             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.035          ,10             ,78             ,25             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
74             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 72, 7, 1, 32, 3, 18, 0.035, 10, 78, 25, True, 74, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (4h:8)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 74)        558330      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1834 (Flatten)          (None, 518)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1835 (Flatten)          (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1836 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1837 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_629 (Concatenate)   (None, 615)          0           flatten_1834[0][0]               
                                                                 flatten_1835[0][0]               
                                                                 flatten_1836[0][0]               
                                                                 flatten_1837[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 25)           15400       concatenate_629[0][0]            
__________________________________________________________________________________________________
dense_99 (Dense)                (None, 152)          3952        posDense[0][0]                   
==================================================================================================
Total params: 586,188
Trainable params: 586,188
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.035
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 74)        558330      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1838 (Flatten)          (None, 518)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1839 (Flatten)          (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1840 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1841 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1842 (Flatten)          (None, 518)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1843 (Flatten)          (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1844 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1845 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1846 (Flatten)          (None, 518)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1847 (Flatten)          (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1848 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1849 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1850 (Flatten)          (None, 518)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1851 (Flatten)          (None, 84)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1852 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1853 (Flatten)          (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1854 (Flatten)          (None, 518)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1855 (Flatten)          (None, 84)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1856 (Flatten)          (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1857 (Flatten)          (None, 10)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_630 (Concatenate)   (None, 615)          0           flatten_1838[0][0]               
                                                                 flatten_1839[0][0]               
                                                                 flatten_1840[0][0]               
                                                                 flatten_1841[0][0]               
__________________________________________________________________________________________________
concatenate_631 (Concatenate)   (None, 615)          0           flatten_1842[0][0]               
                                                                 flatten_1843[0][0]               
                                                                 flatten_1844[0][0]               
                                                                 flatten_1845[0][0]               
__________________________________________________________________________________________________
concatenate_632 (Concatenate)   (None, 615)          0           flatten_1846[0][0]               
                                                                 flatten_1847[0][0]               
                                                                 flatten_1848[0][0]               
                                                                 flatten_1849[0][0]               
__________________________________________________________________________________________________
concatenate_633 (Concatenate)   (None, 615)          0           flatten_1850[0][0]               
                                                                 flatten_1851[0][0]               
                                                                 flatten_1852[0][0]               
                                                                 flatten_1853[0][0]               
__________________________________________________________________________________________________
concatenate_634 (Concatenate)   (None, 615)          0           flatten_1854[0][0]               
                                                                 flatten_1855[0][0]               
                                                                 flatten_1856[0][0]               
                                                                 flatten_1857[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 25)           15400       concatenate_630[0][0]            
                                                                 concatenate_631[0][0]            
                                                                 concatenate_632[0][0]            
                                                                 concatenate_633[0][0]            
                                                                 concatenate_634[0][0]            
__________________________________________________________________________________________________
concatenate_635 (Concatenate)   (None, 125)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 72)           9072        concatenate_635[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            292         idenDense[0][0]                  
==================================================================================================
Total params: 591,600
Trainable params: 591,600
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2547 - acc: 0.9395
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0881 - acc: 0.9775
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0583 - acc: 0.9852
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0420 - acc: 0.9897
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0714 - acc: 0.9825
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0778 - acc: 0.9804
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0524 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0459 - acc: 0.9894
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0485 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0329 - acc: 0.9927
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0466 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0255 - acc: 0.9945
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0455 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0207 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0450 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0175 - acc: 0.9965
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0446 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0150 - acc: 0.9969
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0130 - acc: 0.9974
MWE identification:
Epoch 1/1
 - 33s - loss: 0.0444 - acc: 0.9895
POS tagging accuracy = 95.1
Loss = 0.256, 
POS tagging accuracy = 95.1
Loss = 0.256, 
	TRAINING TIME: 6.78 minutes 
==================================================================================================
	PARSING TIME: 1.33 minutes 
==================================================================================================
	Identification : 0.588
	P, R  : 0.707, 0.504

==================================================================================================
	XP Ends: 24/4 (4 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,78             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
16             ,3              ,66             ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.196          ,9              ,65             ,52             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
180            ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 78, 16, 3, 66, 1, 8, 0.196, 9, 65, 52, True, 180, False, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (4h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.196
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 180)       2058840     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 16)       18976       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1858 (Flatten)          (None, 1260)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1859 (Flatten)          (None, 192)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1860 (Flatten)          (None, 9)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_636 (Concatenate)   (None, 1461)         0           flatten_1858[0][0]               
                                                                 flatten_1859[0][0]               
                                                                 flatten_1860[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 52)           76024       concatenate_636[0][0]            
__________________________________________________________________________________________________
dense_100 (Dense)               (None, 152)          8056        posDense[0][0]                   
==================================================================================================
Total params: 2,162,076
Trainable params: 2,162,076
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.196
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 180)       2058840     bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 16)       18976       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1861 (Flatten)          (None, 1260)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1862 (Flatten)          (None, 192)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1863 (Flatten)          (None, 9)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1864 (Flatten)          (None, 1260)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1865 (Flatten)          (None, 192)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1866 (Flatten)          (None, 9)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1867 (Flatten)          (None, 1260)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1868 (Flatten)          (None, 192)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1869 (Flatten)          (None, 9)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1870 (Flatten)          (None, 1260)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1871 (Flatten)          (None, 192)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1872 (Flatten)          (None, 9)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_637 (Concatenate)   (None, 1461)         0           flatten_1861[0][0]               
                                                                 flatten_1862[0][0]               
                                                                 flatten_1863[0][0]               
__________________________________________________________________________________________________
concatenate_638 (Concatenate)   (None, 1461)         0           flatten_1864[0][0]               
                                                                 flatten_1865[0][0]               
                                                                 flatten_1866[0][0]               
__________________________________________________________________________________________________
concatenate_639 (Concatenate)   (None, 1461)         0           flatten_1867[0][0]               
                                                                 flatten_1868[0][0]               
                                                                 flatten_1869[0][0]               
__________________________________________________________________________________________________
concatenate_640 (Concatenate)   (None, 1461)         0           flatten_1870[0][0]               
                                                                 flatten_1871[0][0]               
                                                                 flatten_1872[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 52)           76024       concatenate_637[0][0]            
                                                                 concatenate_638[0][0]            
                                                                 concatenate_639[0][0]            
                                                                 concatenate_640[0][0]            
__________________________________________________________________________________________________
concatenate_641 (Concatenate)   (None, 208)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 78)           16302       concatenate_641[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            316         idenDense[0][0]                  
==================================================================================================
Total params: 2,170,638
Trainable params: 2,170,638
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.5192 - acc: 0.8829
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2342 - acc: 0.9546
MWE identification:
Epoch 1/1
 - 15s - loss: 5.3215 - acc: 0.6695
POS tagging:
Epoch 1/1
 - 2s - loss: 0.7447 - acc: 0.9121
MWE identification:
Epoch 1/1
 - 15s - loss: 4.8874 - acc: 0.6965
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2551 - acc: 0.9585
MWE identification:
Epoch 1/1
 - 15s - loss: 4.7220 - acc: 0.7069
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2019 - acc: 0.9708
MWE identification:
Epoch 1/1
 - 15s - loss: 4.6322 - acc: 0.7124
POS tagging accuracy = 87.8
Loss = 0.75, 
POS tagging accuracy = 87.8
Loss = 0.75, 
	TRAINING TIME: 2.1 minutes 
==================================================================================================
	PARSING TIME: 0.93 minutes 
==================================================================================================
	Identification : 0.001
	P, R  : 0.002, 0.001

==================================================================================================
	XP Ends: 24/4 (4 h:20)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,99             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,1              ,32             ,1              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.032          ,6              ,19             ,76             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
28             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 99, 6, 1, 32, 1, 10, 0.032, 6, 19, 76, True, 28, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (4h:20)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1873 (Flatten)          (None, 196)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1874 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1875 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1876 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_642 (Concatenate)   (None, 277)          0           flatten_1873[0][0]               
                                                                 flatten_1874[0][0]               
                                                                 flatten_1875[0][0]               
                                                                 flatten_1876[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 76)           21128       concatenate_642[0][0]            
__________________________________________________________________________________________________
dense_101 (Dense)               (None, 152)          11704       posDense[0][0]                   
==================================================================================================
Total params: 251,332
Trainable params: 251,332
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1877 (Flatten)          (None, 196)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1878 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1879 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1880 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1881 (Flatten)          (None, 196)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1882 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1883 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1884 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1885 (Flatten)          (None, 196)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1886 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1887 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1888 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1889 (Flatten)          (None, 196)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1890 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1891 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1892 (Flatten)          (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_643 (Concatenate)   (None, 277)          0           flatten_1877[0][0]               
                                                                 flatten_1878[0][0]               
                                                                 flatten_1879[0][0]               
                                                                 flatten_1880[0][0]               
__________________________________________________________________________________________________
concatenate_644 (Concatenate)   (None, 277)          0           flatten_1881[0][0]               
                                                                 flatten_1882[0][0]               
                                                                 flatten_1883[0][0]               
                                                                 flatten_1884[0][0]               
__________________________________________________________________________________________________
concatenate_645 (Concatenate)   (None, 277)          0           flatten_1885[0][0]               
                                                                 flatten_1886[0][0]               
                                                                 flatten_1887[0][0]               
                                                                 flatten_1888[0][0]               
__________________________________________________________________________________________________
concatenate_646 (Concatenate)   (None, 277)          0           flatten_1889[0][0]               
                                                                 flatten_1890[0][0]               
                                                                 flatten_1891[0][0]               
                                                                 flatten_1892[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 76)           21128       concatenate_643[0][0]            
                                                                 concatenate_644[0][0]            
                                                                 concatenate_645[0][0]            
                                                                 concatenate_646[0][0]            
__________________________________________________________________________________________________
concatenate_647 (Concatenate)   (None, 304)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 99)           30195       concatenate_647[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            400         idenDense[0][0]                  
==================================================================================================
Total params: 270,223
Trainable params: 270,223
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 6s - loss: 0.2250 - acc: 0.9451
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0893 - acc: 0.9769
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0660 - acc: 0.9833
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0927 - acc: 0.9758
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0511 - acc: 0.9873
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0621 - acc: 0.9842
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0480 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0471 - acc: 0.9884
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0464 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0371 - acc: 0.9910
MWE identification:
Epoch 1/1
 - 28s - loss: 0.0454 - acc: 0.9892
POS tagging accuracy = 95.0
Loss = 0.201, 
POS tagging accuracy = 95.0
Loss = 0.201, 
	TRAINING TIME: 4.1 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.595
	P, R  : 0.725, 0.504

==================================================================================================
	XP Ends: 24/4 (4 h:25)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,31             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
12             ,2              ,70             ,3              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.015          ,5              ,18             ,28             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
102            ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 31, 12, 2, 70, 3, 8, 0.015, 5, 18, 28, True, 102, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (4h:25)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 102)       769590      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1893 (Flatten)          (None, 714)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1894 (Flatten)          (None, 144)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1895 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_648 (Concatenate)   (None, 863)          0           flatten_1893[0][0]               
                                                                 flatten_1894[0][0]               
                                                                 flatten_1895[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 28)           24192       concatenate_648[0][0]            
__________________________________________________________________________________________________
dense_102 (Dense)               (None, 152)          4408        posDense[0][0]                   
==================================================================================================
Total params: 812,522
Trainable params: 812,522
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 102)       769590      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1896 (Flatten)          (None, 714)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1897 (Flatten)          (None, 144)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1898 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1899 (Flatten)          (None, 714)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1900 (Flatten)          (None, 144)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1901 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1902 (Flatten)          (None, 714)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1903 (Flatten)          (None, 144)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1904 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1905 (Flatten)          (None, 714)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1906 (Flatten)          (None, 144)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1907 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1908 (Flatten)          (None, 714)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1909 (Flatten)          (None, 144)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1910 (Flatten)          (None, 5)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_649 (Concatenate)   (None, 863)          0           flatten_1896[0][0]               
                                                                 flatten_1897[0][0]               
                                                                 flatten_1898[0][0]               
__________________________________________________________________________________________________
concatenate_650 (Concatenate)   (None, 863)          0           flatten_1899[0][0]               
                                                                 flatten_1900[0][0]               
                                                                 flatten_1901[0][0]               
__________________________________________________________________________________________________
concatenate_651 (Concatenate)   (None, 863)          0           flatten_1902[0][0]               
                                                                 flatten_1903[0][0]               
                                                                 flatten_1904[0][0]               
__________________________________________________________________________________________________
concatenate_652 (Concatenate)   (None, 863)          0           flatten_1905[0][0]               
                                                                 flatten_1906[0][0]               
                                                                 flatten_1907[0][0]               
__________________________________________________________________________________________________
concatenate_653 (Concatenate)   (None, 863)          0           flatten_1908[0][0]               
                                                                 flatten_1909[0][0]               
                                                                 flatten_1910[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 28)           24192       concatenate_649[0][0]            
                                                                 concatenate_650[0][0]            
                                                                 concatenate_651[0][0]            
                                                                 concatenate_652[0][0]            
                                                                 concatenate_653[0][0]            
__________________________________________________________________________________________________
concatenate_654 (Concatenate)   (None, 140)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 31)           4371        concatenate_654[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            128         idenDense[0][0]                  
==================================================================================================
Total params: 812,613
Trainable params: 812,613
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 6s - loss: 0.3117 - acc: 0.9279
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1241 - acc: 0.9724
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0928 - acc: 0.9779
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0757 - acc: 0.9818
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0786 - acc: 0.9806
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0867 - acc: 0.9786
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0562 - acc: 0.9864
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0690 - acc: 0.9832
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0521 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0589 - acc: 0.9859
MWE identification:
Epoch 1/1
 - 14s - loss: 0.0499 - acc: 0.9882
POS tagging accuracy = 95.1
Loss = 0.218, 
POS tagging accuracy = 95.1
Loss = 0.218, 
	TRAINING TIME: 2.77 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.598
	P, R  : 0.773, 0.488

==================================================================================================
	XP Ends: 24/4 (4 h:29)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,80             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
15             ,9              ,19             ,2              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.098          ,13             ,127            ,26             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
122            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 80, 15, 9, 19, 2, 9, 0.098, 13, 127, 26, True, 122, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (4h:29)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.098
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 122)       920490      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1911 (Flatten)          (None, 854)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1912 (Flatten)          (None, 180)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1913 (Flatten)          (None, 27)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1914 (Flatten)          (None, 13)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_655 (Concatenate)   (None, 1074)         0           flatten_1911[0][0]               
                                                                 flatten_1912[0][0]               
                                                                 flatten_1913[0][0]               
                                                                 flatten_1914[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 26)           27950       concatenate_655[0][0]            
__________________________________________________________________________________________________
dense_103 (Dense)               (None, 152)          4104        posDense[0][0]                   
==================================================================================================
Total params: 970,630
Trainable params: 970,630
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.098
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 122)       920490      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1915 (Flatten)          (None, 854)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1916 (Flatten)          (None, 180)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1917 (Flatten)          (None, 27)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1918 (Flatten)          (None, 13)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1919 (Flatten)          (None, 854)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1920 (Flatten)          (None, 180)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1921 (Flatten)          (None, 27)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1922 (Flatten)          (None, 13)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1923 (Flatten)          (None, 854)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1924 (Flatten)          (None, 180)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1925 (Flatten)          (None, 27)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1926 (Flatten)          (None, 13)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1927 (Flatten)          (None, 854)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1928 (Flatten)          (None, 180)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1929 (Flatten)          (None, 27)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1930 (Flatten)          (None, 13)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1931 (Flatten)          (None, 854)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1932 (Flatten)          (None, 180)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1933 (Flatten)          (None, 27)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_1934 (Flatten)          (None, 13)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_656 (Concatenate)   (None, 1074)         0           flatten_1915[0][0]               
                                                                 flatten_1916[0][0]               
                                                                 flatten_1917[0][0]               
                                                                 flatten_1918[0][0]               
__________________________________________________________________________________________________
concatenate_657 (Concatenate)   (None, 1074)         0           flatten_1919[0][0]               
                                                                 flatten_1920[0][0]               
                                                                 flatten_1921[0][0]               
                                                                 flatten_1922[0][0]               
__________________________________________________________________________________________________
concatenate_658 (Concatenate)   (None, 1074)         0           flatten_1923[0][0]               
                                                                 flatten_1924[0][0]               
                                                                 flatten_1925[0][0]               
                                                                 flatten_1926[0][0]               
__________________________________________________________________________________________________
concatenate_659 (Concatenate)   (None, 1074)         0           flatten_1927[0][0]               
                                                                 flatten_1928[0][0]               
                                                                 flatten_1929[0][0]               
                                                                 flatten_1930[0][0]               
__________________________________________________________________________________________________
concatenate_660 (Concatenate)   (None, 1074)         0           flatten_1931[0][0]               
                                                                 flatten_1932[0][0]               
                                                                 flatten_1933[0][0]               
                                                                 flatten_1934[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 26)           27950       concatenate_656[0][0]            
                                                                 concatenate_657[0][0]            
                                                                 concatenate_658[0][0]            
                                                                 concatenate_659[0][0]            
                                                                 concatenate_660[0][0]            
__________________________________________________________________________________________________
concatenate_661 (Concatenate)   (None, 130)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 80)           10480       concatenate_661[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            324         idenDense[0][0]                  
==================================================================================================
Total params: 977,330
Trainable params: 977,330
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2660 - acc: 0.9363
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0697 - acc: 0.9809
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0391 - acc: 0.9894
MWE identification:
Epoch 1/1
 - 56s - loss: 12.0882 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0335 - acc: 0.9914
MWE identification:
Epoch 1/1
 - 56s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0216 - acc: 0.9947
MWE identification:
Epoch 1/1
 - 56s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0171 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 56s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0149 - acc: 0.9967
POS tagging accuracy = 95.4
Loss = 0.241, 
POS tagging accuracy = 95.4
Loss = 0.241, 
	TRAINING TIME: 5.23 minutes 
==================================================================================================
	PARSING TIME: 2.43 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (4 h:37)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,140            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,1              ,11             ,2              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.071          ,5              ,96             ,50             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
54             ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 140, 5, 1, 11, 2, 11, 0.071, 5, 96, 50, True, 54, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (4h:37)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 54)        617652      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1935 (Flatten)          (None, 378)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1936 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1937 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_662 (Concatenate)   (None, 443)          0           flatten_1935[0][0]               
                                                                 flatten_1936[0][0]               
                                                                 flatten_1937[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 50)           22200       concatenate_662[0][0]            
__________________________________________________________________________________________________
dense_104 (Dense)               (None, 152)          7752        posDense[0][0]                   
==================================================================================================
Total params: 653,634
Trainable params: 653,634
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.071
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 54)        617652      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1938 (Flatten)          (None, 378)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1939 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1940 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1941 (Flatten)          (None, 378)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1942 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1943 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1944 (Flatten)          (None, 378)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1945 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1946 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1947 (Flatten)          (None, 378)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1948 (Flatten)          (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1949 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_1950 (Flatten)          (None, 378)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1951 (Flatten)          (None, 60)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_1952 (Flatten)          (None, 5)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_663 (Concatenate)   (None, 443)          0           flatten_1938[0][0]               
                                                                 flatten_1939[0][0]               
                                                                 flatten_1940[0][0]               
__________________________________________________________________________________________________
concatenate_664 (Concatenate)   (None, 443)          0           flatten_1941[0][0]               
                                                                 flatten_1942[0][0]               
                                                                 flatten_1943[0][0]               
__________________________________________________________________________________________________
concatenate_665 (Concatenate)   (None, 443)          0           flatten_1944[0][0]               
                                                                 flatten_1945[0][0]               
                                                                 flatten_1946[0][0]               
__________________________________________________________________________________________________
concatenate_666 (Concatenate)   (None, 443)          0           flatten_1947[0][0]               
                                                                 flatten_1948[0][0]               
                                                                 flatten_1949[0][0]               
__________________________________________________________________________________________________
concatenate_667 (Concatenate)   (None, 443)          0           flatten_1950[0][0]               
                                                                 flatten_1951[0][0]               
                                                                 flatten_1952[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 50)           22200       concatenate_663[0][0]            
                                                                 concatenate_664[0][0]            
                                                                 concatenate_665[0][0]            
                                                                 concatenate_666[0][0]            
                                                                 concatenate_667[0][0]            
__________________________________________________________________________________________________
concatenate_668 (Concatenate)   (None, 250)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 140)          35140       concatenate_668[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            564         idenDense[0][0]                  
==================================================================================================
Total params: 681,586
Trainable params: 681,586
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2469 - acc: 0.9363
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0901 - acc: 0.9755
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0505 - acc: 0.9865
MWE identification:
Epoch 1/1
 - 80s - loss: 12.0883 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0376 - acc: 0.9908
MWE identification:
Epoch 1/1
 - 80s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0232 - acc: 0.9943
MWE identification:
Epoch 1/1
 - 80s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0168 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 80s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0132 - acc: 0.9970
MWE identification:
Epoch 1/1
 - 80s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0106 - acc: 0.9976
POS tagging accuracy = 93.9
Loss = 0.286, 
POS tagging accuracy = 93.9
Loss = 0.286, 
	TRAINING TIME: 8.05 minutes 
==================================================================================================
	PARSING TIME: 2.42 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.075

==================================================================================================
	XP Ends: 24/4 (4 h:48)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,75             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
18             ,9              ,13             ,1              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.083          ,12             ,32             ,53             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
167            ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 75, 18, 9, 13, 1, 11, 0.083, 12, 32, 53, True, 167, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (4h:48)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 167)       1260015     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_1953 (Flatten)          (None, 1169)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1954 (Flatten)          (None, 216)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1955 (Flatten)          (None, 27)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_1956 (Flatten)          (None, 12)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_669 (Concatenate)   (None, 1424)         0           flatten_1953[0][0]               
                                                                 flatten_1954[0][0]               
                                                                 flatten_1955[0][0]               
                                                                 flatten_1956[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 53)           75525       concatenate_669[0][0]            
__________________________________________________________________________________________________
dense_105 (Dense)               (None, 152)          8208        posDense[0][0]                   
==================================================================================================
Total params: 1,365,372
Trainable params: 1,365,372
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.083
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 167)       1260015     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_1957 (Flatten)          (None, 1169)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1958 (Flatten)          (None, 216)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1959 (Flatten)          (None, 27)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1960 (Flatten)          (None, 12)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_1961 (Flatten)          (None, 1169)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1962 (Flatten)          (None, 216)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1963 (Flatten)          (None, 27)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1964 (Flatten)          (None, 12)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_1965 (Flatten)          (None, 1169)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1966 (Flatten)          (None, 216)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1967 (Flatten)          (None, 27)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1968 (Flatten)          (None, 12)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_1969 (Flatten)          (None, 1169)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1970 (Flatten)          (None, 216)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1971 (Flatten)          (None, 27)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_1972 (Flatten)          (None, 12)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_670 (Concatenate)   (None, 1424)         0           flatten_1957[0][0]               
                                                                 flatten_1958[0][0]               
                                                                 flatten_1959[0][0]               
                                                                 flatten_1960[0][0]               
__________________________________________________________________________________________________
concatenate_671 (Concatenate)   (None, 1424)         0           flatten_1961[0][0]               
                                                                 flatten_1962[0][0]               
                                                                 flatten_1963[0][0]               
                                                                 flatten_1964[0][0]               
__________________________________________________________________________________________________
concatenate_672 (Concatenate)   (None, 1424)         0           flatten_1965[0][0]               
                                                                 flatten_1966[0][0]               
                                                                 flatten_1967[0][0]               
                                                                 flatten_1968[0][0]               
__________________________________________________________________________________________________
concatenate_673 (Concatenate)   (None, 1424)         0           flatten_1969[0][0]               
                                                                 flatten_1970[0][0]               
                                                                 flatten_1971[0][0]               
                                                                 flatten_1972[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 53)           75525       concatenate_670[0][0]            
                                                                 concatenate_671[0][0]            
                                                                 concatenate_672[0][0]            
                                                                 concatenate_673[0][0]            
__________________________________________________________________________________________________
concatenate_674 (Concatenate)   (None, 212)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 75)           15975       concatenate_674[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            304         idenDense[0][0]                  
==================================================================================================
Total params: 1,373,443
Trainable params: 1,373,443
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2267 - acc: 0.9462
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0663 - acc: 0.9819
MWE identification:
Epoch 1/1
 - 73s - loss: 0.0720 - acc: 0.9817
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1110 - acc: 0.9719
MWE identification:
Epoch 1/1
 - 72s - loss: 0.0508 - acc: 0.9874
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0505 - acc: 0.9869
MWE identification:
Epoch 1/1
 - 73s - loss: 0.0464 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0326 - acc: 0.9920
MWE identification:
Epoch 1/1
 - 73s - loss: 0.0451 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0253 - acc: 0.9939
MWE identification:
Epoch 1/1
 - 73s - loss: 0.0446 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0216 - acc: 0.9948
POS tagging accuracy = 94.7
Loss = 0.283, 
POS tagging accuracy = 94.7
Loss = 0.283, 
	TRAINING TIME: 7.67 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.658, 0.528

==================================================================================================
	XP Ends: 24/4 (4 h:57)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,45             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
15             ,1              ,9              ,1              ,19             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.016          ,5              ,84             ,58             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
33             ,True           ,True           ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 45, 15, 1, 9, 1, 19, 0.016, 5, 84, 58, True, 33, True, True, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (4h:57)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 33)        377454      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       affixes[0][0]                    
__________________________________________________________________________________________________
flatten_1973 (Flatten)          (None, 231)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1974 (Flatten)          (None, 180)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_675 (Concatenate)   (None, 411)          0           flatten_1973[0][0]               
                                                                 flatten_1974[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 58)           23896       concatenate_675[0][0]            
__________________________________________________________________________________________________
dense_106 (Dense)               (None, 152)          8968        posDense[0][0]                   
==================================================================================================
Total params: 428,108
Trainable params: 428,108
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 33)        377454      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_1975 (Flatten)          (None, 231)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1976 (Flatten)          (None, 180)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1977 (Flatten)          (None, 231)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1978 (Flatten)          (None, 180)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1979 (Flatten)          (None, 231)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1980 (Flatten)          (None, 180)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1981 (Flatten)          (None, 231)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1982 (Flatten)          (None, 180)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1983 (Flatten)          (None, 231)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_1984 (Flatten)          (None, 180)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
concatenate_676 (Concatenate)   (None, 411)          0           flatten_1975[0][0]               
                                                                 flatten_1976[0][0]               
__________________________________________________________________________________________________
concatenate_677 (Concatenate)   (None, 411)          0           flatten_1977[0][0]               
                                                                 flatten_1978[0][0]               
__________________________________________________________________________________________________
concatenate_678 (Concatenate)   (None, 411)          0           flatten_1979[0][0]               
                                                                 flatten_1980[0][0]               
__________________________________________________________________________________________________
concatenate_679 (Concatenate)   (None, 411)          0           flatten_1981[0][0]               
                                                                 flatten_1982[0][0]               
__________________________________________________________________________________________________
concatenate_680 (Concatenate)   (None, 411)          0           flatten_1983[0][0]               
                                                                 flatten_1984[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 58)           23896       concatenate_676[0][0]            
                                                                 concatenate_677[0][0]            
                                                                 concatenate_678[0][0]            
                                                                 concatenate_679[0][0]            
                                                                 concatenate_680[0][0]            
__________________________________________________________________________________________________
concatenate_681 (Concatenate)   (None, 290)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 45)           13095       concatenate_681[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            184         idenDense[0][0]                  
==================================================================================================
Total params: 432,419
Trainable params: 432,419
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.3836 - acc: 0.9068
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1796 - acc: 0.9564
MWE identification:
Epoch 1/1
 - 79s - loss: 0.0788 - acc: 0.9798
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1630 - acc: 0.9608
MWE identification:
Epoch 1/1
 - 82s - loss: 0.0578 - acc: 0.9859
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1294 - acc: 0.9689
MWE identification:
Epoch 1/1
 - 80s - loss: 0.0524 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1101 - acc: 0.9736
MWE identification:
Epoch 1/1
 - 83s - loss: 0.0497 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0959 - acc: 0.9769
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0480 - acc: 0.9887
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0849 - acc: 0.9798
MWE identification:
Epoch 1/1
 - 82s - loss: 0.0470 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0761 - acc: 0.9824
MWE identification:
Epoch 1/1
 - 83s - loss: 0.0464 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0688 - acc: 0.9842
MWE identification:
Epoch 1/1
 - 82s - loss: 0.0458 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0627 - acc: 0.9855
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0455 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0575 - acc: 0.9868
POS tagging accuracy = 94.1
Loss = 0.222, 
POS tagging accuracy = 94.1
Loss = 0.222, 
	TRAINING TIME: 13.38 minutes 
==================================================================================================
	PARSING TIME: 0.83 minutes 
==================================================================================================
	Identification : 0.522
	P, R  : 0.554, 0.494

==================================================================================================
	XP Ends: 24/4 (5 h:12)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,161            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,8              ,16             ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.155          ,8              ,32             ,146            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
58             ,True           ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 161, 7, 8, 16, 1, 8, 0.155, 8, 32, 146, True, 58, True, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (5h:12)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.155
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 58)        437610      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_1985 (Flatten)          (None, 406)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_1986 (Flatten)          (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_1987 (Flatten)          (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_682 (Concatenate)   (None, 514)          0           flatten_1985[0][0]               
                                                                 flatten_1986[0][0]               
                                                                 flatten_1987[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 146)          75190       concatenate_682[0][0]            
__________________________________________________________________________________________________
dense_107 (Dense)               (None, 152)          22344       posDense[0][0]                   
==================================================================================================
Total params: 543,478
Trainable params: 543,478
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.155
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 58)        437610      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_1988 (Flatten)          (None, 406)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_1989 (Flatten)          (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_1990 (Flatten)          (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_1991 (Flatten)          (None, 406)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_1992 (Flatten)          (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_1993 (Flatten)          (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_1994 (Flatten)          (None, 406)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_1995 (Flatten)          (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_1996 (Flatten)          (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_1997 (Flatten)          (None, 406)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_1998 (Flatten)          (None, 84)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_1999 (Flatten)          (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_683 (Concatenate)   (None, 514)          0           flatten_1988[0][0]               
                                                                 flatten_1989[0][0]               
                                                                 flatten_1990[0][0]               
__________________________________________________________________________________________________
concatenate_684 (Concatenate)   (None, 514)          0           flatten_1991[0][0]               
                                                                 flatten_1992[0][0]               
                                                                 flatten_1993[0][0]               
__________________________________________________________________________________________________
concatenate_685 (Concatenate)   (None, 514)          0           flatten_1994[0][0]               
                                                                 flatten_1995[0][0]               
                                                                 flatten_1996[0][0]               
__________________________________________________________________________________________________
concatenate_686 (Concatenate)   (None, 514)          0           flatten_1997[0][0]               
                                                                 flatten_1998[0][0]               
                                                                 flatten_1999[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 146)          75190       concatenate_683[0][0]            
                                                                 concatenate_684[0][0]            
                                                                 concatenate_685[0][0]            
                                                                 concatenate_686[0][0]            
__________________________________________________________________________________________________
concatenate_687 (Concatenate)   (None, 584)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 161)          94185       concatenate_687[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            648         idenDense[0][0]                  
==================================================================================================
Total params: 615,967
Trainable params: 615,967
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2763 - acc: 0.9336
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0905 - acc: 0.9768
MWE identification:
Epoch 1/1
 - 49s - loss: 8.2670 - acc: 0.4871
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1165 - acc: 0.9711
MWE identification:
Epoch 1/1
 - 49s - loss: 8.1138 - acc: 0.4966
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0628 - acc: 0.9840
MWE identification:
Epoch 1/1
 - 49s - loss: 8.1108 - acc: 0.4968
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0400 - acc: 0.9904
MWE identification:
Epoch 1/1
 - 49s - loss: 8.1128 - acc: 0.4967
POS tagging accuracy = 93.0
Loss = 0.353, 
POS tagging accuracy = 93.0
Loss = 0.353, 
	TRAINING TIME: 4.48 minutes 
==================================================================================================
	PARSING TIME: 0.87 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (5 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,129            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
12             ,5              ,52             ,3              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.031          ,11             ,31             ,25             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
37             ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 129, 12, 5, 52, 3, 13, 0.031, 11, 31, 25, True, 37, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (5h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 37)        279165      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 11)        220         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2000 (Flatten)          (None, 259)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2001 (Flatten)          (None, 144)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2002 (Flatten)          (None, 11)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_688 (Concatenate)   (None, 414)          0           flatten_2000[0][0]               
                                                                 flatten_2001[0][0]               
                                                                 flatten_2002[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 25)           10375       concatenate_688[0][0]            
__________________________________________________________________________________________________
dense_108 (Dense)               (None, 152)          3952        posDense[0][0]                   
==================================================================================================
Total params: 307,944
Trainable params: 307,944
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 37)        279165      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 11)        220         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2003 (Flatten)          (None, 259)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2004 (Flatten)          (None, 144)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2005 (Flatten)          (None, 11)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2006 (Flatten)          (None, 259)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2007 (Flatten)          (None, 144)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2008 (Flatten)          (None, 11)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2009 (Flatten)          (None, 259)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2010 (Flatten)          (None, 144)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2011 (Flatten)          (None, 11)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2012 (Flatten)          (None, 259)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2013 (Flatten)          (None, 144)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2014 (Flatten)          (None, 11)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2015 (Flatten)          (None, 259)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2016 (Flatten)          (None, 144)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2017 (Flatten)          (None, 11)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_689 (Concatenate)   (None, 414)          0           flatten_2003[0][0]               
                                                                 flatten_2004[0][0]               
                                                                 flatten_2005[0][0]               
__________________________________________________________________________________________________
concatenate_690 (Concatenate)   (None, 414)          0           flatten_2006[0][0]               
                                                                 flatten_2007[0][0]               
                                                                 flatten_2008[0][0]               
__________________________________________________________________________________________________
concatenate_691 (Concatenate)   (None, 414)          0           flatten_2009[0][0]               
                                                                 flatten_2010[0][0]               
                                                                 flatten_2011[0][0]               
__________________________________________________________________________________________________
concatenate_692 (Concatenate)   (None, 414)          0           flatten_2012[0][0]               
                                                                 flatten_2013[0][0]               
                                                                 flatten_2014[0][0]               
__________________________________________________________________________________________________
concatenate_693 (Concatenate)   (None, 414)          0           flatten_2015[0][0]               
                                                                 flatten_2016[0][0]               
                                                                 flatten_2017[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 25)           10375       concatenate_689[0][0]            
                                                                 concatenate_690[0][0]            
                                                                 concatenate_691[0][0]            
                                                                 concatenate_692[0][0]            
                                                                 concatenate_693[0][0]            
__________________________________________________________________________________________________
concatenate_694 (Concatenate)   (None, 125)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 129)          16254       concatenate_694[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            520         idenDense[0][0]                  
==================================================================================================
Total params: 320,766
Trainable params: 320,766
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2547 - acc: 0.9395
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1022 - acc: 0.9748
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0726 - acc: 0.9821
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0564 - acc: 0.9858
MWE identification:
Epoch 1/1
 - 17s - loss: 12.0868 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0480 - acc: 0.9885
MWE identification:
Epoch 1/1
 - 17s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0380 - acc: 0.9912
MWE identification:
Epoch 1/1
 - 17s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0317 - acc: 0.9926
MWE identification:
Epoch 1/1
 - 17s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0270 - acc: 0.9941
MWE identification:
Epoch 1/1
 - 17s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0233 - acc: 0.9952
MWE identification:
Epoch 1/1
 - 17s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0204 - acc: 0.9957
POS tagging accuracy = 95.0
Loss = 0.226, 
POS tagging accuracy = 95.0
Loss = 0.226, 
	TRAINING TIME: 3.48 minutes 
==================================================================================================
	PARSING TIME: 1.03 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (5 h:22)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,34             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
18             ,4              ,29             ,2              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.117          ,5              ,34             ,47             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
69             ,True           ,True           ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 34, 18, 4, 29, 2, 13, 0.117, 5, 34, 47, True, 69, True, True, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (5h:22)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.117
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 69)        520605      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       affixes[0][0]                    
__________________________________________________________________________________________________
flatten_2018 (Flatten)          (None, 483)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2019 (Flatten)          (None, 216)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_695 (Concatenate)   (None, 699)          0           flatten_2018[0][0]               
                                                                 flatten_2019[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 47)           32900       concatenate_695[0][0]            
__________________________________________________________________________________________________
dense_109 (Dense)               (None, 152)          7296        posDense[0][0]                   
==================================================================================================
Total params: 582,149
Trainable params: 582,149
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.117
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 69)        520605      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_2020 (Flatten)          (None, 483)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2021 (Flatten)          (None, 216)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2022 (Flatten)          (None, 483)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2023 (Flatten)          (None, 216)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2024 (Flatten)          (None, 483)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2025 (Flatten)          (None, 216)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2026 (Flatten)          (None, 483)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2027 (Flatten)          (None, 216)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2028 (Flatten)          (None, 483)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2029 (Flatten)          (None, 216)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
concatenate_696 (Concatenate)   (None, 699)          0           flatten_2020[0][0]               
                                                                 flatten_2021[0][0]               
__________________________________________________________________________________________________
concatenate_697 (Concatenate)   (None, 699)          0           flatten_2022[0][0]               
                                                                 flatten_2023[0][0]               
__________________________________________________________________________________________________
concatenate_698 (Concatenate)   (None, 699)          0           flatten_2024[0][0]               
                                                                 flatten_2025[0][0]               
__________________________________________________________________________________________________
concatenate_699 (Concatenate)   (None, 699)          0           flatten_2026[0][0]               
                                                                 flatten_2027[0][0]               
__________________________________________________________________________________________________
concatenate_700 (Concatenate)   (None, 699)          0           flatten_2028[0][0]               
                                                                 flatten_2029[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 47)           32900       concatenate_696[0][0]            
                                                                 concatenate_697[0][0]            
                                                                 concatenate_698[0][0]            
                                                                 concatenate_699[0][0]            
                                                                 concatenate_700[0][0]            
__________________________________________________________________________________________________
concatenate_701 (Concatenate)   (None, 235)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 34)           8024        concatenate_701[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            140         idenDense[0][0]                  
==================================================================================================
Total params: 583,017
Trainable params: 583,017
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2398 - acc: 0.9429
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0763 - acc: 0.9798
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0475 - acc: 0.9872
MWE identification:
Epoch 1/1
 - 27s - loss: 0.0757 - acc: 0.9812
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1179 - acc: 0.9701
MWE identification:
Epoch 1/1
 - 27s - loss: 0.0522 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0561 - acc: 0.9852
MWE identification:
Epoch 1/1
 - 27s - loss: 0.0477 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0367 - acc: 0.9909
MWE identification:
Epoch 1/1
 - 26s - loss: 0.0457 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0286 - acc: 0.9933
MWE identification:
Epoch 1/1
 - 26s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0246 - acc: 0.9943
MWE identification:
Epoch 1/1
 - 26s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0220 - acc: 0.9951
POS tagging accuracy = 94.8
Loss = 0.314, 
POS tagging accuracy = 94.8
Loss = 0.314, 
	TRAINING TIME: 3.97 minutes 
==================================================================================================
	PARSING TIME: 0.83 minutes 
==================================================================================================
	Identification : 0.563
	P, R  : 0.611, 0.522

==================================================================================================
	XP Ends: 24/4 (5 h:27)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,148            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,9              ,80             ,1              ,17             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.049          ,10             ,25             ,27             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
42             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 148, 13, 9, 80, 1, 17, 0.049, 10, 25, 27, True, 42, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (5h:27)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.049
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 42)        480396      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2030 (Flatten)          (None, 294)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2031 (Flatten)          (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2032 (Flatten)          (None, 27)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_702 (Concatenate)   (None, 477)          0           flatten_2030[0][0]               
                                                                 flatten_2031[0][0]               
                                                                 flatten_2032[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 27)           12906       concatenate_702[0][0]            
__________________________________________________________________________________________________
dense_110 (Dense)               (None, 152)          4256        posDense[0][0]                   
==================================================================================================
Total params: 513,012
Trainable params: 513,012
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.049
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 42)        480396      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2033 (Flatten)          (None, 294)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2034 (Flatten)          (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2035 (Flatten)          (None, 27)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2036 (Flatten)          (None, 294)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2037 (Flatten)          (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2038 (Flatten)          (None, 27)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2039 (Flatten)          (None, 294)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2040 (Flatten)          (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2041 (Flatten)          (None, 27)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2042 (Flatten)          (None, 294)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2043 (Flatten)          (None, 156)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2044 (Flatten)          (None, 27)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2045 (Flatten)          (None, 294)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2046 (Flatten)          (None, 156)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2047 (Flatten)          (None, 27)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_703 (Concatenate)   (None, 477)          0           flatten_2033[0][0]               
                                                                 flatten_2034[0][0]               
                                                                 flatten_2035[0][0]               
__________________________________________________________________________________________________
concatenate_704 (Concatenate)   (None, 477)          0           flatten_2036[0][0]               
                                                                 flatten_2037[0][0]               
                                                                 flatten_2038[0][0]               
__________________________________________________________________________________________________
concatenate_705 (Concatenate)   (None, 477)          0           flatten_2039[0][0]               
                                                                 flatten_2040[0][0]               
                                                                 flatten_2041[0][0]               
__________________________________________________________________________________________________
concatenate_706 (Concatenate)   (None, 477)          0           flatten_2042[0][0]               
                                                                 flatten_2043[0][0]               
                                                                 flatten_2044[0][0]               
__________________________________________________________________________________________________
concatenate_707 (Concatenate)   (None, 477)          0           flatten_2045[0][0]               
                                                                 flatten_2046[0][0]               
                                                                 flatten_2047[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 27)           12906       concatenate_703[0][0]            
                                                                 concatenate_704[0][0]            
                                                                 concatenate_705[0][0]            
                                                                 concatenate_706[0][0]            
                                                                 concatenate_707[0][0]            
__________________________________________________________________________________________________
concatenate_708 (Concatenate)   (None, 135)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 148)          20128       concatenate_708[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            596         idenDense[0][0]                  
==================================================================================================
Total params: 529,480
Trainable params: 529,480
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2548 - acc: 0.9366
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1134 - acc: 0.9709
MWE identification:
Epoch 1/1
 - 12s - loss: 0.3932 - acc: 0.9613
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1196 - acc: 0.9705
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0584 - acc: 0.9867
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0755 - acc: 0.9821
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0489 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0533 - acc: 0.9875
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0462 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0408 - acc: 0.9907
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0453 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0329 - acc: 0.9922
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0272 - acc: 0.9938
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0447 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0230 - acc: 0.9950
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0198 - acc: 0.9956
POS tagging accuracy = 93.7
Loss = 0.286, 
POS tagging accuracy = 93.7
Loss = 0.286, 
	TRAINING TIME: 3.52 minutes 
==================================================================================================
	PARSING TIME: 1.15 minutes 
==================================================================================================
	Identification : 0.504
	P, R  : 0.536, 0.476

==================================================================================================
	XP Ends: 24/4 (5 h:32)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,41             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,2              ,8              ,1              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.031          ,8              ,52             ,170            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
52             ,False          ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 41, 5, 2, 8, 1, 15, 0.031, 8, 52, 170, True, 52, False, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (5h:32)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 52)        392340      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2048 (Flatten)          (None, 364)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2049 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2050 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_709 (Concatenate)   (None, 430)          0           flatten_2048[0][0]               
                                                                 flatten_2049[0][0]               
                                                                 flatten_2050[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 170)          73270       concatenate_709[0][0]            
__________________________________________________________________________________________________
dense_111 (Dense)               (None, 152)          25992       posDense[0][0]                   
==================================================================================================
Total params: 497,540
Trainable params: 497,540
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.031
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 52)        392340      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2051 (Flatten)          (None, 364)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2052 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2053 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2054 (Flatten)          (None, 364)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2055 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2056 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2057 (Flatten)          (None, 364)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2058 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2059 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
concatenate_710 (Concatenate)   (None, 430)          0           flatten_2051[0][0]               
                                                                 flatten_2052[0][0]               
                                                                 flatten_2053[0][0]               
__________________________________________________________________________________________________
concatenate_711 (Concatenate)   (None, 430)          0           flatten_2054[0][0]               
                                                                 flatten_2055[0][0]               
                                                                 flatten_2056[0][0]               
__________________________________________________________________________________________________
concatenate_712 (Concatenate)   (None, 430)          0           flatten_2057[0][0]               
                                                                 flatten_2058[0][0]               
                                                                 flatten_2059[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 170)          73270       concatenate_710[0][0]            
                                                                 concatenate_711[0][0]            
                                                                 concatenate_712[0][0]            
__________________________________________________________________________________________________
concatenate_713 (Concatenate)   (None, 510)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 41)           20951       concatenate_713[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            168         idenDense[0][0]                  
==================================================================================================
Total params: 492,667
Trainable params: 492,667
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2089 - acc: 0.9483
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0682 - acc: 0.9819
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0624 - acc: 0.9841
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0714 - acc: 0.9804
MWE identification:
Epoch 1/1
 - 83s - loss: 0.0494 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0387 - acc: 0.9904
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0466 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0256 - acc: 0.9940
MWE identification:
Epoch 1/1
 - 83s - loss: 0.0454 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0180 - acc: 0.9959
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0132 - acc: 0.9973
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0100 - acc: 0.9980
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0081 - acc: 0.9984
POS tagging accuracy = 94.7
Loss = 0.259, 
POS tagging accuracy = 94.7
Loss = 0.259, 
	TRAINING TIME: 10.65 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.589
	P, R  : 0.759, 0.481

==================================================================================================
	XP Ends: 24/4 (5 h:44)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,61             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,3              ,93             ,1              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.022          ,10             ,123            ,35             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
32             ,True           ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 61, 6, 3, 93, 1, 13, 0.022, 10, 123, 35, True, 32, True, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (5h:44)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 32)        366016      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2060 (Flatten)          (None, 224)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2061 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2062 (Flatten)          (None, 9)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_714 (Concatenate)   (None, 305)          0           flatten_2060[0][0]               
                                                                 flatten_2061[0][0]               
                                                                 flatten_2062[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           10710       concatenate_714[0][0]            
__________________________________________________________________________________________________
dense_112 (Dense)               (None, 152)          5472        posDense[0][0]                   
==================================================================================================
Total params: 389,326
Trainable params: 389,326
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.022
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 32)        366016      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2063 (Flatten)          (None, 224)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2064 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2065 (Flatten)          (None, 9)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2066 (Flatten)          (None, 224)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2067 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2068 (Flatten)          (None, 9)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2069 (Flatten)          (None, 224)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2070 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2071 (Flatten)          (None, 9)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2072 (Flatten)          (None, 224)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2073 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2074 (Flatten)          (None, 9)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_715 (Concatenate)   (None, 305)          0           flatten_2063[0][0]               
                                                                 flatten_2064[0][0]               
                                                                 flatten_2065[0][0]               
__________________________________________________________________________________________________
concatenate_716 (Concatenate)   (None, 305)          0           flatten_2066[0][0]               
                                                                 flatten_2067[0][0]               
                                                                 flatten_2068[0][0]               
__________________________________________________________________________________________________
concatenate_717 (Concatenate)   (None, 305)          0           flatten_2069[0][0]               
                                                                 flatten_2070[0][0]               
                                                                 flatten_2071[0][0]               
__________________________________________________________________________________________________
concatenate_718 (Concatenate)   (None, 305)          0           flatten_2072[0][0]               
                                                                 flatten_2073[0][0]               
                                                                 flatten_2074[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           10710       concatenate_715[0][0]            
                                                                 concatenate_716[0][0]            
                                                                 concatenate_717[0][0]            
                                                                 concatenate_718[0][0]            
__________________________________________________________________________________________________
concatenate_719 (Concatenate)   (None, 140)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 61)           8601        concatenate_719[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            248         idenDense[0][0]                  
==================================================================================================
Total params: 392,703
Trainable params: 392,703
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.4354 - acc: 0.8938
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1836 - acc: 0.9561
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0868 - acc: 0.9784
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1588 - acc: 0.9618
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0569 - acc: 0.9862
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1260 - acc: 0.9697
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0512 - acc: 0.9878
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1061 - acc: 0.9751
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0487 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0917 - acc: 0.9784
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0471 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0807 - acc: 0.9812
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0464 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0719 - acc: 0.9829
POS tagging accuracy = 93.8
Loss = 0.223, 
POS tagging accuracy = 93.8
Loss = 0.223, 
	TRAINING TIME: 1.97 minutes 
==================================================================================================
	PARSING TIME: 0.88 minutes 
==================================================================================================
	Identification : 0.511
	P, R  : 0.521, 0.501

==================================================================================================
	XP Ends: 24/4 (5 h:47)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,45             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
14             ,3              ,80             ,2              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.03           ,12             ,14             ,99             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
177            ,True           ,False          ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 45, 14, 3, 80, 2, 10, 0.03, 12, 14, 99, True, 177, True, False, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (5h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 177)       1335465     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2075 (Flatten)          (None, 1239)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2076 (Flatten)          (None, 168)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2077 (Flatten)          (None, 12)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_720 (Concatenate)   (None, 1419)         0           flatten_2075[0][0]               
                                                                 flatten_2076[0][0]               
                                                                 flatten_2077[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 99)           140580      concatenate_720[0][0]            
__________________________________________________________________________________________________
dense_113 (Dense)               (None, 152)          15200       posDense[0][0]                   
==================================================================================================
Total params: 1,508,089
Trainable params: 1,508,089
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 177)       1335465     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2078 (Flatten)          (None, 1239)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2079 (Flatten)          (None, 168)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2080 (Flatten)          (None, 12)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2081 (Flatten)          (None, 1239)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2082 (Flatten)          (None, 168)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2083 (Flatten)          (None, 12)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2084 (Flatten)          (None, 1239)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2085 (Flatten)          (None, 168)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2086 (Flatten)          (None, 12)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2087 (Flatten)          (None, 1239)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2088 (Flatten)          (None, 168)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2089 (Flatten)          (None, 12)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_721 (Concatenate)   (None, 1419)         0           flatten_2078[0][0]               
                                                                 flatten_2079[0][0]               
                                                                 flatten_2080[0][0]               
__________________________________________________________________________________________________
concatenate_722 (Concatenate)   (None, 1419)         0           flatten_2081[0][0]               
                                                                 flatten_2082[0][0]               
                                                                 flatten_2083[0][0]               
__________________________________________________________________________________________________
concatenate_723 (Concatenate)   (None, 1419)         0           flatten_2084[0][0]               
                                                                 flatten_2085[0][0]               
                                                                 flatten_2086[0][0]               
__________________________________________________________________________________________________
concatenate_724 (Concatenate)   (None, 1419)         0           flatten_2087[0][0]               
                                                                 flatten_2088[0][0]               
                                                                 flatten_2089[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 99)           140580      concatenate_721[0][0]            
                                                                 concatenate_722[0][0]            
                                                                 concatenate_723[0][0]            
                                                                 concatenate_724[0][0]            
__________________________________________________________________________________________________
concatenate_725 (Concatenate)   (None, 396)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 45)           17865       concatenate_725[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            184         idenDense[0][0]                  
==================================================================================================
Total params: 1,510,938
Trainable params: 1,510,938
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1937 - acc: 0.9518
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0596 - acc: 0.9839
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0330 - acc: 0.9914
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0661 - acc: 0.9835
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0526 - acc: 0.9870
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0486 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0232 - acc: 0.9947
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0459 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0150 - acc: 0.9967
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0111 - acc: 0.9974
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0445 - acc: 0.9895
POS tagging accuracy = 94.9
Loss = 0.245, 
POS tagging accuracy = 94.9
Loss = 0.245, 
	TRAINING TIME: 3.13 minutes 
==================================================================================================
	PARSING TIME: 0.88 minutes 
==================================================================================================
	Identification : 0.596
	P, R  : 0.706, 0.515

==================================================================================================
	XP Ends: 24/4 (5 h:51)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,117            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
18             ,7              ,22             ,2              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.093          ,12             ,12             ,188            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
73             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 117, 18, 7, 22, 2, 14, 0.093, 12, 12, 188, True, 73, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (5h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.093
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 73)        550785      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2090 (Flatten)          (None, 511)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2091 (Flatten)          (None, 216)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2092 (Flatten)          (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2093 (Flatten)          (None, 12)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_726 (Concatenate)   (None, 760)          0           flatten_2090[0][0]               
                                                                 flatten_2091[0][0]               
                                                                 flatten_2092[0][0]               
                                                                 flatten_2093[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 188)          143068      concatenate_726[0][0]            
__________________________________________________________________________________________________
dense_114 (Dense)               (None, 152)          28728       posDense[0][0]                   
==================================================================================================
Total params: 744,197
Trainable params: 744,197
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.093
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 73)        550785      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2094 (Flatten)          (None, 511)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2095 (Flatten)          (None, 216)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2096 (Flatten)          (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2097 (Flatten)          (None, 12)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2098 (Flatten)          (None, 511)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2099 (Flatten)          (None, 216)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2100 (Flatten)          (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2101 (Flatten)          (None, 12)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2102 (Flatten)          (None, 511)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2103 (Flatten)          (None, 216)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2104 (Flatten)          (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2105 (Flatten)          (None, 12)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2106 (Flatten)          (None, 511)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2107 (Flatten)          (None, 216)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2108 (Flatten)          (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2109 (Flatten)          (None, 12)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2110 (Flatten)          (None, 511)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2111 (Flatten)          (None, 216)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2112 (Flatten)          (None, 21)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_2113 (Flatten)          (None, 12)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_727 (Concatenate)   (None, 760)          0           flatten_2094[0][0]               
                                                                 flatten_2095[0][0]               
                                                                 flatten_2096[0][0]               
                                                                 flatten_2097[0][0]               
__________________________________________________________________________________________________
concatenate_728 (Concatenate)   (None, 760)          0           flatten_2098[0][0]               
                                                                 flatten_2099[0][0]               
                                                                 flatten_2100[0][0]               
                                                                 flatten_2101[0][0]               
__________________________________________________________________________________________________
concatenate_729 (Concatenate)   (None, 760)          0           flatten_2102[0][0]               
                                                                 flatten_2103[0][0]               
                                                                 flatten_2104[0][0]               
                                                                 flatten_2105[0][0]               
__________________________________________________________________________________________________
concatenate_730 (Concatenate)   (None, 760)          0           flatten_2106[0][0]               
                                                                 flatten_2107[0][0]               
                                                                 flatten_2108[0][0]               
                                                                 flatten_2109[0][0]               
__________________________________________________________________________________________________
concatenate_731 (Concatenate)   (None, 760)          0           flatten_2110[0][0]               
                                                                 flatten_2111[0][0]               
                                                                 flatten_2112[0][0]               
                                                                 flatten_2113[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 188)          143068      concatenate_727[0][0]            
                                                                 concatenate_728[0][0]            
                                                                 concatenate_729[0][0]            
                                                                 concatenate_730[0][0]            
                                                                 concatenate_731[0][0]            
__________________________________________________________________________________________________
concatenate_732 (Concatenate)   (None, 940)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 117)          110097      concatenate_732[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            472         idenDense[0][0]                  
==================================================================================================
Total params: 826,038
Trainable params: 826,038
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 10s - loss: 0.2202 - acc: 0.9462
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0646 - acc: 0.9821
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0348 - acc: 0.9910
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0737 - acc: 0.9819
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1235 - acc: 0.9688
MWE identification:
Epoch 1/1
 - 48s - loss: 0.0537 - acc: 0.9867
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0529 - acc: 0.9875
MWE identification:
Epoch 1/1
 - 48s - loss: 0.0481 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0301 - acc: 0.9931
MWE identification:
Epoch 1/1
 - 48s - loss: 0.0457 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0201 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0148 - acc: 0.9970
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0446 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0118 - acc: 0.9977
MWE identification:
Epoch 1/1
 - 47s - loss: 0.0444 - acc: 0.9895
POS tagging accuracy = 94.3
Loss = 0.305, 
POS tagging accuracy = 94.3
Loss = 0.305, 
	TRAINING TIME: 8.4 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.577
	P, R  : 0.627, 0.534

==================================================================================================
	XP Ends: 24/4 (6 h:1)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,70             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,9              ,17             ,1              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.016          ,10             ,93             ,94             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
119            ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 70, 8, 9, 17, 1, 13, 0.016, 10, 93, 94, True, 119, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:1)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 119)       897855      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2114 (Flatten)          (None, 833)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2115 (Flatten)          (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2116 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_733 (Concatenate)   (None, 939)          0           flatten_2114[0][0]               
                                                                 flatten_2115[0][0]               
                                                                 flatten_2116[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 94)           88360       concatenate_733[0][0]            
__________________________________________________________________________________________________
dense_115 (Dense)               (None, 152)          14440       posDense[0][0]                   
==================================================================================================
Total params: 1,010,343
Trainable params: 1,010,343
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 119)       897855      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2117 (Flatten)          (None, 833)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2118 (Flatten)          (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2119 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2120 (Flatten)          (None, 833)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2121 (Flatten)          (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2122 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2123 (Flatten)          (None, 833)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2124 (Flatten)          (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2125 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2126 (Flatten)          (None, 833)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2127 (Flatten)          (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2128 (Flatten)          (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2129 (Flatten)          (None, 833)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2130 (Flatten)          (None, 96)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2131 (Flatten)          (None, 10)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_734 (Concatenate)   (None, 939)          0           flatten_2117[0][0]               
                                                                 flatten_2118[0][0]               
                                                                 flatten_2119[0][0]               
__________________________________________________________________________________________________
concatenate_735 (Concatenate)   (None, 939)          0           flatten_2120[0][0]               
                                                                 flatten_2121[0][0]               
                                                                 flatten_2122[0][0]               
__________________________________________________________________________________________________
concatenate_736 (Concatenate)   (None, 939)          0           flatten_2123[0][0]               
                                                                 flatten_2124[0][0]               
                                                                 flatten_2125[0][0]               
__________________________________________________________________________________________________
concatenate_737 (Concatenate)   (None, 939)          0           flatten_2126[0][0]               
                                                                 flatten_2127[0][0]               
                                                                 flatten_2128[0][0]               
__________________________________________________________________________________________________
concatenate_738 (Concatenate)   (None, 939)          0           flatten_2129[0][0]               
                                                                 flatten_2130[0][0]               
                                                                 flatten_2131[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 94)           88360       concatenate_734[0][0]            
                                                                 concatenate_735[0][0]            
                                                                 concatenate_736[0][0]            
                                                                 concatenate_737[0][0]            
                                                                 concatenate_738[0][0]            
__________________________________________________________________________________________________
concatenate_739 (Concatenate)   (None, 470)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 70)           32970       concatenate_739[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            284         idenDense[0][0]                  
==================================================================================================
Total params: 1,029,157
Trainable params: 1,029,157
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2686 - acc: 0.9366
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0913 - acc: 0.9773
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0648 - acc: 0.9839
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0843 - acc: 0.9784
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0505 - acc: 0.9877
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0569 - acc: 0.9860
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0475 - acc: 0.9887
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0435 - acc: 0.9898
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0460 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0347 - acc: 0.9921
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0453 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0284 - acc: 0.9939
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0238 - acc: 0.9952
POS tagging accuracy = 95.2
Loss = 0.212, 
POS tagging accuracy = 95.2
Loss = 0.212, 
	TRAINING TIME: 6.68 minutes 
==================================================================================================
	PARSING TIME: 1.05 minutes 
==================================================================================================
	Identification : 0.597
	P, R  : 0.793, 0.479

==================================================================================================
	XP Ends: 24/4 (6 h:9)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,38             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
9              ,2              ,10             ,3              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.123          ,6              ,25             ,48             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
167            ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 38, 9, 2, 10, 3, 10, 0.123, 6, 25, 48, True, 167, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:9)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.123
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 167)       1260015     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2132 (Flatten)          (None, 1169)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2133 (Flatten)          (None, 108)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2134 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2135 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_740 (Concatenate)   (None, 1289)         0           flatten_2132[0][0]               
                                                                 flatten_2133[0][0]               
                                                                 flatten_2134[0][0]               
                                                                 flatten_2135[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 48)           61920       concatenate_740[0][0]            
__________________________________________________________________________________________________
dense_116 (Dense)               (None, 152)          7448        posDense[0][0]                   
==================================================================================================
Total params: 1,340,185
Trainable params: 1,340,185
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.123
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 167)       1260015     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2136 (Flatten)          (None, 1169)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2137 (Flatten)          (None, 108)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2138 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2139 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2140 (Flatten)          (None, 1169)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2141 (Flatten)          (None, 108)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2142 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2143 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2144 (Flatten)          (None, 1169)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2145 (Flatten)          (None, 108)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2146 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2147 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2148 (Flatten)          (None, 1169)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2149 (Flatten)          (None, 108)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2150 (Flatten)          (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2151 (Flatten)          (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_741 (Concatenate)   (None, 1289)         0           flatten_2136[0][0]               
                                                                 flatten_2137[0][0]               
                                                                 flatten_2138[0][0]               
                                                                 flatten_2139[0][0]               
__________________________________________________________________________________________________
concatenate_742 (Concatenate)   (None, 1289)         0           flatten_2140[0][0]               
                                                                 flatten_2141[0][0]               
                                                                 flatten_2142[0][0]               
                                                                 flatten_2143[0][0]               
__________________________________________________________________________________________________
concatenate_743 (Concatenate)   (None, 1289)         0           flatten_2144[0][0]               
                                                                 flatten_2145[0][0]               
                                                                 flatten_2146[0][0]               
                                                                 flatten_2147[0][0]               
__________________________________________________________________________________________________
concatenate_744 (Concatenate)   (None, 1289)         0           flatten_2148[0][0]               
                                                                 flatten_2149[0][0]               
                                                                 flatten_2150[0][0]               
                                                                 flatten_2151[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 48)           61920       concatenate_741[0][0]            
                                                                 concatenate_742[0][0]            
                                                                 concatenate_743[0][0]            
                                                                 concatenate_744[0][0]            
__________________________________________________________________________________________________
concatenate_745 (Concatenate)   (None, 192)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 38)           7334        concatenate_745[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            156         idenDense[0][0]                  
==================================================================================================
Total params: 1,340,227
Trainable params: 1,340,227
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.2974 - acc: 0.9301
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0977 - acc: 0.9766
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0652 - acc: 0.9849
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0515 - acc: 0.9888
MWE identification:
Epoch 1/1
 - 95s - loss: 8.1408 - acc: 0.4949
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1117 - acc: 0.9751
MWE identification:
Epoch 1/1
 - 95s - loss: 8.1177 - acc: 0.4963
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0656 - acc: 0.9858
MWE identification:
Epoch 1/1
 - 95s - loss: 8.0995 - acc: 0.4973
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0576 - acc: 0.9876
MWE identification:
Epoch 1/1
 - 95s - loss: 8.0726 - acc: 0.4990
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0460 - acc: 0.9905
MWE identification:
Epoch 1/1
 - 95s - loss: 8.0637 - acc: 0.4996
POS tagging accuracy = 93.7
Loss = 0.344, 
POS tagging accuracy = 93.7
Loss = 0.344, 
	TRAINING TIME: 9.83 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (6 h:21)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,34             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,2              ,81             ,1              ,10             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.094          ,11             ,55             ,107            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
48             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 34, 5, 2, 81, 1, 10, 0.094, 11, 55, 107, True, 48, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:21)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.094
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 48)        362160      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2152 (Flatten)          (None, 336)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2153 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2154 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_746 (Concatenate)   (None, 402)          0           flatten_2152[0][0]               
                                                                 flatten_2153[0][0]               
                                                                 flatten_2154[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 107)          43121       concatenate_746[0][0]            
__________________________________________________________________________________________________
dense_117 (Dense)               (None, 152)          16416       posDense[0][0]                   
==================================================================================================
Total params: 427,635
Trainable params: 427,635
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.094
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 48)        362160      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2155 (Flatten)          (None, 336)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2156 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2157 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2158 (Flatten)          (None, 336)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2159 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2160 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2161 (Flatten)          (None, 336)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2162 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2163 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2164 (Flatten)          (None, 336)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2165 (Flatten)          (None, 60)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2166 (Flatten)          (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2167 (Flatten)          (None, 336)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2168 (Flatten)          (None, 60)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2169 (Flatten)          (None, 6)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_747 (Concatenate)   (None, 402)          0           flatten_2155[0][0]               
                                                                 flatten_2156[0][0]               
                                                                 flatten_2157[0][0]               
__________________________________________________________________________________________________
concatenate_748 (Concatenate)   (None, 402)          0           flatten_2158[0][0]               
                                                                 flatten_2159[0][0]               
                                                                 flatten_2160[0][0]               
__________________________________________________________________________________________________
concatenate_749 (Concatenate)   (None, 402)          0           flatten_2161[0][0]               
                                                                 flatten_2162[0][0]               
                                                                 flatten_2163[0][0]               
__________________________________________________________________________________________________
concatenate_750 (Concatenate)   (None, 402)          0           flatten_2164[0][0]               
                                                                 flatten_2165[0][0]               
                                                                 flatten_2166[0][0]               
__________________________________________________________________________________________________
concatenate_751 (Concatenate)   (None, 402)          0           flatten_2167[0][0]               
                                                                 flatten_2168[0][0]               
                                                                 flatten_2169[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 107)          43121       concatenate_747[0][0]            
                                                                 concatenate_748[0][0]            
                                                                 concatenate_749[0][0]            
                                                                 concatenate_750[0][0]            
                                                                 concatenate_751[0][0]            
__________________________________________________________________________________________________
concatenate_752 (Concatenate)   (None, 535)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 34)           18224       concatenate_752[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            140         idenDense[0][0]                  
==================================================================================================
Total params: 429,583
Trainable params: 429,583
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2190 - acc: 0.9468
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0630 - acc: 0.9827
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0759 - acc: 0.9819
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0971 - acc: 0.9732
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0508 - acc: 0.9874
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0410 - acc: 0.9891
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0465 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0249 - acc: 0.9938
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0451 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0177 - acc: 0.9957
MWE identification:
Epoch 1/1
 - 12s - loss: 0.0446 - acc: 0.9895
POS tagging accuracy = 94.3
Loss = 0.278, 
POS tagging accuracy = 94.3
Loss = 0.278, 
	TRAINING TIME: 2.43 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.567
	P, R  : 0.635, 0.512

==================================================================================================
	XP Ends: 24/4 (6 h:24)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,44             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
9              ,1              ,19             ,2              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.013          ,5              ,12             ,54             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
46             ,True           ,False          ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 44, 9, 1, 19, 2, 8, 0.013, 5, 12, 54, True, 46, True, False, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 46)        347070      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       affixes[0][0]                    
__________________________________________________________________________________________________
flatten_2170 (Flatten)          (None, 322)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2171 (Flatten)          (None, 108)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_753 (Concatenate)   (None, 430)          0           flatten_2170[0][0]               
                                                                 flatten_2171[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 54)           23274       concatenate_753[0][0]            
__________________________________________________________________________________________________
dense_118 (Dense)               (None, 152)          8360        posDense[0][0]                   
==================================================================================================
Total params: 389,378
Trainable params: 389,378
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.013
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 46)        347070      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_2172 (Flatten)          (None, 322)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2173 (Flatten)          (None, 108)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2174 (Flatten)          (None, 322)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2175 (Flatten)          (None, 108)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2176 (Flatten)          (None, 322)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2177 (Flatten)          (None, 108)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2178 (Flatten)          (None, 322)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2179 (Flatten)          (None, 108)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
concatenate_754 (Concatenate)   (None, 430)          0           flatten_2172[0][0]               
                                                                 flatten_2173[0][0]               
__________________________________________________________________________________________________
concatenate_755 (Concatenate)   (None, 430)          0           flatten_2174[0][0]               
                                                                 flatten_2175[0][0]               
__________________________________________________________________________________________________
concatenate_756 (Concatenate)   (None, 430)          0           flatten_2176[0][0]               
                                                                 flatten_2177[0][0]               
__________________________________________________________________________________________________
concatenate_757 (Concatenate)   (None, 430)          0           flatten_2178[0][0]               
                                                                 flatten_2179[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 54)           23274       concatenate_754[0][0]            
                                                                 concatenate_755[0][0]            
                                                                 concatenate_756[0][0]            
                                                                 concatenate_757[0][0]            
__________________________________________________________________________________________________
concatenate_758 (Concatenate)   (None, 216)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 44)           9548        concatenate_758[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            180         idenDense[0][0]                  
==================================================================================================
Total params: 390,746
Trainable params: 390,746
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 8s - loss: 0.3343 - acc: 0.9219
POS tagging:
Epoch 1/1
 - 8s - loss: 0.1385 - acc: 0.9691
POS tagging:
Epoch 1/1
 - 8s - loss: 0.1059 - acc: 0.9755
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0729 - acc: 0.9816
POS tagging:
Epoch 1/1
 - 8s - loss: 0.1021 - acc: 0.9754
MWE identification:
Epoch 1/1
 - 38s - loss: 0.0553 - acc: 0.9864
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0845 - acc: 0.9793
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0515 - acc: 0.9874
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0739 - acc: 0.9817
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0496 - acc: 0.9880
POS tagging accuracy = 95.0
Loss = 0.207, 
POS tagging accuracy = 95.0
Loss = 0.207, 
	TRAINING TIME: 3.82 minutes 
==================================================================================================
	PARSING TIME: 0.7 minutes 
==================================================================================================
	Identification : 0.596
	P, R  : 0.78, 0.482

==================================================================================================
	XP Ends: 24/4 (6 h:29)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,127            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
8              ,7              ,122            ,3              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.068          ,6              ,65             ,192            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
63             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 127, 8, 7, 122, 3, 14, 0.068, 6, 65, 192, True, 63, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:29)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.068
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 63)        475335      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2180 (Flatten)          (None, 441)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2181 (Flatten)          (None, 96)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2182 (Flatten)          (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2183 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_759 (Concatenate)   (None, 564)          0           flatten_2180[0][0]               
                                                                 flatten_2181[0][0]               
                                                                 flatten_2182[0][0]               
                                                                 flatten_2183[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 192)          108480      concatenate_759[0][0]            
__________________________________________________________________________________________________
dense_119 (Dense)               (None, 152)          29336       posDense[0][0]                   
==================================================================================================
Total params: 622,787
Trainable params: 622,787
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.068
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 63)        475335      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 8)        9488        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2184 (Flatten)          (None, 441)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2185 (Flatten)          (None, 96)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2186 (Flatten)          (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2187 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2188 (Flatten)          (None, 441)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2189 (Flatten)          (None, 96)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2190 (Flatten)          (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2191 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2192 (Flatten)          (None, 441)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2193 (Flatten)          (None, 96)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2194 (Flatten)          (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2195 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2196 (Flatten)          (None, 441)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2197 (Flatten)          (None, 96)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2198 (Flatten)          (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2199 (Flatten)          (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2200 (Flatten)          (None, 441)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2201 (Flatten)          (None, 96)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2202 (Flatten)          (None, 21)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_2203 (Flatten)          (None, 6)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_760 (Concatenate)   (None, 564)          0           flatten_2184[0][0]               
                                                                 flatten_2185[0][0]               
                                                                 flatten_2186[0][0]               
                                                                 flatten_2187[0][0]               
__________________________________________________________________________________________________
concatenate_761 (Concatenate)   (None, 564)          0           flatten_2188[0][0]               
                                                                 flatten_2189[0][0]               
                                                                 flatten_2190[0][0]               
                                                                 flatten_2191[0][0]               
__________________________________________________________________________________________________
concatenate_762 (Concatenate)   (None, 564)          0           flatten_2192[0][0]               
                                                                 flatten_2193[0][0]               
                                                                 flatten_2194[0][0]               
                                                                 flatten_2195[0][0]               
__________________________________________________________________________________________________
concatenate_763 (Concatenate)   (None, 564)          0           flatten_2196[0][0]               
                                                                 flatten_2197[0][0]               
                                                                 flatten_2198[0][0]               
                                                                 flatten_2199[0][0]               
__________________________________________________________________________________________________
concatenate_764 (Concatenate)   (None, 564)          0           flatten_2200[0][0]               
                                                                 flatten_2201[0][0]               
                                                                 flatten_2202[0][0]               
                                                                 flatten_2203[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 192)          108480      concatenate_760[0][0]            
                                                                 concatenate_761[0][0]            
                                                                 concatenate_762[0][0]            
                                                                 concatenate_763[0][0]            
                                                                 concatenate_764[0][0]            
__________________________________________________________________________________________________
concatenate_765 (Concatenate)   (None, 960)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 127)          122047      concatenate_765[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            512         idenDense[0][0]                  
==================================================================================================
Total params: 716,010
Trainable params: 716,010
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2112 - acc: 0.9488
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0543 - acc: 0.9849
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0270 - acc: 0.9926
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0157 - acc: 0.9961
MWE identification:
Epoch 1/1
 - 10s - loss: 12.0850 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0164 - acc: 0.9965
MWE identification:
Epoch 1/1
 - 10s - loss: 0.2129 - acc: 0.9735
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0524 - acc: 0.9852
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0510 - acc: 0.9874
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0142 - acc: 0.9969
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0465 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0075 - acc: 0.9983
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0450 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0051 - acc: 0.9988
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0446 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0040 - acc: 0.9991
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0445 - acc: 0.9895
POS tagging accuracy = 94.8
Loss = 0.293, 
POS tagging accuracy = 94.8
Loss = 0.293, 
	TRAINING TIME: 2.88 minutes 
==================================================================================================
	PARSING TIME: 1.43 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.664, 0.525

==================================================================================================
	XP Ends: 24/4 (6 h:34)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,27             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
14             ,4              ,14             ,1              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.079          ,5              ,80             ,145            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
33             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 27, 14, 4, 14, 1, 13, 0.079, 5, 80, 145, True, 33, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:34)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.079
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 33)        248985      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2204 (Flatten)          (None, 231)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2205 (Flatten)          (None, 168)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2206 (Flatten)          (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_766 (Concatenate)   (None, 411)          0           flatten_2204[0][0]               
                                                                 flatten_2205[0][0]               
                                                                 flatten_2206[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 145)          59740       concatenate_766[0][0]            
__________________________________________________________________________________________________
dense_120 (Dense)               (None, 152)          22192       posDense[0][0]                   
==================================================================================================
Total params: 347,537
Trainable params: 347,537
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.079
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 33)        248985      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2207 (Flatten)          (None, 231)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2208 (Flatten)          (None, 168)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2209 (Flatten)          (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2210 (Flatten)          (None, 231)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2211 (Flatten)          (None, 168)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2212 (Flatten)          (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2213 (Flatten)          (None, 231)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2214 (Flatten)          (None, 168)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2215 (Flatten)          (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2216 (Flatten)          (None, 231)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2217 (Flatten)          (None, 168)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2218 (Flatten)          (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2219 (Flatten)          (None, 231)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2220 (Flatten)          (None, 168)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2221 (Flatten)          (None, 12)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_767 (Concatenate)   (None, 411)          0           flatten_2207[0][0]               
                                                                 flatten_2208[0][0]               
                                                                 flatten_2209[0][0]               
__________________________________________________________________________________________________
concatenate_768 (Concatenate)   (None, 411)          0           flatten_2210[0][0]               
                                                                 flatten_2211[0][0]               
                                                                 flatten_2212[0][0]               
__________________________________________________________________________________________________
concatenate_769 (Concatenate)   (None, 411)          0           flatten_2213[0][0]               
                                                                 flatten_2214[0][0]               
                                                                 flatten_2215[0][0]               
__________________________________________________________________________________________________
concatenate_770 (Concatenate)   (None, 411)          0           flatten_2216[0][0]               
                                                                 flatten_2217[0][0]               
                                                                 flatten_2218[0][0]               
__________________________________________________________________________________________________
concatenate_771 (Concatenate)   (None, 411)          0           flatten_2219[0][0]               
                                                                 flatten_2220[0][0]               
                                                                 flatten_2221[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 145)          59740       concatenate_767[0][0]            
                                                                 concatenate_768[0][0]            
                                                                 concatenate_769[0][0]            
                                                                 concatenate_770[0][0]            
                                                                 concatenate_771[0][0]            
__________________________________________________________________________________________________
concatenate_772 (Concatenate)   (None, 725)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 27)           19602       concatenate_772[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            112         idenDense[0][0]                  
==================================================================================================
Total params: 345,059
Trainable params: 345,059
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2152 - acc: 0.9477
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0604 - acc: 0.9832
MWE identification:
Epoch 1/1
 - 69s - loss: 0.0673 - acc: 0.9827
POS tagging:
Epoch 1/1
 - 1s - loss: 0.1003 - acc: 0.9731
MWE identification:
Epoch 1/1
 - 62s - loss: 0.0516 - acc: 0.9872
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0439 - acc: 0.9884
MWE identification:
Epoch 1/1
 - 62s - loss: 0.0474 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0242 - acc: 0.9942
MWE identification:
Epoch 1/1
 - 68s - loss: 0.0456 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0152 - acc: 0.9966
MWE identification:
Epoch 1/1
 - 62s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0106 - acc: 0.9978
MWE identification:
Epoch 1/1
 - 63s - loss: 0.0446 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0080 - acc: 0.9984
POS tagging accuracy = 94.8
Loss = 0.296, 
POS tagging accuracy = 94.8
Loss = 0.296, 
	TRAINING TIME: 7.83 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.569
	P, R  : 0.702, 0.478

==================================================================================================
	XP Ends: 24/4 (6 h:43)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,31             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
20             ,1              ,19             ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.087          ,5              ,47             ,106            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
186            ,True           ,False          ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 31, 20, 1, 19, 1, 8, 0.087, 5, 47, 106, True, 186, True, False, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:43)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.087
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 186)       1403370     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2222 (Flatten)          (None, 1302)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2223 (Flatten)          (None, 240)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2224 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_773 (Concatenate)   (None, 1547)         0           flatten_2222[0][0]               
                                                                 flatten_2223[0][0]               
                                                                 flatten_2224[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 106)          164088      concatenate_773[0][0]            
__________________________________________________________________________________________________
dense_121 (Dense)               (None, 152)          16264       posDense[0][0]                   
==================================================================================================
Total params: 1,607,542
Trainable params: 1,607,542
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.087
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 186)       1403370     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 20)       23720       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2225 (Flatten)          (None, 1302)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2226 (Flatten)          (None, 240)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2227 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2228 (Flatten)          (None, 1302)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2229 (Flatten)          (None, 240)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2230 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2231 (Flatten)          (None, 1302)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2232 (Flatten)          (None, 240)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2233 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2234 (Flatten)          (None, 1302)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2235 (Flatten)          (None, 240)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2236 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_774 (Concatenate)   (None, 1547)         0           flatten_2225[0][0]               
                                                                 flatten_2226[0][0]               
                                                                 flatten_2227[0][0]               
__________________________________________________________________________________________________
concatenate_775 (Concatenate)   (None, 1547)         0           flatten_2228[0][0]               
                                                                 flatten_2229[0][0]               
                                                                 flatten_2230[0][0]               
__________________________________________________________________________________________________
concatenate_776 (Concatenate)   (None, 1547)         0           flatten_2231[0][0]               
                                                                 flatten_2232[0][0]               
                                                                 flatten_2233[0][0]               
__________________________________________________________________________________________________
concatenate_777 (Concatenate)   (None, 1547)         0           flatten_2234[0][0]               
                                                                 flatten_2235[0][0]               
                                                                 flatten_2236[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 106)          164088      concatenate_774[0][0]            
                                                                 concatenate_775[0][0]            
                                                                 concatenate_776[0][0]            
                                                                 concatenate_777[0][0]            
__________________________________________________________________________________________________
concatenate_778 (Concatenate)   (None, 424)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 31)           13175       concatenate_778[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            128         idenDense[0][0]                  
==================================================================================================
Total params: 1,604,581
Trainable params: 1,604,581
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2416 - acc: 0.9446
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0688 - acc: 0.9828
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0704 - acc: 0.9821
POS tagging:
Epoch 1/1
 - 3s - loss: 0.1385 - acc: 0.9689
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0517 - acc: 0.9872
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0597 - acc: 0.9863
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0464 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0362 - acc: 0.9920
MWE identification:
Epoch 1/1
 - 45s - loss: 0.0449 - acc: 0.9894
POS tagging accuracy = 94.6
Loss = 0.295, 
POS tagging accuracy = 94.6
Loss = 0.295, 
	TRAINING TIME: 4.18 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.599
	P, R  : 0.682, 0.534

==================================================================================================
	XP Ends: 24/4 (6 h:48)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,27             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,7              ,37             ,4              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.029          ,6              ,10             ,157            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
31             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 27, 6, 7, 37, 4, 9, 0.029, 6, 10, 157, True, 31, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:48)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 31)        233895      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2237 (Flatten)          (None, 217)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2238 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2239 (Flatten)          (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2240 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_779 (Concatenate)   (None, 316)          0           flatten_2237[0][0]               
                                                                 flatten_2238[0][0]               
                                                                 flatten_2239[0][0]               
                                                                 flatten_2240[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 157)          49769       concatenate_779[0][0]            
__________________________________________________________________________________________________
dense_122 (Dense)               (None, 152)          24016       posDense[0][0]                   
==================================================================================================
Total params: 314,944
Trainable params: 314,944
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.029
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 31)        233895      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2241 (Flatten)          (None, 217)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2242 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2243 (Flatten)          (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2244 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2245 (Flatten)          (None, 217)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2246 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2247 (Flatten)          (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2248 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2249 (Flatten)          (None, 217)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2250 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2251 (Flatten)          (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2252 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2253 (Flatten)          (None, 217)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2254 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2255 (Flatten)          (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2256 (Flatten)          (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_780 (Concatenate)   (None, 316)          0           flatten_2241[0][0]               
                                                                 flatten_2242[0][0]               
                                                                 flatten_2243[0][0]               
                                                                 flatten_2244[0][0]               
__________________________________________________________________________________________________
concatenate_781 (Concatenate)   (None, 316)          0           flatten_2245[0][0]               
                                                                 flatten_2246[0][0]               
                                                                 flatten_2247[0][0]               
                                                                 flatten_2248[0][0]               
__________________________________________________________________________________________________
concatenate_782 (Concatenate)   (None, 316)          0           flatten_2249[0][0]               
                                                                 flatten_2250[0][0]               
                                                                 flatten_2251[0][0]               
                                                                 flatten_2252[0][0]               
__________________________________________________________________________________________________
concatenate_783 (Concatenate)   (None, 316)          0           flatten_2253[0][0]               
                                                                 flatten_2254[0][0]               
                                                                 flatten_2255[0][0]               
                                                                 flatten_2256[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 157)          49769       concatenate_780[0][0]            
                                                                 concatenate_781[0][0]            
                                                                 concatenate_782[0][0]            
                                                                 concatenate_783[0][0]            
__________________________________________________________________________________________________
concatenate_784 (Concatenate)   (None, 628)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 27)           16983       concatenate_784[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            112         idenDense[0][0]                  
==================================================================================================
Total params: 308,023
Trainable params: 308,023
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 11s - loss: 0.2120 - acc: 0.9475
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0799 - acc: 0.9787
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0516 - acc: 0.9868
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0366 - acc: 0.9906
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0272 - acc: 0.9933
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0649 - acc: 0.9833
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0546 - acc: 0.9850
MWE identification:
Epoch 1/1
 - 26s - loss: 0.0506 - acc: 0.9875
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0297 - acc: 0.9929
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0474 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0214 - acc: 0.9953
MWE identification:
Epoch 1/1
 - 25s - loss: 0.0459 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0164 - acc: 0.9965
POS tagging accuracy = 94.5
Loss = 0.242, 
POS tagging accuracy = 94.5
Loss = 0.242, 
	TRAINING TIME: 4.5 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.585
	P, R  : 0.71, 0.497

==================================================================================================
	XP Ends: 24/4 (6 h:54)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,44             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
10             ,1              ,112            ,3              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.081          ,5              ,102            ,48             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
141            ,True           ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 44, 10, 1, 112, 3, 12, 0.081, 5, 102, 48, True, 141, True, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:54)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.081
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 141)       1612758     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2257 (Flatten)          (None, 987)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2258 (Flatten)          (None, 120)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2259 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_785 (Concatenate)   (None, 1112)         0           flatten_2257[0][0]               
                                                                 flatten_2258[0][0]               
                                                                 flatten_2259[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 48)           53424       concatenate_785[0][0]            
__________________________________________________________________________________________________
dense_123 (Dense)               (None, 152)          7448        posDense[0][0]                   
==================================================================================================
Total params: 1,685,590
Trainable params: 1,685,590
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.081
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 141)       1612758     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2260 (Flatten)          (None, 987)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2261 (Flatten)          (None, 120)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2262 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2263 (Flatten)          (None, 987)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2264 (Flatten)          (None, 120)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2265 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2266 (Flatten)          (None, 987)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2267 (Flatten)          (None, 120)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2268 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2269 (Flatten)          (None, 987)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2270 (Flatten)          (None, 120)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2271 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2272 (Flatten)          (None, 987)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2273 (Flatten)          (None, 120)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2274 (Flatten)          (None, 5)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_786 (Concatenate)   (None, 1112)         0           flatten_2260[0][0]               
                                                                 flatten_2261[0][0]               
                                                                 flatten_2262[0][0]               
__________________________________________________________________________________________________
concatenate_787 (Concatenate)   (None, 1112)         0           flatten_2263[0][0]               
                                                                 flatten_2264[0][0]               
                                                                 flatten_2265[0][0]               
__________________________________________________________________________________________________
concatenate_788 (Concatenate)   (None, 1112)         0           flatten_2266[0][0]               
                                                                 flatten_2267[0][0]               
                                                                 flatten_2268[0][0]               
__________________________________________________________________________________________________
concatenate_789 (Concatenate)   (None, 1112)         0           flatten_2269[0][0]               
                                                                 flatten_2270[0][0]               
                                                                 flatten_2271[0][0]               
__________________________________________________________________________________________________
concatenate_790 (Concatenate)   (None, 1112)         0           flatten_2272[0][0]               
                                                                 flatten_2273[0][0]               
                                                                 flatten_2274[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 48)           53424       concatenate_786[0][0]            
                                                                 concatenate_787[0][0]            
                                                                 concatenate_788[0][0]            
                                                                 concatenate_789[0][0]            
                                                                 concatenate_790[0][0]            
__________________________________________________________________________________________________
concatenate_791 (Concatenate)   (None, 240)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 44)           10604       concatenate_791[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            180         idenDense[0][0]                  
==================================================================================================
Total params: 1,688,926
Trainable params: 1,688,926
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2633 - acc: 0.9339
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0806 - acc: 0.9786
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0438 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0276 - acc: 0.9929
MWE identification:
Epoch 1/1
 - 10s - loss: 12.0865 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0293 - acc: 0.9926
MWE identification:
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0168 - acc: 0.9957
MWE identification:
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0126 - acc: 0.9970
MWE identification:
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0105 - acc: 0.9974
MWE identification:
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0088 - acc: 0.9979
MWE identification:
Epoch 1/1
 - 10s - loss: 12.0886 - acc: 0.2500
POS tagging accuracy = 94.0
Loss = 0.298, 
POS tagging accuracy = 94.0
Loss = 0.298, 
	TRAINING TIME: 2.37 minutes 
==================================================================================================
	PARSING TIME: 1.05 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (6 h:58)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,26             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
17             ,8              ,10             ,2              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.144          ,13             ,14             ,120            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
131            ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 26, 17, 8, 10, 2, 11, 0.144, 13, 14, 120, True, 131, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (6h:58)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.144
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 131)       988395      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2275 (Flatten)          (None, 917)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2276 (Flatten)          (None, 204)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2277 (Flatten)          (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2278 (Flatten)          (None, 13)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_792 (Concatenate)   (None, 1158)         0           flatten_2275[0][0]               
                                                                 flatten_2276[0][0]               
                                                                 flatten_2277[0][0]               
                                                                 flatten_2278[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 120)          139080      concatenate_792[0][0]            
__________________________________________________________________________________________________
dense_124 (Dense)               (None, 152)          18392       posDense[0][0]                   
==================================================================================================
Total params: 1,166,321
Trainable params: 1,166,321
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.144
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 131)       988395      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2279 (Flatten)          (None, 917)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2280 (Flatten)          (None, 204)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2281 (Flatten)          (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2282 (Flatten)          (None, 13)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2283 (Flatten)          (None, 917)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2284 (Flatten)          (None, 204)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2285 (Flatten)          (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2286 (Flatten)          (None, 13)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2287 (Flatten)          (None, 917)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2288 (Flatten)          (None, 204)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2289 (Flatten)          (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2290 (Flatten)          (None, 13)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2291 (Flatten)          (None, 917)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2292 (Flatten)          (None, 204)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2293 (Flatten)          (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2294 (Flatten)          (None, 13)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_793 (Concatenate)   (None, 1158)         0           flatten_2279[0][0]               
                                                                 flatten_2280[0][0]               
                                                                 flatten_2281[0][0]               
                                                                 flatten_2282[0][0]               
__________________________________________________________________________________________________
concatenate_794 (Concatenate)   (None, 1158)         0           flatten_2283[0][0]               
                                                                 flatten_2284[0][0]               
                                                                 flatten_2285[0][0]               
                                                                 flatten_2286[0][0]               
__________________________________________________________________________________________________
concatenate_795 (Concatenate)   (None, 1158)         0           flatten_2287[0][0]               
                                                                 flatten_2288[0][0]               
                                                                 flatten_2289[0][0]               
                                                                 flatten_2290[0][0]               
__________________________________________________________________________________________________
concatenate_796 (Concatenate)   (None, 1158)         0           flatten_2291[0][0]               
                                                                 flatten_2292[0][0]               
                                                                 flatten_2293[0][0]               
                                                                 flatten_2294[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 120)          139080      concatenate_793[0][0]            
                                                                 concatenate_794[0][0]            
                                                                 concatenate_795[0][0]            
                                                                 concatenate_796[0][0]            
__________________________________________________________________________________________________
concatenate_797 (Concatenate)   (None, 480)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 26)           12506       concatenate_797[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            108         idenDense[0][0]                  
==================================================================================================
Total params: 1,160,543
Trainable params: 1,160,543
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 9s - loss: 0.3449 - acc: 0.9219
POS tagging:
Epoch 1/1
 - 9s - loss: 0.1298 - acc: 0.9727
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0852 - acc: 0.9813
MWE identification:
Epoch 1/1
 - 91s - loss: 12.0880 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 9s - loss: 0.0893 - acc: 0.9796
MWE identification:
Epoch 1/1
 - 91s - loss: 4.2748 - acc: 0.7347
POS tagging:
Epoch 1/1
 - 10s - loss: 0.1297 - acc: 0.9730
MWE identification:
Epoch 1/1
 - 91s - loss: 0.2232 - acc: 0.9740
POS tagging:
Epoch 1/1
 - 10s - loss: 0.1534 - acc: 0.9674
MWE identification:
Epoch 1/1
 - 91s - loss: 0.0699 - acc: 0.9835
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0828 - acc: 0.9814
MWE identification:
Epoch 1/1
 - 91s - loss: 0.0529 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 10s - loss: 0.0636 - acc: 0.9864
POS tagging accuracy = 94.3
Loss = 0.313, 
POS tagging accuracy = 94.3
Loss = 0.313, 
	TRAINING TIME: 10.0 minutes 
==================================================================================================
	PARSING TIME: 1.18 minutes 
==================================================================================================
	Identification : 0.511
	P, R  : 0.436, 0.616

==================================================================================================
	XP Ends: 24/4 (7 h:9)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,68             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,5              ,32             ,1              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.109          ,10             ,12             ,189            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
170            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 68, 7, 5, 32, 1, 13, 0.109, 10, 12, 189, True, 170, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (7h:9)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.109
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 170)       1282650     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2295 (Flatten)          (None, 1190)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2296 (Flatten)          (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2297 (Flatten)          (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2298 (Flatten)          (None, 10)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_798 (Concatenate)   (None, 1299)         0           flatten_2295[0][0]               
                                                                 flatten_2296[0][0]               
                                                                 flatten_2297[0][0]               
                                                                 flatten_2298[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 189)          245700      concatenate_798[0][0]            
__________________________________________________________________________________________________
dense_125 (Dense)               (None, 152)          28880       posDense[0][0]                   
==================================================================================================
Total params: 1,565,752
Trainable params: 1,565,752
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.109
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 170)       1282650     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 10)        200         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2299 (Flatten)          (None, 1190)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2300 (Flatten)          (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2301 (Flatten)          (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2302 (Flatten)          (None, 10)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2303 (Flatten)          (None, 1190)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2304 (Flatten)          (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2305 (Flatten)          (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2306 (Flatten)          (None, 10)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2307 (Flatten)          (None, 1190)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2308 (Flatten)          (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2309 (Flatten)          (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2310 (Flatten)          (None, 10)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2311 (Flatten)          (None, 1190)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2312 (Flatten)          (None, 84)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2313 (Flatten)          (None, 15)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2314 (Flatten)          (None, 10)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2315 (Flatten)          (None, 1190)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2316 (Flatten)          (None, 84)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2317 (Flatten)          (None, 15)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_2318 (Flatten)          (None, 10)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_799 (Concatenate)   (None, 1299)         0           flatten_2299[0][0]               
                                                                 flatten_2300[0][0]               
                                                                 flatten_2301[0][0]               
                                                                 flatten_2302[0][0]               
__________________________________________________________________________________________________
concatenate_800 (Concatenate)   (None, 1299)         0           flatten_2303[0][0]               
                                                                 flatten_2304[0][0]               
                                                                 flatten_2305[0][0]               
                                                                 flatten_2306[0][0]               
__________________________________________________________________________________________________
concatenate_801 (Concatenate)   (None, 1299)         0           flatten_2307[0][0]               
                                                                 flatten_2308[0][0]               
                                                                 flatten_2309[0][0]               
                                                                 flatten_2310[0][0]               
__________________________________________________________________________________________________
concatenate_802 (Concatenate)   (None, 1299)         0           flatten_2311[0][0]               
                                                                 flatten_2312[0][0]               
                                                                 flatten_2313[0][0]               
                                                                 flatten_2314[0][0]               
__________________________________________________________________________________________________
concatenate_803 (Concatenate)   (None, 1299)         0           flatten_2315[0][0]               
                                                                 flatten_2316[0][0]               
                                                                 flatten_2317[0][0]               
                                                                 flatten_2318[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 189)          245700      concatenate_799[0][0]            
                                                                 concatenate_800[0][0]            
                                                                 concatenate_801[0][0]            
                                                                 concatenate_802[0][0]            
                                                                 concatenate_803[0][0]            
__________________________________________________________________________________________________
concatenate_804 (Concatenate)   (None, 945)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 68)           64328       concatenate_804[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            276         idenDense[0][0]                  
==================================================================================================
Total params: 1,601,476
Trainable params: 1,601,476
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 11s - loss: 0.2788 - acc: 0.9331
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0913 - acc: 0.9774
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0794 - acc: 0.9804
POS tagging:
Epoch 1/1
 - 11s - loss: 0.1946 - acc: 0.9587
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0535 - acc: 0.9868
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0889 - acc: 0.9798
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0477 - acc: 0.9885
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0598 - acc: 0.9866
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0455 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0470 - acc: 0.9896
MWE identification:
Epoch 1/1
 - 35s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0401 - acc: 0.9914
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0365 - acc: 0.9923
POS tagging accuracy = 94.7
Loss = 0.323, 
POS tagging accuracy = 94.7
Loss = 0.323, 
	TRAINING TIME: 6.55 minutes 
==================================================================================================
	PARSING TIME: 1.32 minutes 
==================================================================================================
	Identification : 0.578
	P, R  : 0.641, 0.527

==================================================================================================
	XP Ends: 24/4 (7 h:17)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,66             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
15             ,2              ,68             ,2              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.055          ,6              ,17             ,78             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
48             ,False          ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 66, 15, 2, 68, 2, 12, 0.055, 6, 17, 78, True, 48, False, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (7h:17)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 48)        362160      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2319 (Flatten)          (None, 336)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2320 (Flatten)          (None, 180)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2321 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_805 (Concatenate)   (None, 522)          0           flatten_2319[0][0]               
                                                                 flatten_2320[0][0]               
                                                                 flatten_2321[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 78)           40794       concatenate_805[0][0]            
__________________________________________________________________________________________________
dense_126 (Dense)               (None, 152)          12008       posDense[0][0]                   
==================================================================================================
Total params: 432,760
Trainable params: 432,760
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.055
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 48)        362160      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2322 (Flatten)          (None, 336)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2323 (Flatten)          (None, 180)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2324 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2325 (Flatten)          (None, 336)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2326 (Flatten)          (None, 180)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2327 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2328 (Flatten)          (None, 336)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2329 (Flatten)          (None, 180)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2330 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
concatenate_806 (Concatenate)   (None, 522)          0           flatten_2322[0][0]               
                                                                 flatten_2323[0][0]               
                                                                 flatten_2324[0][0]               
__________________________________________________________________________________________________
concatenate_807 (Concatenate)   (None, 522)          0           flatten_2325[0][0]               
                                                                 flatten_2326[0][0]               
                                                                 flatten_2327[0][0]               
__________________________________________________________________________________________________
concatenate_808 (Concatenate)   (None, 522)          0           flatten_2328[0][0]               
                                                                 flatten_2329[0][0]               
                                                                 flatten_2330[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 78)           40794       concatenate_806[0][0]            
                                                                 concatenate_807[0][0]            
                                                                 concatenate_808[0][0]            
__________________________________________________________________________________________________
concatenate_809 (Concatenate)   (None, 234)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 66)           15510       concatenate_809[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            268         idenDense[0][0]                  
==================================================================================================
Total params: 436,530
Trainable params: 436,530
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 6s - loss: 0.2003 - acc: 0.9503
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0652 - acc: 0.9819
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0366 - acc: 0.9898
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0688 - acc: 0.9828
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0658 - acc: 0.9817
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0505 - acc: 0.9877
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0314 - acc: 0.9920
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0468 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0196 - acc: 0.9951
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0453 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0143 - acc: 0.9966
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0111 - acc: 0.9975
MWE identification:
Epoch 1/1
 - 10s - loss: 0.0445 - acc: 0.9895
POS tagging accuracy = 94.8
Loss = 0.271, 
POS tagging accuracy = 94.8
Loss = 0.271, 
	TRAINING TIME: 2.58 minutes 
==================================================================================================
	PARSING TIME: 0.73 minutes 
==================================================================================================
	Identification : 0.586
	P, R  : 0.732, 0.488

==================================================================================================
	XP Ends: 24/4 (7 h:21)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,34             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,4              ,20             ,4              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.161          ,7              ,78             ,42             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
25             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 34, 6, 4, 20, 4, 12, 0.161, 7, 78, 42, True, 25, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (7h:21)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.161
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 25)        188625      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2331 (Flatten)          (None, 175)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2332 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2333 (Flatten)          (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2334 (Flatten)          (None, 7)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_810 (Concatenate)   (None, 266)          0           flatten_2331[0][0]               
                                                                 flatten_2332[0][0]               
                                                                 flatten_2333[0][0]               
                                                                 flatten_2334[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 42)           11214       concatenate_810[0][0]            
__________________________________________________________________________________________________
dense_127 (Dense)               (None, 152)          6536        posDense[0][0]                   
==================================================================================================
Total params: 213,647
Trainable params: 213,647
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.161
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 25)        188625      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 7)         140         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2335 (Flatten)          (None, 175)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2336 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2337 (Flatten)          (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2338 (Flatten)          (None, 7)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2339 (Flatten)          (None, 175)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2340 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2341 (Flatten)          (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2342 (Flatten)          (None, 7)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2343 (Flatten)          (None, 175)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2344 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2345 (Flatten)          (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2346 (Flatten)          (None, 7)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2347 (Flatten)          (None, 175)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2348 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2349 (Flatten)          (None, 12)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2350 (Flatten)          (None, 7)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_811 (Concatenate)   (None, 266)          0           flatten_2335[0][0]               
                                                                 flatten_2336[0][0]               
                                                                 flatten_2337[0][0]               
                                                                 flatten_2338[0][0]               
__________________________________________________________________________________________________
concatenate_812 (Concatenate)   (None, 266)          0           flatten_2339[0][0]               
                                                                 flatten_2340[0][0]               
                                                                 flatten_2341[0][0]               
                                                                 flatten_2342[0][0]               
__________________________________________________________________________________________________
concatenate_813 (Concatenate)   (None, 266)          0           flatten_2343[0][0]               
                                                                 flatten_2344[0][0]               
                                                                 flatten_2345[0][0]               
                                                                 flatten_2346[0][0]               
__________________________________________________________________________________________________
concatenate_814 (Concatenate)   (None, 266)          0           flatten_2347[0][0]               
                                                                 flatten_2348[0][0]               
                                                                 flatten_2349[0][0]               
                                                                 flatten_2350[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 42)           11214       concatenate_811[0][0]            
                                                                 concatenate_812[0][0]            
                                                                 concatenate_813[0][0]            
                                                                 concatenate_814[0][0]            
__________________________________________________________________________________________________
concatenate_815 (Concatenate)   (None, 168)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 34)           5746        concatenate_815[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            140         idenDense[0][0]                  
==================================================================================================
Total params: 212,997
Trainable params: 212,997
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2593 - acc: 0.9369
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0837 - acc: 0.9769
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0525 - acc: 0.9858
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0367 - acc: 0.9906
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0274 - acc: 0.9932
MWE identification:
Epoch 1/1
 - 44s - loss: 8.0606 - acc: 0.4999
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0570 - acc: 0.9849
MWE identification:
Epoch 1/1
 - 44s - loss: 8.0604 - acc: 0.4999
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0308 - acc: 0.9923
MWE identification:
Epoch 1/1
 - 44s - loss: 8.0601 - acc: 0.4999
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0194 - acc: 0.9955
MWE identification:
Epoch 1/1
 - 44s - loss: 8.0601 - acc: 0.4999
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0161 - acc: 0.9966
MWE identification:
Epoch 1/1
 - 45s - loss: 8.0601 - acc: 0.4999
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0143 - acc: 0.9971
MWE identification:
Epoch 1/1
 - 46s - loss: 8.0601 - acc: 0.4999
POS tagging accuracy = 94.8
Loss = 0.3, 
POS tagging accuracy = 94.8
Loss = 0.3, 
	TRAINING TIME: 5.88 minutes 
==================================================================================================
	PARSING TIME: 2.73 minutes 
==================================================================================================
	Identification : 0.004
	P, R  : 0.002, 0.118

==================================================================================================
	XP Ends: 24/4 (7 h:30)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,49             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
14             ,9              ,107            ,4              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.17           ,9              ,21             ,35             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
31             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 49, 14, 9, 107, 4, 8, 0.17, 9, 21, 35, True, 31, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (7h:30)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.17
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 31)        233895      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2351 (Flatten)          (None, 217)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2352 (Flatten)          (None, 168)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2353 (Flatten)          (None, 27)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2354 (Flatten)          (None, 9)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_816 (Concatenate)   (None, 421)          0           flatten_2351[0][0]               
                                                                 flatten_2352[0][0]               
                                                                 flatten_2353[0][0]               
                                                                 flatten_2354[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           14770       concatenate_816[0][0]            
__________________________________________________________________________________________________
dense_128 (Dense)               (None, 152)          5472        posDense[0][0]                   
==================================================================================================
Total params: 270,957
Trainable params: 270,957
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.17
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 31)        233895      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 9)         36          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2355 (Flatten)          (None, 217)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2356 (Flatten)          (None, 168)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2357 (Flatten)          (None, 27)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2358 (Flatten)          (None, 9)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2359 (Flatten)          (None, 217)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2360 (Flatten)          (None, 168)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2361 (Flatten)          (None, 27)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2362 (Flatten)          (None, 9)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2363 (Flatten)          (None, 217)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2364 (Flatten)          (None, 168)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2365 (Flatten)          (None, 27)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2366 (Flatten)          (None, 9)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2367 (Flatten)          (None, 217)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2368 (Flatten)          (None, 168)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2369 (Flatten)          (None, 27)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2370 (Flatten)          (None, 9)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_817 (Concatenate)   (None, 421)          0           flatten_2355[0][0]               
                                                                 flatten_2356[0][0]               
                                                                 flatten_2357[0][0]               
                                                                 flatten_2358[0][0]               
__________________________________________________________________________________________________
concatenate_818 (Concatenate)   (None, 421)          0           flatten_2359[0][0]               
                                                                 flatten_2360[0][0]               
                                                                 flatten_2361[0][0]               
                                                                 flatten_2362[0][0]               
__________________________________________________________________________________________________
concatenate_819 (Concatenate)   (None, 421)          0           flatten_2363[0][0]               
                                                                 flatten_2364[0][0]               
                                                                 flatten_2365[0][0]               
                                                                 flatten_2366[0][0]               
__________________________________________________________________________________________________
concatenate_820 (Concatenate)   (None, 421)          0           flatten_2367[0][0]               
                                                                 flatten_2368[0][0]               
                                                                 flatten_2369[0][0]               
                                                                 flatten_2370[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           14770       concatenate_817[0][0]            
                                                                 concatenate_818[0][0]            
                                                                 concatenate_819[0][0]            
                                                                 concatenate_820[0][0]            
__________________________________________________________________________________________________
concatenate_821 (Concatenate)   (None, 140)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 49)           6909        concatenate_821[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            200         idenDense[0][0]                  
==================================================================================================
Total params: 272,594
Trainable params: 272,594
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 5s - loss: 0.3051 - acc: 0.9262
POS tagging:
Epoch 1/1
 - 5s - loss: 0.1099 - acc: 0.9724
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0771 - acc: 0.9802
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0602 - acc: 0.9847
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0513 - acc: 0.9877
MWE identification:
Epoch 1/1
 - 9s - loss: 0.1210 - acc: 0.9630
POS tagging:
Epoch 1/1
 - 6s - loss: 0.3189 - acc: 0.9167
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0712 - acc: 0.9823
POS tagging:
Epoch 1/1
 - 6s - loss: 0.1224 - acc: 0.9717
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0562 - acc: 0.9861
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0811 - acc: 0.9807
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0495 - acc: 0.9878
POS tagging accuracy = 90.2
Loss = 0.487, 
POS tagging accuracy = 90.2
Loss = 0.487, 
	TRAINING TIME: 2.48 minutes 
==================================================================================================
	PARSING TIME: 1.12 minutes 
==================================================================================================
	Identification : 0.538
	P, R  : 0.626, 0.472

==================================================================================================
	XP Ends: 24/4 (7 h:34)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,58             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
9              ,5              ,14             ,2              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.097          ,12             ,37             ,29             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
140            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 58, 9, 5, 14, 2, 12, 0.097, 12, 37, 29, True, 140, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (7h:34)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.097
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 140)       1601320     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2371 (Flatten)          (None, 980)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2372 (Flatten)          (None, 108)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2373 (Flatten)          (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2374 (Flatten)          (None, 12)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_822 (Concatenate)   (None, 1115)         0           flatten_2371[0][0]               
                                                                 flatten_2372[0][0]               
                                                                 flatten_2373[0][0]               
                                                                 flatten_2374[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 29)           32364       concatenate_822[0][0]            
__________________________________________________________________________________________________
dense_129 (Dense)               (None, 152)          4560        posDense[0][0]                   
==================================================================================================
Total params: 1,649,178
Trainable params: 1,649,178
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.097
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 140)       1601320     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 9)        10674       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2375 (Flatten)          (None, 980)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2376 (Flatten)          (None, 108)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2377 (Flatten)          (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2378 (Flatten)          (None, 12)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2379 (Flatten)          (None, 980)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2380 (Flatten)          (None, 108)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2381 (Flatten)          (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2382 (Flatten)          (None, 12)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2383 (Flatten)          (None, 980)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2384 (Flatten)          (None, 108)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2385 (Flatten)          (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2386 (Flatten)          (None, 12)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2387 (Flatten)          (None, 980)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2388 (Flatten)          (None, 108)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2389 (Flatten)          (None, 15)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2390 (Flatten)          (None, 12)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2391 (Flatten)          (None, 980)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2392 (Flatten)          (None, 108)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2393 (Flatten)          (None, 15)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_2394 (Flatten)          (None, 12)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_823 (Concatenate)   (None, 1115)         0           flatten_2375[0][0]               
                                                                 flatten_2376[0][0]               
                                                                 flatten_2377[0][0]               
                                                                 flatten_2378[0][0]               
__________________________________________________________________________________________________
concatenate_824 (Concatenate)   (None, 1115)         0           flatten_2379[0][0]               
                                                                 flatten_2380[0][0]               
                                                                 flatten_2381[0][0]               
                                                                 flatten_2382[0][0]               
__________________________________________________________________________________________________
concatenate_825 (Concatenate)   (None, 1115)         0           flatten_2383[0][0]               
                                                                 flatten_2384[0][0]               
                                                                 flatten_2385[0][0]               
                                                                 flatten_2386[0][0]               
__________________________________________________________________________________________________
concatenate_826 (Concatenate)   (None, 1115)         0           flatten_2387[0][0]               
                                                                 flatten_2388[0][0]               
                                                                 flatten_2389[0][0]               
                                                                 flatten_2390[0][0]               
__________________________________________________________________________________________________
concatenate_827 (Concatenate)   (None, 1115)         0           flatten_2391[0][0]               
                                                                 flatten_2392[0][0]               
                                                                 flatten_2393[0][0]               
                                                                 flatten_2394[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 29)           32364       concatenate_823[0][0]            
                                                                 concatenate_824[0][0]            
                                                                 concatenate_825[0][0]            
                                                                 concatenate_826[0][0]            
                                                                 concatenate_827[0][0]            
__________________________________________________________________________________________________
concatenate_828 (Concatenate)   (None, 145)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 58)           8468        concatenate_828[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            236         idenDense[0][0]                  
==================================================================================================
Total params: 1,653,322
Trainable params: 1,653,322
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2687 - acc: 0.9332
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0892 - acc: 0.9761
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0502 - acc: 0.9868
MWE identification:
Epoch 1/1
 - 79s - loss: 0.8507 - acc: 0.9346
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1281 - acc: 0.9661
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0527 - acc: 0.9870
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0497 - acc: 0.9868
MWE identification:
Epoch 1/1
 - 79s - loss: 0.0464 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0307 - acc: 0.9925
MWE identification:
Epoch 1/1
 - 81s - loss: 0.0450 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0232 - acc: 0.9946
MWE identification:
Epoch 1/1
 - 80s - loss: 0.0446 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0192 - acc: 0.9956
MWE identification:
Epoch 1/1
 - 80s - loss: 0.0445 - acc: 0.9895
POS tagging accuracy = 93.2
Loss = 0.364, 
POS tagging accuracy = 93.2
Loss = 0.364, 
	TRAINING TIME: 9.93 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.509
	P, R  : 0.483, 0.537

==================================================================================================
	XP Ends: 24/4 (7 h:45)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,91             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
11             ,1              ,88             ,1              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.014          ,14             ,18             ,116            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
78             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 91, 11, 1, 88, 1, 13, 0.014, 14, 18, 116, True, 78, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (7h:45)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 78)        588510      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2395 (Flatten)          (None, 546)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2396 (Flatten)          (None, 132)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2397 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2398 (Flatten)          (None, 14)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_829 (Concatenate)   (None, 695)          0           flatten_2395[0][0]               
                                                                 flatten_2396[0][0]               
                                                                 flatten_2397[0][0]               
                                                                 flatten_2398[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 116)          80736       concatenate_829[0][0]            
__________________________________________________________________________________________________
dense_130 (Dense)               (None, 152)          17784       posDense[0][0]                   
==================================================================================================
Total params: 700,360
Trainable params: 700,360
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.014
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 78)        588510      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2399 (Flatten)          (None, 546)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2400 (Flatten)          (None, 132)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2401 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2402 (Flatten)          (None, 14)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2403 (Flatten)          (None, 546)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2404 (Flatten)          (None, 132)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2405 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2406 (Flatten)          (None, 14)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2407 (Flatten)          (None, 546)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2408 (Flatten)          (None, 132)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2409 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2410 (Flatten)          (None, 14)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2411 (Flatten)          (None, 546)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2412 (Flatten)          (None, 132)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2413 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2414 (Flatten)          (None, 14)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2415 (Flatten)          (None, 546)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2416 (Flatten)          (None, 132)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2417 (Flatten)          (None, 3)            0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_2418 (Flatten)          (None, 14)           0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_830 (Concatenate)   (None, 695)          0           flatten_2399[0][0]               
                                                                 flatten_2400[0][0]               
                                                                 flatten_2401[0][0]               
                                                                 flatten_2402[0][0]               
__________________________________________________________________________________________________
concatenate_831 (Concatenate)   (None, 695)          0           flatten_2403[0][0]               
                                                                 flatten_2404[0][0]               
                                                                 flatten_2405[0][0]               
                                                                 flatten_2406[0][0]               
__________________________________________________________________________________________________
concatenate_832 (Concatenate)   (None, 695)          0           flatten_2407[0][0]               
                                                                 flatten_2408[0][0]               
                                                                 flatten_2409[0][0]               
                                                                 flatten_2410[0][0]               
__________________________________________________________________________________________________
concatenate_833 (Concatenate)   (None, 695)          0           flatten_2411[0][0]               
                                                                 flatten_2412[0][0]               
                                                                 flatten_2413[0][0]               
                                                                 flatten_2414[0][0]               
__________________________________________________________________________________________________
concatenate_834 (Concatenate)   (None, 695)          0           flatten_2415[0][0]               
                                                                 flatten_2416[0][0]               
                                                                 flatten_2417[0][0]               
                                                                 flatten_2418[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 116)          80736       concatenate_830[0][0]            
                                                                 concatenate_831[0][0]            
                                                                 concatenate_832[0][0]            
                                                                 concatenate_833[0][0]            
                                                                 concatenate_834[0][0]            
__________________________________________________________________________________________________
concatenate_835 (Concatenate)   (None, 580)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 91)           52871       concatenate_835[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            368         idenDense[0][0]                  
==================================================================================================
Total params: 735,815
Trainable params: 735,815
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 7s - loss: 0.2443 - acc: 0.9420
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0994 - acc: 0.9754
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0726 - acc: 0.9820
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0915 - acc: 0.9767
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0526 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0669 - acc: 0.9826
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0491 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0534 - acc: 0.9869
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0473 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0441 - acc: 0.9898
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0463 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0372 - acc: 0.9917
MWE identification:
Epoch 1/1
 - 13s - loss: 0.0456 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 7s - loss: 0.0319 - acc: 0.9930
POS tagging accuracy = 95.2
Loss = 0.207, 
POS tagging accuracy = 95.2
Loss = 0.207, 
	TRAINING TIME: 3.68 minutes 
==================================================================================================
	PARSING TIME: 1.38 minutes 
==================================================================================================
	Identification : 0.589
	P, R  : 0.774, 0.476

==================================================================================================
	XP Ends: 24/4 (7 h:51)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,26             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
18             ,6              ,8              ,2              ,15             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.028          ,13             ,120            ,79             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
57             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 26, 18, 6, 8, 2, 15, 0.028, 13, 120, 79, True, 57, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (7h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 57)        430065      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2419 (Flatten)          (None, 399)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2420 (Flatten)          (None, 216)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2421 (Flatten)          (None, 18)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2422 (Flatten)          (None, 13)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_836 (Concatenate)   (None, 646)          0           flatten_2419[0][0]               
                                                                 flatten_2420[0][0]               
                                                                 flatten_2421[0][0]               
                                                                 flatten_2422[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 79)           51113       concatenate_836[0][0]            
__________________________________________________________________________________________________
dense_131 (Dense)               (None, 152)          12160       posDense[0][0]                   
==================================================================================================
Total params: 514,970
Trainable params: 514,970
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.028
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 57)        430065      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 13)        260         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2423 (Flatten)          (None, 399)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2424 (Flatten)          (None, 216)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2425 (Flatten)          (None, 18)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2426 (Flatten)          (None, 13)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2427 (Flatten)          (None, 399)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2428 (Flatten)          (None, 216)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2429 (Flatten)          (None, 18)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2430 (Flatten)          (None, 13)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2431 (Flatten)          (None, 399)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2432 (Flatten)          (None, 216)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2433 (Flatten)          (None, 18)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2434 (Flatten)          (None, 13)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2435 (Flatten)          (None, 399)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2436 (Flatten)          (None, 216)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2437 (Flatten)          (None, 18)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2438 (Flatten)          (None, 13)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_837 (Concatenate)   (None, 646)          0           flatten_2423[0][0]               
                                                                 flatten_2424[0][0]               
                                                                 flatten_2425[0][0]               
                                                                 flatten_2426[0][0]               
__________________________________________________________________________________________________
concatenate_838 (Concatenate)   (None, 646)          0           flatten_2427[0][0]               
                                                                 flatten_2428[0][0]               
                                                                 flatten_2429[0][0]               
                                                                 flatten_2430[0][0]               
__________________________________________________________________________________________________
concatenate_839 (Concatenate)   (None, 646)          0           flatten_2431[0][0]               
                                                                 flatten_2432[0][0]               
                                                                 flatten_2433[0][0]               
                                                                 flatten_2434[0][0]               
__________________________________________________________________________________________________
concatenate_840 (Concatenate)   (None, 646)          0           flatten_2435[0][0]               
                                                                 flatten_2436[0][0]               
                                                                 flatten_2437[0][0]               
                                                                 flatten_2438[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 79)           51113       concatenate_837[0][0]            
                                                                 concatenate_838[0][0]            
                                                                 concatenate_839[0][0]            
                                                                 concatenate_840[0][0]            
__________________________________________________________________________________________________
concatenate_841 (Concatenate)   (None, 316)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 26)           8242        concatenate_841[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            108         idenDense[0][0]                  
==================================================================================================
Total params: 511,160
Trainable params: 511,160
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2392 - acc: 0.9421
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0793 - acc: 0.9790
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0496 - acc: 0.9871
MWE identification:
Epoch 1/1
 - 109s - loss: 0.0642 - acc: 0.9837
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0648 - acc: 0.9830
MWE identification:
Epoch 1/1
 - 118s - loss: 0.0507 - acc: 0.9876
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0389 - acc: 0.9906
MWE identification:
Epoch 1/1
 - 109s - loss: 0.0476 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0276 - acc: 0.9938
MWE identification:
Epoch 1/1
 - 116s - loss: 0.0462 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0212 - acc: 0.9953
MWE identification:
Epoch 1/1
 - 120s - loss: 0.0454 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0167 - acc: 0.9965
MWE identification:
Epoch 1/1
 - 121s - loss: 0.0450 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0135 - acc: 0.9971
MWE identification:
Epoch 1/1
 - 113s - loss: 0.0447 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0112 - acc: 0.9977
POS tagging accuracy = 94.9
Loss = 0.233, 
POS tagging accuracy = 94.9
Loss = 0.233, 
	TRAINING TIME: 14.78 minutes 
==================================================================================================
	PARSING TIME: 1.1 minutes 
==================================================================================================
	Identification : 0.589
	P, R  : 0.776, 0.475

==================================================================================================
	XP Ends: 24/4 (8 h:7)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,37             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,7              ,12             ,4              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.119          ,5              ,9              ,104            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
60             ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 37, 6, 7, 12, 4, 8, 0.119, 5, 9, 104, True, 60, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (8h:7)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.119
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 60)        452700      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2439 (Flatten)          (None, 420)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2440 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2441 (Flatten)          (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_842 (Concatenate)   (None, 513)          0           flatten_2439[0][0]               
                                                                 flatten_2440[0][0]               
                                                                 flatten_2441[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 104)          53456       concatenate_842[0][0]            
__________________________________________________________________________________________________
dense_132 (Dense)               (None, 152)          15960       posDense[0][0]                   
==================================================================================================
Total params: 529,260
Trainable params: 529,260
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.119
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 60)        452700      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2442 (Flatten)          (None, 420)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2443 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2444 (Flatten)          (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2445 (Flatten)          (None, 420)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2446 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2447 (Flatten)          (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2448 (Flatten)          (None, 420)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2449 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2450 (Flatten)          (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2451 (Flatten)          (None, 420)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2452 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2453 (Flatten)          (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2454 (Flatten)          (None, 420)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2455 (Flatten)          (None, 72)           0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2456 (Flatten)          (None, 21)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_843 (Concatenate)   (None, 513)          0           flatten_2442[0][0]               
                                                                 flatten_2443[0][0]               
                                                                 flatten_2444[0][0]               
__________________________________________________________________________________________________
concatenate_844 (Concatenate)   (None, 513)          0           flatten_2445[0][0]               
                                                                 flatten_2446[0][0]               
                                                                 flatten_2447[0][0]               
__________________________________________________________________________________________________
concatenate_845 (Concatenate)   (None, 513)          0           flatten_2448[0][0]               
                                                                 flatten_2449[0][0]               
                                                                 flatten_2450[0][0]               
__________________________________________________________________________________________________
concatenate_846 (Concatenate)   (None, 513)          0           flatten_2451[0][0]               
                                                                 flatten_2452[0][0]               
                                                                 flatten_2453[0][0]               
__________________________________________________________________________________________________
concatenate_847 (Concatenate)   (None, 513)          0           flatten_2454[0][0]               
                                                                 flatten_2455[0][0]               
                                                                 flatten_2456[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 104)          53456       concatenate_843[0][0]            
                                                                 concatenate_844[0][0]            
                                                                 concatenate_845[0][0]            
                                                                 concatenate_846[0][0]            
                                                                 concatenate_847[0][0]            
__________________________________________________________________________________________________
concatenate_848 (Concatenate)   (None, 520)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 37)           19277       concatenate_848[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            152         idenDense[0][0]                  
==================================================================================================
Total params: 532,729
Trainable params: 532,729
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 12s - loss: 0.2562 - acc: 0.9390
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0840 - acc: 0.9782
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0531 - acc: 0.9870
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0382 - acc: 0.9912
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0302 - acc: 0.9936
MWE identification:
Epoch 1/1
 - 75s - loss: 0.1726 - acc: 0.9755
POS tagging:
Epoch 1/1
 - 12s - loss: 0.1432 - acc: 0.9654
MWE identification:
Epoch 1/1
 - 74s - loss: 0.0557 - acc: 0.9860
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0527 - acc: 0.9872
MWE identification:
Epoch 1/1
 - 74s - loss: 0.0485 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0336 - acc: 0.9927
MWE identification:
Epoch 1/1
 - 74s - loss: 0.0462 - acc: 0.9890
POS tagging accuracy = 94.0
Loss = 0.326, 
POS tagging accuracy = 94.0
Loss = 0.326, 
	TRAINING TIME: 7.68 minutes 
==================================================================================================
	PARSING TIME: 1.07 minutes 
==================================================================================================
	Identification : 0.548
	P, R  : 0.569, 0.528

==================================================================================================
	XP Ends: 24/4 (8 h:16)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,50             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
15             ,5              ,29             ,1              ,19             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.021          ,8              ,77             ,94             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
37             ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 50, 15, 5, 29, 1, 19, 0.021, 8, 77, 94, True, 37, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (8h:16)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 37)        279165      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2457 (Flatten)          (None, 259)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2458 (Flatten)          (None, 180)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2459 (Flatten)          (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2460 (Flatten)          (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_849 (Concatenate)   (None, 462)          0           flatten_2457[0][0]               
                                                                 flatten_2458[0][0]               
                                                                 flatten_2459[0][0]               
                                                                 flatten_2460[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 94)           43522       concatenate_849[0][0]            
__________________________________________________________________________________________________
dense_133 (Dense)               (None, 152)          14440       posDense[0][0]                   
==================================================================================================
Total params: 355,097
Trainable params: 355,097
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.021
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 37)        279165      bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2461 (Flatten)          (None, 259)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2462 (Flatten)          (None, 180)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2463 (Flatten)          (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2464 (Flatten)          (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2465 (Flatten)          (None, 259)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2466 (Flatten)          (None, 180)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2467 (Flatten)          (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2468 (Flatten)          (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2469 (Flatten)          (None, 259)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2470 (Flatten)          (None, 180)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2471 (Flatten)          (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2472 (Flatten)          (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2473 (Flatten)          (None, 259)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2474 (Flatten)          (None, 180)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2475 (Flatten)          (None, 15)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2476 (Flatten)          (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2477 (Flatten)          (None, 259)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2478 (Flatten)          (None, 180)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2479 (Flatten)          (None, 15)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_2480 (Flatten)          (None, 8)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_850 (Concatenate)   (None, 462)          0           flatten_2461[0][0]               
                                                                 flatten_2462[0][0]               
                                                                 flatten_2463[0][0]               
                                                                 flatten_2464[0][0]               
__________________________________________________________________________________________________
concatenate_851 (Concatenate)   (None, 462)          0           flatten_2465[0][0]               
                                                                 flatten_2466[0][0]               
                                                                 flatten_2467[0][0]               
                                                                 flatten_2468[0][0]               
__________________________________________________________________________________________________
concatenate_852 (Concatenate)   (None, 462)          0           flatten_2469[0][0]               
                                                                 flatten_2470[0][0]               
                                                                 flatten_2471[0][0]               
                                                                 flatten_2472[0][0]               
__________________________________________________________________________________________________
concatenate_853 (Concatenate)   (None, 462)          0           flatten_2473[0][0]               
                                                                 flatten_2474[0][0]               
                                                                 flatten_2475[0][0]               
                                                                 flatten_2476[0][0]               
__________________________________________________________________________________________________
concatenate_854 (Concatenate)   (None, 462)          0           flatten_2477[0][0]               
                                                                 flatten_2478[0][0]               
                                                                 flatten_2479[0][0]               
                                                                 flatten_2480[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 94)           43522       concatenate_850[0][0]            
                                                                 concatenate_851[0][0]            
                                                                 concatenate_852[0][0]            
                                                                 concatenate_853[0][0]            
                                                                 concatenate_854[0][0]            
__________________________________________________________________________________________________
concatenate_855 (Concatenate)   (None, 470)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 50)           23550       concatenate_855[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            204         idenDense[0][0]                  
==================================================================================================
Total params: 364,411
Trainable params: 364,411
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2571 - acc: 0.9380
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0999 - acc: 0.9752
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0683 - acc: 0.9828
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0930 - acc: 0.9763
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0525 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0679 - acc: 0.9829
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0492 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0541 - acc: 0.9867
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0475 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0442 - acc: 0.9894
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0463 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0369 - acc: 0.9912
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0457 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0311 - acc: 0.9926
MWE identification:
Epoch 1/1
 - 39s - loss: 0.0453 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0267 - acc: 0.9938
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0450 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0231 - acc: 0.9949
MWE identification:
Epoch 1/1
 - 36s - loss: 0.0448 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0201 - acc: 0.9956
POS tagging accuracy = 94.9
Loss = 0.211, 
POS tagging accuracy = 94.9
Loss = 0.211, 
	TRAINING TIME: 7.02 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.578
	P, R  : 0.742, 0.473

==================================================================================================
	XP Ends: 24/4 (8 h:24)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,62             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
17             ,3              ,87             ,2              ,13             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.167          ,5              ,11             ,163            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
193            ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 62, 17, 3, 87, 2, 13, 0.167, 5, 11, 163, True, 193, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (8h:24)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.167
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 193)       2207534     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2481 (Flatten)          (None, 1351)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2482 (Flatten)          (None, 204)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2483 (Flatten)          (None, 9)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2484 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_856 (Concatenate)   (None, 1569)         0           flatten_2481[0][0]               
                                                                 flatten_2482[0][0]               
                                                                 flatten_2483[0][0]               
                                                                 flatten_2484[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 163)          255910      concatenate_856[0][0]            
__________________________________________________________________________________________________
dense_134 (Dense)               (None, 152)          24928       posDense[0][0]                   
==================================================================================================
Total params: 2,508,646
Trainable params: 2,508,646
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.167
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 193)       2207534     b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 17)       20162       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2485 (Flatten)          (None, 1351)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2486 (Flatten)          (None, 204)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2487 (Flatten)          (None, 9)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2488 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2489 (Flatten)          (None, 1351)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2490 (Flatten)          (None, 204)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2491 (Flatten)          (None, 9)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2492 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2493 (Flatten)          (None, 1351)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2494 (Flatten)          (None, 204)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2495 (Flatten)          (None, 9)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2496 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2497 (Flatten)          (None, 1351)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2498 (Flatten)          (None, 204)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2499 (Flatten)          (None, 9)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2500 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_857 (Concatenate)   (None, 1569)         0           flatten_2485[0][0]               
                                                                 flatten_2486[0][0]               
                                                                 flatten_2487[0][0]               
                                                                 flatten_2488[0][0]               
__________________________________________________________________________________________________
concatenate_858 (Concatenate)   (None, 1569)         0           flatten_2489[0][0]               
                                                                 flatten_2490[0][0]               
                                                                 flatten_2491[0][0]               
                                                                 flatten_2492[0][0]               
__________________________________________________________________________________________________
concatenate_859 (Concatenate)   (None, 1569)         0           flatten_2493[0][0]               
                                                                 flatten_2494[0][0]               
                                                                 flatten_2495[0][0]               
                                                                 flatten_2496[0][0]               
__________________________________________________________________________________________________
concatenate_860 (Concatenate)   (None, 1569)         0           flatten_2497[0][0]               
                                                                 flatten_2498[0][0]               
                                                                 flatten_2499[0][0]               
                                                                 flatten_2500[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 163)          255910      concatenate_857[0][0]            
                                                                 concatenate_858[0][0]            
                                                                 concatenate_859[0][0]            
                                                                 concatenate_860[0][0]            
__________________________________________________________________________________________________
concatenate_861 (Concatenate)   (None, 652)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 62)           40486       concatenate_861[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            252         idenDense[0][0]                  
==================================================================================================
Total params: 2,524,456
Trainable params: 2,524,456
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 13s - loss: 8.8319 - acc: 0.4510
POS tagging:
Epoch 1/1
 - 13s - loss: 8.5371 - acc: 0.4700
POS tagging:
Epoch 1/1
 - 13s - loss: 8.4950 - acc: 0.4727
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0883 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 13s - loss: 8.4556 - acc: 0.4752
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 13s - loss: 8.3860 - acc: 0.4796
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0854 - acc: 0.2502
POS tagging:
Epoch 1/1
 - 13s - loss: 8.4189 - acc: 0.4774
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0876 - acc: 0.2501
POS tagging:
Epoch 1/1
 - 13s - loss: 8.3840 - acc: 0.4796
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0876 - acc: 0.2501
POS tagging:
Epoch 1/1
 - 13s - loss: 8.3694 - acc: 0.4806
MWE identification:
Epoch 1/1
 - 14s - loss: 12.0865 - acc: 0.2501
POS tagging:
Epoch 1/1
 - 13s - loss: 8.3610 - acc: 0.4811
POS tagging accuracy = 50.2
Loss = 8.016, 
POS tagging accuracy = 50.2
Loss = 8.016, 
	TRAINING TIME: 4.55 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (8 h:31)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,41             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
12             ,2              ,101            ,4              ,12             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.104          ,14             ,30             ,52             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
54             ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 41, 12, 2, 101, 4, 12, 0.104, 14, 30, 52, True, 54, False, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (8h:31)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.104
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 54)        407430      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2501 (Flatten)          (None, 378)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2502 (Flatten)          (None, 144)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2503 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2504 (Flatten)          (None, 14)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_862 (Concatenate)   (None, 542)          0           flatten_2501[0][0]               
                                                                 flatten_2502[0][0]               
                                                                 flatten_2503[0][0]               
                                                                 flatten_2504[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 52)           28236       concatenate_862[0][0]            
__________________________________________________________________________________________________
dense_135 (Dense)               (None, 152)          8056        posDense[0][0]                   
==================================================================================================
Total params: 458,242
Trainable params: 458,242
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.104
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 54)        407430      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 14)        280         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2505 (Flatten)          (None, 378)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2506 (Flatten)          (None, 144)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2507 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2508 (Flatten)          (None, 14)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2509 (Flatten)          (None, 378)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2510 (Flatten)          (None, 144)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2511 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2512 (Flatten)          (None, 14)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2513 (Flatten)          (None, 378)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2514 (Flatten)          (None, 144)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2515 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2516 (Flatten)          (None, 14)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_863 (Concatenate)   (None, 542)          0           flatten_2505[0][0]               
                                                                 flatten_2506[0][0]               
                                                                 flatten_2507[0][0]               
                                                                 flatten_2508[0][0]               
__________________________________________________________________________________________________
concatenate_864 (Concatenate)   (None, 542)          0           flatten_2509[0][0]               
                                                                 flatten_2510[0][0]               
                                                                 flatten_2511[0][0]               
                                                                 flatten_2512[0][0]               
__________________________________________________________________________________________________
concatenate_865 (Concatenate)   (None, 542)          0           flatten_2513[0][0]               
                                                                 flatten_2514[0][0]               
                                                                 flatten_2515[0][0]               
                                                                 flatten_2516[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 52)           28236       concatenate_863[0][0]            
                                                                 concatenate_864[0][0]            
                                                                 concatenate_865[0][0]            
__________________________________________________________________________________________________
concatenate_866 (Concatenate)   (None, 156)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 41)           6437        concatenate_866[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            168         idenDense[0][0]                  
==================================================================================================
Total params: 456,791
Trainable params: 456,791
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2224 - acc: 0.9457
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0719 - acc: 0.9803
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0428 - acc: 0.9888
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0289 - acc: 0.9931
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0220 - acc: 0.9950
MWE identification:
Epoch 1/1
 - 8s - loss: 0.0782 - acc: 0.9813
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0950 - acc: 0.9781
MWE identification:
Epoch 1/1
 - 8s - loss: 0.0518 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0377 - acc: 0.9910
MWE identification:
Epoch 1/1
 - 8s - loss: 0.0470 - acc: 0.9887
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0232 - acc: 0.9949
MWE identification:
Epoch 1/1
 - 8s - loss: 0.0453 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0179 - acc: 0.9962
MWE identification:
Epoch 1/1
 - 8s - loss: 0.0446 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0151 - acc: 0.9969
MWE identification:
Epoch 1/1
 - 8s - loss: 0.0444 - acc: 0.9895
POS tagging accuracy = 94.4
Loss = 0.32, 
POS tagging accuracy = 94.4
Loss = 0.32, 
	TRAINING TIME: 2.38 minutes 
==================================================================================================
	PARSING TIME: 0.92 minutes 
==================================================================================================
	Identification : 0.572
	P, R  : 0.675, 0.497

==================================================================================================
	XP Ends: 24/4 (8 h:35)
==================================================================================================
INFO (theano.gof.compilelock): Waiting for existing lock by unknown process (I am process '5264')
INFO (theano.gof.compilelock): To manually release the lock, delete /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/lock_dir
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,115            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,5              ,112            ,1              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.13           ,9              ,98             ,30             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
38             ,True           ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 115, 13, 5, 112, 1, 8, 0.13, 9, 98, 30, True, 38, True, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (8h:35)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.13
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 38)        286710      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2517 (Flatten)          (None, 266)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2518 (Flatten)          (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2519 (Flatten)          (None, 15)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2520 (Flatten)          (None, 9)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_867 (Concatenate)   (None, 446)          0           flatten_2517[0][0]               
                                                                 flatten_2518[0][0]               
                                                                 flatten_2519[0][0]               
                                                                 flatten_2520[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 30)           13410       concatenate_867[0][0]            
__________________________________________________________________________________________________
dense_136 (Dense)               (None, 152)          4712        posDense[0][0]                   
==================================================================================================
Total params: 320,450
Trainable params: 320,450
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.13
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 38)        286710      b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 5)         20          b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 9)         180         b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2521 (Flatten)          (None, 266)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2522 (Flatten)          (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2523 (Flatten)          (None, 15)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2524 (Flatten)          (None, 9)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2525 (Flatten)          (None, 266)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2526 (Flatten)          (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2527 (Flatten)          (None, 15)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2528 (Flatten)          (None, 9)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2529 (Flatten)          (None, 266)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2530 (Flatten)          (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2531 (Flatten)          (None, 15)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2532 (Flatten)          (None, 9)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2533 (Flatten)          (None, 266)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2534 (Flatten)          (None, 156)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2535 (Flatten)          (None, 15)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2536 (Flatten)          (None, 9)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_868 (Concatenate)   (None, 446)          0           flatten_2521[0][0]               
                                                                 flatten_2522[0][0]               
                                                                 flatten_2523[0][0]               
                                                                 flatten_2524[0][0]               
__________________________________________________________________________________________________
concatenate_869 (Concatenate)   (None, 446)          0           flatten_2525[0][0]               
                                                                 flatten_2526[0][0]               
                                                                 flatten_2527[0][0]               
                                                                 flatten_2528[0][0]               
__________________________________________________________________________________________________
concatenate_870 (Concatenate)   (None, 446)          0           flatten_2529[0][0]               
                                                                 flatten_2530[0][0]               
                                                                 flatten_2531[0][0]               
                                                                 flatten_2532[0][0]               
__________________________________________________________________________________________________
concatenate_871 (Concatenate)   (None, 446)          0           flatten_2533[0][0]               
                                                                 flatten_2534[0][0]               
                                                                 flatten_2535[0][0]               
                                                                 flatten_2536[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 30)           13410       concatenate_868[0][0]            
                                                                 concatenate_869[0][0]            
                                                                 concatenate_870[0][0]            
                                                                 concatenate_871[0][0]            
__________________________________________________________________________________________________
concatenate_872 (Concatenate)   (None, 120)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 115)          13915       concatenate_872[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            464         idenDense[0][0]                  
==================================================================================================
Total params: 330,117
Trainable params: 330,117
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2486 - acc: 0.9404
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0759 - acc: 0.9794
MWE identification:
Epoch 1/1
 - 9s - loss: 12.0848 - acc: 0.2501
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0612 - acc: 0.9828
MWE identification:
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0332 - acc: 0.9910
MWE identification:
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0238 - acc: 0.9937
MWE identification:
Epoch 1/1
 - 9s - loss: 12.0886 - acc: 0.2500
POS tagging accuracy = 95.0
Loss = 0.234, 
POS tagging accuracy = 95.0
Loss = 0.234, 
	TRAINING TIME: 2.13 minutes 
==================================================================================================
	PARSING TIME: 1.92 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (8 h:39)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,34             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
15             ,3              ,25             ,2              ,19             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.08           ,14             ,87             ,99             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
166            ,True           ,True           ,False          ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 34, 15, 3, 25, 2, 19, 0.08, 14, 87, 99, True, 166, True, True, False, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (8h:39)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 166)       1898708     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       affixes[0][0]                    
__________________________________________________________________________________________________
flatten_2537 (Flatten)          (None, 1162)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2538 (Flatten)          (None, 180)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
concatenate_873 (Concatenate)   (None, 1342)         0           flatten_2537[0][0]               
                                                                 flatten_2538[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 99)           132957      concatenate_873[0][0]            
__________________________________________________________________________________________________
dense_137 (Dense)               (None, 152)          15200       posDense[0][0]                   
==================================================================================================
Total params: 2,064,655
Trainable params: 2,064,655
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.08
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 166)       1898708     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 15)       17790       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
flatten_2539 (Flatten)          (None, 1162)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2540 (Flatten)          (None, 180)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2541 (Flatten)          (None, 1162)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2542 (Flatten)          (None, 180)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2543 (Flatten)          (None, 1162)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2544 (Flatten)          (None, 180)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2545 (Flatten)          (None, 1162)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2546 (Flatten)          (None, 180)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2547 (Flatten)          (None, 1162)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2548 (Flatten)          (None, 180)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
concatenate_874 (Concatenate)   (None, 1342)         0           flatten_2539[0][0]               
                                                                 flatten_2540[0][0]               
__________________________________________________________________________________________________
concatenate_875 (Concatenate)   (None, 1342)         0           flatten_2541[0][0]               
                                                                 flatten_2542[0][0]               
__________________________________________________________________________________________________
concatenate_876 (Concatenate)   (None, 1342)         0           flatten_2543[0][0]               
                                                                 flatten_2544[0][0]               
__________________________________________________________________________________________________
concatenate_877 (Concatenate)   (None, 1342)         0           flatten_2545[0][0]               
                                                                 flatten_2546[0][0]               
__________________________________________________________________________________________________
concatenate_878 (Concatenate)   (None, 1342)         0           flatten_2547[0][0]               
                                                                 flatten_2548[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 99)           132957      concatenate_874[0][0]            
                                                                 concatenate_875[0][0]            
                                                                 concatenate_876[0][0]            
                                                                 concatenate_877[0][0]            
                                                                 concatenate_878[0][0]            
__________________________________________________________________________________________________
concatenate_879 (Concatenate)   (None, 495)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 34)           16864       concatenate_879[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            140         idenDense[0][0]                  
==================================================================================================
Total params: 2,066,459
Trainable params: 2,066,459
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.2694 - acc: 0.9336
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0818 - acc: 0.9791
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0434 - acc: 0.9898
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0694 - acc: 0.9827
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1123 - acc: 0.9702
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0482 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0417 - acc: 0.9906
MWE identification:
Epoch 1/1
 - 35s - loss: 0.0452 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0255 - acc: 0.9948
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0446 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0192 - acc: 0.9965
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0160 - acc: 0.9972
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0138 - acc: 0.9977
MWE identification:
Epoch 1/1
 - 35s - loss: 0.0442 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0126 - acc: 0.9981
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0442 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0116 - acc: 0.9983
MWE identification:
Epoch 1/1
 - 34s - loss: 0.0442 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0107 - acc: 0.9985
POS tagging accuracy = 93.5
Loss = 0.367, 
POS tagging accuracy = 93.5
Loss = 0.367, 
	TRAINING TIME: 6.42 minutes 
==================================================================================================
	PARSING TIME: 0.83 minutes 
==================================================================================================
	Identification : 0.544
	P, R  : 0.538, 0.551

==================================================================================================
	XP Ends: 24/4 (8 h:47)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,103            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
16             ,2              ,105            ,4              ,19             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.018          ,12             ,26             ,65             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
67             ,False          ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 103, 16, 2, 105, 4, 19, 0.018, 12, 26, 65, True, 67, False, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (8h:47)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 67)        505515      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 16)       18976       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2549 (Flatten)          (None, 469)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2550 (Flatten)          (None, 192)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2551 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_880 (Concatenate)   (None, 667)          0           flatten_2549[0][0]               
                                                                 flatten_2550[0][0]               
                                                                 flatten_2551[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 65)           43420       concatenate_880[0][0]            
__________________________________________________________________________________________________
dense_138 (Dense)               (None, 152)          10032       posDense[0][0]                   
==================================================================================================
Total params: 577,951
Trainable params: 577,951
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.018
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 67)        505515      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 16)       18976       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2552 (Flatten)          (None, 469)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2553 (Flatten)          (None, 192)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2554 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2555 (Flatten)          (None, 469)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2556 (Flatten)          (None, 192)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2557 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2558 (Flatten)          (None, 469)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2559 (Flatten)          (None, 192)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2560 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
concatenate_881 (Concatenate)   (None, 667)          0           flatten_2552[0][0]               
                                                                 flatten_2553[0][0]               
                                                                 flatten_2554[0][0]               
__________________________________________________________________________________________________
concatenate_882 (Concatenate)   (None, 667)          0           flatten_2555[0][0]               
                                                                 flatten_2556[0][0]               
                                                                 flatten_2557[0][0]               
__________________________________________________________________________________________________
concatenate_883 (Concatenate)   (None, 667)          0           flatten_2558[0][0]               
                                                                 flatten_2559[0][0]               
                                                                 flatten_2560[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 65)           43420       concatenate_881[0][0]            
                                                                 concatenate_882[0][0]            
                                                                 concatenate_883[0][0]            
__________________________________________________________________________________________________
concatenate_884 (Concatenate)   (None, 195)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 103)          20188       concatenate_884[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            416         idenDense[0][0]                  
==================================================================================================
Total params: 588,523
Trainable params: 588,523
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2504 - acc: 0.9410
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1019 - acc: 0.9749
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0723 - acc: 0.9814
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0552 - acc: 0.9863
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0438 - acc: 0.9896
MWE identification:
Epoch 1/1
 - 7s - loss: 0.0707 - acc: 0.9823
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0548 - acc: 0.9856
MWE identification:
Epoch 1/1
 - 7s - loss: 0.0519 - acc: 0.9873
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0405 - acc: 0.9904
MWE identification:
Epoch 1/1
 - 7s - loss: 0.0486 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0329 - acc: 0.9924
MWE identification:
Epoch 1/1
 - 8s - loss: 0.0470 - acc: 0.9887
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0278 - acc: 0.9938
MWE identification:
Epoch 1/1
 - 7s - loss: 0.0461 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0240 - acc: 0.9948
MWE identification:
Epoch 1/1
 - 7s - loss: 0.0455 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0208 - acc: 0.9957
MWE identification:
Epoch 1/1
 - 7s - loss: 0.0451 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0184 - acc: 0.9963
MWE identification:
Epoch 1/1
 - 7s - loss: 0.0449 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0163 - acc: 0.9968
MWE identification:
Epoch 1/1
 - 7s - loss: 0.0447 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0146 - acc: 0.9971
POS tagging accuracy = 94.9
Loss = 0.228, 
POS tagging accuracy = 94.9
Loss = 0.228, 
	TRAINING TIME: 2.87 minutes 
==================================================================================================
	PARSING TIME: 0.8 minutes 
==================================================================================================
	Identification : 0.589
	P, R  : 0.787, 0.47

==================================================================================================
	XP Ends: 24/4 (8 h:51)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,187            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
14             ,7              ,9              ,2              ,11             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.054          ,12             ,26             ,40             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
31             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 187, 14, 7, 9, 2, 11, 0.054, 12, 26, 40, True, 31, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (8h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 31)        354578      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2561 (Flatten)          (None, 217)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2562 (Flatten)          (None, 168)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2563 (Flatten)          (None, 21)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2564 (Flatten)          (None, 12)           0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_885 (Concatenate)   (None, 418)          0           flatten_2561[0][0]               
                                                                 flatten_2562[0][0]               
                                                                 flatten_2563[0][0]               
                                                                 flatten_2564[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 40)           16760       concatenate_885[0][0]            
__________________________________________________________________________________________________
dense_139 (Dense)               (None, 152)          6232        posDense[0][0]                   
==================================================================================================
Total params: 394,442
Trainable params: 394,442
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.054
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 31)        354578      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 14)       16604       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 7)         28          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 12)        240         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2565 (Flatten)          (None, 217)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2566 (Flatten)          (None, 168)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2567 (Flatten)          (None, 21)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2568 (Flatten)          (None, 12)           0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2569 (Flatten)          (None, 217)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2570 (Flatten)          (None, 168)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2571 (Flatten)          (None, 21)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2572 (Flatten)          (None, 12)           0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2573 (Flatten)          (None, 217)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2574 (Flatten)          (None, 168)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2575 (Flatten)          (None, 21)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2576 (Flatten)          (None, 12)           0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2577 (Flatten)          (None, 217)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2578 (Flatten)          (None, 168)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2579 (Flatten)          (None, 21)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2580 (Flatten)          (None, 12)           0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_886 (Concatenate)   (None, 418)          0           flatten_2565[0][0]               
                                                                 flatten_2566[0][0]               
                                                                 flatten_2567[0][0]               
                                                                 flatten_2568[0][0]               
__________________________________________________________________________________________________
concatenate_887 (Concatenate)   (None, 418)          0           flatten_2569[0][0]               
                                                                 flatten_2570[0][0]               
                                                                 flatten_2571[0][0]               
                                                                 flatten_2572[0][0]               
__________________________________________________________________________________________________
concatenate_888 (Concatenate)   (None, 418)          0           flatten_2573[0][0]               
                                                                 flatten_2574[0][0]               
                                                                 flatten_2575[0][0]               
                                                                 flatten_2576[0][0]               
__________________________________________________________________________________________________
concatenate_889 (Concatenate)   (None, 418)          0           flatten_2577[0][0]               
                                                                 flatten_2578[0][0]               
                                                                 flatten_2579[0][0]               
                                                                 flatten_2580[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 40)           16760       concatenate_886[0][0]            
                                                                 concatenate_887[0][0]            
                                                                 concatenate_888[0][0]            
                                                                 concatenate_889[0][0]            
__________________________________________________________________________________________________
concatenate_890 (Concatenate)   (None, 160)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 187)          30107       concatenate_890[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            752         idenDense[0][0]                  
==================================================================================================
Total params: 419,069
Trainable params: 419,069
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2426 - acc: 0.9385
POS tagging:
Epoch 1/1
 - 4s - loss: 0.1096 - acc: 0.9717
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0717 - acc: 0.9817
MWE identification:
Epoch 1/1
 - 98s - loss: 12.0884 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0576 - acc: 0.9854
MWE identification:
Epoch 1/1
 - 96s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0389 - acc: 0.9903
MWE identification:
Epoch 1/1
 - 97s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0299 - acc: 0.9927
MWE identification:
Epoch 1/1
 - 96s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0239 - acc: 0.9943
MWE identification:
Epoch 1/1
 - 96s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 5s - loss: 0.0194 - acc: 0.9955
POS tagging accuracy = 94.2
Loss = 0.254, 
POS tagging accuracy = 94.2
Loss = 0.254, 
	TRAINING TIME: 9.82 minutes 
==================================================================================================
	PARSING TIME: 1.98 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (9 h:3)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,65             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
13             ,2              ,8              ,2              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.082          ,6              ,20             ,36             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
47             ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 65, 13, 2, 8, 2, 9, 0.082, 6, 20, 36, True, 47, False, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (9h:3)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.082
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 47)        354615      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2581 (Flatten)          (None, 329)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2582 (Flatten)          (None, 156)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2583 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2584 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_891 (Concatenate)   (None, 497)          0           flatten_2581[0][0]               
                                                                 flatten_2582[0][0]               
                                                                 flatten_2583[0][0]               
                                                                 flatten_2584[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           17928       concatenate_891[0][0]            
__________________________________________________________________________________________________
dense_140 (Dense)               (None, 152)          5624        posDense[0][0]                   
==================================================================================================
Total params: 393,713
Trainable params: 393,713
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.082
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 47)        354615      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 13)       15418       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2585 (Flatten)          (None, 329)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2586 (Flatten)          (None, 156)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2587 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2588 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2589 (Flatten)          (None, 329)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2590 (Flatten)          (None, 156)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2591 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2592 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2593 (Flatten)          (None, 329)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2594 (Flatten)          (None, 156)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2595 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2596 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_892 (Concatenate)   (None, 497)          0           flatten_2585[0][0]               
                                                                 flatten_2586[0][0]               
                                                                 flatten_2587[0][0]               
                                                                 flatten_2588[0][0]               
__________________________________________________________________________________________________
concatenate_893 (Concatenate)   (None, 497)          0           flatten_2589[0][0]               
                                                                 flatten_2590[0][0]               
                                                                 flatten_2591[0][0]               
                                                                 flatten_2592[0][0]               
__________________________________________________________________________________________________
concatenate_894 (Concatenate)   (None, 497)          0           flatten_2593[0][0]               
                                                                 flatten_2594[0][0]               
                                                                 flatten_2595[0][0]               
                                                                 flatten_2596[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 36)           17928       concatenate_892[0][0]            
                                                                 concatenate_893[0][0]            
                                                                 concatenate_894[0][0]            
__________________________________________________________________________________________________
concatenate_895 (Concatenate)   (None, 108)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 65)           7085        concatenate_895[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            264         idenDense[0][0]                  
==================================================================================================
Total params: 395,438
Trainable params: 395,438
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 6s - loss: 0.2079 - acc: 0.9488
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0686 - acc: 0.9810
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0400 - acc: 0.9892
MWE identification:
Epoch 1/1
 - 92s - loss: 0.0680 - acc: 0.9824
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0876 - acc: 0.9768
MWE identification:
Epoch 1/1
 - 92s - loss: 0.0511 - acc: 0.9873
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0401 - acc: 0.9896
MWE identification:
Epoch 1/1
 - 94s - loss: 0.0471 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0271 - acc: 0.9935
MWE identification:
Epoch 1/1
 - 92s - loss: 0.0455 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 6s - loss: 0.0213 - acc: 0.9951
POS tagging accuracy = 94.9
Loss = 0.264, 
POS tagging accuracy = 94.9
Loss = 0.264, 
	TRAINING TIME: 7.8 minutes 
==================================================================================================
	PARSING TIME: 0.85 minutes 
==================================================================================================
	Identification : 0.585
	P, R  : 0.69, 0.507

==================================================================================================
	XP Ends: 24/4 (9 h:12)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,199            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
10             ,6              ,29             ,3              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.074          ,5              ,33             ,126            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
164            ,True           ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 199, 10, 6, 29, 3, 9, 0.074, 5, 33, 126, True, 164, True, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (9h:12)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 164)       1237380     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2597 (Flatten)          (None, 1148)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2598 (Flatten)          (None, 120)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2599 (Flatten)          (None, 18)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_896 (Concatenate)   (None, 1286)         0           flatten_2597[0][0]               
                                                                 flatten_2598[0][0]               
                                                                 flatten_2599[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 126)          162162      concatenate_896[0][0]            
__________________________________________________________________________________________________
dense_141 (Dense)               (None, 152)          19304       posDense[0][0]                   
==================================================================================================
Total params: 1,430,730
Trainable params: 1,430,730
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.074
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 164)       1237380     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 10)       11860       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 6)         24          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2600 (Flatten)          (None, 1148)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2601 (Flatten)          (None, 120)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2602 (Flatten)          (None, 18)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2603 (Flatten)          (None, 1148)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2604 (Flatten)          (None, 120)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2605 (Flatten)          (None, 18)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2606 (Flatten)          (None, 1148)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2607 (Flatten)          (None, 120)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2608 (Flatten)          (None, 18)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2609 (Flatten)          (None, 1148)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2610 (Flatten)          (None, 120)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2611 (Flatten)          (None, 18)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2612 (Flatten)          (None, 1148)         0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2613 (Flatten)          (None, 120)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2614 (Flatten)          (None, 18)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
concatenate_897 (Concatenate)   (None, 1286)         0           flatten_2600[0][0]               
                                                                 flatten_2601[0][0]               
                                                                 flatten_2602[0][0]               
__________________________________________________________________________________________________
concatenate_898 (Concatenate)   (None, 1286)         0           flatten_2603[0][0]               
                                                                 flatten_2604[0][0]               
                                                                 flatten_2605[0][0]               
__________________________________________________________________________________________________
concatenate_899 (Concatenate)   (None, 1286)         0           flatten_2606[0][0]               
                                                                 flatten_2607[0][0]               
                                                                 flatten_2608[0][0]               
__________________________________________________________________________________________________
concatenate_900 (Concatenate)   (None, 1286)         0           flatten_2609[0][0]               
                                                                 flatten_2610[0][0]               
                                                                 flatten_2611[0][0]               
__________________________________________________________________________________________________
concatenate_901 (Concatenate)   (None, 1286)         0           flatten_2612[0][0]               
                                                                 flatten_2613[0][0]               
                                                                 flatten_2614[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 126)          162162      concatenate_897[0][0]            
                                                                 concatenate_898[0][0]            
                                                                 concatenate_899[0][0]            
                                                                 concatenate_900[0][0]            
                                                                 concatenate_901[0][0]            
__________________________________________________________________________________________________
concatenate_902 (Concatenate)   (None, 630)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 199)          125569      concatenate_902[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            800         idenDense[0][0]                  
==================================================================================================
Total params: 1,537,795
Trainable params: 1,537,795
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2217 - acc: 0.9466
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0600 - acc: 0.9840
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0315 - acc: 0.9919
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0209 - acc: 0.9950
MWE identification:
Epoch 1/1
 - 34s - loss: 12.0866 - acc: 0.2501
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0244 - acc: 0.9941
MWE identification:
Epoch 1/1
 - 34s - loss: 8.2780 - acc: 0.4864
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0572 - acc: 0.9868
MWE identification:
Epoch 1/1
 - 34s - loss: 8.1339 - acc: 0.4953
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0248 - acc: 0.9939
MWE identification:
Epoch 1/1
 - 34s - loss: 8.0911 - acc: 0.4980
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0146 - acc: 0.9965
POS tagging accuracy = 94.8
Loss = 0.29, 
POS tagging accuracy = 94.8
Loss = 0.29, 
	TRAINING TIME: 3.97 minutes 
==================================================================================================
	PARSING TIME: 1.93 minutes 
==================================================================================================
	Identification : 0.006
	P, R  : 0.004, 0.015

==================================================================================================
	XP Ends: 24/4 (9 h:18)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,161            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
5              ,1              ,36             ,1              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.015          ,5              ,14             ,42             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
70             ,False          ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 161, 5, 1, 36, 1, 14, 0.015, 5, 14, 42, True, 70, False, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (9h:18)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 70)        528150      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2615 (Flatten)          (None, 490)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2616 (Flatten)          (None, 60)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2617 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_903 (Concatenate)   (None, 553)          0           flatten_2615[0][0]               
                                                                 flatten_2616[0][0]               
                                                                 flatten_2617[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 42)           23268       concatenate_903[0][0]            
__________________________________________________________________________________________________
dense_142 (Dense)               (None, 152)          6536        posDense[0][0]                   
==================================================================================================
Total params: 563,888
Trainable params: 563,888
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.015
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 70)        528150      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 5)        5930        b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2618 (Flatten)          (None, 490)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2619 (Flatten)          (None, 60)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2620 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2621 (Flatten)          (None, 490)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2622 (Flatten)          (None, 60)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2623 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2624 (Flatten)          (None, 490)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2625 (Flatten)          (None, 60)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2626 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
concatenate_904 (Concatenate)   (None, 553)          0           flatten_2618[0][0]               
                                                                 flatten_2619[0][0]               
                                                                 flatten_2620[0][0]               
__________________________________________________________________________________________________
concatenate_905 (Concatenate)   (None, 553)          0           flatten_2621[0][0]               
                                                                 flatten_2622[0][0]               
                                                                 flatten_2623[0][0]               
__________________________________________________________________________________________________
concatenate_906 (Concatenate)   (None, 553)          0           flatten_2624[0][0]               
                                                                 flatten_2625[0][0]               
                                                                 flatten_2626[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 42)           23268       concatenate_904[0][0]            
                                                                 concatenate_905[0][0]            
                                                                 concatenate_906[0][0]            
__________________________________________________________________________________________________
concatenate_907 (Concatenate)   (None, 126)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 161)          20447       concatenate_907[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            648         idenDense[0][0]                  
==================================================================================================
Total params: 578,447
Trainable params: 578,447
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 8s - loss: 0.3231 - acc: 0.9257
POS tagging:
Epoch 1/1
 - 8s - loss: 0.1289 - acc: 0.9718
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0693 - acc: 0.9823
POS tagging:
Epoch 1/1
 - 8s - loss: 0.1132 - acc: 0.9734
MWE identification:
Epoch 1/1
 - 19s - loss: 0.0531 - acc: 0.9869
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0877 - acc: 0.9791
MWE identification:
Epoch 1/1
 - 19s - loss: 0.0496 - acc: 0.9880
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0739 - acc: 0.9823
MWE identification:
Epoch 1/1
 - 20s - loss: 0.0478 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0640 - acc: 0.9850
MWE identification:
Epoch 1/1
 - 19s - loss: 0.0468 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0565 - acc: 0.9867
MWE identification:
Epoch 1/1
 - 19s - loss: 0.0461 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0505 - acc: 0.9885
MWE identification:
Epoch 1/1
 - 19s - loss: 0.0457 - acc: 0.9892
POS tagging accuracy = 95.0
Loss = 0.209, 
POS tagging accuracy = 95.0
Loss = 0.209, 
	TRAINING TIME: 4.02 minutes 
==================================================================================================
	PARSING TIME: 0.75 minutes 
==================================================================================================
	Identification : 0.603
	P, R  : 0.781, 0.491

==================================================================================================
	XP Ends: 24/4 (9 h:23)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,143            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
19             ,8              ,17             ,1              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.027          ,6              ,15             ,197            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
59             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 143, 19, 8, 17, 1, 14, 0.027, 6, 15, 197, True, 59, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (9h:23)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.027
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 59)        674842      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 19)       22534       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2627 (Flatten)          (None, 413)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2628 (Flatten)          (None, 228)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2629 (Flatten)          (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2630 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_908 (Concatenate)   (None, 671)          0           flatten_2627[0][0]               
                                                                 flatten_2628[0][0]               
                                                                 flatten_2629[0][0]               
                                                                 flatten_2630[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 197)          132384      concatenate_908[0][0]            
__________________________________________________________________________________________________
dense_143 (Dense)               (None, 152)          30096       posDense[0][0]                   
==================================================================================================
Total params: 860,008
Trainable params: 860,008
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.027
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 59)        674842      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 19)       22534       bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2631 (Flatten)          (None, 413)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2632 (Flatten)          (None, 228)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2633 (Flatten)          (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2634 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2635 (Flatten)          (None, 413)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2636 (Flatten)          (None, 228)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2637 (Flatten)          (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2638 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2639 (Flatten)          (None, 413)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2640 (Flatten)          (None, 228)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2641 (Flatten)          (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2642 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2643 (Flatten)          (None, 413)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2644 (Flatten)          (None, 228)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2645 (Flatten)          (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2646 (Flatten)          (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_909 (Concatenate)   (None, 671)          0           flatten_2631[0][0]               
                                                                 flatten_2632[0][0]               
                                                                 flatten_2633[0][0]               
                                                                 flatten_2634[0][0]               
__________________________________________________________________________________________________
concatenate_910 (Concatenate)   (None, 671)          0           flatten_2635[0][0]               
                                                                 flatten_2636[0][0]               
                                                                 flatten_2637[0][0]               
                                                                 flatten_2638[0][0]               
__________________________________________________________________________________________________
concatenate_911 (Concatenate)   (None, 671)          0           flatten_2639[0][0]               
                                                                 flatten_2640[0][0]               
                                                                 flatten_2641[0][0]               
                                                                 flatten_2642[0][0]               
__________________________________________________________________________________________________
concatenate_912 (Concatenate)   (None, 671)          0           flatten_2643[0][0]               
                                                                 flatten_2644[0][0]               
                                                                 flatten_2645[0][0]               
                                                                 flatten_2646[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 197)          132384      concatenate_909[0][0]            
                                                                 concatenate_910[0][0]            
                                                                 concatenate_911[0][0]            
                                                                 concatenate_912[0][0]            
__________________________________________________________________________________________________
concatenate_913 (Concatenate)   (None, 788)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 143)          112827      concatenate_913[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            576         idenDense[0][0]                  
==================================================================================================
Total params: 943,315
Trainable params: 943,315
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 8s - loss: 0.2233 - acc: 0.9425
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0960 - acc: 0.9746
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0650 - acc: 0.9837
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0885 - acc: 0.9763
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0484 - acc: 0.9883
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0495 - acc: 0.9874
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0456 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0333 - acc: 0.9918
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0448 - acc: 0.9894
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0240 - acc: 0.9942
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0180 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 53s - loss: 0.0443 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 8s - loss: 0.0140 - acc: 0.9969
MWE identification:
Epoch 1/1
 - 54s - loss: 0.0443 - acc: 0.9895
POS tagging accuracy = 94.2
Loss = 0.253, 
POS tagging accuracy = 94.2
Loss = 0.253, 
	TRAINING TIME: 8.53 minutes 
==================================================================================================
	PARSING TIME: 1.08 minutes 
==================================================================================================
	Identification : 0.534
	P, R  : 0.48, 0.601

==================================================================================================
	XP Ends: 24/4 (9 h:33)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,34             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,4              ,12             ,1              ,9              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.042          ,8              ,98             ,35             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
143            ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 34, 6, 4, 12, 1, 9, 0.042, 8, 98, 35, True, 143, False, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (9h:33)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.042
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 143)       1078935     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2647 (Flatten)          (None, 1001)         0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2648 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2649 (Flatten)          (None, 8)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_914 (Concatenate)   (None, 1081)         0           flatten_2647[0][0]               
                                                                 flatten_2648[0][0]               
                                                                 flatten_2649[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           37870       concatenate_914[0][0]            
__________________________________________________________________________________________________
dense_144 (Dense)               (None, 152)          5472        posDense[0][0]                   
==================================================================================================
Total params: 1,129,553
Trainable params: 1,129,553
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.042
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 143)       1078935     bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 8)         160         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2650 (Flatten)          (None, 1001)         0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2651 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2652 (Flatten)          (None, 8)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2653 (Flatten)          (None, 1001)         0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2654 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2655 (Flatten)          (None, 8)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2656 (Flatten)          (None, 1001)         0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2657 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2658 (Flatten)          (None, 8)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2659 (Flatten)          (None, 1001)         0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2660 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2661 (Flatten)          (None, 8)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_915 (Concatenate)   (None, 1081)         0           flatten_2650[0][0]               
                                                                 flatten_2651[0][0]               
                                                                 flatten_2652[0][0]               
__________________________________________________________________________________________________
concatenate_916 (Concatenate)   (None, 1081)         0           flatten_2653[0][0]               
                                                                 flatten_2654[0][0]               
                                                                 flatten_2655[0][0]               
__________________________________________________________________________________________________
concatenate_917 (Concatenate)   (None, 1081)         0           flatten_2656[0][0]               
                                                                 flatten_2657[0][0]               
                                                                 flatten_2658[0][0]               
__________________________________________________________________________________________________
concatenate_918 (Concatenate)   (None, 1081)         0           flatten_2659[0][0]               
                                                                 flatten_2660[0][0]               
                                                                 flatten_2661[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 35)           37870       concatenate_915[0][0]            
                                                                 concatenate_916[0][0]            
                                                                 concatenate_917[0][0]            
                                                                 concatenate_918[0][0]            
__________________________________________________________________________________________________
concatenate_919 (Concatenate)   (None, 140)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 34)           4794        concatenate_919[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            140         idenDense[0][0]                  
==================================================================================================
Total params: 1,129,015
Trainable params: 1,129,015
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2256 - acc: 0.9456
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0658 - acc: 0.9825
MWE identification:
Epoch 1/1
 - 68s - loss: 0.0670 - acc: 0.9836
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0797 - acc: 0.9794
MWE identification:
Epoch 1/1
 - 68s - loss: 0.0497 - acc: 0.9879
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0418 - acc: 0.9901
MWE identification:
Epoch 1/1
 - 68s - loss: 0.0465 - acc: 0.9889
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0277 - acc: 0.9937
MWE identification:
Epoch 1/1
 - 67s - loss: 0.0453 - acc: 0.9893
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0205 - acc: 0.9955
POS tagging accuracy = 95.3
Loss = 0.23, 
POS tagging accuracy = 95.3
Loss = 0.23, 
	TRAINING TIME: 5.6 minutes 
==================================================================================================
	PARSING TIME: 0.9 minutes 
==================================================================================================
	Identification : 0.589
	P, R  : 0.767, 0.478

==================================================================================================
	XP Ends: 24/4 (9 h:40)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,183            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
12             ,8              ,28             ,2              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.023          ,5              ,39             ,188            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
108            ,True           ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, False, True, False, 1, 1, 183, 12, 8, 28, 2, 14, 0.023, 5, 39, 188, True, 108, True, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (9h:40)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 14798
	After : 11438

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 11438 * POS : 152
__________________________________________________________________________________________________
	Important words not in vocabulary 675
	MWE not in vocabulary 1297
	Dashed keys in vocabulary 2182
	One occurrence keys in vocabulary 2182 / 11438

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 108)       1235304     tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2662 (Flatten)          (None, 756)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2663 (Flatten)          (None, 144)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2664 (Flatten)          (None, 24)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2665 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_920 (Concatenate)   (None, 929)          0           flatten_2662[0][0]               
                                                                 flatten_2663[0][0]               
                                                                 flatten_2664[0][0]               
                                                                 flatten_2665[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 188)          174840      concatenate_920[0][0]            
__________________________________________________________________________________________________
dense_145 (Dense)               (None, 152)          28728       posDense[0][0]                   
==================================================================================================
Total params: 1,453,236
Trainable params: 1,453,236
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.023
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 108)       1235304     bxTokens[0][0]                   
                                                                 b1Tokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 12)       14232       bxAffixes[0][0]                  
                                                                 b1Affixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 8)         32          bxCapitalization[0][0]           
                                                                 b1Capitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b1Symbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2666 (Flatten)          (None, 756)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2667 (Flatten)          (None, 144)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2668 (Flatten)          (None, 24)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2669 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2670 (Flatten)          (None, 756)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2671 (Flatten)          (None, 144)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2672 (Flatten)          (None, 24)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2673 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2674 (Flatten)          (None, 756)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2675 (Flatten)          (None, 144)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2676 (Flatten)          (None, 24)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2677 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2678 (Flatten)          (None, 756)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2679 (Flatten)          (None, 144)          0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2680 (Flatten)          (None, 24)           0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2681 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
flatten_2682 (Flatten)          (None, 756)          0           tokenEmb[5][0]                   
__________________________________________________________________________________________________
flatten_2683 (Flatten)          (None, 144)          0           affixeseEmb[5][0]                
__________________________________________________________________________________________________
flatten_2684 (Flatten)          (None, 24)           0           capitalizationEmb[5][0]          
__________________________________________________________________________________________________
flatten_2685 (Flatten)          (None, 5)            0           symbolsEmb[5][0]                 
__________________________________________________________________________________________________
concatenate_921 (Concatenate)   (None, 929)          0           flatten_2666[0][0]               
                                                                 flatten_2667[0][0]               
                                                                 flatten_2668[0][0]               
                                                                 flatten_2669[0][0]               
__________________________________________________________________________________________________
concatenate_922 (Concatenate)   (None, 929)          0           flatten_2670[0][0]               
                                                                 flatten_2671[0][0]               
                                                                 flatten_2672[0][0]               
                                                                 flatten_2673[0][0]               
__________________________________________________________________________________________________
concatenate_923 (Concatenate)   (None, 929)          0           flatten_2674[0][0]               
                                                                 flatten_2675[0][0]               
                                                                 flatten_2676[0][0]               
                                                                 flatten_2677[0][0]               
__________________________________________________________________________________________________
concatenate_924 (Concatenate)   (None, 929)          0           flatten_2678[0][0]               
                                                                 flatten_2679[0][0]               
                                                                 flatten_2680[0][0]               
                                                                 flatten_2681[0][0]               
__________________________________________________________________________________________________
concatenate_925 (Concatenate)   (None, 929)          0           flatten_2682[0][0]               
                                                                 flatten_2683[0][0]               
                                                                 flatten_2684[0][0]               
                                                                 flatten_2685[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 188)          174840      concatenate_921[0][0]            
                                                                 concatenate_922[0][0]            
                                                                 concatenate_923[0][0]            
                                                                 concatenate_924[0][0]            
                                                                 concatenate_925[0][0]            
__________________________________________________________________________________________________
concatenate_926 (Concatenate)   (None, 940)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
                                                                 posDense[5][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 183)          172203      concatenate_926[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            736         idenDense[0][0]                  
==================================================================================================
Total params: 1,597,447
Trainable params: 1,597,447
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 4s - loss: 0.2286 - acc: 0.9413
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0929 - acc: 0.9754
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0559 - acc: 0.9852
MWE identification:
Epoch 1/1
 - 40s - loss: 0.1166 - acc: 0.9805
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0699 - acc: 0.9821
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0490 - acc: 0.9884
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0383 - acc: 0.9910
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0458 - acc: 0.9892
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0251 - acc: 0.9943
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0448 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0183 - acc: 0.9960
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0445 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0139 - acc: 0.9971
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0444 - acc: 0.9895
POS tagging:
Epoch 1/1
 - 4s - loss: 0.0111 - acc: 0.9977
MWE identification:
Epoch 1/1
 - 40s - loss: 0.0443 - acc: 0.9895
POS tagging accuracy = 94.1
Loss = 0.256, 
POS tagging accuracy = 94.1
Loss = 0.256, 
	TRAINING TIME: 6.57 minutes 
==================================================================================================
	PARSING TIME: 1.3 minutes 
==================================================================================================
	Identification : 0.541
	P, R  : 0.527, 0.555

==================================================================================================
	XP Ends: 24/4 (9 h:48)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,88             ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,3              ,43             ,3              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.016          ,5              ,49             ,38             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
28             ,False          ,True           ,False          ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 88, 6, 3, 43, 3, 8, 0.016, 5, 49, 38, True, 28, False, True, False, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (9h:48)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2686 (Flatten)          (None, 196)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2687 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2688 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_927 (Concatenate)   (None, 273)          0           flatten_2686[0][0]               
                                                                 flatten_2687[0][0]               
                                                                 flatten_2688[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 38)           10412       concatenate_927[0][0]            
__________________________________________________________________________________________________
dense_146 (Dense)               (None, 152)          5928        posDense[0][0]                   
==================================================================================================
Total params: 234,816
Trainable params: 234,816
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.016
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 28)        211260      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2689 (Flatten)          (None, 196)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2690 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2691 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2692 (Flatten)          (None, 196)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2693 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2694 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2695 (Flatten)          (None, 196)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2696 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2697 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2698 (Flatten)          (None, 196)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2699 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2700 (Flatten)          (None, 5)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_928 (Concatenate)   (None, 273)          0           flatten_2689[0][0]               
                                                                 flatten_2690[0][0]               
                                                                 flatten_2691[0][0]               
__________________________________________________________________________________________________
concatenate_929 (Concatenate)   (None, 273)          0           flatten_2692[0][0]               
                                                                 flatten_2693[0][0]               
                                                                 flatten_2694[0][0]               
__________________________________________________________________________________________________
concatenate_930 (Concatenate)   (None, 273)          0           flatten_2695[0][0]               
                                                                 flatten_2696[0][0]               
                                                                 flatten_2697[0][0]               
__________________________________________________________________________________________________
concatenate_931 (Concatenate)   (None, 273)          0           flatten_2698[0][0]               
                                                                 flatten_2699[0][0]               
                                                                 flatten_2700[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 38)           10412       concatenate_928[0][0]            
                                                                 concatenate_929[0][0]            
                                                                 concatenate_930[0][0]            
                                                                 concatenate_931[0][0]            
__________________________________________________________________________________________________
concatenate_932 (Concatenate)   (None, 152)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 88)           13464       concatenate_932[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            356         idenDense[0][0]                  
==================================================================================================
Total params: 242,708
Trainable params: 242,708
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.4352 - acc: 0.8957
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1597 - acc: 0.9649
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1203 - acc: 0.9730
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1000 - acc: 0.9761
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0768 - acc: 0.9806
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1074 - acc: 0.9745
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0561 - acc: 0.9861
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0891 - acc: 0.9780
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0523 - acc: 0.9872
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0785 - acc: 0.9803
MWE identification:
Epoch 1/1
 - 18s - loss: 0.0503 - acc: 0.9878
POS tagging accuracy = 95.3
Loss = 0.195, 
POS tagging accuracy = 95.3
Loss = 0.195, 
	TRAINING TIME: 2.4 minutes 
==================================================================================================
	PARSING TIME: 0.88 minutes 
==================================================================================================
	Identification : 0.597
	P, R  : 0.76, 0.491

==================================================================================================
	XP Ends: 24/4 (9 h:51)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,135            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
6              ,1              ,12             ,3              ,16             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.182          ,6              ,10             ,163            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
47             ,False          ,True           ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 135, 6, 1, 12, 3, 16, 0.182, 6, 10, 163, True, 47, False, True, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (9h:51)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.182
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 47)        354615      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2701 (Flatten)          (None, 329)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2702 (Flatten)          (None, 72)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2703 (Flatten)          (None, 3)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2704 (Flatten)          (None, 6)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_933 (Concatenate)   (None, 410)          0           flatten_2701[0][0]               
                                                                 flatten_2702[0][0]               
                                                                 flatten_2703[0][0]               
                                                                 flatten_2704[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 163)          66993       concatenate_933[0][0]            
__________________________________________________________________________________________________
dense_147 (Dense)               (None, 152)          24928       posDense[0][0]                   
==================================================================================================
Total params: 453,776
Trainable params: 453,776
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.182
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
bxSymbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 47)        354615      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 6)        7116        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 1)         4           bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 6)         120         bxSymbols[0][0]                  
                                                                 b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2705 (Flatten)          (None, 329)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2706 (Flatten)          (None, 72)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2707 (Flatten)          (None, 3)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2708 (Flatten)          (None, 6)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2709 (Flatten)          (None, 329)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2710 (Flatten)          (None, 72)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2711 (Flatten)          (None, 3)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2712 (Flatten)          (None, 6)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2713 (Flatten)          (None, 329)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2714 (Flatten)          (None, 72)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2715 (Flatten)          (None, 3)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2716 (Flatten)          (None, 6)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
flatten_2717 (Flatten)          (None, 329)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2718 (Flatten)          (None, 72)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2719 (Flatten)          (None, 3)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
flatten_2720 (Flatten)          (None, 6)            0           symbolsEmb[4][0]                 
__________________________________________________________________________________________________
concatenate_934 (Concatenate)   (None, 410)          0           flatten_2705[0][0]               
                                                                 flatten_2706[0][0]               
                                                                 flatten_2707[0][0]               
                                                                 flatten_2708[0][0]               
__________________________________________________________________________________________________
concatenate_935 (Concatenate)   (None, 410)          0           flatten_2709[0][0]               
                                                                 flatten_2710[0][0]               
                                                                 flatten_2711[0][0]               
                                                                 flatten_2712[0][0]               
__________________________________________________________________________________________________
concatenate_936 (Concatenate)   (None, 410)          0           flatten_2713[0][0]               
                                                                 flatten_2714[0][0]               
                                                                 flatten_2715[0][0]               
                                                                 flatten_2716[0][0]               
__________________________________________________________________________________________________
concatenate_937 (Concatenate)   (None, 410)          0           flatten_2717[0][0]               
                                                                 flatten_2718[0][0]               
                                                                 flatten_2719[0][0]               
                                                                 flatten_2720[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 163)          66993       concatenate_934[0][0]            
                                                                 concatenate_935[0][0]            
                                                                 concatenate_936[0][0]            
                                                                 concatenate_937[0][0]            
__________________________________________________________________________________________________
concatenate_938 (Concatenate)   (None, 652)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 135)          88155       concatenate_938[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            544         idenDense[0][0]                  
==================================================================================================
Total params: 517,547
Trainable params: 517,547
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 11s - loss: 0.3376 - acc: 0.9212
POS tagging:
Epoch 1/1
 - 11s - loss: 0.1239 - acc: 0.9713
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0854 - acc: 0.9792
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0699 - acc: 0.9830
MWE identification:
Epoch 1/1
 - 74s - loss: 12.0884 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0781 - acc: 0.9806
MWE identification:
Epoch 1/1
 - 74s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0586 - acc: 0.9861
MWE identification:
Epoch 1/1
 - 74s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0522 - acc: 0.9880
MWE identification:
Epoch 1/1
 - 74s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0491 - acc: 0.9887
MWE identification:
Epoch 1/1
 - 74s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0463 - acc: 0.9894
MWE identification:
Epoch 1/1
 - 75s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 12s - loss: 0.0445 - acc: 0.9899
MWE identification:
Epoch 1/1
 - 77s - loss: 12.0886 - acc: 0.2500
POS tagging:
Epoch 1/1
 - 11s - loss: 0.0434 - acc: 0.9902
MWE identification:
Epoch 1/1
 - 76s - loss: 12.0886 - acc: 0.2500
POS tagging accuracy = 94.3
Loss = 0.288, 
POS tagging accuracy = 94.3
Loss = 0.288, 
	TRAINING TIME: 13.23 minutes 
==================================================================================================
	PARSING TIME: 1.97 minutes 
==================================================================================================
	Identification : 0
	P, R  : 0.0, 0.0

==================================================================================================
	XP Ends: 24/4 (10 h:7)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,109            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
11             ,3              ,24             ,2              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.032          ,8              ,117            ,129            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
124            ,False          ,False          ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 109, 11, 3, 24, 2, 8, 0.032, 8, 117, 129, True, 124, False, False, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (10h:7)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 124)       935580      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2721 (Flatten)          (None, 868)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2722 (Flatten)          (None, 132)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2723 (Flatten)          (None, 9)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_939 (Concatenate)   (None, 1009)         0           flatten_2721[0][0]               
                                                                 flatten_2722[0][0]               
                                                                 flatten_2723[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 129)          130290      concatenate_939[0][0]            
__________________________________________________________________________________________________
dense_148 (Dense)               (None, 152)          19760       posDense[0][0]                   
==================================================================================================
Total params: 1,098,688
Trainable params: 1,098,688
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.032
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 124)       935580      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 11)       13046       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 3)         12          b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2724 (Flatten)          (None, 868)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2725 (Flatten)          (None, 132)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2726 (Flatten)          (None, 9)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2727 (Flatten)          (None, 868)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2728 (Flatten)          (None, 132)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2729 (Flatten)          (None, 9)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2730 (Flatten)          (None, 868)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2731 (Flatten)          (None, 132)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2732 (Flatten)          (None, 9)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
concatenate_940 (Concatenate)   (None, 1009)         0           flatten_2724[0][0]               
                                                                 flatten_2725[0][0]               
                                                                 flatten_2726[0][0]               
__________________________________________________________________________________________________
concatenate_941 (Concatenate)   (None, 1009)         0           flatten_2727[0][0]               
                                                                 flatten_2728[0][0]               
                                                                 flatten_2729[0][0]               
__________________________________________________________________________________________________
concatenate_942 (Concatenate)   (None, 1009)         0           flatten_2730[0][0]               
                                                                 flatten_2731[0][0]               
                                                                 flatten_2732[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 129)          130290      concatenate_940[0][0]            
                                                                 concatenate_941[0][0]            
                                                                 concatenate_942[0][0]            
__________________________________________________________________________________________________
concatenate_943 (Concatenate)   (None, 387)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 109)          42292       concatenate_943[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            440         idenDense[0][0]                  
==================================================================================================
Total params: 1,121,660
Trainable params: 1,121,660
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 1s - loss: 0.2104 - acc: 0.9483
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0570 - acc: 0.9848
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0301 - acc: 0.9919
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0645 - acc: 0.9839
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0500 - acc: 0.9864
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0487 - acc: 0.9882
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0221 - acc: 0.9949
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0459 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 1s - loss: 0.0135 - acc: 0.9971
MWE identification:
Epoch 1/1
 - 29s - loss: 0.0449 - acc: 0.9894
POS tagging accuracy = 94.9
Loss = 0.224, 
POS tagging accuracy = 94.9
Loss = 0.224, 
	TRAINING TIME: 2.9 minutes 
==================================================================================================
	PARSING TIME: 0.72 minutes 
==================================================================================================
	Identification : 0.588
	P, R  : 0.727, 0.494

==================================================================================================
	XP Ends: 24/4 (10 h:11)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,145            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
7              ,2              ,95             ,2              ,8              ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.03           ,12             ,42             ,147            ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
94             ,False          ,True           ,True           ,False          ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 145, 7, 2, 95, 2, 8, 0.03, 12, 42, 147, True, 94, False, True, True, False, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (10h:11)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 94)        709230      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           capitalization[0][0]             
__________________________________________________________________________________________________
flatten_2733 (Flatten)          (None, 658)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2734 (Flatten)          (None, 84)           0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2735 (Flatten)          (None, 6)            0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
concatenate_944 (Concatenate)   (None, 748)          0           flatten_2733[0][0]               
                                                                 flatten_2734[0][0]               
                                                                 flatten_2735[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 147)          110103      concatenate_944[0][0]            
__________________________________________________________________________________________________
dense_149 (Dense)               (None, 152)          22496       posDense[0][0]                   
==================================================================================================
Total params: 850,139
Trainable params: 850,139
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.03
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
bxTokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
bxAffixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
bxCapitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 94)        709230      bxTokens[0][0]                   
                                                                 b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 7)        8302        bxAffixes[0][0]                  
                                                                 b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 2)         8           bxCapitalization[0][0]           
                                                                 b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
flatten_2736 (Flatten)          (None, 658)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2737 (Flatten)          (None, 84)           0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2738 (Flatten)          (None, 6)            0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2739 (Flatten)          (None, 658)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2740 (Flatten)          (None, 84)           0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2741 (Flatten)          (None, 6)            0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2742 (Flatten)          (None, 658)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2743 (Flatten)          (None, 84)           0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2744 (Flatten)          (None, 6)            0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2745 (Flatten)          (None, 658)          0           tokenEmb[4][0]                   
__________________________________________________________________________________________________
flatten_2746 (Flatten)          (None, 84)           0           affixeseEmb[4][0]                
__________________________________________________________________________________________________
flatten_2747 (Flatten)          (None, 6)            0           capitalizationEmb[4][0]          
__________________________________________________________________________________________________
concatenate_945 (Concatenate)   (None, 748)          0           flatten_2736[0][0]               
                                                                 flatten_2737[0][0]               
                                                                 flatten_2738[0][0]               
__________________________________________________________________________________________________
concatenate_946 (Concatenate)   (None, 748)          0           flatten_2739[0][0]               
                                                                 flatten_2740[0][0]               
                                                                 flatten_2741[0][0]               
__________________________________________________________________________________________________
concatenate_947 (Concatenate)   (None, 748)          0           flatten_2742[0][0]               
                                                                 flatten_2743[0][0]               
                                                                 flatten_2744[0][0]               
__________________________________________________________________________________________________
concatenate_948 (Concatenate)   (None, 748)          0           flatten_2745[0][0]               
                                                                 flatten_2746[0][0]               
                                                                 flatten_2747[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 147)          110103      concatenate_945[0][0]            
                                                                 concatenate_946[0][0]            
                                                                 concatenate_947[0][0]            
                                                                 concatenate_948[0][0]            
__________________________________________________________________________________________________
concatenate_949 (Concatenate)   (None, 588)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
                                                                 posDense[4][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 145)          85405       concatenate_949[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            584         idenDense[0][0]                  
==================================================================================================
Total params: 913,632
Trainable params: 913,632
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 3s - loss: 0.2004 - acc: 0.9508
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0625 - acc: 0.9830
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0350 - acc: 0.9907
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0726 - acc: 0.9832
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0515 - acc: 0.9866
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0493 - acc: 0.9880
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0246 - acc: 0.9944
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0462 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 3s - loss: 0.0153 - acc: 0.9967
MWE identification:
Epoch 1/1
 - 9s - loss: 0.0450 - acc: 0.9893
POS tagging accuracy = 94.7
Loss = 0.236, 
POS tagging accuracy = 94.7
Loss = 0.236, 
	TRAINING TIME: 1.83 minutes 
==================================================================================================
	PARSING TIME: 0.88 minutes 
==================================================================================================
	Identification : 0.609
	P, R  : 0.727, 0.524

==================================================================================================
	XP Ends: 24/4 (10 h:14)
==================================================================================================
	Mode: MULTITASKING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: FIXEDSIZE
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, IdenDenseUnitNumber, affixeDim, capitalDim, identBatchSize, initialEpochs, jointLearningEpochs, lr, symbolDim, taggingBatchSize, taggingDenseUnits, testOnToken, tokenDim, useB1, useBx, useCapitalization, useSymbols, windowSize
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
multitasking   ,sharedtask2    ,fixedSize      ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
True           ,False          ,35             ,True           ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,IdenDenseUnitNu,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,165            ,
__________________________________________________________________________________________________
affixeDim      ,capitalDim     ,identBatchSize ,initialEpochs  ,jointLearningEp,
__________________________________________________________________________________________________
18             ,4              ,32             ,3              ,14             ,
__________________________________________________________________________________________________
lr             ,symbolDim      ,taggingBatchSiz,taggingDenseUni,testOnToken    ,
__________________________________________________________________________________________________
0.012          ,5              ,53             ,94             ,True           ,
__________________________________________________________________________________________________
tokenDim       ,useB1          ,useBx          ,useCapitalizati,useSymbols     ,
__________________________________________________________________________________________________
62             ,False          ,False          ,True           ,True           ,
__________________________________________________________________________________________________
windowSize     ,
__________________________________________________________________________________________________
3              ,
__________________________________________________________________________________________________
# Configs: multitasking, sharedtask2, fixedSize, 1, False, True, False, 35, True, False, True, False, False, False, True, True, False, 1, 1, 165, 18, 4, 32, 3, 14, 0.012, 5, 53, 94, True, 62, False, False, True, True, 3
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 24/4 (10h:14)
==================================================================================================

==================================================================================================
	BG Train (3124)
==================================================================================================
	Important sentence: 3124
	Token occurrences: 89121
	MWE number: 1372
	MWE occurrences: 3583
	Continuous occurrences: 81.0 %
	Frequent MWE occurences: 49.0 %
	MWE length: 2.12
	Recognizable MWEs: 100.0 %
	MWT occurrences: 8

==================================================================================================
	 Test (1954)
==================================================================================================
	Important sentence: 574
	Token occurrences: 42020
	MWE number: 451
	MWE occurrences: 670
	Continuous occurrences: 75.0 %
	MWE length: 2.14
	Seen occurrences : 57% 
	Recognizable MWEs: 100.0 %
	MWT occurrences: 1

==================================================================================================
	Non frequent word cleaning:
==================================================================================================
	Before : 9312
	After : 7545

__________________________________________________________________________________________________
	Vocabulary
==================================================================================================
	Tokens := 7545 * POS : 152
__________________________________________________________________________________________________
	Dashed keys in vocabulary 1622
	One occurrence keys in vocabulary 1622 / 7545

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
tokens (InputLayer)             (None, 7)            0                                            
__________________________________________________________________________________________________
affixes (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
capitalization (InputLayer)     (None, 3)            0                                            
__________________________________________________________________________________________________
symbol (InputLayer)             (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 62)        467790      tokens[0][0]                     
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       affixes[0][0]                    
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          capitalization[0][0]             
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         symbol[0][0]                     
__________________________________________________________________________________________________
flatten_2748 (Flatten)          (None, 434)          0           tokenEmb[0][0]                   
__________________________________________________________________________________________________
flatten_2749 (Flatten)          (None, 216)          0           affixeseEmb[0][0]                
__________________________________________________________________________________________________
flatten_2750 (Flatten)          (None, 12)           0           capitalizationEmb[0][0]          
__________________________________________________________________________________________________
flatten_2751 (Flatten)          (None, 5)            0           symbolsEmb[0][0]                 
__________________________________________________________________________________________________
concatenate_950 (Concatenate)   (None, 667)          0           flatten_2748[0][0]               
                                                                 flatten_2749[0][0]               
                                                                 flatten_2750[0][0]               
                                                                 flatten_2751[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 94)           62792       concatenate_950[0][0]            
__________________________________________________________________________________________________
dense_150 (Dense)               (None, 152)          14440       posDense[0][0]                   
==================================================================================================
Total params: 566,486
Trainable params: 566,486
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.012
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
b0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
b0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
b0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
b0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s0Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s0Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s0Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s0Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
s1Tokens (InputLayer)           (None, 7)            0                                            
__________________________________________________________________________________________________
s1Affixes (InputLayer)          (None, 12)           0                                            
__________________________________________________________________________________________________
s1Capitalization (InputLayer)   (None, 3)            0                                            
__________________________________________________________________________________________________
s1Symbols (InputLayer)          (None, 1)            0                                            
__________________________________________________________________________________________________
tokenEmb (Embedding)            (None, 7, 62)        467790      b0Tokens[0][0]                   
                                                                 s0Tokens[0][0]                   
                                                                 s1Tokens[0][0]                   
__________________________________________________________________________________________________
affixeseEmb (Embedding)         (None, 12, 18)       21348       b0Affixes[0][0]                  
                                                                 s0Affixes[0][0]                  
                                                                 s1Affixes[0][0]                  
__________________________________________________________________________________________________
capitalizationEmb (Embedding)   (None, 3, 4)         16          b0Capitalization[0][0]           
                                                                 s0Capitalization[0][0]           
                                                                 s1Capitalization[0][0]           
__________________________________________________________________________________________________
symbolsEmb (Embedding)          (None, 1, 5)         100         b0Symbols[0][0]                  
                                                                 s0Symbols[0][0]                  
                                                                 s1Symbols[0][0]                  
__________________________________________________________________________________________________
flatten_2752 (Flatten)          (None, 434)          0           tokenEmb[1][0]                   
__________________________________________________________________________________________________
flatten_2753 (Flatten)          (None, 216)          0           affixeseEmb[1][0]                
__________________________________________________________________________________________________
flatten_2754 (Flatten)          (None, 12)           0           capitalizationEmb[1][0]          
__________________________________________________________________________________________________
flatten_2755 (Flatten)          (None, 5)            0           symbolsEmb[1][0]                 
__________________________________________________________________________________________________
flatten_2756 (Flatten)          (None, 434)          0           tokenEmb[2][0]                   
__________________________________________________________________________________________________
flatten_2757 (Flatten)          (None, 216)          0           affixeseEmb[2][0]                
__________________________________________________________________________________________________
flatten_2758 (Flatten)          (None, 12)           0           capitalizationEmb[2][0]          
__________________________________________________________________________________________________
flatten_2759 (Flatten)          (None, 5)            0           symbolsEmb[2][0]                 
__________________________________________________________________________________________________
flatten_2760 (Flatten)          (None, 434)          0           tokenEmb[3][0]                   
__________________________________________________________________________________________________
flatten_2761 (Flatten)          (None, 216)          0           affixeseEmb[3][0]                
__________________________________________________________________________________________________
flatten_2762 (Flatten)          (None, 12)           0           capitalizationEmb[3][0]          
__________________________________________________________________________________________________
flatten_2763 (Flatten)          (None, 5)            0           symbolsEmb[3][0]                 
__________________________________________________________________________________________________
concatenate_951 (Concatenate)   (None, 667)          0           flatten_2752[0][0]               
                                                                 flatten_2753[0][0]               
                                                                 flatten_2754[0][0]               
                                                                 flatten_2755[0][0]               
__________________________________________________________________________________________________
concatenate_952 (Concatenate)   (None, 667)          0           flatten_2756[0][0]               
                                                                 flatten_2757[0][0]               
                                                                 flatten_2758[0][0]               
                                                                 flatten_2759[0][0]               
__________________________________________________________________________________________________
concatenate_953 (Concatenate)   (None, 667)          0           flatten_2760[0][0]               
                                                                 flatten_2761[0][0]               
                                                                 flatten_2762[0][0]               
                                                                 flatten_2763[0][0]               
__________________________________________________________________________________________________
posDense (Dense)                (None, 94)           62792       concatenate_951[0][0]            
                                                                 concatenate_952[0][0]            
                                                                 concatenate_953[0][0]            
__________________________________________________________________________________________________
concatenate_954 (Concatenate)   (None, 282)          0           posDense[1][0]                   
                                                                 posDense[2][0]                   
                                                                 posDense[3][0]                   
__________________________________________________________________________________________________
idenDense (Dense)               (None, 165)          46695       concatenate_954[0][0]            
__________________________________________________________________________________________________
idenSoftMax (Dense)             (None, 4)            664         idenDense[0][0]                  
==================================================================================================
Total params: 599,405
Trainable params: 599,405
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Identication data = 356484
POS Tagging data = 92704
POS tagging:
Epoch 1/1
 - 2s - loss: 0.3061 - acc: 0.9284
POS tagging:
Epoch 1/1
 - 2s - loss: 0.1223 - acc: 0.9713
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0911 - acc: 0.9777
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0734 - acc: 0.9818
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0686 - acc: 0.9827
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0818 - acc: 0.9797
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0524 - acc: 0.9871
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0647 - acc: 0.9842
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0492 - acc: 0.9881
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0545 - acc: 0.9869
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0476 - acc: 0.9886
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0472 - acc: 0.9891
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0465 - acc: 0.9890
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0415 - acc: 0.9906
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0459 - acc: 0.9891
POS tagging:
Epoch 1/1
 - 2s - loss: 0.0370 - acc: 0.9917
MWE identification:
Epoch 1/1
 - 24s - loss: 0.0454 - acc: 0.9893
POS tagging accuracy = 95.0
Loss = 0.193, 
POS tagging accuracy = 95.0
Loss = 0.193, 
	TRAINING TIME: 4.12 minutes 
==================================================================================================
	PARSING TIME: 0.85 minutes 
==================================================================================================
	Identification : 0.588
	P, R  : 0.727, 0.494

==================================================================================================
	XP Ends: 24/4 (10 h:19)
==================================================================================================
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
WARNING (theano.gof.cmodule): The same cache key is associated to different modules (/home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpyduhOc and /home/halsaied/.theano/compiledir_Linux-4.9--amd64-x86_64-with-debian-9.8--2.7.14-64/tmpnFgx6M). This is not supposed to happen! You may need to manually delete your cache directory to fix this.
