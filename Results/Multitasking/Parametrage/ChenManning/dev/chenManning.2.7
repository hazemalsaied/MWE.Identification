Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:
/tmp/try_flags_hE_wLC.c:4:10: fatal error: cudnn.h: No such file or directory
 #include <cudnn.h>
          ^~~~~~~~~
compilation terminated.

Preallocating 10869/11441 Mb (0.950000) on cuda
Mapped name None to device cuda: Tesla K40m (0000:03:00.0)
/home/halsaied/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using Theano backend.
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,96             ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
False          ,relu           ,0.6            ,169            ,False          ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,1e-05          ,0.011          ,0.083          ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,9              ,True           ,True           ,10             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
300            ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, False, True, False, 1, 1, 96, False, relu, 0.6, 169, False, 20, 1e-05, 0.011, 0.083, val_loss, 4, 9, True, True, 10, 300, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (15h:15)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 18)           0                                            
__________________________________________________________________________________________________
input_2 (InputLayer)            (None, 18)           0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 18, 25)       1055500     input_1[0][0]                    
__________________________________________________________________________________________________
embedding_2 (Embedding)         (None, 18, 25)       500         input_2[0][0]                    
__________________________________________________________________________________________________
embedding_3 (Embedding)         (None, 12, 8)        408         input_3[0][0]                    
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 450)          0           embedding_1[0][0]                
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 450)          0           embedding_2[0][0]                
__________________________________________________________________________________________________
flatten_3 (Flatten)             (None, 96)           0           embedding_3[0][0]                
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 996)          0           flatten_1[0][0]                  
                                                                 flatten_2[0][0]                  
                                                                 flatten_3[0][0]                  
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 74)           73778       concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 74)           0           dense_1[0][0]                    
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 74)           0           activation_2[0][0]               
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 86)           6450        dropout_1[0][0]                  
==================================================================================================
Total params: 1,136,636
Trainable params: 1,136,636
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 99s - loss: 0.7751 - acc: 0.7987 - val_loss: 0.4951 - val_acc: 0.8673
Epoch 2/20
 - 99s - loss: 0.6106 - acc: 0.8333 - val_loss: 0.4559 - val_acc: 0.8738
Epoch 3/20
 - 99s - loss: 0.5573 - acc: 0.8466 - val_loss: 0.4423 - val_acc: 0.8777
Epoch 4/20
 - 99s - loss: 0.5253 - acc: 0.8551 - val_loss: 0.4292 - val_acc: 0.8816
Epoch 5/20
 - 99s - loss: 0.4989 - acc: 0.8629 - val_loss: 0.4358 - val_acc: 0.8807
Epoch 6/20
 - 99s - loss: 0.4798 - acc: 0.8679 - val_loss: 0.4252 - val_acc: 0.8842
Epoch 7/20
 - 99s - loss: 0.4624 - acc: 0.8725 - val_loss: 0.4230 - val_acc: 0.8846
Epoch 8/20
 - 99s - loss: 0.4484 - acc: 0.8772 - val_loss: 0.4231 - val_acc: 0.8849
Epoch 9/20
 - 99s - loss: 0.4352 - acc: 0.8810 - val_loss: 0.4248 - val_acc: 0.8860
Epoch 10/20
 - 99s - loss: 0.4238 - acc: 0.8847 - val_loss: 0.4252 - val_acc: 0.8863
Epoch 11/20
 - 99s - loss: 0.4148 - acc: 0.8874 - val_loss: 0.4340 - val_acc: 0.8849
Epoch 00011: early stopping
LAS = 71.3
UAS = 81.9
	XP Ends: 12/7 (15 h:43)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,48             ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
True           ,relu           ,0.5            ,61             ,False          ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,0.01           ,0.163          ,0.002          ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,27             ,False          ,True           ,14             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
30             ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, False, True, False, 1, 1, 48, True, relu, 0.5, 61, False, 20, 0.01, 0.163, 0.002, val_loss, 4, 27, False, True, 14, 30, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (15h:43)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_4 (InputLayer)            (None, 18)           0                                            
__________________________________________________________________________________________________
input_5 (InputLayer)            (None, 18)           0                                            
__________________________________________________________________________________________________
input_6 (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_4 (Embedding)         (None, 18, 25)       1055500     input_4[0][0]                    
__________________________________________________________________________________________________
embedding_5 (Embedding)         (None, 18, 25)       500         input_5[0][0]                    
__________________________________________________________________________________________________
embedding_6 (Embedding)         (None, 12, 8)        408         input_6[0][0]                    
__________________________________________________________________________________________________
flatten_4 (Flatten)             (None, 450)          0           embedding_4[0][0]                
__________________________________________________________________________________________________
flatten_5 (Flatten)             (None, 450)          0           embedding_5[0][0]                
__________________________________________________________________________________________________
flatten_6 (Flatten)             (None, 96)           0           embedding_6[0][0]                
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 996)          0           flatten_4[0][0]                  
                                                                 flatten_5[0][0]                  
                                                                 flatten_6[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 74)           73778       concatenate_2[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 74)           0           dense_3[0][0]                    
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 74)           0           activation_4[0][0]               
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 86)           6450        dropout_2[0][0]                  
==================================================================================================
Total params: 1,136,636
Trainable params: 1,136,636
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 99s - loss: 0.7764 - acc: 0.7986 - val_loss: 0.4929 - val_acc: 0.8678
Epoch 2/20
 - 98s - loss: 0.6112 - acc: 0.8335 - val_loss: 0.4569 - val_acc: 0.8745
Epoch 3/20
 - 99s - loss: 0.5582 - acc: 0.8463 - val_loss: 0.4414 - val_acc: 0.8778
Epoch 4/20
 - 99s - loss: 0.5264 - acc: 0.8549 - val_loss: 0.4316 - val_acc: 0.8795
Epoch 5/20
 - 99s - loss: 0.5011 - acc: 0.8628 - val_loss: 0.4335 - val_acc: 0.8798
Epoch 6/20
 - 99s - loss: 0.4808 - acc: 0.8678 - val_loss: 0.4251 - val_acc: 0.8846
Epoch 7/20
 - 99s - loss: 0.4634 - acc: 0.8727 - val_loss: 0.4242 - val_acc: 0.8846
Epoch 8/20
 - 99s - loss: 0.4491 - acc: 0.8772 - val_loss: 0.4250 - val_acc: 0.8848
Epoch 9/20
 - 99s - loss: 0.4369 - acc: 0.8808 - val_loss: 0.4222 - val_acc: 0.8868
Epoch 10/20
 - 99s - loss: 0.4249 - acc: 0.8847 - val_loss: 0.4232 - val_acc: 0.8864
Epoch 11/20
 - 99s - loss: 0.4164 - acc: 0.8872 - val_loss: 0.4351 - val_acc: 0.8853
Epoch 12/20
 - 99s - loss: 0.4063 - acc: 0.8904 - val_loss: 0.4275 - val_acc: 0.8862
Epoch 13/20
 - 99s - loss: 0.3991 - acc: 0.8926 - val_loss: 0.4326 - val_acc: 0.8856
Epoch 00013: early stopping
LAS = 71.3
UAS = 81.7
	XP Ends: 12/7 (16 h:13)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,128            ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
True           ,relu           ,0.6            ,169            ,True           ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,0.1            ,0.041          ,0.003          ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,29             ,False          ,False          ,8              ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
27             ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, False, True, False, 1, 1, 128, True, relu, 0.6, 169, True, 20, 0.1, 0.041, 0.003, val_loss, 4, 29, False, False, 8, 27, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (16h:13)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_7 (InputLayer)            (None, 18)           0                                            
__________________________________________________________________________________________________
input_8 (InputLayer)            (None, 18)           0                                            
__________________________________________________________________________________________________
input_9 (InputLayer)            (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_7 (Embedding)         (None, 18, 25)       1055500     input_7[0][0]                    
__________________________________________________________________________________________________
embedding_8 (Embedding)         (None, 18, 25)       500         input_8[0][0]                    
__________________________________________________________________________________________________
embedding_9 (Embedding)         (None, 12, 8)        408         input_9[0][0]                    
__________________________________________________________________________________________________
flatten_7 (Flatten)             (None, 450)          0           embedding_7[0][0]                
__________________________________________________________________________________________________
flatten_8 (Flatten)             (None, 450)          0           embedding_8[0][0]                
__________________________________________________________________________________________________
flatten_9 (Flatten)             (None, 96)           0           embedding_9[0][0]                
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 996)          0           flatten_7[0][0]                  
                                                                 flatten_8[0][0]                  
                                                                 flatten_9[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 74)           73778       concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 74)           0           dense_5[0][0]                    
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 74)           0           activation_6[0][0]               
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 86)           6450        dropout_3[0][0]                  
==================================================================================================
Total params: 1,136,636
Trainable params: 1,136,636
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 101s - loss: 0.7758 - acc: 0.7985 - val_loss: 0.4951 - val_acc: 0.8675
Epoch 2/20
 - 100s - loss: 0.6122 - acc: 0.8328 - val_loss: 0.4569 - val_acc: 0.8735
Epoch 3/20
 - 99s - loss: 0.5588 - acc: 0.8459 - val_loss: 0.4427 - val_acc: 0.8777
Epoch 4/20
 - 99s - loss: 0.5277 - acc: 0.8549 - val_loss: 0.4306 - val_acc: 0.8818
Epoch 5/20
 - 99s - loss: 0.5020 - acc: 0.8619 - val_loss: 0.4345 - val_acc: 0.8808
Epoch 6/20
 - 100s - loss: 0.4820 - acc: 0.8675 - val_loss: 0.4261 - val_acc: 0.8853
Epoch 7/20
 - 99s - loss: 0.4643 - acc: 0.8730 - val_loss: 0.4234 - val_acc: 0.8856
Epoch 8/20
 - 99s - loss: 0.4499 - acc: 0.8773 - val_loss: 0.4246 - val_acc: 0.8853
Epoch 9/20
 - 99s - loss: 0.4377 - acc: 0.8806 - val_loss: 0.4253 - val_acc: 0.8860
Epoch 10/20
 - 99s - loss: 0.4261 - acc: 0.8844 - val_loss: 0.4239 - val_acc: 0.8871
Epoch 11/20
 - 99s - loss: 0.4170 - acc: 0.8865 - val_loss: 0.4329 - val_acc: 0.8858
Epoch 00011: early stopping
LAS = 71.6
UAS = 82.2
	XP Ends: 12/7 (16 h:40)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,16             ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
False          ,relu           ,0.1            ,103            ,True           ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,0.001          ,0.116          ,0.006          ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,45             ,False          ,True           ,49             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
25             ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, True, True, False, 1, 1, 16, False, relu, 0.1, 103, True, 20, 0.001, 0.116, 0.006, val_loss, 4, 45, False, True, 49, 25, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (16h:40)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_10 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_11 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_12 (InputLayer)           (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_10 (Embedding)        (None, 18, 25)       810725      input_10[0][0]                   
__________________________________________________________________________________________________
embedding_11 (Embedding)        (None, 18, 25)       500         input_11[0][0]                   
__________________________________________________________________________________________________
embedding_12 (Embedding)        (None, 12, 8)        408         input_12[0][0]                   
__________________________________________________________________________________________________
flatten_10 (Flatten)            (None, 450)          0           embedding_10[0][0]               
__________________________________________________________________________________________________
flatten_11 (Flatten)            (None, 450)          0           embedding_11[0][0]               
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 96)           0           embedding_12[0][0]               
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 996)          0           flatten_10[0][0]                 
                                                                 flatten_11[0][0]                 
                                                                 flatten_12[0][0]                 
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 74)           73778       concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 74)           0           dense_7[0][0]                    
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 74)           0           activation_8[0][0]               
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 86)           6450        dropout_4[0][0]                  
==================================================================================================
Total params: 891,861
Trainable params: 891,861
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 97s - loss: 0.7612 - acc: 0.8030 - val_loss: 0.4924 - val_acc: 0.8688
Epoch 2/20
 - 97s - loss: 0.6035 - acc: 0.8360 - val_loss: 0.4495 - val_acc: 0.8782
Epoch 3/20
 - 97s - loss: 0.5579 - acc: 0.8466 - val_loss: 0.4397 - val_acc: 0.8794
Epoch 4/20
 - 97s - loss: 0.5280 - acc: 0.8555 - val_loss: 0.4236 - val_acc: 0.8840
Epoch 5/20
 - 97s - loss: 0.5056 - acc: 0.8613 - val_loss: 0.4214 - val_acc: 0.8835
Epoch 6/20
 - 97s - loss: 0.4891 - acc: 0.8654 - val_loss: 0.4157 - val_acc: 0.8866
Epoch 7/20
 - 97s - loss: 0.4741 - acc: 0.8699 - val_loss: 0.4067 - val_acc: 0.8886
Epoch 8/20
 - 97s - loss: 0.4638 - acc: 0.8727 - val_loss: 0.4083 - val_acc: 0.8883
Epoch 9/20
 - 97s - loss: 0.4516 - acc: 0.8754 - val_loss: 0.4120 - val_acc: 0.8878
Epoch 10/20
 - 97s - loss: 0.4425 - acc: 0.8785 - val_loss: 0.4093 - val_acc: 0.8896
Epoch 11/20
 - 97s - loss: 0.4354 - acc: 0.8800 - val_loss: 0.4144 - val_acc: 0.8880
Epoch 00011: early stopping
LAS = 71.3
UAS = 81.6
	XP Ends: 12/7 (17 h:7)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,96             ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
True           ,relu           ,0.3            ,35             ,False          ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,1e-06          ,0.082          ,0.003          ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,22             ,False          ,False          ,58             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
395            ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, False, True, False, 1, 1, 96, True, relu, 0.3, 35, False, 20, 1e-06, 0.082, 0.003, val_loss, 4, 22, False, False, 58, 395, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (17h:7)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_14 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_15 (InputLayer)           (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_13 (Embedding)        (None, 18, 25)       1055500     input_13[0][0]                   
__________________________________________________________________________________________________
embedding_14 (Embedding)        (None, 18, 25)       500         input_14[0][0]                   
__________________________________________________________________________________________________
embedding_15 (Embedding)        (None, 12, 8)        408         input_15[0][0]                   
__________________________________________________________________________________________________
flatten_13 (Flatten)            (None, 450)          0           embedding_13[0][0]               
__________________________________________________________________________________________________
flatten_14 (Flatten)            (None, 450)          0           embedding_14[0][0]               
__________________________________________________________________________________________________
flatten_15 (Flatten)            (None, 96)           0           embedding_15[0][0]               
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 996)          0           flatten_13[0][0]                 
                                                                 flatten_14[0][0]                 
                                                                 flatten_15[0][0]                 
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 74)           73778       concatenate_5[0][0]              
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 74)           0           dense_9[0][0]                    
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 74)           0           activation_10[0][0]              
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 86)           6450        dropout_5[0][0]                  
==================================================================================================
Total params: 1,136,636
Trainable params: 1,136,636
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 99s - loss: 0.7756 - acc: 0.7985 - val_loss: 0.4938 - val_acc: 0.8685
Epoch 2/20
 - 99s - loss: 0.6107 - acc: 0.8335 - val_loss: 0.4569 - val_acc: 0.8738
Epoch 3/20
 - 99s - loss: 0.5591 - acc: 0.8457 - val_loss: 0.4440 - val_acc: 0.8776
Epoch 4/20
 - 99s - loss: 0.5269 - acc: 0.8553 - val_loss: 0.4311 - val_acc: 0.8813
Epoch 5/20
 - 99s - loss: 0.5015 - acc: 0.8618 - val_loss: 0.4338 - val_acc: 0.8809
Epoch 6/20
 - 99s - loss: 0.4818 - acc: 0.8672 - val_loss: 0.4261 - val_acc: 0.8845
Epoch 7/20
 - 99s - loss: 0.4640 - acc: 0.8725 - val_loss: 0.4225 - val_acc: 0.8857
Epoch 8/20
 - 99s - loss: 0.4501 - acc: 0.8766 - val_loss: 0.4258 - val_acc: 0.8846
Epoch 9/20
 - 99s - loss: 0.4368 - acc: 0.8807 - val_loss: 0.4247 - val_acc: 0.8865
Epoch 10/20
 - 99s - loss: 0.4255 - acc: 0.8841 - val_loss: 0.4237 - val_acc: 0.8870
Epoch 11/20
 - 99s - loss: 0.4164 - acc: 0.8868 - val_loss: 0.4360 - val_acc: 0.8857
Epoch 00011: early stopping
LAS = 71.4
UAS = 82.3
	XP Ends: 12/7 (17 h:34)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,32             ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
False          ,relu           ,0.2            ,124            ,True           ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,1e-06          ,0.109          ,0.074          ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,20             ,False          ,False          ,53             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
40             ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, True, True, False, 1, 1, 32, False, relu, 0.2, 124, True, 20, 1e-06, 0.109, 0.074, val_loss, 4, 20, False, False, 53, 40, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (17h:34)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_16 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_17 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_18 (InputLayer)           (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_16 (Embedding)        (None, 18, 25)       810725      input_16[0][0]                   
__________________________________________________________________________________________________
embedding_17 (Embedding)        (None, 18, 25)       500         input_17[0][0]                   
__________________________________________________________________________________________________
embedding_18 (Embedding)        (None, 12, 8)        408         input_18[0][0]                   
__________________________________________________________________________________________________
flatten_16 (Flatten)            (None, 450)          0           embedding_16[0][0]               
__________________________________________________________________________________________________
flatten_17 (Flatten)            (None, 450)          0           embedding_17[0][0]               
__________________________________________________________________________________________________
flatten_18 (Flatten)            (None, 96)           0           embedding_18[0][0]               
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 996)          0           flatten_16[0][0]                 
                                                                 flatten_17[0][0]                 
                                                                 flatten_18[0][0]                 
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 74)           73778       concatenate_6[0][0]              
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 74)           0           dense_11[0][0]                   
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 74)           0           activation_12[0][0]              
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 86)           6450        dropout_6[0][0]                  
==================================================================================================
Total params: 891,861
Trainable params: 891,861
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 97s - loss: 0.7610 - acc: 0.8036 - val_loss: 0.4889 - val_acc: 0.8699
Epoch 2/20
 - 97s - loss: 0.6034 - acc: 0.8364 - val_loss: 0.4492 - val_acc: 0.8780
Epoch 3/20
 - 97s - loss: 0.5581 - acc: 0.8468 - val_loss: 0.4363 - val_acc: 0.8800
Epoch 4/20
 - 97s - loss: 0.5282 - acc: 0.8554 - val_loss: 0.4255 - val_acc: 0.8827
Epoch 5/20
 - 97s - loss: 0.5066 - acc: 0.8609 - val_loss: 0.4206 - val_acc: 0.8844
Epoch 6/20
 - 97s - loss: 0.4902 - acc: 0.8647 - val_loss: 0.4156 - val_acc: 0.8868
Epoch 7/20
 - 97s - loss: 0.4745 - acc: 0.8697 - val_loss: 0.4072 - val_acc: 0.8887
Epoch 8/20
 - 97s - loss: 0.4638 - acc: 0.8725 - val_loss: 0.4079 - val_acc: 0.8872
Epoch 9/20
 - 97s - loss: 0.4518 - acc: 0.8753 - val_loss: 0.4099 - val_acc: 0.8875
Epoch 10/20
 - 97s - loss: 0.4430 - acc: 0.8780 - val_loss: 0.4059 - val_acc: 0.8892
Epoch 11/20
 - 97s - loss: 0.4356 - acc: 0.8801 - val_loss: 0.4144 - val_acc: 0.8877
Epoch 12/20
 - 97s - loss: 0.4286 - acc: 0.8819 - val_loss: 0.4107 - val_acc: 0.8884
Epoch 13/20
 - 97s - loss: 0.4223 - acc: 0.8841 - val_loss: 0.4104 - val_acc: 0.8886
Epoch 14/20
 - 97s - loss: 0.4158 - acc: 0.8858 - val_loss: 0.4053 - val_acc: 0.8886
Epoch 00014: early stopping
LAS = 71.6
UAS = 81.9
	XP Ends: 12/7 (18 h:6)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,False          ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,16             ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
True           ,relu           ,0.2            ,84             ,True           ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,0.0001         ,0.02           ,0.001          ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,8              ,False          ,False          ,30             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
30             ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, False, True, False, 1, 1, 16, True, relu, 0.2, 84, True, 20, 0.0001, 0.02, 0.001, val_loss, 4, 8, False, False, 30, 30, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (18h:6)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_19 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_20 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_21 (InputLayer)           (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_19 (Embedding)        (None, 18, 25)       1055500     input_19[0][0]                   
__________________________________________________________________________________________________
embedding_20 (Embedding)        (None, 18, 25)       500         input_20[0][0]                   
__________________________________________________________________________________________________
embedding_21 (Embedding)        (None, 12, 8)        408         input_21[0][0]                   
__________________________________________________________________________________________________
flatten_19 (Flatten)            (None, 450)          0           embedding_19[0][0]               
__________________________________________________________________________________________________
flatten_20 (Flatten)            (None, 450)          0           embedding_20[0][0]               
__________________________________________________________________________________________________
flatten_21 (Flatten)            (None, 96)           0           embedding_21[0][0]               
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 996)          0           flatten_19[0][0]                 
                                                                 flatten_20[0][0]                 
                                                                 flatten_21[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 74)           73778       concatenate_7[0][0]              
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 74)           0           dense_13[0][0]                   
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 74)           0           activation_14[0][0]              
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 86)           6450        dropout_7[0][0]                  
==================================================================================================
Total params: 1,136,636
Trainable params: 1,136,636
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 99s - loss: 0.7753 - acc: 0.7985 - val_loss: 0.4949 - val_acc: 0.8678
Epoch 2/20
 - 99s - loss: 0.6106 - acc: 0.8333 - val_loss: 0.4573 - val_acc: 0.8737
Epoch 3/20
 - 99s - loss: 0.5581 - acc: 0.8464 - val_loss: 0.4423 - val_acc: 0.8774
Epoch 4/20
 - 99s - loss: 0.5267 - acc: 0.8547 - val_loss: 0.4308 - val_acc: 0.8806
Epoch 5/20
 - 99s - loss: 0.5001 - acc: 0.8620 - val_loss: 0.4357 - val_acc: 0.8802
Epoch 6/20
 - 99s - loss: 0.4802 - acc: 0.8679 - val_loss: 0.4251 - val_acc: 0.8847
Epoch 7/20
 - 99s - loss: 0.4626 - acc: 0.8728 - val_loss: 0.4238 - val_acc: 0.8850
Epoch 8/20
 - 99s - loss: 0.4494 - acc: 0.8769 - val_loss: 0.4259 - val_acc: 0.8847
Epoch 9/20
 - 99s - loss: 0.4367 - acc: 0.8808 - val_loss: 0.4250 - val_acc: 0.8860
Epoch 10/20
 - 99s - loss: 0.4253 - acc: 0.8845 - val_loss: 0.4258 - val_acc: 0.8864
Epoch 11/20
 - 99s - loss: 0.4159 - acc: 0.8870 - val_loss: 0.4357 - val_acc: 0.8854
Epoch 00011: early stopping
LAS = 71.5
UAS = 82.1
	XP Ends: 12/7 (18 h:33)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,256            ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
True           ,relu           ,0.5            ,157            ,True           ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,0.0001         ,0.024          ,0.003          ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,6              ,True           ,False          ,95             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
300            ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, True, True, False, 1, 1, 256, True, relu, 0.5, 157, True, 20, 0.0001, 0.024, 0.003, val_loss, 4, 6, True, False, 95, 300, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (18h:33)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_22 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_23 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_24 (InputLayer)           (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_22 (Embedding)        (None, 18, 25)       810725      input_22[0][0]                   
__________________________________________________________________________________________________
embedding_23 (Embedding)        (None, 18, 25)       500         input_23[0][0]                   
__________________________________________________________________________________________________
embedding_24 (Embedding)        (None, 12, 8)        408         input_24[0][0]                   
__________________________________________________________________________________________________
flatten_22 (Flatten)            (None, 450)          0           embedding_22[0][0]               
__________________________________________________________________________________________________
flatten_23 (Flatten)            (None, 450)          0           embedding_23[0][0]               
__________________________________________________________________________________________________
flatten_24 (Flatten)            (None, 96)           0           embedding_24[0][0]               
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 996)          0           flatten_22[0][0]                 
                                                                 flatten_23[0][0]                 
                                                                 flatten_24[0][0]                 
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 74)           73778       concatenate_8[0][0]              
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 74)           0           dense_15[0][0]                   
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 74)           0           activation_16[0][0]              
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 86)           6450        dropout_8[0][0]                  
==================================================================================================
Total params: 891,861
Trainable params: 891,861
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 98s - loss: 0.7611 - acc: 0.8032 - val_loss: 0.4916 - val_acc: 0.8682
Epoch 2/20
 - 97s - loss: 0.6039 - acc: 0.8356 - val_loss: 0.4508 - val_acc: 0.8763
Epoch 3/20
 - 97s - loss: 0.5575 - acc: 0.8469 - val_loss: 0.4378 - val_acc: 0.8795
Epoch 4/20
 - 97s - loss: 0.5279 - acc: 0.8550 - val_loss: 0.4250 - val_acc: 0.8824
Epoch 5/20
 - 97s - loss: 0.5062 - acc: 0.8608 - val_loss: 0.4210 - val_acc: 0.8823
Epoch 6/20
 - 97s - loss: 0.4903 - acc: 0.8642 - val_loss: 0.4150 - val_acc: 0.8865
Epoch 7/20
 - 97s - loss: 0.4748 - acc: 0.8691 - val_loss: 0.4072 - val_acc: 0.8885
Epoch 8/20
 - 97s - loss: 0.4639 - acc: 0.8720 - val_loss: 0.4085 - val_acc: 0.8876
Epoch 9/20
 - 97s - loss: 0.4517 - acc: 0.8752 - val_loss: 0.4110 - val_acc: 0.8879
Epoch 10/20
 - 97s - loss: 0.4431 - acc: 0.8776 - val_loss: 0.4055 - val_acc: 0.8896
Epoch 11/20
 - 97s - loss: 0.4355 - acc: 0.8798 - val_loss: 0.4142 - val_acc: 0.8876
Epoch 12/20
 - 97s - loss: 0.4281 - acc: 0.8822 - val_loss: 0.4100 - val_acc: 0.8881
Epoch 13/20
 - 97s - loss: 0.4215 - acc: 0.8839 - val_loss: 0.4128 - val_acc: 0.8878
Epoch 14/20
 - 97s - loss: 0.4146 - acc: 0.8863 - val_loss: 0.4052 - val_acc: 0.8892
Epoch 00014: early stopping
LAS = 71.8
UAS = 82.2
	XP Ends: 12/7 (19 h:4)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,48             ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
True           ,relu           ,0.4            ,51             ,True           ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,1e-05          ,0.051          ,0.003          ,val_acc        ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,17             ,False          ,True           ,75             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
38             ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, True, True, False, 1, 1, 48, True, relu, 0.4, 51, True, 20, 1e-05, 0.051, 0.003, val_acc, 4, 17, False, True, 75, 38, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (19h:4)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_25 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_26 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_27 (InputLayer)           (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_25 (Embedding)        (None, 18, 25)       810725      input_25[0][0]                   
__________________________________________________________________________________________________
embedding_26 (Embedding)        (None, 18, 25)       500         input_26[0][0]                   
__________________________________________________________________________________________________
embedding_27 (Embedding)        (None, 12, 8)        408         input_27[0][0]                   
__________________________________________________________________________________________________
flatten_25 (Flatten)            (None, 450)          0           embedding_25[0][0]               
__________________________________________________________________________________________________
flatten_26 (Flatten)            (None, 450)          0           embedding_26[0][0]               
__________________________________________________________________________________________________
flatten_27 (Flatten)            (None, 96)           0           embedding_27[0][0]               
__________________________________________________________________________________________________
concatenate_9 (Concatenate)     (None, 996)          0           flatten_25[0][0]                 
                                                                 flatten_26[0][0]                 
                                                                 flatten_27[0][0]                 
__________________________________________________________________________________________________
dense_17 (Dense)                (None, 74)           73778       concatenate_9[0][0]              
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 74)           0           dense_17[0][0]                   
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 74)           0           activation_18[0][0]              
__________________________________________________________________________________________________
dense_18 (Dense)                (None, 86)           6450        dropout_9[0][0]                  
==================================================================================================
Total params: 891,861
Trainable params: 891,861
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 104s - loss: 0.7609 - acc: 0.8031 - val_loss: 0.4904 - val_acc: 0.8698
Epoch 2/20
 - 97s - loss: 0.6038 - acc: 0.8353 - val_loss: 0.4506 - val_acc: 0.8774
Epoch 3/20
 - 97s - loss: 0.5583 - acc: 0.8461 - val_loss: 0.4374 - val_acc: 0.8795
Epoch 4/20
 - 97s - loss: 0.5295 - acc: 0.8543 - val_loss: 0.4247 - val_acc: 0.8834
Epoch 5/20
 - 97s - loss: 0.5072 - acc: 0.8603 - val_loss: 0.4207 - val_acc: 0.8830
Epoch 6/20
 - 97s - loss: 0.4915 - acc: 0.8641 - val_loss: 0.4143 - val_acc: 0.8873
Epoch 7/20
 - 97s - loss: 0.4759 - acc: 0.8686 - val_loss: 0.4069 - val_acc: 0.8885
Epoch 8/20
 - 97s - loss: 0.4656 - acc: 0.8717 - val_loss: 0.4088 - val_acc: 0.8876
Epoch 9/20
 - 97s - loss: 0.4539 - acc: 0.8751 - val_loss: 0.4098 - val_acc: 0.8877
Epoch 10/20
 - 97s - loss: 0.4449 - acc: 0.8776 - val_loss: 0.4075 - val_acc: 0.8886
Epoch 11/20
 - 97s - loss: 0.4378 - acc: 0.8794 - val_loss: 0.4142 - val_acc: 0.8877
Epoch 00011: early stopping
LAS = 70.9
UAS = 81.3
	XP Ends: 12/7 (19 h:31)
==================================================================================================
ERROR:root:ATTENTION: Oracle problems with 2 sentences!
	Mode: CHENMANNING
==================================================================================================
	Dataset: SHAREDTASK2
==================================================================================================
	Division: TRAINVSDEV
==================================================================================================
	GPU Enabled
==================================================================================================
# CTitles: xp, Dataset, Evaluation, favorisationCoeff, focused, importantSentences, importantTransitions, mweRepeition, overSampling, sampleWeight, average, compactVocab, dynamicVocab, keras, lemma, manual, pretrained, useB-1, useB1, batchSize, cubeActivation, dense1Activation, dense1Dropout, dense1UnitNumber, earlyStopping, epochs, l2, lr, minDelta, monitor, patience, posEmb, pretrained, regularizer, synLabelEmb, tokenEmb, unlabeled, validationSplit
==================================================================================================
xp             ,Dataset        ,Evaluation     ,favorisationCoe,focused        ,
__________________________________________________________________________________________________
chenManning    ,sharedtask2    ,trainVsDev     ,1              ,False          ,
__________________________________________________________________________________________________
importantSenten,importantTransi,mweRepeition   ,overSampling   ,sampleWeight   ,
__________________________________________________________________________________________________
False          ,False          ,35             ,False          ,False          ,
__________________________________________________________________________________________________
average        ,compactVocab   ,dynamicVocab   ,keras          ,lemma          ,
__________________________________________________________________________________________________
True           ,False          ,False          ,False          ,True           ,
__________________________________________________________________________________________________
manual         ,pretrained     ,useB-1         ,useB1          ,batchSize      ,
__________________________________________________________________________________________________
True           ,False          ,1              ,1              ,96             ,
__________________________________________________________________________________________________
cubeActivation ,dense1Activatio,dense1Dropout  ,dense1UnitNumbe,earlyStopping  ,
__________________________________________________________________________________________________
False          ,relu           ,0.1            ,108            ,False          ,
__________________________________________________________________________________________________
epochs         ,l2             ,lr             ,minDelta       ,monitor        ,
__________________________________________________________________________________________________
20             ,0.01           ,0.01           ,0.01           ,val_loss       ,
__________________________________________________________________________________________________
patience       ,posEmb         ,pretrained     ,regularizer    ,synLabelEmb    ,
__________________________________________________________________________________________________
4              ,82             ,False          ,True           ,16             ,
__________________________________________________________________________________________________
tokenEmb       ,unlabeled      ,validationSplit,
__________________________________________________________________________________________________
42             ,False          ,0.2            ,
__________________________________________________________________________________________________
# Configs: chenManning, sharedtask2, trainVsDev, 1, False, False, False, 35, False, False, True, False, False, False, True, True, False, 1, 1, 96, False, relu, 0.1, 108, False, 20, 0.01, 0.01, 0.01, val_loss, 4, 82, False, True, 16, 42, False, 0.2
==================================================================================================
# Seed: 0
==================================================================================================
XP Starts: 12/7 (19h:31)
==================================================================================================

==================================================================================================
	FR Train (17225)
==================================================================================================
	Important sentence: 3889
	Token occurrences: 420762
	MWE number: 1606
	MWE occurrences: 4521
	Continuous occurrences: 59.0 %
	Frequent MWE occurences: 51.0 %
	MWE length: 2.29
	Recognizable MWEs: 100.0 %
	MWT occurrences: 3
	Embedded occurrences: 33

==================================================================================================
	 Test (2236)
==================================================================================================
	Important sentence: 537
	Token occurrences: 54685
	MWE number: 393
	MWE occurrences: 629
	Continuous occurrences: 57.0 %
	MWE length: 2.26
	Seen occurrences : 75% 
	Recognizable MWEs: 99.0 %
	MWT occurrences: 2
	Embedded occurrences: 7
	Interleaving occurrences: 5

==================================================================================================
 Number of training examples : 17225
 Number of projective examples : 15875

__________________________________________________________________________________________________
	Optimizer : Adagrad,  learning rate = 0.061
__________________________________________________________________________________________________
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_28 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_29 (InputLayer)           (None, 18)           0                                            
__________________________________________________________________________________________________
input_30 (InputLayer)           (None, 12)           0                                            
__________________________________________________________________________________________________
embedding_28 (Embedding)        (None, 18, 25)       810725      input_28[0][0]                   
__________________________________________________________________________________________________
embedding_29 (Embedding)        (None, 18, 25)       500         input_29[0][0]                   
__________________________________________________________________________________________________
embedding_30 (Embedding)        (None, 12, 8)        408         input_30[0][0]                   
__________________________________________________________________________________________________
flatten_28 (Flatten)            (None, 450)          0           embedding_28[0][0]               
__________________________________________________________________________________________________
flatten_29 (Flatten)            (None, 450)          0           embedding_29[0][0]               
__________________________________________________________________________________________________
flatten_30 (Flatten)            (None, 96)           0           embedding_30[0][0]               
__________________________________________________________________________________________________
concatenate_10 (Concatenate)    (None, 996)          0           flatten_28[0][0]                 
                                                                 flatten_29[0][0]                 
                                                                 flatten_30[0][0]                 
__________________________________________________________________________________________________
dense_19 (Dense)                (None, 74)           73778       concatenate_10[0][0]             
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 74)           0           dense_19[0][0]                   
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 74)           0           activation_20[0][0]              
__________________________________________________________________________________________________
dense_20 (Dense)                (None, 86)           6450        dropout_10[0][0]                 
==================================================================================================
Total params: 891,861
Trainable params: 891,861
Non-trainable params: 0
__________________________________________________________________________________________________
None
==================================================================================================
Train on 599334 samples, validate on 149834 samples
Epoch 1/20
 - 98s - loss: 0.7607 - acc: 0.8027 - val_loss: 0.4916 - val_acc: 0.8686
Epoch 2/20
 - 97s - loss: 0.6040 - acc: 0.8355 - val_loss: 0.4485 - val_acc: 0.8776
Epoch 3/20
 - 97s - loss: 0.5595 - acc: 0.8459 - val_loss: 0.4370 - val_acc: 0.8796
Epoch 4/20
 - 97s - loss: 0.5301 - acc: 0.8539 - val_loss: 0.4230 - val_acc: 0.8830
Epoch 5/20
 - 97s - loss: 0.5077 - acc: 0.8600 - val_loss: 0.4201 - val_acc: 0.8826
Epoch 6/20
 - 97s - loss: 0.4920 - acc: 0.8638 - val_loss: 0.4135 - val_acc: 0.8864
Epoch 7/20
 - 97s - loss: 0.4769 - acc: 0.8680 - val_loss: 0.4065 - val_acc: 0.8881
Epoch 8/20
 - 97s - loss: 0.4666 - acc: 0.8708 - val_loss: 0.4073 - val_acc: 0.8879
Epoch 9/20
 - 97s - loss: 0.4543 - acc: 0.8742 - val_loss: 0.4076 - val_acc: 0.8877
Epoch 10/20
 - 97s - loss: 0.4452 - acc: 0.8768 - val_loss: 0.4052 - val_acc: 0.8889
Epoch 11/20
 - 97s - loss: 0.4380 - acc: 0.8787 - val_loss: 0.4137 - val_acc: 0.8870
Epoch 12/20
 - 97s - loss: 0.4307 - acc: 0.8810 - val_loss: 0.4094 - val_acc: 0.8881
Epoch 13/20
 - 97s - loss: 0.4246 - acc: 0.8826 - val_loss: 0.4110 - val_acc: 0.8873
Epoch 14/20
 - 97s - loss: 0.4180 - acc: 0.8849 - val_loss: 0.4060 - val_acc: 0.8883
## OAR [2019-07-14 17:15:21] Job 2001351 KILLED ##
